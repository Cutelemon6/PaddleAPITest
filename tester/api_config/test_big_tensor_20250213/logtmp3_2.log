test begin: paddle.nn.functional.relu(Tensor([2, 88, 28, 871544],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 88, 28, 871544],"float32"), None, )

W0208 14:36:46.524930 79175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 14:36:46.525806 79175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 88, 435772, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 88, 435772, 56],"float32"), None, )

W0208 14:40:41.824560 81352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 14:40:41.825538 81352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 88, 56, 435772],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 88, 56, 435772],"float32"), None, )

W0208 14:44:34.337222 83239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 14:44:34.338146 83239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 88, 871544, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 88, 871544, 28],"float32"), None, )

W0208 14:48:41.378562 85167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 14:48:41.379504 85167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 96, 109, 205226],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 96, 109, 205226],"float32"), )

W0208 14:52:42.709077 87220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 14:52:42.710008 87220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 96, 12, 1864136],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 96, 12, 1864136],"float32"), None, )

W0208 14:56:26.352926 89125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 14:56:26.353925 89125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 96, 14, 1597831],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 96, 14, 1597831],"float32"), None, )

W0208 14:59:54.994570 90814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 14:59:54.995460 90814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 96, 1597831, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 96, 1597831, 14],"float32"), None, )

W0208 15:03:35.788241 92496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:03:35.789289 92496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 96, 1864136, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 96, 1864136, 12],"float32"), None, )

W0208 15:07:20.295083 94406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:07:20.296187 94406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 96, 205226, 109],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 96, 205226, 109],"float32"), )

W0208 15:11:12.462327 96168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:11:12.463306 96168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 96, 25, 894785],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 96, 25, 894785],"float32"), None, )

W0208 15:14:56.710436 98132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:14:56.711351 98132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 96, 3195661, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 96, 3195661, 7],"float32"), None, )

W0208 15:18:25.068745 99788 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:18:25.069871 99788 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 96, 7, 3195661],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 96, 7, 3195661],"float32"), None, )

W0208 15:21:53.277927 101438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:21:53.278793 101438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 96, 894785, 25],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 96, 894785, 25],"float32"), None, )

W0208 15:25:38.567512 103367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:25:38.568563 103367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([20, 214748365],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([20, 214748365],"float32"), )

W0208 15:29:19.873013 105509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:29:19.874333 105509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([21400, 1024, 14, 14],"float16"), )
[paddle error] paddle.nn.functional.relu(Tensor([21400, 1024, 14, 14],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_relu(_object*, _object*, _object*)
1   relu_ad_func(paddle::Tensor const&)
2   paddle::experimental::relu(paddle::Tensor const&)
3   void phi::ReluKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   void phi::ActivationGPUImpl<phi::dtype::float16, phi::GPUContext, phi::funcs::CudaReluFunctor<phi::dtype::float16> >(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::funcs::CudaReluFunctor<phi::dtype::float16> const&)
5   phi::dtype::float16* phi::DeviceContext::Alloc<phi::dtype::float16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000183GB memory on GPU 0, 78.440369GB memory has been allocated and available memory is only 762.375000MB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 15:33:22.619185 107379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:33:22.620151 107379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([21400, 16, 112, 112],"float32"), None, )
[torch error] paddle.nn.functional.relu(Tensor([21400, 16, 112, 112],"float32"), None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.49 GiB is free. Process 17561 has 57.70 GiB memory in use. Process 89176 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0208 15:34:47.940364 108362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:34:47.941483 108362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2147483648, 2],"float32"), )
[paddle error] paddle.nn.functional.relu(Tensor([2147483648, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_relu(_object*, _object*, _object*)
1   relu_ad_func(paddle::Tensor const&)
2   paddle::experimental::relu(paddle::Tensor const&)
3   void phi::ReluKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   void phi::ActivationGPUImpl<float, phi::GPUContext, phi::funcs::CudaReluFunctor<float> >(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::funcs::CudaReluFunctor<float> const&)
5   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.606384GB memory has been allocated and available memory is only 13.578491GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 15:36:08.879799 108869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:36:08.880983 108869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([214748365, 20],"float32"), None, )
[torch error] paddle.nn.functional.relu(Tensor([214748365, 20],"float32"), None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 7.34 GiB is free. Process 40372 has 54.85 GiB memory in use. Process 73224 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0208 15:37:33.367489 109578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:37:33.368480 109578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([214749, 32, 25, 25],"float32"), None, )
[torch error] paddle.nn.functional.relu(Tensor([214749, 32, 25, 25],"float32"), None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.40 GiB is free. Process 40372 has 59.79 GiB memory in use. Process 148896 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0208 15:38:49.814177 110274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:38:49.815210 110274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([22185, 64, 55, 55],"float32"), )
[paddle error] paddle.nn.functional.relu(Tensor([22185, 64, 55, 55],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000181GB memory on GPU 0, 79.174744GB memory has been allocated and available memory is only 10.375000MB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 15:40:20.518185 110793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:40:20.519151 110793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([22185, 64, 55, 55],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([22185, 64, 55, 55],"float32"), None, )

W0208 15:41:44.154413 111581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:41:44.155455 111581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([22452, 244, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([22452, 244, 28, 28],"float32"), None, )

W0208 15:45:43.104624 113510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:45:43.105844 113510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([228262, 24, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([228262, 24, 28, 28],"float32"), None, )

W0208 15:50:38.358284 116059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:50:38.359261 116059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([228262, 96, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([228262, 96, 14, 14],"float32"), None, )

W0208 15:54:09.713551 117717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:54:09.714514 117717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([23015, 256, 27, 27],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([23015, 256, 27, 27],"float32"), )

W0208 15:57:43.147445 119395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:57:43.148710 119395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([23015, 64, 54, 54],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([23015, 64, 54, 54],"float32"), )

W0208 16:01:38.622937 121403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:01:38.624027 121403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([233017, 128, 12, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([233017, 128, 12, 12],"float32"), None, )

W0208 16:05:25.618532 123327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:05:25.619500 123327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([23614, 58, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([23614, 58, 56, 56],"float32"), None, )

W0208 16:09:56.047821 125486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:09:56.048820 125486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([24819, 256, 26, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([24819, 256, 26, 26],"float32"), )

W0208 16:14:00.832697 127181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:14:00.833673 127181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2485514, 192, 3, 3],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2485514, 192, 3, 3],"float16"), )

W0208 16:18:27.015697 129496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:18:27.016779 129496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2485514, 192, 3, 3],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2485514, 192, 3, 3],"float16"), None, )

W0208 16:28:34.781657 134311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:28:34.783257 134311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2485514, 192, 3, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2485514, 192, 3, 3],"float32"), )

W0208 16:38:30.894531 139293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:38:30.895592 139293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2485514, 192, 3, 3],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2485514, 192, 3, 3],"float32"), None, )

W0208 16:42:31.773885 141222 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:42:31.774856 141222 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([249013, 352, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([249013, 352, 7, 7],"float32"), None, )

W0208 16:46:18.139407 143139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:46:18.140259 143139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([25415, 1000, 13, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([25415, 1000, 13, 13],"float32"), )

W0208 16:50:11.348173 144823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:50:11.348996 144823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([25565282, 168, 1, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([25565282, 168, 1, 1],"float32"), None, )

W0208 16:53:50.708139 146676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:53:50.709470 146676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2675, 128, 112, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2675, 128, 112, 112],"float32"), None, )

W0208 16:57:24.379817 148332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:57:24.380877 148332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2675, 512, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2675, 512, 56, 56],"float32"), None, )

W0208 17:00:59.499572 149986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:00:59.500653 149986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([268435457, 8],"float64"), )
[Pass] paddle.nn.functional.relu(Tensor([268435457, 8],"float64"), )

W0208 17:04:20.029080 151667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:04:20.029963 151667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2684355, 16, 10, 10],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2684355, 16, 10, 10],"float16"), None, )

W0208 17:07:53.568586 153072 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:07:53.569485 153072 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([272, 1, 28, 563941],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([272, 1, 28, 563941],"float32"), )

W0208 17:16:46.629755 157518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:16:46.630607 157518 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([272, 1, 563941, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([272, 1, 563941, 28],"float32"), )

W0208 17:20:22.229341 159152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:20:22.230317 159152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([272, 15790321],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([272, 15790321],"float32"), )

W0208 17:24:04.609695 160800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:24:04.610687 160800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([272, 20141, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([272, 20141, 28, 28],"float32"), )

W0208 17:27:52.137291 162702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:27:52.138193 162702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([272, 6, 14, 187981],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([272, 6, 14, 187981],"float32"), )

W0208 17:31:53.572669  1097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:31:53.573979  1097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([272, 6, 187981, 14],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([272, 6, 187981, 14],"float32"), )

W0208 17:35:37.743360  2767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:35:37.744237  2767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([272, 80563, 14, 14],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([272, 80563, 14, 14],"float32"), )

W0208 17:39:37.088552  4648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:39:37.089619  4648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([286331153, 3, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([286331153, 3, 5],"float32"), None, )

W0208 17:43:16.375387  6521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:43:16.376307  6521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([28633116, 6, 5, 5],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([28633116, 6, 5, 5],"float32"), )

W0208 17:46:59.429235  8222 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:46:59.430699  8222 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([29827, 1000, 12, 12],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([29827, 1000, 12, 12],"float32"), )

W0208 17:50:47.269742 10096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:50:47.270823 10096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 1024, 16, 87382],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 1024, 16, 87382],"float32"), None, )

W0208 17:54:45.538940 11990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:54:45.539824 11990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 1024, 87382, 16],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 1024, 87382, 16],"float32"), None, )

W0208 17:58:21.331861 13700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:58:21.332770 13700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 128, 174763, 64],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 128, 174763, 64],"float32"), None, )

W0208 18:01:59.176913 15379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:01:59.177793 15379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 128, 32, 349526],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 128, 32, 349526],"float32"), None, )

W0208 18:05:36.881723 16976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:05:36.882881 16976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 128, 349526, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 128, 349526, 32],"float32"), None, )

W0208 18:09:26.779711 18877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:09:26.780557 18877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 128, 64, 174763],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 128, 64, 174763],"float32"), None, )

W0208 18:13:06.057503 20604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:13:06.058357 20604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 1398102, 32, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 1398102, 32, 32],"float32"), None, )

W0208 18:16:51.592813 22481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:16:51.593722 22481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 1431655765],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([3, 1431655765],"float32"), )

W0208 18:20:34.680364 24143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:20:34.681172 24143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 1431655765],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 1431655765],"float32"), None, )

W0208 18:24:31.009662 26055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:24:31.010480 26055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 2048, 8, 87382],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 2048, 8, 87382],"float32"), None, )

W0208 18:28:11.472980 27759 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:28:11.473951 27759 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 2048, 87382, 8],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 2048, 87382, 8],"float32"), None, )

W0208 18:31:47.244952 29647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:31:47.245880 29647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 22369622, 8, 8],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 22369622, 8, 8],"float32"), None, )

W0208 18:35:21.838755 31327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:35:21.839596 31327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 256, 16, 349526],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 256, 16, 349526],"float32"), None, )

W0208 18:38:53.396474 32996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:38:53.397637 32996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 256, 174763, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 256, 174763, 32],"float32"), None, )

W0208 18:42:36.323681 34671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:42:36.324556 34671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 256, 32, 174763],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 256, 32, 174763],"float32"), None, )

W0208 18:46:10.014598 36325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:46:10.015654 36325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 256, 349526, 16],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 256, 349526, 16],"float32"), None, )

W0208 18:49:38.641724 37957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:49:38.642601 37957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 256, 64, 87382],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 256, 64, 87382],"float32"), None, )

W0208 18:53:09.003715 39597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:53:09.004554 39597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 256, 87382, 64],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 256, 87382, 64],"float32"), None, )

W0208 18:56:43.928218 41291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:56:43.929095 41291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 349526, 64, 64],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 349526, 64, 64],"float32"), None, )

W0208 19:00:33.027904 43160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:00:33.028795 43160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 512, 16, 174763],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 512, 16, 174763],"float32"), None, )

W0208 19:04:20.604406 44863 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:04:20.605437 44863 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 512, 174763, 16],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 512, 174763, 16],"float32"), None, )

W0208 19:08:14.794214 46756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:08:14.795068 46756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 512, 32, 87382],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 512, 32, 87382],"float32"), None, )

W0208 19:12:02.103471 48672 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:12:02.104385 48672 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 512, 349526, 8],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 512, 349526, 8],"float32"), None, )

W0208 19:15:42.264047 50350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:15:42.264909 50350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 512, 8, 349526],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 512, 8, 349526],"float32"), None, )

W0208 19:19:27.727329 52200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:19:27.728263 52200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 512, 87382, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 512, 87382, 32],"float32"), None, )

W0208 19:23:12.773048 53900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:23:12.774008 53900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 5592406, 16, 16],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 5592406, 16, 16],"float32"), None, )

W0208 19:27:05.894457 55775 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:27:05.895282 55775 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 64, 128, 174763],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 64, 128, 174763],"float32"), None, )

W0208 19:30:45.776630 57637 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:30:45.777730 57637 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 64, 174763, 128],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 64, 174763, 128],"float32"), None, )

W0208 19:34:41.151435 59347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:34:41.152485 59347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 64, 349526, 64],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 64, 349526, 64],"float32"), None, )

W0208 19:38:21.834395 61229 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:38:21.835399 61229 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 64, 64, 349526],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 64, 64, 349526],"float32"), None, )

W0208 19:42:02.345763 62898 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:42:02.346675 62898 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3, 87382, 128, 128],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([3, 87382, 128, 128],"float32"), None, )

W0208 19:45:35.346763 64569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:45:35.347688 64569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([30, 10, 14316558],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([30, 10, 14316558],"float32"), None, )

W0208 19:49:16.767974 66208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:49:16.768877 66208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([30, 143165577],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([30, 143165577],"float32"), )

W0208 19:53:07.880964 68085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:53:07.881824 68085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([30, 2236963, 64],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([30, 2236963, 64],"float32"), None, )

W0208 19:57:06.116194 69961 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:57:06.117098 69961 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([30546, 832, 13, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([30546, 832, 13, 13],"float32"), )

W0208 20:00:33.804261 71614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:00:33.805130 71614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([30686, 192, 27, 27],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([30686, 192, 27, 27],"float32"), None, )

W0208 20:04:22.130606 73658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:04:22.131419 73658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([31, 1065749, 130],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([31, 1065749, 130],"float32"), )

W0208 20:08:31.340792 75746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:08:31.341691 75746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([31, 98, 1413749],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([31, 98, 1413749],"float32"), )

W0208 20:12:05.883327 77412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:12:05.884323 77412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([310690, 96, 12, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([310690, 96, 12, 12],"float32"), None, )

W0208 20:15:40.773165 79262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:15:40.774061 79262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([31127, 176, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([31127, 176, 28, 28],"float32"), None, )

W0208 20:19:27.663318 80943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:19:27.664402 80943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 131072, 32, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 131072, 32, 32],"float32"), None, )

W0208 20:23:01.190657 82611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:23:01.191560 82611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 134217728],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([32, 134217728],"float32"), )

W0208 20:26:38.499569 84273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:26:38.500576 84273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 1342178, 10, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 1342178, 10, 10],"float32"), None, )

W0208 20:30:11.051102 86134 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:30:11.052157 86134 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 16, 10, 838861],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 16, 10, 838861],"float32"), None, )

W0208 20:33:48.350757 87609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:33:48.351730 87609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 16, 12, 699051],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 16, 12, 699051],"float32"), None, )

W0208 20:37:24.396413 89485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:37:24.397287 89485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 16, 699051, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 16, 699051, 12],"float32"), None, )

W0208 20:40:59.926857 91114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:40:59.927960 91114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 16, 838861, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 16, 838861, 10],"float32"), None, )

W0208 20:44:36.609128 92784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:44:36.610086 92784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 171197, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 171197, 28, 28],"float32"), None, )

W0208 20:48:09.757664 94431 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:48:09.758495 94431 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 4, 33554432],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([32, 4, 33554432],"float32"), )

W0208 20:51:39.111995 96061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:51:39.112890 96061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 6, 28, 798916],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 6, 28, 798916],"float32"), None, )

W0208 20:55:10.700557 97882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:55:10.701532 97882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 6, 32, 699051],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 6, 32, 699051],"float32"), None, )

W0208 20:58:46.196506 99526 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:58:46.197530 99526 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 6, 699051, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 6, 699051, 32],"float32"), None, )

W0208 21:02:16.435249 101197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:02:16.436326 101197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 6, 798916, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 6, 798916, 28],"float32"), None, )

W0208 21:05:54.984537 102876 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:05:54.985500 102876 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 65536, 2048],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([32, 65536, 2048],"float32"), )

W0208 21:09:37.535941 104570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:09:37.536859 104570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32, 932068, 12, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32, 932068, 12, 12],"float32"), None, )

W0208 21:13:10.411968 106239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:13:10.412873 106239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32768, 128, 32, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32768, 128, 32, 32],"float32"), None, )

W0208 21:17:03.282619 108066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:17:03.283700 108066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32768, 2048, 8, 8],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32768, 2048, 8, 8],"float32"), None, )

W0208 21:20:39.689997 109722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:20:39.691105 109722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([32768, 512, 16, 16],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([32768, 512, 16, 16],"float32"), None, )

W0208 21:24:28.187090 111579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:24:28.188413 111579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([33092, 192, 26, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([33092, 192, 26, 26],"float32"), )

W0208 21:28:10.042953 113273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:28:10.043810 113273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([337125, 98, 130],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([337125, 98, 130],"float32"), )

W0208 21:31:58.256244 115135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:31:58.257122 115135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([342393, 16, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([342393, 16, 28, 28],"float32"), None, )

W0208 21:35:35.702579 116796 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:35:35.703576 116796 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([342393, 64, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([342393, 64, 14, 14],"float32"), None, )

W0208 21:39:39.218806 118569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:39:39.219635 118569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3480525, 1234],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([3480525, 1234],"float32"), )

W0208 21:43:20.317724 120120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:43:20.318943 120120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([357913942, 3, 4],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([357913942, 3, 4],"float32"), )

W0208 21:47:05.605926 121453 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:47:05.606938 121453 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([35791395, 120, 1, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([35791395, 120, 1, 1],"float32"), None, )

W0208 21:50:47.185496 122791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:50:47.186447 122791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([35791395, 120],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([35791395, 120],"float32"), )

W0208 21:54:32.199093 124332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:54:32.199971 124332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([36, 1193047, 10, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([36, 1193047, 10, 10],"float32"), None, )

W0208 21:58:06.269935 125658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:58:06.270814 125658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([36, 152175, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([36, 152175, 28, 28],"float32"), None, )

W0208 22:01:44.869065 127155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:01:44.869918 127155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([36, 16, 10, 745655],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([36, 16, 10, 745655],"float32"), None, )

W0208 22:05:15.304833 128494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:05:15.305752 128494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([36, 16, 745655, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([36, 16, 745655, 10],"float32"), None, )

W0208 22:09:21.098795 129993 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:09:21.099681 129993 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([36, 6, 28, 710147],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([36, 6, 28, 710147],"float32"), None, )

W0208 22:12:53.060801 131331 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:12:53.061709 131331 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([36, 6, 710147, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([36, 6, 710147, 28],"float32"), None, )

W0208 22:16:32.671659 133016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:16:32.672565 133016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3652184, 6, 14, 14],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([3652184, 6, 14, 14],"float32"), )

W0208 22:20:14.375674 134384 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:20:14.376952 134384 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([3766, 96, 109, 109],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([3766, 96, 109, 109],"float32"), )

W0208 22:23:56.724308 135891 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:23:56.725224 135891 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([377813, 232, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([377813, 232, 7, 7],"float32"), None, )

W0208 22:27:43.493093 137195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:27:43.494036 137195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([383480, 448, 5, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([383480, 448, 5, 5],"float32"), None, )

W0208 22:31:18.064333 138746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:31:18.065287 138746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([397094, 64, 13, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([397094, 64, 13, 13],"float32"), )

W0208 22:34:49.962067 140087 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:34:49.962958 140087 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 10, 10, 10737419],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 10, 10, 10737419],"float16"), )

W0208 22:38:36.697041 141391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:38:36.697976 141391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 10, 10737419, 10],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 10, 10737419, 10],"float16"), )

W0208 22:47:55.800384 144760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:47:55.801338 144760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 1073741824, 1, 1],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 1073741824, 1, 1],"float16"), None, )

W0208 22:57:06.966251 148343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:57:06.967123 148343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 1073741824, 1, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 1073741824, 1, 1],"float32"), None, )

W0208 23:05:55.542402 151764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:05:55.543465 151764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 1073741824],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 1073741824],"float16"), )

W0208 23:10:00.596210 153286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:10:00.597095 153286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 1073741824],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 1073741824],"float32"), )

W0208 23:18:52.329902 156734 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:18:52.330849 156734 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 1073741824],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 1073741824],"float32"), None, )

W0208 23:22:24.616884 158091 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:22:24.617822 158091 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 10737419, 10, 10],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 10737419, 10, 10],"float16"), )

W0208 23:26:17.519702 159437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:26:17.520720 159437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 119304648, 3, 3],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 119304648, 3, 3],"float16"), None, )

W0208 23:35:40.582479 163059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:35:40.583572 163059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 119304648, 3, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 119304648, 3, 3],"float32"), )

W0208 23:44:54.929031  3162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:44:54.929942  3162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 119304648, 3, 3],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 119304648, 3, 3],"float32"), None, )

W0208 23:48:44.905638  4520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:48:44.906705  4520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 192, 1864136, 3],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 192, 1864136, 3],"float16"), None, )

W0208 23:52:35.244760  6038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:52:35.245658  6038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 192, 1864136, 3],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 192, 1864136, 3],"float32"), None, )

W0209 00:01:31.245187  9473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:01:31.246121  9473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 192, 3, 1864136],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 192, 3, 1864136],"float16"), None, )

W0209 00:05:24.186108 10819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:05:24.187558 10819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 192, 3, 1864136],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 192, 3, 1864136],"float32"), None, )

W0209 00:14:23.714759 14463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:14:23.716405 14463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 2, 536870912],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 2, 536870912],"float32"), )

W0209 00:18:10.202893 15468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:18:10.203752 15468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 2097152, 16, 32],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 2097152, 16, 32],"float32"), )

W0209 00:21:47.376608 15510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:21:47.377614 15510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 214748365, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 214748365, 5],"float32"), None, )

W0209 00:25:34.435379 15566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:25:34.436342 15566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 21913099, 7, 7],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 21913099, 7, 7],"float16"), None, )

W0209 00:29:30.927592 15623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:29:30.928880 15623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 21913099, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 21913099, 7, 7],"float32"), None, )

W0209 00:38:31.321278 15763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:38:31.322190 15763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 256, 1, 4194304],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 256, 1, 4194304],"float16"), None, )

W0209 00:42:18.209916 15860 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:42:18.210879 15860 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 256, 1, 4194304],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 256, 1, 4194304],"float32"), None, )

W0209 00:51:06.528936 16042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:51:06.529824 16042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 256, 4194304, 1],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 256, 4194304, 1],"float16"), None, )

W0209 00:54:50.829526 16099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:54:50.830461 16099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 256, 4194304, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 256, 4194304, 1],"float32"), None, )

W0209 01:03:32.472642 16197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:03:32.473546 16197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 3, 357913942],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 3, 357913942],"float32"), None, )

W0209 01:07:03.275723 16253 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:07:03.276551 16253 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 33554432, 32],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 33554432, 32],"float32"), )

W0209 01:10:40.431660 16294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:10:40.432940 16294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 357913942, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 357913942, 3],"float32"), )

W0209 01:14:13.834625 16350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:14:13.835482 16350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 384, 1, 2796203],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 384, 1, 2796203],"float16"), None, )

W0209 01:18:11.228845 16420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:18:11.229761 16420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 384, 1, 2796203],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 384, 1, 2796203],"float32"), None, )

W0209 01:27:11.891654 16615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:27:11.892980 16615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 384, 2796203, 1],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 384, 2796203, 1],"float16"), None, )

W0209 01:30:59.290781 16700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:30:59.291689 16700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 384, 2796203, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 384, 2796203, 1],"float32"), None, )

W0209 01:39:37.204921 16910 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:39:37.205991 16910 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 536870913],"float64"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 536870913],"float64"), )

W0209 01:42:59.918751 16966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:42:59.919648 16966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 6, 3, 59652324],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 6, 3, 59652324],"float32"), )

W0209 01:46:21.462895 17037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:46:21.463874 17037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 6, 59652324, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 6, 59652324, 3],"float32"), )

W0209 01:50:04.650683 17120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:50:04.651767 17120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 64, 2396746, 7],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 64, 2396746, 7],"float16"), None, )

W0209 01:53:57.991367 17218 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:53:57.992673 17218 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 64, 2396746, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 64, 2396746, 7],"float32"), None, )

W0209 02:03:09.929836 17371 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:03:09.930670 17371 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 64, 7, 2396746],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 64, 7, 2396746],"float16"), None, )

W0209 02:06:59.860558 17457 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:06:59.861419 17457 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 64, 7, 2396746],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4, 64, 7, 2396746],"float32"), None, )

W0209 02:15:58.357640 17625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:15:58.359023 17625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 8, 134217728],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 8, 134217728],"float32"), )

W0209 02:19:53.498840 17694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:19:53.500036 17694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 8, 16, 8388608],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 8, 16, 8388608],"float32"), )

W0209 02:23:39.690214 17791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:23:39.691355 17791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4, 8, 4194304, 32],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4, 8, 4194304, 32],"float32"), )

W0209 02:27:09.855502 17848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:27:09.856374 17848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([400, 10737419],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([400, 10737419],"float32"), )

W0209 02:31:02.250001 17932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:31:02.251734 17932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4096, 256, 64, 64],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4096, 256, 64, 64],"float32"), None, )

W0209 02:34:46.584067 17988 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:34:46.585644 17988 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4096, 64, 128, 128],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([4096, 64, 128, 128],"float32"), None, )

W0209 02:38:23.077466 18058 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:38:23.078640 18058 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4194304, 1024],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([4194304, 1024],"float32"), )

W0209 02:42:10.737241 18128 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:42:10.738152 18128 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([42800, 2048, 7, 7],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([42800, 2048, 7, 7],"float16"), )

W0209 02:46:01.877527 18198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:46:01.878463 18198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([4294968, 10, 10, 10],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([4294968, 10, 10, 10],"float16"), )

W0209 02:55:03.063262 18394 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:55:03.064483 18394 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([447393, 384, 5, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([447393, 384, 5, 5],"float32"), None, )

W0209 03:03:55.314465 18506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:03:55.315379 18506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([44904, 488, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([44904, 488, 14, 14],"float32"), None, )

W0209 03:07:36.491767 18563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:07:36.492789 18563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([456523, 12, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([456523, 12, 28, 28],"float32"), None, )

W0209 03:11:20.586934 18618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:11:20.587805 18618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([456523, 48, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([456523, 48, 14, 14],"float32"), None, )

W0209 03:14:55.942128 18688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:14:55.942979 18688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([45653, 120, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([45653, 120, 28, 28],"float32"), None, )

W0209 03:18:36.389354 18744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:18:36.390236 18744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([46029, 128, 27, 27],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([46029, 128, 27, 27],"float32"), )

W0209 03:22:21.721122 18800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:22:21.722292 18800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([46029, 32, 54, 54],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([46029, 32, 54, 54],"float32"), )

W0209 03:26:06.789908 18856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:26:06.790776 18856 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([466034, 64, 12, 12],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([466034, 64, 12, 12],"float32"), )

W0209 03:29:37.477492 18912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:29:37.478470 18912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([47227, 116, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([47227, 116, 28, 28],"float32"), None, )

W0209 03:33:11.513465 18955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:33:11.514326 18955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([477218589, 1, 3, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([477218589, 1, 3, 3],"float32"), )

W0209 03:36:51.934095 19023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:36:51.934971 19023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([48133, 528, 13, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([48133, 528, 13, 13],"float32"), )

W0209 03:40:22.772290 19079 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:40:22.773466 19079 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([48914, 112, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([48914, 112, 28, 28],"float32"), None, )

W0209 03:44:03.868391 19151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:44:03.869414 19151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([49637, 128, 26, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([49637, 128, 26, 26],"float32"), )

W0209 03:47:41.804054 19220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:47:41.804942 19220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([49637, 512, 13, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([49637, 512, 13, 13],"float32"), )

W0209 03:51:09.481083 19290 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:51:09.482205 19290 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([5, 858993459],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([5, 858993459],"float32"), )

W0209 03:55:00.633277 19374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:55:00.634140 19374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([512, 1, 28, 299594],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([512, 1, 28, 299594],"float32"), )

W0209 03:58:35.119714 19458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:58:35.120637 19458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([512, 1, 299594, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([512, 1, 299594, 28],"float32"), )

W0209 04:02:31.155999 19528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:02:31.156872 19528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([512, 10700, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([512, 10700, 28, 28],"float32"), )

W0209 04:06:17.504863 19598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:06:17.505796 19598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([512, 10700, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([512, 10700, 28, 28],"float32"), None, )

W0209 04:09:52.022650 19641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:09:52.023645 19641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([512, 42800, 14, 14],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([512, 42800, 14, 14],"float32"), )

W0209 04:13:33.562906 19696 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:13:33.563807 19696 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([512, 6, 14, 99865],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([512, 6, 14, 99865],"float32"), )

W0209 04:17:16.351434 19766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:17:16.352380 19766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([512, 6, 28, 49933],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([512, 6, 28, 49933],"float32"), None, )

W0209 04:20:56.844851 19850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:20:56.845827 19850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([512, 6, 49933, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([512, 6, 49933, 28],"float32"), None, )

W0209 04:24:28.982405 19907 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:24:28.983280 19907 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([512, 6, 99865, 14],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([512, 6, 99865, 14],"float32"), )

W0209 04:28:07.526463 19962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:28:07.527333 19962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([512, 8388608],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([512, 8388608],"float32"), )

W0209 04:31:47.632123 20031 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:31:47.633615 20031 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([524288, 4, 2048],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([524288, 4, 2048],"float32"), )

W0209 04:35:37.261382 20088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:35:37.262262 20088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([529459, 48, 13, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([529459, 48, 13, 13],"float32"), )

W0209 04:39:27.075793 20157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:39:27.076740 20157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([5350, 1024, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([5350, 1024, 28, 28],"float32"), None, )

W0209 04:43:08.016672 20242 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:43:08.017606 20242 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([5350, 256, 56, 56],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([5350, 256, 56, 56],"float16"), )

W0209 04:46:57.146361 20295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:46:57.147336 20295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([5350, 64, 112, 112],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([5350, 64, 112, 112],"float32"), )

W0209 04:55:49.580734 20509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:55:49.581697 20509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([536870912, 8],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([536870912, 8],"float16"), )

W0209 04:59:37.976773 20579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:59:37.977639 20579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([536870912, 8],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([536870912, 8],"float32"), )

W0209 05:08:18.151695 20774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:08:18.152660 20774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([536871, 320, 5, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([536871, 320, 5, 5],"float32"), None, )

W0209 05:12:01.698658 20844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:12:01.699470 20844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([5478275, 1, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([5478275, 1, 28, 28],"float32"), )

W0209 05:15:51.294873 20902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:15:51.295804 20902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([5478275, 784],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([5478275, 784],"float32"), )

W0209 05:19:29.363951 20985 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:19:29.364952 20985 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([5592406, 768],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([5592406, 768],"float32"), )

W0209 05:23:17.427161 21026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:23:17.428025 21026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([5649, 64, 109, 109],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([5649, 64, 109, 109],"float32"), None, )

W0209 05:27:02.457288 21069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:27:02.458838 21069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([57066, 24, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([57066, 24, 56, 56],"float32"), None, )

W0209 05:30:40.857568 21111 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:30:40.858690 21111 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([6, 1, 238609295, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([6, 1, 238609295, 3],"float32"), )

W0209 05:34:27.401234 21154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:34:27.402715 21154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([6, 1, 3, 238609295],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([6, 1, 3, 238609295],"float32"), )

W0209 05:37:57.791878 21223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:37:57.792692 21223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([6, 79536432, 3, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([6, 79536432, 3, 3],"float32"), )

W0209 05:41:30.855414 21279 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:41:30.856370 21279 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([600, 7158279],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([600, 7158279],"float32"), )

W0209 05:45:08.340417 21350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:45:08.341361 21350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([62254, 352, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([62254, 352, 14, 14],"float32"), None, )

W0209 05:48:36.436265 21405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:48:36.437266 21405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([62254, 88, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([62254, 88, 28, 28],"float32"), None, )

W0209 05:52:10.867321 21488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:52:10.868252 21488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 1, 2396746, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([64, 1, 2396746, 28],"float32"), )

W0209 05:55:43.325870 21532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:55:43.327054 21532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 1, 28, 2396746],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([64, 1, 28, 2396746],"float32"), )

W0209 05:59:37.133301 21588 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:59:37.134703 21588 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 128, 18725, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 128, 18725, 28],"float32"), None, )

W0209 06:03:18.045637 21658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:03:18.046553 21658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 128, 28, 18725],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 128, 28, 18725],"float32"), None, )

W0209 06:06:58.886667 21714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:06:58.887578 21714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 1369569, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 1369569, 7, 7],"float32"), None, )

W0209 06:10:35.100888 21810 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:10:35.101794 21810 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 16, 10, 419431],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 16, 10, 419431],"float16"), None, )

W0209 06:14:24.240991 21879 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:14:24.241889 21879 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 16, 10, 419431],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 16, 10, 419431],"float32"), None, )

W0209 06:23:26.189072 22006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:23:26.190053 22006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 16, 419431, 10],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 16, 419431, 10],"float16"), None, )

W0209 06:27:27.225528 22075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:27:27.226419 22075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 16, 419431, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 16, 419431, 10],"float32"), None, )

W0209 06:36:18.422099 22202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:36:18.423050 22202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 21400, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 21400, 56, 56],"float32"), None, )

W0209 06:39:50.914256 22244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:39:50.915246 22244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 256, 14, 18725],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 256, 14, 18725],"float32"), None, )

W0209 06:43:31.091598 22285 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:43:31.092674 22285 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 256, 18725, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 256, 18725, 14],"float32"), None, )

W0209 06:47:09.827482 22341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:47:09.828471 22341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 342393, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 342393, 14, 14],"float32"), None, )

W0209 06:50:49.588315 22384 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:50:49.589215 22384 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 512, 18725, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 512, 18725, 7],"float32"), None, )

W0209 06:54:21.816856 22439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:54:21.817734 22439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 512, 7, 18725],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 512, 7, 18725],"float32"), None, )

W0209 06:57:53.208279 22495 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:57:53.209203 22495 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 5350, 112, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 5350, 112, 112],"float32"), None, )

W0209 07:01:22.662062 22551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:01:22.663079 22551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 6, 28, 399458],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 6, 28, 399458],"float16"), None, )

W0209 07:05:03.500603 22594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:05:03.501456 22594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 6, 28, 399458],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 6, 28, 399458],"float32"), None, )

W0209 07:13:46.787972 22733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:13:46.788882 22733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 6, 399458, 28],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 6, 399458, 28],"float16"), None, )

W0209 07:17:35.965298 22789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:17:35.966434 22789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 6, 399458, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 6, 399458, 28],"float32"), None, )

W0209 07:26:33.700924 22916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:26:33.701886 22916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 64, 112, 9363],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 64, 112, 9363],"float32"), None, )

W0209 07:30:04.588908 22971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:30:04.589736 22971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 64, 18725, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 64, 18725, 56],"float32"), None, )

W0209 07:33:42.507006 23027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:33:42.508096 23027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 64, 56, 18725],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 64, 56, 18725],"float32"), None, )

W0209 07:37:24.454437 23098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:37:24.455314 23098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 64, 9363, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 64, 9363, 112],"float32"), None, )

W0209 07:41:02.768178 23154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:41:02.769012 23154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 671089, 10, 10],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 671089, 10, 10],"float16"), None, )

W0209 07:45:01.712348 23196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:45:01.713255 23196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 671089, 10, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 671089, 10, 10],"float32"), None, )

W0209 07:53:50.002970 23348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:53:50.003849 23348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 85599, 28, 28],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 85599, 28, 28],"float16"), None, )

W0209 07:57:34.585973 23418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:57:34.586886 23418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 85599, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([64, 85599, 28, 28],"float32"), )

W0209 08:06:28.506161 23572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:06:28.507148 23572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([64, 85599, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([64, 85599, 28, 28],"float32"), None, )

W0209 08:10:29.230515 23643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:10:29.231657 23643 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([65536, 256, 16, 16],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([65536, 256, 16, 16],"float32"), None, )

W0209 08:14:22.360649 23713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:14:22.361531 23713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([66183, 384, 13, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([66183, 384, 13, 13],"float32"), )

W0209 08:18:02.152196 23770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:18:02.153121 23770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([6710887, 10, 64],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([6710887, 10, 64],"float32"), None, )

W0209 08:21:32.786477 23867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:21:32.787406 23867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([684785, 32, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([684785, 32, 14, 14],"float32"), None, )

W0209 08:25:20.304292 23923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:25:20.305385 23923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([6991, 300, 2048],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([6991, 300, 2048],"float32"), )

W0209 08:29:08.697628 23994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:29:08.698433 23994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([715827883, 2, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([715827883, 2, 3],"float32"), )

W0209 08:32:39.995422 24077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:32:39.996282 24077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([715827883, 3, 2],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([715827883, 3, 2],"float32"), )

W0209 08:36:13.684259 24147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:36:13.685110 24147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([715827883, 3],"float64"), )
[Pass] paddle.nn.functional.relu(Tensor([715827883, 3],"float64"), )

W0209 08:39:25.047371 24204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:39:25.048225 24204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([7158279, 600],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([7158279, 600],"float32"), )

W0209 08:42:36.555876 24251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:42:36.556819 24251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([71583, 96, 25, 25],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([71583, 96, 25, 25],"float32"), None, )

W0209 08:46:17.344875 24315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:46:17.346117 24315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([76088, 72, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([76088, 72, 28, 28],"float32"), None, )

W0209 08:50:07.893899 24371 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:50:07.894810 24371 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([77673, 384, 12, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([77673, 384, 12, 12],"float32"), None, )

W0209 08:53:44.518610 24427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:53:44.519505 24427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([79536432, 6, 3, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([79536432, 6, 3, 3],"float32"), )

W0209 08:57:38.474663 24470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:57:38.475749 24470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 1024, 14, 37450],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 1024, 14, 37450],"float32"), )

W0209 09:01:43.167918 24553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:01:43.169085 24553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 1024, 37450, 14],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 1024, 37450, 14],"float32"), )

W0209 09:05:22.476900 24623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:05:22.477761 24623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 10956550, 7, 7],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 10956550, 7, 7],"float32"), )

W0209 09:08:46.356666 24652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:08:46.357599 24652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 16, 10, 3355444],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8, 16, 10, 3355444],"float32"), None, )

W0209 09:12:23.487776 24679 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:12:23.488575 24679 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 16, 33554432],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8, 16, 33554432],"float32"), None, )

W0209 09:16:01.171985 24735 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:16:01.173071 24735 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 16, 3355444, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8, 16, 3355444, 10],"float32"), None, )

W0209 09:19:32.148010 24833 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:19:32.148861 24833 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 16777216, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8, 16777216, 32],"float32"), None, )

W0209 09:23:03.774266 24931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:23:03.775272 24931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 171197, 56, 56],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 171197, 56, 56],"float32"), )

W0209 09:26:32.954981 25015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:26:32.956142 25015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 2048, 37450, 7],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 2048, 37450, 7],"float32"), )

W0209 09:30:06.703234 25099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:30:06.704149 25099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 2048, 7, 37450],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 2048, 7, 37450],"float32"), )

W0209 09:33:34.068282 25197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:33:34.069154 25197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 256, 37450, 56],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 256, 37450, 56],"float32"), )

W0209 09:37:10.238997 25294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:37:10.240305 25294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 256, 56, 37450],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 256, 56, 37450],"float32"), )

W0209 09:40:55.110556 25393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:40:55.111636 25393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 2739138, 14, 14],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 2739138, 14, 14],"float32"), )

W0209 09:44:35.013557 25436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:44:35.014511 25436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 512, 28, 37450],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 512, 28, 37450],"float32"), )

W0209 09:48:23.073593 25518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:48:23.074426 25518 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 512, 37450, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 512, 37450, 28],"float32"), )

W0209 09:52:15.703004 25561 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:52:15.703878 25561 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 536870912],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 536870912],"float32"), )

W0209 09:55:53.992880 25590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:55:53.993772 25590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 5368710, 10, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8, 5368710, 10, 10],"float32"), None, )

W0209 09:59:31.315481 25632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:59:31.316434 25632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 6, 28, 3195661],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8, 6, 28, 3195661],"float32"), None, )

W0209 10:03:13.416599 25673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:03:13.417506 25673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 6, 3195661, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8, 6, 3195661, 28],"float32"), None, )

W0209 10:06:50.578034 25729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:06:50.578871 25729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 684785, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8, 684785, 28, 28],"float32"), )

W0209 10:10:27.159541 25771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:10:27.160755 25771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8, 684785, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8, 684785, 28, 28],"float32"), None, )

W0209 10:14:24.958175 25827 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:14:24.959020 25827 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8192, 128, 64, 64],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8192, 128, 64, 64],"float32"), None, )

W0209 10:18:18.371479 27104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:18:18.372355 27104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8192, 512, 32, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8192, 512, 32, 32],"float32"), None, )

W0209 10:21:51.635609 28805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:21:51.636415 28805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8273, 192, 52, 52],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8273, 192, 52, 52],"float32"), None, )

W0209 10:25:20.698839 31024 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:25:20.699718 31024 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8388608, 16, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([8388608, 16, 32],"float32"), None, )

W0209 10:28:54.706346 32495 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:28:54.707206 32495 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8388608, 8, 8, 8],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([8388608, 8, 8, 8],"float16"), )

W0209 10:32:48.952548 34318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:32:48.953414 34318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([8388608, 8, 8, 8],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([8388608, 8, 8, 8],"float32"), )

W0209 10:41:53.288345 38514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:41:53.289456 38514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([84, 51130564],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([84, 51130564],"float32"), )

W0209 10:45:38.715826 40378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:45:38.716691 40378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([85599, 1024, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([85599, 1024, 7, 7],"float32"), None, )

W0209 10:49:28.555735 42055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:49:28.556830 42055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([85599, 16, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([85599, 16, 56, 56],"float32"), None, )

W0209 10:53:08.838856 43926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:53:08.839865 43926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([858993459, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([858993459, 5],"float32"), None, )

W0209 10:56:43.921746 45579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:56:43.922820 45579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([88739, 16, 55, 55],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([88739, 16, 55, 55],"float32"), )

W0209 11:00:28.429404 47446 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:00:28.430464 47446 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([894785, 192, 5, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([894785, 192, 5, 5],"float32"), None, )

W0209 11:04:06.748881 49108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:04:06.749799 49108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([89808, 244, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([89808, 244, 14, 14],"float32"), None, )

W0209 11:07:47.424237 50743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:07:47.425235 50743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([913046, 24, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([913046, 24, 14, 14],"float32"), None, )

W0209 11:11:17.659071 52399 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:11:17.659960 52399 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([913046, 6, 28, 28],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([913046, 6, 28, 28],"float16"), None, )

W0209 11:15:08.079870 54246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:15:08.080963 54246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([913046, 96, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([913046, 96, 7, 7],"float32"), None, )

W0209 11:24:07.777465 58478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:24:07.778573 58478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([92057, 16, 54, 54],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([92057, 16, 54, 54],"float32"), )

W0209 11:27:58.743522 60348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:27:58.744436 60348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([94454, 232, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([94454, 232, 14, 14],"float32"), None, )

W0209 11:31:32.815665 61997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:31:32.816738 61997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([94454, 58, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([94454, 58, 28, 28],"float32"), None, )

W0209 11:35:20.786656 63666 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:35:20.787730 63666 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([99274, 256, 13, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([99274, 256, 13, 13],"float32"), )

W0209 11:39:04.158754 65504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:39:04.159814 65504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([99274, 256, 13, 13],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([99274, 256, 13, 13],"float32"), None, )

W0209 11:42:49.140612 67168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:42:49.141420 67168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([99274, 64, 26, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([99274, 64, 26, 26],"float32"), )

W0209 11:46:25.074039 69016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:46:25.075091 69016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu_(Tensor([10, 20, 21474837],"float32"), )
[Pass] paddle.nn.functional.relu_(Tensor([10, 20, 21474837],"float32"), )

W0209 11:50:03.974165 70669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:50:03.975086 70669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu_(Tensor([10, 429496730, 1],"float32"), )
[Pass] paddle.nn.functional.relu_(Tensor([10, 429496730, 1],"float32"), )

W0209 11:53:50.962942 72342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:53:50.963829 72342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu_(Tensor([214748365, 20, 1],"float32"), )
[Pass] paddle.nn.functional.relu_(Tensor([214748365, 20, 1],"float32"), )

W0209 11:57:29.692981 74514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:57:29.693938 74514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 1280, 479350, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 1280, 479350, 7],"float32"), )

W0209 12:01:18.289849 76186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:01:18.290804 76186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 1280, 479350, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 1280, 479350, 7],"float32"), None, )

W0209 12:05:09.202934 78034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:05:09.203785 78034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 1280, 7, 479350],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 1280, 7, 479350],"float32"), )

W0209 12:08:48.179400 79700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:08:48.180310 79700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 1280, 7, 479350],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 1280, 7, 479350],"float32"), None, )

W0209 12:12:19.979589 81341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:12:19.980437 81341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 1369569, 56, 56],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 1369569, 56, 56],"float32"), )

W0209 12:15:53.026985 83164 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:15:53.027931 83164 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 1369569, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 1369569, 56, 56],"float32"), None, )

W0209 12:19:29.243705 84851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:19:29.244690 84851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 144, 1065221, 28],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 144, 1065221, 28],"float32"), )

W0209 12:23:14.708015 86530 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:23:14.708982 86530 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 144, 1065221, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 144, 1065221, 28],"float32"), None, )

W0209 12:26:54.220331 88418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:26:54.221266 88418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 144, 28, 1065221],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 144, 28, 1065221],"float32"), )

W0209 12:30:29.999965 90105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:30:30.000919 90105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 144, 28, 1065221],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 144, 28, 1065221],"float32"), None, )

W0209 12:34:00.734750 91781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:34:00.735637 91781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 144, 532611, 56],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 144, 532611, 56],"float32"), )

W0209 12:37:26.427516 93435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:37:26.428397 93435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 144, 532611, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 144, 532611, 56],"float32"), None, )

W0209 12:41:00.008738 95110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:41:00.009742 95110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 144, 56, 532611],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 144, 56, 532611],"float32"), )

W0209 12:44:27.407474 96813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:44:27.408473 96813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 144, 56, 532611],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 144, 56, 532611],"float32"), None, )

W0209 12:47:57.679248 98493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:47:57.680090 98493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 192, 14, 1597831],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 192, 14, 1597831],"float32"), )

W0209 12:51:38.560292 100157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:51:38.561208 100157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 192, 14, 1597831],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 192, 14, 1597831],"float32"), None, )

W0209 12:55:18.318377 101822 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:55:18.319264 101822 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 192, 1597831, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 192, 1597831, 14],"float32"), )

W0209 12:58:49.473271 103552 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:58:49.474187 103552 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 192, 1597831, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 192, 1597831, 14],"float32"), None, )

W0209 13:02:31.250154 105441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:02:31.251391 105441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 192, 28, 798916],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 192, 28, 798916],"float32"), )

W0209 13:06:11.812510 107161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:06:11.813438 107161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 192, 28, 798916],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 192, 28, 798916],"float32"), None, )

W0209 13:09:52.994627 109078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:09:52.995587 109078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 192, 798916, 28],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 192, 798916, 28],"float32"), )

W0209 13:13:32.206342 110775 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:13:32.207186 110775 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 192, 798916, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 192, 798916, 28],"float32"), None, )

W0209 13:17:08.038890 112530 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:17:08.039834 112530 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 21913099, 14, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 21913099, 14, 14],"float32"), )

W0209 13:20:40.070897 113577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:20:40.071794 113577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 21913099, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 21913099, 14, 14],"float32"), None, )

W0209 13:24:08.666167 113689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:24:08.667095 113689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 32, 112, 1198373],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 32, 112, 1198373],"float32"), )

W0209 13:27:44.356081 113785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:27:44.356988 113785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 32, 112, 1198373],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 32, 112, 1198373],"float32"), None, )

W0209 13:31:16.488456 113870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:31:16.489354 113870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 32, 1198373, 112],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 32, 1198373, 112],"float32"), )

W0209 13:34:52.925069 113981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:34:52.925940 113981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 32, 1198373, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 32, 1198373, 112],"float32"), None, )

W0209 13:38:28.498188 114093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:38:28.499190 114093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 342393, 112, 112],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 342393, 112, 112],"float32"), )

W0209 13:42:18.434358 114177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:42:18.435196 114177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 342393, 112, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 342393, 112, 112],"float32"), None, )

W0209 13:45:44.298511 114262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:45:44.299443 114262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 384, 14, 798916],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 384, 14, 798916],"float32"), )

W0209 13:49:12.339331 114319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:49:12.340174 114319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 384, 14, 798916],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 384, 14, 798916],"float32"), None, )

W0209 13:52:46.348403 114402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:52:46.349326 114402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 384, 798916, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 384, 798916, 14],"float32"), )

W0209 13:56:29.686681 114472 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:56:29.687674 114472 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 384, 798916, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 384, 798916, 14],"float32"), None, )

W0209 14:00:20.323149 114557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:00:20.324011 114557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 5478275, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 5478275, 28, 28],"float32"), )

W0209 14:03:54.593268 114654 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:03:54.594178 114654 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 5478275, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 5478275, 28, 28],"float32"), None, )

W0209 14:07:26.467589 114765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:07:26.468462 114765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 576, 1065221, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 576, 1065221, 7],"float32"), )

W0209 14:11:02.588238 114855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:11:02.589151 114855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 576, 1065221, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 576, 1065221, 7],"float32"), None, )

W0209 14:14:53.065335 114934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:14:53.066215 114934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 576, 14, 532611],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 576, 14, 532611],"float32"), )

W0209 14:18:43.963779 115033 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:18:43.964924 115033 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 576, 14, 532611],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 576, 14, 532611],"float32"), None, )

W0209 14:22:26.248271 115130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:22:26.249217 115130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 576, 532611, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 576, 532611, 14],"float32"), )

W0209 14:26:06.520354 115200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:26:06.521376 115200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 576, 532611, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 576, 532611, 14],"float32"), None, )

W0209 14:29:44.246565 115269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:29:44.247597 115269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 576, 7, 1065221],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 576, 7, 1065221],"float32"), )

W0209 14:33:26.632252 115340 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:33:26.633101 115340 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 576, 7, 1065221],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 576, 7, 1065221],"float32"), None, )

W0209 14:36:56.505504 115397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:36:56.506433 115397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 87652394, 7, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 87652394, 7, 7],"float32"), )

W0209 14:40:39.638921 115495 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:40:39.640094 115495 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 87652394, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 87652394, 7, 7],"float32"), None, )

W0209 14:44:30.338097 115607 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:44:30.338913 115607 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 96, 112, 399458],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 96, 112, 399458],"float32"), )

W0209 14:48:06.034687 115690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:48:06.035591 115690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 96, 112, 399458],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 96, 112, 399458],"float32"), None, )

W0209 14:51:33.431403 115787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:51:33.432381 115787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 96, 399458, 112],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 96, 399458, 112],"float32"), )

W0209 14:55:01.644670 115858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:55:01.645496 115858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 96, 399458, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 96, 399458, 112],"float32"), None, )

W0209 14:58:33.267992 115914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:58:33.268940 115914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 96, 56, 798916],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 96, 56, 798916],"float32"), )

W0209 15:02:16.384482 115998 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:02:16.385627 115998 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 96, 56, 798916],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 96, 56, 798916],"float32"), None, )

W0209 15:05:48.688702 116111 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:05:48.689672 116111 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 96, 798916, 56],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 96, 798916, 56],"float32"), )

W0209 15:09:42.590624 116153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:09:42.591535 116153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 96, 798916, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 96, 798916, 56],"float32"), None, )

W0209 15:13:37.623016 116236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:13:37.623850 116236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 960, 639133, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 960, 639133, 7],"float32"), )

W0209 15:17:25.745268 116293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:17:25.746197 116293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 960, 639133, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 960, 639133, 7],"float32"), None, )

W0209 15:21:01.621112 116321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:21:01.622090 116321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 960, 7, 639133],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([1, 960, 7, 639133],"float32"), )

W0209 15:24:26.067956 116349 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:24:26.068858 116349 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([1, 960, 7, 639133],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([1, 960, 7, 639133],"float32"), None, )

W0209 15:27:56.058521 116405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:27:56.059568 116405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([10700, 32, 112, 112],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([10700, 32, 112, 112],"float32"), )

W0209 15:31:44.643486 116461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:31:44.644438 116461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([10700, 32, 112, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([10700, 32, 112, 112],"float32"), None, )

W0209 15:35:27.260490 116503 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:35:27.261379 116503 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([114131, 192, 14, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([114131, 192, 14, 14],"float32"), )

W0209 15:39:03.889755 116559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:39:03.890709 116559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([114131, 192, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([114131, 192, 14, 14],"float32"), None, )

W0209 15:42:35.451645 116628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:42:35.452531 116628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([14267, 96, 56, 56],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([14267, 96, 56, 56],"float32"), )

W0209 15:46:00.622421 116671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:46:00.623356 116671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([14267, 96, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([14267, 96, 56, 56],"float32"), None, )

W0209 15:49:30.156848 116713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:49:30.158037 116713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([152175, 576, 7, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([152175, 576, 7, 7],"float32"), )

W0209 15:53:07.488679 116727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:53:07.490056 116727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([152175, 576, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([152175, 576, 7, 7],"float32"), None, )

W0209 15:56:59.701339 116755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:56:59.702325 116755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 1048576, 2048],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([2, 1048576, 2048],"float32"), )

W0209 16:00:42.375934 116811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:00:42.376964 116811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 10956550, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 10956550, 14, 14],"float32"), None, )

W0209 16:04:57.489415 116881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:04:57.490345 116881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 1280, 239675, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 1280, 239675, 7],"float32"), None, )

W0209 16:08:36.752982 116950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:08:36.753877 116950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 1280, 7, 239675],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 1280, 7, 239675],"float32"), None, )

W0209 16:12:15.073320 116979 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:12:15.074208 116979 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 144, 266306, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 144, 266306, 56],"float32"), None, )

W0209 16:15:42.415499 117006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:15:42.416430 117006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 144, 28, 532611],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 144, 28, 532611],"float32"), None, )

W0209 16:19:19.338415 117034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:19:19.339257 117034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 144, 532611, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 144, 532611, 28],"float32"), None, )

W0209 16:24:02.462450 117063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:24:02.463346 117063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 144, 56, 266306],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 144, 56, 266306],"float32"), None, )

W0209 16:28:00.482432 117077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:28:00.483259 117077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 171197, 112, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 171197, 112, 112],"float32"), None, )

W0209 16:32:59.647377 117104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:32:59.648275 117104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 192, 14, 798916],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 192, 14, 798916],"float32"), None, )

W0209 16:37:23.828218 117147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:37:23.829145 117147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 192, 28, 399458],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 192, 28, 399458],"float32"), None, )

W0209 16:40:55.651840 117175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:40:55.652778 117175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 192, 399458, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 192, 399458, 28],"float32"), None, )

W0209 16:44:42.022308 117202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:44:42.023239 117202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 192, 798916, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 192, 798916, 14],"float32"), None, )

W0209 16:48:16.977978 117245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:48:16.978907 117245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 2739138, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 2739138, 28, 28],"float32"), None, )

W0209 16:51:54.885651 117287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:51:54.886973 117287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 300, 7158279],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([2, 300, 7158279],"float32"), )

W0209 16:55:32.803252 117329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:55:32.804157 117329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 32, 112, 599187],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 32, 112, 599187],"float32"), None, )

W0209 16:59:03.570194 117371 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:59:03.571286 117371 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 32, 599187, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 32, 599187, 112],"float32"), None, )

W0209 17:02:44.482234 117413 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:02:44.483105 117413 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 384, 14, 399458],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 384, 14, 399458],"float32"), None, )

W0209 17:06:29.843981 117441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:06:29.844996 117441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 384, 399458, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 384, 399458, 14],"float32"), None, )

W0209 17:10:00.756234 117483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:10:00.757238 117483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 43826197, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 43826197, 7, 7],"float32"), None, )

W0209 17:13:35.403944 117525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:13:35.404841 117525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 576, 14, 266306],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 576, 14, 266306],"float32"), None, )

W0209 17:17:04.000491 117553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:17:04.001360 117553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 576, 266306, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 576, 266306, 14],"float32"), None, )

W0209 17:20:43.074429 117594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:20:43.075402 117594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 576, 532611, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 576, 532611, 7],"float32"), None, )

W0209 17:24:23.345176 117622 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:24:23.345994 117622 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 576, 7, 532611],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 576, 7, 532611],"float32"), None, )

W0209 17:28:19.522213 117664 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:28:19.523175 117664 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 684785, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 684785, 56, 56],"float32"), None, )

W0209 17:31:52.016845 117706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:31:52.017722 117706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 96, 112, 199729],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 96, 112, 199729],"float32"), None, )

W0209 17:35:29.101867 117748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:35:29.102809 117748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 96, 199729, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 96, 199729, 112],"float32"), None, )

W0209 17:39:19.290808 117791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:39:19.291671 117791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 96, 399458, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 96, 399458, 56],"float32"), None, )

W0209 17:42:54.605700 117832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:42:54.606541 117832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 96, 56, 399458],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 96, 56, 399458],"float32"), None, )

W0209 17:46:43.876307 117874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:46:43.877211 117874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 960, 319567, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 960, 319567, 7],"float32"), None, )

W0209 17:50:12.554229 117902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:50:12.555171 117902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2, 960, 7, 319567],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2, 960, 7, 319567],"float32"), None, )

W0209 17:53:51.322713 117944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:53:51.323747 117944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([2684355, 16, 10, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([2684355, 16, 10, 10],"float32"), None, )

W0209 17:57:24.873826 117986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:57:24.874779 117986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([28533, 192, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([28533, 192, 28, 28],"float32"), )

W0209 18:01:01.555631 118015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:01:01.556612 118015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([28533, 192, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([28533, 192, 28, 28],"float32"), None, )

W0209 18:04:30.242106 118043 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:04:30.243008 118043 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([3567, 96, 112, 112],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([3567, 96, 112, 112],"float32"), )

W0209 18:08:08.666177 118071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:08:08.667097 118071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([3567, 96, 112, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([3567, 96, 112, 112],"float32"), None, )

W0209 18:12:03.501111 118113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:12:03.502044 118113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([38044, 144, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([38044, 144, 28, 28],"float32"), )

W0209 18:15:34.580088 118141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:15:34.580994 118141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([38044, 144, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([38044, 144, 28, 28],"float32"), None, )

W0209 18:19:02.665119 118182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:19:02.666122 118182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([38044, 576, 14, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([38044, 576, 14, 14],"float32"), )

W0209 18:22:32.629448 118211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:22:32.630410 118211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([38044, 576, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([38044, 576, 14, 14],"float32"), None, )

W0209 18:26:04.561028 118239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:26:04.562093 118239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 1280, 119838, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 1280, 119838, 7],"float32"), )

W0209 18:29:37.091914 118281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:29:37.092877 118281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 1280, 7, 119838],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 1280, 7, 119838],"float32"), )

W0209 18:33:31.417878 118323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:33:31.418752 118323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 1369569, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 1369569, 28, 28],"float32"), )

W0209 18:37:10.577477 118365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:37:10.578393 118365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 144, 133153, 56],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 144, 133153, 56],"float32"), )

W0209 18:40:42.992597 118407 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:40:42.993479 118407 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 144, 266306, 28],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 144, 266306, 28],"float32"), )

W0209 18:44:21.450327 118687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:44:21.452040 118687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 144, 28, 266306],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 144, 28, 266306],"float32"), )

W0209 18:48:08.222533 118911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:48:08.223870 118911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 144, 56, 133153],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 144, 56, 133153],"float32"), )

W0209 18:51:49.303362 118939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:51:49.304396 118939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 192, 14, 399458],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 192, 14, 399458],"float32"), )

W0209 18:55:32.712546 118967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:55:32.713567 118967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 192, 199729, 28],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 192, 199729, 28],"float32"), )

W0209 18:59:13.563974 119023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:59:13.564841 119023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 192, 28, 199729],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 192, 28, 199729],"float32"), )

W0209 19:02:53.202011 119135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:02:53.203176 119135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 192, 399458, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 192, 399458, 14],"float32"), )

W0209 19:06:27.708683 119205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:06:27.709509 119205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 21913099, 7, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 21913099, 7, 7],"float32"), )

W0209 19:10:06.582540 119219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:10:06.583345 119219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 32, 112, 299594],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 32, 112, 299594],"float32"), )

W0209 19:13:45.295861 119247 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:13:45.296815 119247 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 32, 299594, 112],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 32, 299594, 112],"float32"), )

W0209 19:17:18.438719 119303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:17:18.439611 119303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 342393, 56, 56],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 342393, 56, 56],"float32"), )

W0209 19:20:49.184772 119345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:20:49.185732 119345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 384, 14, 199729],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 384, 14, 199729],"float32"), )

W0209 19:24:23.415020 119400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:24:23.415854 119400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 384, 199729, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 384, 199729, 14],"float32"), )

W0209 19:27:54.363521 119443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:27:54.364387 119443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 5478275, 14, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 5478275, 14, 14],"float32"), )

W0209 19:31:36.662467 119499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:31:36.663398 119499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 576, 133153, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 576, 133153, 14],"float32"), )

W0209 19:35:15.518669 119555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:35:15.519901 119555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 576, 14, 133153],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 576, 14, 133153],"float32"), )

W0209 19:39:07.667672 119597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:39:07.668670 119597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 576, 266306, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 576, 266306, 7],"float32"), )

W0209 19:43:08.455302 119639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:43:08.456372 119639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 576, 7, 266306],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 576, 7, 266306],"float32"), )

W0209 19:47:06.469252 119694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:47:06.470225 119694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 85599, 112, 112],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 85599, 112, 112],"float32"), )

W0209 19:50:52.393065 119737 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:50:52.394073 119737 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 96, 112, 99865],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 96, 112, 99865],"float32"), )

W0209 19:54:42.756011 119765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:54:42.757269 119765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 96, 199729, 56],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 96, 199729, 56],"float32"), )

W0209 19:58:17.538509 119793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:58:17.539366 119793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 96, 56, 199729],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 96, 56, 199729],"float32"), )

W0209 20:01:51.915053 119835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:01:51.915902 119835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 96, 99865, 112],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 96, 99865, 112],"float32"), )

W0209 20:05:20.698613 119877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:05:20.699436 119877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 960, 159784, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 960, 159784, 7],"float32"), )

W0209 20:09:10.958859 119904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:09:10.959774 119904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([4, 960, 7, 159784],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([4, 960, 7, 159784],"float32"), )

W0209 20:12:44.301623 119945 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:12:44.302480 119945 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([512, 16, 10, 52429],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([512, 16, 10, 52429],"float32"), None, )

W0209 20:16:11.859336 119974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:16:11.860340 119974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([512, 16, 52429, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([512, 16, 52429, 10],"float32"), None, )

W0209 20:19:51.920751 120017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:19:51.921660 120017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([512, 83887, 10, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([512, 83887, 10, 10],"float32"), None, )

W0209 20:23:22.246389 120058 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:23:22.247334 120058 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([57066, 384, 14, 14],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([57066, 384, 14, 14],"float32"), )

W0209 20:27:00.257725 120087 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:27:00.258750 120087 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([57066, 384, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([57066, 384, 14, 14],"float32"), None, )

W0209 20:30:34.478883 120129 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:30:34.479811 120129 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([68479, 1280, 7, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([68479, 1280, 7, 7],"float32"), )

W0209 20:34:06.434005 120184 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:34:06.434952 120184 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([68479, 1280, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([68479, 1280, 7, 7],"float32"), None, )

W0209 20:37:39.017099 120213 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:37:39.018000 120213 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([6991, 300, 2048],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([6991, 300, 2048],"float32"), )

W0209 20:41:20.642333 120241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:41:20.643318 120241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([8, 16, 33554432],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([8, 16, 33554432],"float32"), None, )

W0209 20:45:03.981168 120269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:45:03.982450 120269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([8, 16777216, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([8, 16777216, 32],"float32"), None, )

W0209 20:48:39.293650 120311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:48:39.294765 120311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([8388608, 16, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([8388608, 16, 32],"float32"), None, )

W0209 20:52:06.411501 120338 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:52:06.412498 120338 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([91305, 960, 7, 7],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([91305, 960, 7, 7],"float32"), )

W0209 20:56:29.404603 120367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:56:29.405438 120367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([91305, 960, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([91305, 960, 7, 7],"float32"), None, )

W0209 21:00:04.169391 120409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:00:04.170707 120409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([9511, 144, 56, 56],"float32"), )
[Pass] paddle.nn.functional.relu6(Tensor([9511, 144, 56, 56],"float32"), )

W0209 21:03:45.880621 120450 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:03:45.881551 120450 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu6(Tensor([9511, 144, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu6(Tensor([9511, 144, 56, 56],"float32"), None, )

W0209 21:07:22.467000 120492 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:07:22.468201 120492 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([1, 178956971, 3, 4],"float64"), 0.05, 0.25, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([1, 178956971, 3, 4],"float64"), 0.05, 0.25, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:11:18.177820 120520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:11:18.178812 120520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([1, 178956971, 3, 4],"float64"), 0.1, 0.33, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([1, 178956971, 3, 4],"float64"), 0.1, 0.33, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:12:22.115653 120548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:12:22.116515 120548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([1, 178956971, 3, 4],"float64"), lower=0.05, upper=0.25, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([1, 178956971, 3, 4],"float64"), lower=0.05, upper=0.25, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:13:25.959865 120563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:13:25.960778 120563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 268435457, 4],"float64"), 0.05, 0.25, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([1, 2, 268435457, 4],"float64"), 0.05, 0.25, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:14:31.930855 120577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:14:31.932288 120577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 268435457, 4],"float64"), 0.1, 0.33, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([1, 2, 268435457, 4],"float64"), 0.1, 0.33, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:15:37.358912 120604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:15:37.359807 120604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 268435457, 4],"float64"), lower=0.05, upper=0.25, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([1, 2, 268435457, 4],"float64"), lower=0.05, upper=0.25, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:16:46.318930 120632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:16:46.319921 120632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3, 357913942],"float64"), 0.05, 0.25, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([1, 2, 3, 357913942],"float64"), 0.05, 0.25, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:17:52.239464 120647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:17:52.240336 120647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3, 357913942],"float64"), 0.1, 0.33, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([1, 2, 3, 357913942],"float64"), 0.1, 0.33, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:18:56.080935 120661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:18:56.081897 120661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([1, 2, 3, 357913942],"float64"), lower=0.05, upper=0.25, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([1, 2, 3, 357913942],"float64"), lower=0.05, upper=0.25, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:20:24.296018 120688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:20:24.296954 120688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 107374183, 4, 5],"float16"), 0.1, 0.3, training=False, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([2, 107374183, 4, 5],"float16"), 0.1, 0.3, training=False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 23 / 4294967320 (5.36e-07%)
Max absolute difference: 0.9946
Max relative difference: 1.
 x: array([[[[0.2874  , 0.4763  , 0.9883  , 0.891   , 0.12067 ],
         [0.1829  , 0.796   , 0.862   , 0.3848  , 0.5557  ],
         [0.4985  , 0.8296  , 0.2189  , 0.4229  , 0.7646  ],...
 y: array([[[[0.2874  , 0.4763  , 0.9883  , 0.891   , 0.12067 ],
         [0.1829  , 0.796   , 0.862   , 0.3848  , 0.5557  ],
         [0.4985  , 0.8296  , 0.2189  , 0.4229  , 0.7646  ],...

W0209 21:22:10.228123 120703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:22:10.228986 120703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 107374183, 4, 5],"float16"), 0.3, 0.300000009, training=True, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([2, 107374183, 4, 5],"float16"), 0.3, 0.300000009, training=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4252000910 / 4294967320 (99%)
Max absolute difference: 1.
Max relative difference: 0.
 x: array([[[[0.3557  , 0.448   , 0.4402  , 0.9966  , 0.4536  ],
         [0.915   , 0.907   , 0.675   , 0.01535 , 0.779   ],
         [0.6562  , 0.905   , 0.1423  , 0.07825 , 0.597   ],...
 y: array([[[[0.3557 , 0.448  , 0.4402 , 0.9966 , 0.4536 ],
         [0.915  , 0.907  , 0.675  , 0.01535, 0.779  ],
         [0.6562 , 0.905  , 0.1423 , 0.07825, 0.597  ],...

W0209 21:35:57.756261 120828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:35:57.757158 120828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 107374183, 4, 5],"float32"), 0.1, 0.3, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 107374183, 4, 5],"float32"), 0.1, 0.3, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:47:34.350644 120954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:47:34.351526 120954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 107374183, 4, 5],"float32"), 0.3, 0.300000009, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 107374183, 4, 5],"float32"), 0.3, 0.300000009, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 21:48:58.438784 120969 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:48:58.439815 120969 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 143165577, 5],"float16"), 0.1, 0.3, training=False, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([2, 3, 143165577, 5],"float16"), 0.1, 0.3, training=False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 14 / 4294967310 (3.26e-07%)
Max absolute difference: 0.9565
Max relative difference: 1.
 x: array([[[[0.3142 , 0.6567 , 0.424  , 0.1593 , 0.872  ],
         [0.3376 , 0.7866 , 0.3926 , 0.1495 , 0.903  ],
         [0.2646 , 0.4875 , 0.755  , 0.7573 , 0.02046],...
 y: array([[[[0.3142 , 0.6567 , 0.424  , 0.1593 , 0.872  ],
         [0.3376 , 0.7866 , 0.3926 , 0.1495 , 0.903  ],
         [0.2646 , 0.4875 , 0.755  , 0.7573 , 0.02046],...

W0209 21:50:34.435006 120996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:50:34.435889 120996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 143165577, 5],"float16"), 0.3, 0.300000009, training=True, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([2, 3, 143165577, 5],"float16"), 0.3, 0.300000009, training=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4251992120 / 4294967310 (99%)
Max absolute difference: 1.
Max relative difference: 0.
 x: array([[[[0.5825  , 0.2043  , 0.1669  , 0.877   , 0.2266  ],
         [0.6704  , 0.4192  , 0.03384 , 0.02231 , 0.962   ],
         [0.7676  , 0.884   , 0.3757  , 0.3738  , 0.637   ],...
 y: array([[[[0.5825 , 0.2043 , 0.1669 , 0.877  , 0.2266 ],
         [0.6704 , 0.4192 , 0.03384, 0.02231, 0.962  ],
         [0.7676 , 0.884  , 0.3757 , 0.3738 , 0.     ],...

W0209 22:04:02.642269 121109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:04:02.643177 121109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 143165577, 5],"float32"), 0.1, 0.3, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 3, 143165577, 5],"float32"), 0.1, 0.3, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:15:37.826663 121207 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:15:37.827533 121207 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 143165577, 5],"float32"), 0.3, 0.300000009, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 3, 143165577, 5],"float32"), 0.3, 0.300000009, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:17:14.353632 121235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:17:14.354472 121235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float16"), 0.1, 0.3, training=False, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float16"), 0.1, 0.3, training=False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 8 / 4294967304 (1.86e-07%)
Max absolute difference: 0.935
Max relative difference: 1.
 x: array([[[[0.1137  , 0.6055  , 0.953   , ..., 0.5615  , 0.7227  ,
          0.7163  ],
         [0.936   , 0.2705  , 0.9185  , ..., 0.4287  , 0.3247  ,...
 y: array([[[[0.1137  , 0.6055  , 0.953   , ..., 0.5615  , 0.7227  ,
          0.7163  ],
         [0.936   , 0.2705  , 0.9185  , ..., 0.4287  , 0.3247  ,...

W0209 22:18:58.470856 121900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:18:58.471745 121900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float16"), 0.3, 0.300000009, training=True, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float16"), 0.3, 0.300000009, training=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4251993721 / 4294967304 (99%)
Max absolute difference: 1.
Max relative difference: 0.
 x: array([[[[0.7812 , 0.2727 , 0.445  , ..., 0.0567 , 0.571  , 0.843  ],
         [0.2097 , 0.686  , 0.6436 , ..., 0.841  , 0.5034 , 0.0742 ],
         [0.6685 , 0.958  , 0.623  , ..., 0.1953 , 0.903  , 0.9927 ],...
 y: array([[[[0.7812, 0.2727, 0.445 , ..., 0.    , 0.    , 0.    ],
         [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],
         [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],...

W0209 22:32:55.588972 128798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:32:55.589900 128798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float32"), 0.1, 0.3, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float32"), 0.1, 0.3, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:44:37.258213 135065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:44:37.259195 135065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float32"), 0.3, 0.300000009, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float32"), 0.3, 0.300000009, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:46:12.373874 135814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:46:12.375607 135814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 89478486],"float64"), 0.1, 0.3, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 89478486],"float64"), 0.1, 0.3, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:47:15.505345 136577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:47:15.506237 136577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 89478486],"float64"), 0.3, 0.300000009, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 89478486],"float64"), 0.3, 0.300000009, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:48:25.919458 137098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:48:25.920403 137098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 71582789, 5],"float64"), 0.1, 0.3, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 3, 71582789, 5],"float64"), 0.1, 0.3, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:49:35.296926 137814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:49:35.297817 137814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 3, 71582789, 5],"float64"), 0.3, 0.300000009, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 3, 71582789, 5],"float64"), 0.3, 0.300000009, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:50:48.949393 138330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:50:48.950387 138330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 53687092, 4, 5],"float64"), 0.1, 0.3, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 53687092, 4, 5],"float64"), 0.1, 0.3, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:52:07.288125 139004 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:52:07.288936 139004 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([2, 53687092, 4, 5],"float64"), 0.3, 0.300000009, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([2, 53687092, 4, 5],"float64"), 0.3, 0.300000009, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:53:18.270151 139600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:53:18.271369 139600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([35791395, 3, 4, 5],"float64"), 0.1, 0.3, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([35791395, 3, 4, 5],"float64"), 0.1, 0.3, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:54:29.395334 140138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:54:29.396382 140138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([35791395, 3, 4, 5],"float64"), 0.3, 0.300000009, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([35791395, 3, 4, 5],"float64"), 0.3, 0.300000009, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 22:55:40.391764 140858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:55:40.393289 140858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float16"), 0.1, 0.3, training=False, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float16"), 0.1, 0.3, training=False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 44 / 4294967340 (1.02e-06%)
Max absolute difference: 0.9805
Max relative difference: 1.
 x: array([[[[0.8086  , 0.825   , 0.4092  , 0.397   , 0.4988  ],
         [0.771   , 0.2438  , 0.9727  , 0.903   , 0.634   ],
         [0.49    , 0.2974  , 0.8823  , 0.3254  , 0.9395  ],...
 y: array([[[[0.8086  , 0.825   , 0.4092  , 0.397   , 0.4988  ],
         [0.771   , 0.2438  , 0.9727  , 0.903   , 0.634   ],
         [0.49    , 0.2974  , 0.8823  , 0.3254  , 0.9395  ],...

W0209 22:57:30.039917 141379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:57:30.040798 141379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float16"), 0.3, 0.300000009, training=True, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float16"), 0.3, 0.300000009, training=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4251981709 / 4294967340 (99%)
Max absolute difference: 1.
Max relative difference: 0.
 x: array([[[[0.1594  , 0.3936  , 0.00587 , 0.67    , 0.1232  ],
         [0.907   , 0.0657  , 0.285   , 0.7793  , 0.1836  ],
         [0.2032  , 0.9165  , 0.6885  , 0.774   , 0.863   ],...
 y: array([[[[0.1594  , 0.3936  , 0.00587 , 0.67    , 0.1232  ],
         [0.907   , 0.0657  , 0.285   , 0.7793  , 0.1836  ],
         [0.2032  , 0.9165  , 0.6885  , 0.774   , 0.863   ],...

W0209 23:11:09.629328 148275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:11:09.630160 148275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float32"), 0.1, 0.3, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float32"), 0.1, 0.3, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 23:23:12.288975 154286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:23:12.290042 154286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float32"), 0.3, 0.300000009, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float32"), 0.3, 0.300000009, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 23:24:48.120079 155020 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:24:48.121062 155020 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([89478486, 2, 3, 4],"float64"), 0.05, 0.25, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([89478486, 2, 3, 4],"float64"), 0.05, 0.25, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 23:25:53.818497 155972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:25:53.819597 155972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([89478486, 2, 3, 4],"float64"), 0.1, 0.33, training=False, )
[paddle error] paddle.nn.functional.rrelu(Tensor([89478486, 2, 3, 4],"float64"), 0.1, 0.33, training=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 23:27:05.177927 156503 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:27:05.178828 156503 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.rrelu(Tensor([89478486, 2, 3, 4],"float64"), lower=0.05, upper=0.25, training=True, )
[paddle error] paddle.nn.functional.rrelu(Tensor([89478486, 2, 3, 4],"float64"), lower=0.05, upper=0.25, training=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_rrelu(_object*, _object*, _object*)
1   rrelu_ad_func(paddle::Tensor const&, float, float, bool)
2   paddle::experimental::rrelu_intermediate(paddle::Tensor const&, float, float, bool)
3   void phi::RReluKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, float, float, bool, phi::DenseTensor*, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 23:28:16.093641 157026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:28:16.094458 157026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.selu(Tensor([3, 14316558, 5, 10],"float64"), 1.5, 2.0, )
[paddle_to_torch2] paddle.nn.functional.selu(Tensor([3, 14316558, 5, 10],"float64"), 1.5, 2.0, ) 
api need manual fix

W0209 23:28:32.568496 157547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:28:32.569489 157547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.selu(Tensor([3, 14316558, 5, 10],"float64"), 1.5, 2.0, None, )
[paddle_to_torch2] paddle.nn.functional.selu(Tensor([3, 14316558, 5, 10],"float64"), 1.5, 2.0, None, ) 
api need manual fix

W0209 23:28:38.616354 157761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:28:38.617372 157761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.selu(Tensor([3, 5, 14316558, 10],"float64"), 1.5, 2.0, )
[paddle_to_torch2] paddle.nn.functional.selu(Tensor([3, 5, 14316558, 10],"float64"), 1.5, 2.0, ) 
api need manual fix

W0209 23:28:44.985666 157787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:28:44.986734 157787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.selu(Tensor([3, 5, 14316558, 10],"float64"), 1.5, 2.0, None, )
[paddle_to_torch2] paddle.nn.functional.selu(Tensor([3, 5, 14316558, 10],"float64"), 1.5, 2.0, None, ) 
api need manual fix

W0209 23:28:51.265645 157814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:28:51.266692 157814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.selu(Tensor([3, 5, 5, 28633116],"float64"), 1.5, 2.0, )
[paddle_to_torch2] paddle.nn.functional.selu(Tensor([3, 5, 5, 28633116],"float64"), 1.5, 2.0, ) 
api need manual fix

W0209 23:28:57.522179 157840 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:28:57.523125 157840 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.selu(Tensor([3, 5, 5, 28633116],"float64"), 1.5, 2.0, None, )
[paddle_to_torch2] paddle.nn.functional.selu(Tensor([3, 5, 5, 28633116],"float64"), 1.5, 2.0, None, ) 
api need manual fix

W0209 23:29:03.622184 157864 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:29:03.623126 157864 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.selu(Tensor([8589935, 5, 5, 10],"float64"), 1.5, 2.0, )
[paddle_to_torch2] paddle.nn.functional.selu(Tensor([8589935, 5, 5, 10],"float64"), 1.5, 2.0, ) 
api need manual fix

W0209 23:29:09.802783 158075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:29:09.803774 158075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.selu(Tensor([8589935, 5, 5, 10],"float64"), 1.5, 2.0, None, )
[paddle_to_torch2] paddle.nn.functional.selu(Tensor([8589935, 5, 5, 10],"float64"), 1.5, 2.0, None, ) 
api need manual fix

W0209 23:29:15.903383 158101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:29:15.904371 158101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1, 107374183, 5, 2, 4],"float16"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1, 107374183, 5, 2, 4],"float16"), )

W0209 23:30:48.319231 158128 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:30:48.320048 158128 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1, 107374183, 5, 2, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1, 107374183, 5, 2, 4],"float32"), )

W0209 23:39:44.124977 162622 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:39:44.126287 162622 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1, 2147483649],"float64"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1, 2147483649],"float64"), )

W0209 23:43:44.926357  1360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:43:44.927461  1360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1, 3, 178956971, 2, 4],"float16"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1, 3, 178956971, 2, 4],"float16"), )

W0209 23:47:17.837484  2851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:47:17.838773  2851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1, 3, 178956971, 2, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1, 3, 178956971, 2, 4],"float32"), )

W0209 23:56:26.451035  7545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:56:26.451951  7545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1, 3, 5, 2, 143165577],"float16"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1, 3, 5, 2, 143165577],"float16"), )

W0210 00:00:16.315779  9313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:00:16.316756  9313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1, 3, 5, 2, 143165577],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1, 3, 5, 2, 143165577],"float32"), )

W0210 00:09:07.464138 13789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:09:07.465719 13789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1, 3, 5, 71582789, 4],"float16"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1, 3, 5, 71582789, 4],"float16"), )

W0210 00:13:12.687983 15801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:13:12.688908 15801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1, 3, 5, 71582789, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1, 3, 5, 71582789, 4],"float32"), )

W0210 00:22:08.172626 20311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:22:08.173561 20311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1, 4294967295],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1, 4294967295],"float32"), )

W0210 00:25:53.031894 22315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:25:53.033139 22315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([10, 429496730],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([10, 429496730],"float32"), )

W0210 00:29:32.073936 24109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:29:32.074846 24109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([10, 429496730],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([10, 429496730],"float32"), None, )

W0210 00:33:10.052241 25849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:33:10.053269 25849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1048576, 8, 8, 8, 8],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1048576, 8, 8, 8, 8],"float32"), )

W0210 00:36:43.458197 27971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:36:43.459116 27971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([10604858, 9, 9, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([10604858, 9, 9, 5],"float32"), )

W0210 00:40:21.277415 29538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:40:21.278366 29538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1073741824, 2, 2],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1073741824, 2, 2],"float32"), )

W0210 00:43:51.859006 31519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:43:51.859932 31519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([10737419, 400],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([10737419, 400],"float32"), )

W0210 00:47:18.043080 33262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:47:18.043913 33262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1073742, 5, 8, 10, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1073742, 5, 8, 10, 10],"float32"), )

W0210 00:51:13.947815 35053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:51:13.948788 35053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([128, 33554432],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([128, 33554432],"float32"), )

W0210 00:54:56.101182 37015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:54:56.102133 37015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([134217729, 16],"float64"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([134217729, 16],"float64"), )

W0210 00:58:12.482151 38801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 00:58:12.483142 38801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1342178, 8, 10, 8, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1342178, 8, 10, 8, 5],"float32"), )

W0210 01:01:21.074842 40281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:01:21.076088 40281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1398102, 8, 8, 8, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1398102, 8, 8, 8, 6],"float32"), )

W0210 01:04:58.529522 42056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:04:58.530496 42056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([16, 268435456],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([16, 268435456],"float32"), None, )

W0210 01:09:08.261241 44073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:09:08.262077 44073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([16777216, 256],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([16777216, 256],"float32"), )

W0210 01:12:38.905880 45833 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:12:38.906860 45833 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1789570, 6, 8, 10, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1789570, 6, 8, 10, 5],"float32"), )

W0210 01:16:15.441047 47781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:16:15.441988 47781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1864136, 6, 8, 6, 8],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1864136, 6, 8, 6, 8],"float32"), )

W0210 01:19:59.586119 49084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:19:59.587441 49084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([1864136, 6, 8, 8, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([1864136, 6, 8, 8, 6],"float32"), )

W0210 01:23:45.943895 49112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:23:45.944836 49112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 10, 28, 7669585],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 10, 28, 7669585],"float32"), )

W0210 01:27:23.219123 49140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:27:23.220017 49140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 10, 3, 71582789],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 10, 3, 71582789],"float32"), None, )

W0210 01:31:02.851239 49168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:31:02.852123 49168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 10, 71582789, 3],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 10, 71582789, 3],"float32"), None, )

W0210 01:34:45.729460 49196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:34:45.730350 49196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 10, 7669585, 28],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 10, 7669585, 28],"float32"), )

W0210 01:38:20.298233 49224 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:38:20.299292 49224 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 2147483648],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 2147483648],"float32"), )

W0210 01:42:28.545930 49251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:42:28.546881 49251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 238609295, 3, 3],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 238609295, 3, 3],"float32"), None, )

W0210 01:46:05.836937 49279 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:46:05.837847 49279 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 2739138, 28, 28],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 2739138, 28, 28],"float32"), )

W0210 01:50:01.026432 49307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:50:01.027307 49307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 3, 5, 2, 71582789],"float16"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 3, 5, 2, 71582789],"float16"), )

W0210 01:53:44.410851 49335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 01:53:44.411806 49335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 3, 5, 2, 71582789],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 3, 5, 2, 71582789],"float32"), )

W0210 02:02:21.871065 49378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:02:21.872161 49378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 3, 5, 35791395, 4],"float16"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 3, 5, 35791395, 4],"float16"), )

W0210 02:06:10.836987 49406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:06:10.837895 49406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 3, 5, 35791395, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 3, 5, 35791395, 4],"float32"), )

W0210 02:14:48.134052 49462 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:14:48.134938 49462 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 3, 89478486, 2, 4],"float16"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 3, 89478486, 2, 4],"float16"), )

W0210 02:18:54.993657 49490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:18:54.994493 49490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 3, 89478486, 2, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 3, 89478486, 2, 4],"float32"), )

W0210 02:27:54.315024 49532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:27:54.315958 49532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 53687092, 5, 2, 4],"float16"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 53687092, 5, 2, 4],"float16"), )

W0210 02:31:42.277484 49559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:31:42.278313 49559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2, 53687092, 5, 2, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2, 53687092, 5, 2, 4],"float32"), )

W0210 02:40:22.727893 49601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:40:22.729125 49601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2086962, 7, 7, 7, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2086962, 7, 7, 7, 6],"float32"), )

W0210 02:43:59.320014 49630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:43:59.321012 49630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2097152, 2048],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2097152, 2048],"float32"), )

W0210 02:48:04.564507 49658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:48:04.565565 49658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2097152, 8, 16, 16],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2097152, 8, 16, 16],"float32"), )

W0210 02:52:05.877856 49686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:52:05.879724 49686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2147483648, 2],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2147483648, 2],"float32"), )

W0210 02:56:04.808248 49714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:56:04.809147 49714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2147483649, 1],"float64"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2147483649, 1],"float64"), )

W0210 02:59:17.188107 49742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 02:59:17.189126 49742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2147483649],"float64"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2147483649],"float64"), )

W0210 03:02:12.819231 49783 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:02:12.820560 49783 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([214748365, 10],"float64"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([214748365, 10],"float64"), )

W0210 03:05:20.920641 49798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:05:20.921474 49798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([214748365, 20],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([214748365, 20],"float32"), )

W0210 03:08:34.283703 49826 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:08:34.284539 49826 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([286331153, 15],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([286331153, 15],"float32"), )

W0210 03:12:05.802814 49854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:12:05.803787 49854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([286331153, 15],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([286331153, 15],"float32"), None, )

W0210 03:15:34.645810 49882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:15:34.646731 49882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2982617, 16, 18, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2982617, 16, 18, 5],"float32"), )

W0210 03:19:13.485464 49923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:19:13.486415 49923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([2982617, 5, 16, 18],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([2982617, 5, 16, 18],"float32"), )

W0210 03:23:14.295140 49951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:23:14.295959 49951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([3, 2, 715827883],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([3, 2, 715827883],"float32"), )

W0210 03:26:57.723608 49979 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:26:57.724527 49979 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([3, 715827883, 2],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([3, 715827883, 2],"float32"), )

W0210 03:30:59.937724 50007 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:30:59.938597 50007 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([3, 715827883],"float64"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([3, 715827883],"float64"), )

W0210 03:34:20.194509 50022 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:34:20.195390 50022 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([32, 134217728],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([32, 134217728],"float32"), )

W0210 03:37:28.211056 50050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:37:28.211977 50050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([32, 134217728],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([32, 134217728],"float32"), None, )

W0210 03:41:04.748800 50091 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:41:04.749748 50091 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([32, 67108865],"float64"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([32, 67108865],"float64"), )

W0210 03:44:13.347613 50106 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:44:13.348435 50106 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([350897, 12, 17, 10, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([350897, 12, 17, 10, 6],"float32"), )

W0210 03:47:17.785423 50121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:47:17.786355 50121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([35791395, 3, 5, 2, 4],"float16"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([35791395, 3, 5, 2, 4],"float16"), )

W0210 03:51:06.288894 50149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:51:06.289809 50149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([35791395, 3, 5, 2, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([35791395, 3, 5, 2, 4],"float32"), )

W0210 03:59:40.771394 50205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 03:59:40.772598 50205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([3834793, 14, 16, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([3834793, 14, 16, 5],"float32"), )

W0210 04:03:11.169914 50219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:03:11.170984 50219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([3976822, 6, 6, 6, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([3976822, 6, 6, 6, 5],"float32"), )

W0210 04:06:47.056051 50233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:06:47.057008 50233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 10, 10, 10, 1073742],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 10, 10, 10, 1073742],"float32"), )

W0210 04:10:15.440641 50261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:10:15.441462 50261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 10, 10, 1789570, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 10, 10, 1789570, 6],"float32"), )

W0210 04:13:52.489629 50289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:13:52.490522 50289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 10, 10, 2147484, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 10, 10, 2147484, 5],"float32"), )

W0210 04:17:30.701267 50317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:17:30.702185 50317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 10, 17, 10, 631613],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 10, 17, 10, 631613],"float32"), )

W0210 04:21:02.243413 50345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:21:02.244274 50345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 10, 17, 1579033, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 10, 17, 1579033, 4],"float32"), )

W0210 04:24:45.611954 50373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:24:45.612861 50373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 10, 1789570, 10, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 10, 1789570, 10, 6],"float32"), )

W0210 04:28:27.067823 50400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:28:27.068753 50400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 10, 2147484, 10, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 10, 2147484, 10, 5],"float32"), )

W0210 04:31:56.039433 50415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:31:56.040287 50415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 10, 2684355, 10, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 10, 2684355, 10, 4],"float32"), )

W0210 04:35:27.713711 50456 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:35:27.714726 50456 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 1052689, 17, 10, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 1052689, 17, 10, 6],"float32"), )

W0210 04:39:16.011348 50484 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:39:16.012401 50484 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 1073741824],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 1073741824],"float32"), )

W0210 04:43:02.820693 50512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:43:02.821539 50512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 1073742, 10, 10, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 1073742, 10, 10, 10],"float32"), )

W0210 04:46:37.787997 50541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:46:37.788941 50541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 11930465, 18, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 11930465, 18, 5],"float32"), )

W0210 04:50:25.139572 50569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:50:25.140429 50569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 12, 1491309, 10, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 12, 1491309, 10, 6],"float32"), )

W0210 04:54:20.398206 50598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:54:20.399045 50598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 12, 17, 10, 526345],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 12, 17, 10, 526345],"float32"), )

W0210 04:57:50.624183 50612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 04:57:50.625067 50612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 12, 17, 877241, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 12, 17, 877241, 6],"float32"), )

W0210 05:01:17.804704 50640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:01:17.805799 50640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 13421773, 16, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 13421773, 16, 5],"float32"), )

W0210 05:05:19.170054 50668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:05:19.171080 50668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 1342178, 8, 10, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 1342178, 8, 10, 10],"float32"), )

W0210 05:09:05.797466 50696 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:09:05.798385 50696 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 14, 14, 5478275],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 14, 14, 5478275],"float32"), )

W0210 05:12:53.157688 50724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:12:53.158700 50724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 14, 15339169, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 14, 15339169, 5],"float32"), )

W0210 05:16:31.856107 50765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:16:31.857069 50765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 14, 16, 4793491],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 14, 16, 4793491],"float32"), )

W0210 05:20:24.464913 50793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:20:24.465911 50793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 15339169, 14, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 15339169, 14, 5],"float32"), )

W0210 05:24:24.414346 50821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:24:24.415318 50821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 1579033, 17, 10, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 1579033, 17, 10, 4],"float32"), )

W0210 05:27:50.538244 50836 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:27:50.539134 50836 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 16, 13421773, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 16, 13421773, 5],"float32"), )

W0210 05:31:33.204636 50850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:31:33.205730 50850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 16, 18, 3728271],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 16, 18, 3728271],"float32"), )

W0210 05:35:34.975564 50878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:35:34.976612 50878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 1789570, 10, 10, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 1789570, 10, 10, 6],"float32"), )

W0210 05:39:41.957891 50906 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:39:41.958724 50906 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 2097152, 8, 8, 8],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 2097152, 8, 8, 8],"float32"), )

W0210 05:43:26.870921 50934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:43:26.871963 50934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 2147484, 10, 10, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 2147484, 10, 10, 5],"float32"), )

W0210 05:47:37.602982 50962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:47:37.604156 50962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 23860930, 9, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 23860930, 9, 5],"float32"), )

W0210 05:51:22.895838 50990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:51:22.896781 50990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 2684355, 10, 8, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 2684355, 10, 8, 5],"float32"), )

W0210 05:54:54.745229 51018 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:54:54.746102 51018 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 2684355, 8, 10, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 2684355, 8, 10, 5],"float32"), )

W0210 05:58:34.281812 51046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 05:58:34.282673 51046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 2796203, 8, 6, 8],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 2796203, 8, 6, 8],"float32"), )

W0210 06:02:05.312407 51087 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:02:05.313324 51087 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 2796203, 8, 8, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 2796203, 8, 8, 6],"float32"), )

W0210 06:05:33.404495 51102 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:05:33.405205 51102 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 3652184, 7, 7, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 3652184, 7, 7, 6],"float32"), )

W0210 06:09:49.864818 51130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:09:49.866115 51130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 3728271, 16, 18],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 3728271, 16, 18],"float32"), )

W0210 06:13:44.631422 51171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:13:44.632274 51171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 4, 10, 17, 1579033],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 4, 10, 17, 1579033],"float32"), )

W0210 06:17:13.467602 51199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:17:13.468678 51199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 4, 10, 2684355, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 4, 10, 2684355, 10],"float32"), )

W0210 06:20:56.533890 51227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:20:56.534958 51227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 4, 1579033, 17, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 4, 1579033, 17, 10],"float32"), )

W0210 06:24:55.321897 51242 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:24:55.322779 51242 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 4194304, 16, 16],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 4194304, 16, 16],"float32"), )

W0210 06:28:50.958259 51270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:28:50.959928 51270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5, 10, 10, 2147484],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5, 10, 10, 2147484],"float32"), )

W0210 06:32:51.110894 51298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:32:51.111754 51298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5, 10, 2147484, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5, 10, 2147484, 10],"float32"), )

W0210 06:37:17.531620 51339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:37:17.532532 51339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5, 11930465, 18],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5, 11930465, 18],"float32"), )

W0210 06:40:49.895110 51368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:40:49.896113 51368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5, 16, 13421773],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5, 16, 13421773],"float32"), )

W0210 06:45:01.309181 51396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:45:01.310381 51396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5, 2147484, 10, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5, 2147484, 10, 10],"float32"), )

W0210 06:48:41.165210 51424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:48:41.166555 51424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5, 5, 6, 7158279],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5, 5, 6, 7158279],"float32"), )

W0210 06:52:33.256898 51438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:52:33.257783 51438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5, 5, 8589935, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5, 5, 8589935, 5],"float32"), )

W0210 06:56:19.861812 51466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:56:19.862625 51466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5, 7158279, 6, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5, 7158279, 6, 5],"float32"), )

W0210 06:59:52.601003 51494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 06:59:52.601922 51494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5, 8, 10, 2684355],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5, 8, 10, 2684355],"float32"), )

W0210 07:03:22.913095 51522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:03:22.914080 51522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5, 8, 2684355, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5, 8, 2684355, 10],"float32"), )

W0210 07:07:00.621292 51536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:07:00.622459 51536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 536870913],"float64"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 536870913],"float64"), )

W0210 07:10:22.252245 51563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:10:22.253324 51563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 5965233, 6, 6, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 5965233, 6, 6, 5],"float32"), )

W0210 07:13:46.144151 51578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:13:46.144985 51578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 3579140, 10, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 3579140, 10, 5],"float32"), )

W0210 07:17:19.669667 51606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:17:19.671154 51606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 3728271, 6, 8],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 3728271, 6, 8],"float32"), )

W0210 07:21:01.165302 51634 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:21:01.166193 51634 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 3728271, 8, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 3728271, 8, 6],"float32"), )

W0210 07:24:52.314421 51661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:24:52.315471 51661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 5965233, 6, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 5965233, 6, 5],"float32"), )

W0210 07:28:42.493399 51689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:28:42.494426 51689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 6, 5965233, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 6, 5965233, 5],"float32"), )

W0210 07:32:14.318775 51704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:32:14.319736 51704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 6, 6, 4971027],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 6, 6, 4971027],"float32"), )

W0210 07:35:53.046265 51732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:35:53.047147 51732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 10, 2236963],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 10, 2236963],"float32"), )

W0210 07:39:46.160852 51773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:39:46.161741 51773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 2796203, 8],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 2796203, 8],"float32"), )

W0210 07:43:28.223934 51801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:43:28.224895 51801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 3728271, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 3728271, 6],"float32"), )

W0210 07:47:07.845763 51829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:47:07.846647 51829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 4473925, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 4473925, 5],"float32"), )

W0210 07:50:53.215050 51857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:50:53.215987 51857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 6, 3728271],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 6, 3728271],"float32"), )

W0210 07:54:43.583830 51886 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:54:43.584643 51886 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 8, 2796203],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 6, 8, 8, 2796203],"float32"), )

W0210 07:58:22.788650 51914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 07:58:22.789528 51914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 631613, 10, 17, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 631613, 10, 17, 10],"float32"), )

W0210 08:01:58.688632 51942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:01:58.690222 51942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 7, 3652184, 7, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 7, 3652184, 7, 6],"float32"), )

W0210 08:05:42.336331 51970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:05:42.337194 51970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 7, 7, 3652184, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 7, 7, 3652184, 6],"float32"), )

W0210 08:09:27.961711 51998 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:09:27.962792 51998 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 7, 7, 7, 3130443],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 7, 7, 7, 3130443],"float32"), )

W0210 08:13:18.616178 52026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:13:18.617113 52026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 7158279, 5, 6, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 7158279, 5, 6, 5],"float32"), )

W0210 08:16:52.664845 52054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:16:52.665690 52054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 8, 10, 2684355, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 8, 10, 2684355, 5],"float32"), )

W0210 08:20:39.592690 52082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:20:39.593778 52082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 8, 10, 8, 1677722],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 8, 10, 8, 1677722],"float32"), )

W0210 08:24:32.927160 52110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:24:32.928020 52110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 8, 16, 8388608],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 8, 16, 8388608],"float32"), )

W0210 08:28:17.749953 52138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:28:17.750896 52138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 8, 2097152, 8, 8],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 8, 2097152, 8, 8],"float32"), )

W0210 08:32:11.174512 52180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:32:11.175457 52180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 8, 2796203, 8, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 8, 2796203, 8, 6],"float32"), )

W0210 08:35:52.113509 52208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:35:52.114446 52208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 8, 3355444, 8, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 8, 3355444, 8, 5],"float32"), )

W0210 08:39:36.507143 52236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:39:36.509888 52236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 8, 8, 2097152, 8],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 8, 8, 2097152, 8],"float32"), )

W0210 08:43:28.462605 52264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:43:28.463528 52264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 8, 8, 2796203, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 8, 8, 2796203, 6],"float32"), )

W0210 08:47:21.761858 52292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:47:21.762867 52292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 8, 8, 8, 2097152],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 8, 8, 8, 2097152],"float32"), )

W0210 08:51:07.522161 52320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:51:07.523099 52320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 8, 8388608, 16],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 8, 8388608, 16],"float32"), )

W0210 08:55:05.420957 52347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:55:05.421881 52347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 9, 23860930, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 9, 23860930, 5],"float32"), )

W0210 08:58:56.125349 52376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 08:58:56.126268 52376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4, 9, 9, 13256072],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4, 9, 9, 13256072],"float32"), )

W0210 09:02:41.380820 52404 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:02:41.381740 52404 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4194304, 1024],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4194304, 1024],"float32"), )

W0210 09:06:28.698740 52432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:06:28.699695 52432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4294967295, 1],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4294967295, 1],"float32"), )

W0210 09:10:36.375295 52473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:10:36.376168 52473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4294967295],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4294967295],"float32"), )

W0210 09:14:32.917688 52501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:14:32.918699 52501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([429496730, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([429496730, 10],"float32"), )

W0210 09:18:23.024097 52530 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:18:23.024986 52530 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([429496730, 10],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([429496730, 10],"float32"), None, )

W0210 09:22:06.689388 52558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:22:06.690263 52558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([4382620, 14, 14, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([4382620, 14, 14, 5],"float32"), )

W0210 09:25:41.870611 52586 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:25:41.871606 52586 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([464, 9256396],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([464, 9256396],"float32"), )

W0210 09:29:42.153132 52614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:29:42.154013 52614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([47721859, 10, 3, 3],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([47721859, 10, 3, 3],"float32"), None, )

W0210 09:33:24.185896 52642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:33:24.186770 52642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([5, 429496730],"float64"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([5, 429496730],"float64"), )

W0210 09:36:52.474938 54306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:36:52.475790 54306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([5, 858993459],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([5, 858993459],"float32"), )

W0210 09:40:11.234241 55797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:40:11.235164 55797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([51130564, 84],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([51130564, 84],"float32"), None, )

W0210 09:43:57.978078 57785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:43:57.979018 57785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([512, 8388608],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([512, 8388608],"float32"), )

W0210 09:47:43.378333 59555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:47:43.379781 59555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([512, 8388608],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([512, 8388608],"float32"), None, )

W0210 09:51:34.883944 61545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:51:34.884927 61545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([536870912, 8],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([536870912, 8],"float32"), )

W0210 09:55:11.730082 63305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:55:11.730949 63305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([547828, 10, 28, 28],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([547828, 10, 28, 28],"float32"), )

W0210 09:58:58.054459 65321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 09:58:58.055311 65321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([5726624, 5, 5, 6, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([5726624, 5, 5, 6, 5],"float32"), )

W0210 10:02:42.069936 67105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:02:42.070780 67105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([631613, 10, 17, 10, 4],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([631613, 10, 17, 10, 4],"float32"), )

W0210 10:06:16.043061 68867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:06:16.043982 68867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([631613, 4, 10, 17, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([631613, 4, 10, 17, 10],"float32"), )

W0210 10:09:58.515976 70656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:09:58.516813 70656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([64, 67108864],"float32"), None, )
[Pass] paddle.nn.functional.sigmoid(Tensor([64, 67108864],"float32"), None, )

W0210 10:13:52.795815 72664 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:13:52.796960 72664 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([67108865, 32],"float64"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([67108865, 32],"float64"), )

W0210 10:17:43.617291 75281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:17:43.618247 75281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([715827883, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([715827883, 6],"float32"), )

W0210 10:21:05.215888 76793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:21:05.216729 76793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([715828, 10, 10, 10, 6],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([715828, 10, 10, 10, 6],"float32"), )

W0210 10:24:38.720165 78578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:24:38.721530 78578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([8, 536870912],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([8, 536870912],"float32"), )

W0210 10:28:23.173705 80388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:28:23.174549 80388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([8388608, 512],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([8388608, 512],"float32"), )

W0210 10:32:02.835448 82185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:32:02.836966 82185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([858993459, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([858993459, 5],"float32"), )

W0210 10:36:00.571733 84666 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:36:00.572767 84666 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([858994, 10, 10, 10, 5],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([858994, 10, 10, 10, 5],"float32"), )

W0210 10:39:53.974169 86539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:39:53.975116 86539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.sigmoid(Tensor([858994, 5, 10, 10, 10],"float32"), )
[Pass] paddle.nn.functional.sigmoid(Tensor([858994, 5, 10, 10, 10],"float32"), )

W0210 10:43:28.333410 88652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:43:28.334437 88652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([100, 42949673],"float32"), )
[Pass] paddle.nn.functional.silu(Tensor([100, 42949673],"float32"), )

W0210 10:47:00.510522 90585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:47:00.511422 90585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([16777217, 128],"float64"), )
[Pass] paddle.nn.functional.silu(Tensor([16777217, 128],"float64"), )

W0210 10:50:09.839915 92462 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:50:09.840889 92462 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([2, 1048576, 2048],"float32"), )
[Pass] paddle.nn.functional.silu(Tensor([2, 1048576, 2048],"float32"), )

W0210 10:53:43.508042 94075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:53:43.509009 94075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([2, 178956971, 2, 6],"float16"), )
[Pass] paddle.nn.functional.silu(Tensor([2, 178956971, 2, 6],"float16"), )

W0210 10:57:34.092546 95940 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 10:57:34.093403 95940 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([2, 300, 7158279],"float32"), )
[Pass] paddle.nn.functional.silu(Tensor([2, 300, 7158279],"float32"), )

W0210 11:06:19.175096 100564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:06:19.176134 100564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([2, 4, 2, 268435456],"float16"), )
[Pass] paddle.nn.functional.silu(Tensor([2, 4, 2, 268435456],"float16"), )

W0210 11:10:16.134852 102423 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:10:16.135861 102423 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([2, 4, 89478486, 6],"float16"), )
[Pass] paddle.nn.functional.silu(Tensor([2, 4, 89478486, 6],"float16"), )

W0210 11:19:32.208549 107368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:19:32.209424 107368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([21262215, 101],"float64"), )
[Pass] paddle.nn.functional.silu(Tensor([21262215, 101],"float64"), )

W0210 11:28:13.146203 112362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:28:13.147050 112362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([21474837, 100],"float64"), )
[Pass] paddle.nn.functional.silu(Tensor([21474837, 100],"float64"), )

W0210 11:31:04.423355 113955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:31:04.424504 113955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([33554433, 64],"float64"), )
[Pass] paddle.nn.functional.silu(Tensor([33554433, 64],"float64"), )

W0210 11:34:00.047119 115289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:34:00.048202 115289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([4, 1073741824],"float32"), )
[Pass] paddle.nn.functional.silu(Tensor([4, 1073741824],"float32"), )

W0210 11:37:43.958307 117145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:37:43.959193 117145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([4, 536870913],"float64"), )
[Pass] paddle.nn.functional.silu(Tensor([4, 536870913],"float64"), )

W0210 11:40:52.570667 118983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:40:52.571764 118983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([42524429, 101],"float32"), )
[Pass] paddle.nn.functional.silu(Tensor([42524429, 101],"float32"), )

W0210 11:44:10.998225 120551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:44:10.999032 120551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([42949673, 100],"float32"), )
[Pass] paddle.nn.functional.silu(Tensor([42949673, 100],"float32"), )

W0210 11:47:49.826411 122558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:47:49.827291 122558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([6991, 300, 2048],"float32"), )
[Pass] paddle.nn.functional.silu(Tensor([6991, 300, 2048],"float32"), )

W0210 11:51:18.411465 124415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:51:18.412233 124415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([8, 268435457],"float64"), )
[Pass] paddle.nn.functional.silu(Tensor([8, 268435457],"float64"), )

W0210 11:54:50.041980 126488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:54:50.043013 126488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([8, 536870912],"float32"), )
[Pass] paddle.nn.functional.silu(Tensor([8, 536870912],"float32"), )

W0210 11:58:22.014160 128050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 11:58:22.015071 128050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.silu(Tensor([89478486, 4, 2, 6],"float16"), )
[Pass] paddle.nn.functional.silu(Tensor([89478486, 4, 2, 6],"float16"), )

W0210 12:02:35.048619 130183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:02:35.049435 130183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.softplus(Tensor([2, 1073741825],"float64"), )
[Pass] paddle.nn.functional.softplus(Tensor([2, 1073741825],"float64"), )

W0210 12:11:26.598084 135463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:11:26.598985 135463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.softplus(Tensor([2147483649],"float64"), )
[Pass] paddle.nn.functional.softplus(Tensor([2147483649],"float64"), )

W0210 12:14:33.948971 137056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:14:33.950248 137056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.softplus(Tensor([715827883, 3],"float64"), )
[Pass] paddle.nn.functional.softplus(Tensor([715827883, 3],"float64"), )

W0210 12:17:34.519191 138612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:17:34.520509 138612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.softsign(Tensor([1048576, 4096],"float32"), )
[Pass] paddle.nn.functional.softsign(Tensor([1048576, 4096],"float32"), )

W0210 12:21:06.549906 140429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:21:06.550874 140429 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.softsign(Tensor([300, 14316558],"float32"), )
[Pass] paddle.nn.functional.softsign(Tensor([300, 14316558],"float32"), )

W0210 12:24:52.582710 142266 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:24:52.583786 142266 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.softsign(Tensor([32, 134217728],"float32"), )
[Pass] paddle.nn.functional.softsign(Tensor([32, 134217728],"float32"), )

W0210 12:28:42.024336 144332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:28:42.025255 144332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.softsign(Tensor([33554432, 128],"float32"), )
[Pass] paddle.nn.functional.softsign(Tensor([33554432, 128],"float32"), )

W0210 12:32:45.764621 146411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:32:45.765512 146411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.tanh(Tensor([2, 2147483648],"float32"), None, )
[Pass] paddle.nn.functional.tanh(Tensor([2, 2147483648],"float32"), None, )

W0210 12:36:29.932221 148305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:36:29.933220 148305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.tanh(Tensor([71582789, 60],"float32"), None, )
[Pass] paddle.nn.functional.tanh(Tensor([71582789, 60],"float32"), None, )

W0210 12:40:07.144816 150389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:40:07.145706 150389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.thresholded_relu(Tensor([10, 20, 21474837],"float32"), 1.0, )
[torch error] paddle.nn.functional.thresholded_relu(Tensor([10, 20, 21474837],"float32"), 1.0, ) 
 _threshold() missing 1 required positional argument: 'value'

W0210 12:43:43.018210 152213 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:43:43.019345 152213 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.thresholded_relu(Tensor([10, 429496730, 1],"float32"), 1.0, )
[torch error] paddle.nn.functional.thresholded_relu(Tensor([10, 429496730, 1],"float32"), 1.0, ) 
 _threshold() missing 1 required positional argument: 'value'

W0210 12:44:55.135872 152983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:44:55.137032 152983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.thresholded_relu(Tensor([214748365, 20, 1],"float32"), 1.0, )
[torch error] paddle.nn.functional.thresholded_relu(Tensor([214748365, 20, 1],"float32"), 1.0, ) 
 _threshold() missing 1 required positional argument: 'value'

W0210 12:46:11.284570 153547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:46:11.285667 153547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.thresholded_relu_(Tensor([10, 20, 21474837],"float32"), 1.0, )
[torch error] paddle.nn.functional.thresholded_relu_(Tensor([10, 20, 21474837],"float32"), 1.0, ) 
 threshold_() missing 1 required positional arguments: "value"

W0210 12:47:21.487905 154309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:47:21.489301 154309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.thresholded_relu_(Tensor([10, 429496730, 1],"float32"), 1.0, )
[torch error] paddle.nn.functional.thresholded_relu_(Tensor([10, 429496730, 1],"float32"), 1.0, ) 
 threshold_() missing 1 required positional arguments: "value"

W0210 12:48:32.065594 154846 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:48:32.066599 154846 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.thresholded_relu_(Tensor([214748365, 20, 1],"float32"), 1.0, )
[torch error] paddle.nn.functional.thresholded_relu_(Tensor([214748365, 20, 1],"float32"), 1.0, ) 
 threshold_() missing 1 required positional arguments: "value"

W0210 12:49:42.427717 155409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:49:42.428905 155409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 134866 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 12:51:43.609100 156168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:51:43.610126 156168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 10218 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 12:54:03.057024 157212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:54:03.059311 157212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 51522 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 12:56:31.575176 158287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:56:31.576265 158287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 107790 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 12:58:38.451287 159589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:58:38.453630 159589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 0

W0210 12:59:36.184269 160853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 12:59:36.185578 160853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 0

W0210 13:00:32.283111 161185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:00:32.284090 161185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 0

W0210 13:01:28.882555 161712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:01:28.883999 161712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([429496730, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 0

W0210 13:02:25.082862 162244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:02:25.084451 162244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 51908 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:04:35.965201 162756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:04:35.967957 162756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 101205 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:06:55.935787   526 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:06:55.936904   526 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 147315 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:09:01.376415  1640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:09:01.377506  1640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 23001 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:11:12.318332  2705 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:11:12.319392  2705 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 1

W0210 13:12:08.891100  3982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:12:08.892129  3982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 1

W0210 13:12:56.831514  4496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:12:56.833189  4496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 1

W0210 13:13:46.915174  4788 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:13:46.916333  4788 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 429496730],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 1

W0210 13:14:42.666836  5306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:14:42.668118  5306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:15:28.686172  5819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:15:28.687342  5819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:16:20.521410  6138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:16:20.522943  6138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:17:06.745913  6653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:17:06.747052  6653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([429496730, 5],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:17:59.486285  6944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:17:59.487865  6944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 13:18:54.078379  7463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:18:54.079542  7463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 13:20:04.483469  7991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:20:04.484723  7991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 13:21:00.117686  8543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:21:00.118937  8543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 429496730],"float64"), negative=Tensor([5, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 13:21:49.432379  9055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:21:49.433423  9055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:22:37.614481  9568 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:22:37.615743  9568 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:23:25.024242 10093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:23:25.025393 10093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:24:21.574046 10391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:24:21.575165 10391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([429496730, 5],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:25:16.266522 10912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:25:16.267760 10912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="mean", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 13:26:07.838114 11460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:26:07.839251 11460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="none", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 13:26:55.842420 11973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:26:55.843520 11973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=False, reduction="sum", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 13:27:44.231774 12266 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:27:44.232856 12266 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 5],"float64"), positive=Tensor([5, 5],"float64"), negative=Tensor([5, 429496730],"float64"), distance_function=None, margin=0.3, swap=True, reduction="mean", ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 13:28:35.408519 12784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:28:35.410106 12784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 83047 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:30:54.342095 13083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:30:54.343098 13083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 125752 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:33:11.455387 14360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:33:11.457955 14360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 5876 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:35:29.755597 15681 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:35:29.756688 15681 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 50275 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:37:49.390151 16745 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:37:49.391243 16745 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 0

W0210 13:38:38.663329 18048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:38:38.677863 18048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 0

W0210 13:39:26.452073 18551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:39:26.453222 18551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 0

W0210 13:40:24.356513 18852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:40:24.357575 18852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 0

W0210 13:41:20.988252 19397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:41:21.000672 19397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 10115 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:43:37.761014 19910 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:43:37.762132 19910 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 57007 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:45:48.169816 21202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:45:48.170922 21202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 101904 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:48:07.200225 22270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:48:07.201224 22270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 148423 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 13:50:12.413326 23547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:50:12.414458 23547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 1

W0210 13:51:10.991065 24617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:51:10.992417 24617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 1

W0210 13:52:06.062716 25130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:52:06.063931 25130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 1

W0210 13:52:57.726840 25447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:52:57.727980 25447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 The size of tensor a (429496730) must match the size of tensor b (5) at non-singleton dimension 1

W0210 13:53:56.432282 26117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:53:56.433661 26117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:54:49.372550 26648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:54:49.374117 26648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:55:38.086526 27175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:55:38.087726 27175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:56:33.548502 27691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:56:33.549722 27691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 13:57:28.314297 27998 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:57:28.315560 27998 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 13:58:17.466805 28503 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:58:17.467988 28503 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 13:59:11.157732 29035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 13:59:11.159162 29035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 14:00:07.081936 29564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:00:07.083050 29564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), Tensor([5, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 14:01:00.205463 30089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:01:00.206643 30089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 14:02:00.020043 30405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:02:00.021442 30405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 14:02:54.982468 30936 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:02:54.983592 30936 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 14:03:47.032462 31461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:03:47.033704 31461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([429496730, 5],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 0

W0210 14:04:38.455435 31967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:04:38.456568 31967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="mean", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 14:05:32.074556 32481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:05:32.075757 32481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="none", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="none", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 14:06:21.070351 32800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:06:21.071496 32800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="sum", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=False, reduction="sum", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 14:07:16.456135 33321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:07:16.457342 33321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=True, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 5],"float64"), Tensor([5, 5],"float64"), Tensor([5, 429496730],"float64"), margin=0.3, swap=True, reduction="mean", name=None, ) 
 The size of tensor a (5) must match the size of tensor b (429496730) at non-singleton dimension 1

W0210 14:08:23.041405 33846 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:08:23.043004 33846 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 104858, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([10, 104858, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 51593 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:09:42.823091 34385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:09:42.824115 34385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 104858, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[torch error] paddle.nn.functional.unfold(Tensor([10, 104858, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 81250 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:10:53.002696 35143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:10:53.003798 35143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 104858, 64, 64],"float32"), 3, tuple(1,1,), 1, 1, )
[torch error] paddle.nn.functional.unfold(Tensor([10, 104858, 64, 64],"float32"), 3, tuple(1,1,), 1, 1, ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 101155 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:12:05.485760 35708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:12:05.488423 35708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 104858, 64, 64],"float32"), 3, tuple(1,1,), tuple(1,1,), tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([10, 104858, 64, 64],"float32"), 3, tuple(1,1,), tuple(1,1,), tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 123839 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:13:21.403792 36273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:13:21.405254 36273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 104858, 64, 64],"float32"), tuple(3,3,), tuple(1,1,), tuple(1,1,), tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([10, 104858, 64, 64],"float32"), tuple(3,3,), tuple(1,1,), tuple(1,1,), tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 144033 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:14:33.582151 37039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:14:33.583284 37039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 3, 2236963, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([10, 3, 2236963, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 9797 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:15:52.053565 37570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:15:52.055979 37570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 3, 2236963, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[torch error] paddle.nn.functional.unfold(Tensor([10, 3, 2236963, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 37248 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:17:04.573256 38335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:17:04.574266 38335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 3, 2236963, 64],"float32"), 3, tuple(1,1,), 1, 1, )
[torch error] paddle.nn.functional.unfold(Tensor([10, 3, 2236963, 64],"float32"), 3, tuple(1,1,), 1, 1, ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 60151 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:18:18.707095 38909 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:18:18.708232 38909 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 3, 2236963, 64],"float32"), 3, tuple(1,1,), tuple(1,1,), tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([10, 3, 2236963, 64],"float32"), 3, tuple(1,1,), tuple(1,1,), tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 80374 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:19:29.038640 39685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:19:29.041400 39685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 3, 2236963, 64],"float32"), tuple(3,3,), tuple(1,1,), tuple(1,1,), tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([10, 3, 2236963, 64],"float32"), tuple(3,3,), tuple(1,1,), tuple(1,1,), tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 105221 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:20:48.220762 40242 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:20:48.221767 40242 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 2236963],"float32"), 3, 1, 1, tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([10, 3, 64, 2236963],"float32"), 3, 1, 1, tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 135922 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:22:09.327702 41014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:22:09.328917 41014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 2236963],"float32"), 3, 1, tuple(1,1,), 1, )
[torch error] paddle.nn.functional.unfold(Tensor([10, 3, 64, 2236963],"float32"), 3, 1, tuple(1,1,), 1, ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 158141 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:23:28.818533 41949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:23:28.820735 41949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 2236963],"float32"), 3, tuple(1,1,), 1, 1, )
[torch error] paddle.nn.functional.unfold(Tensor([10, 3, 64, 2236963],"float32"), 3, tuple(1,1,), 1, 1, ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 16321 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:24:38.767208 42515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:24:38.768318 42515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 2236963],"float32"), 3, tuple(1,1,), tuple(1,1,), tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([10, 3, 64, 2236963],"float32"), 3, tuple(1,1,), tuple(1,1,), tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 46463 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:25:56.442850 43263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:25:56.445066 43263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([10, 3, 64, 2236963],"float32"), tuple(3,3,), tuple(1,1,), tuple(1,1,), tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([10, 3, 64, 2236963],"float32"), tuple(3,3,), tuple(1,1,), tuple(1,1,), tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 71207 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:27:08.186815 43841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:27:08.187986 43841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([1789570, 3, 20, 20],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, )
[torch error] paddle.nn.functional.unfold(Tensor([1789570, 3, 20, 20],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, ) 
 It is expected padding equals to 2, but got size 4

W0210 14:28:01.108491 44718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:28:01.109892 44718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([3, 1789570, 20, 20],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, )
[torch error] paddle.nn.functional.unfold(Tensor([3, 1789570, 20, 20],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, ) 
 It is expected padding equals to 2, but got size 4

W0210 14:28:57.130286 45023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:28:57.131691 45023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([3, 3, 11930465, 20],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, )
[torch error] paddle.nn.functional.unfold(Tensor([3, 3, 11930465, 20],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, ) 
 It is expected padding equals to 2, but got size 4

W0210 14:29:54.232771 45548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:29:54.234153 45548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([3, 3, 20, 11930465],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, )
[torch error] paddle.nn.functional.unfold(Tensor([3, 3, 20, 11930465],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, ) 
 It is expected padding equals to 2, but got size 4

W0210 14:30:43.087229 46061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:30:43.088599 46061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([349526, 3, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([349526, 3, 64, 64],"float32"), 3, 1, 1, tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 1085 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:31:51.527315 46569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:31:51.528407 46569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([349526, 3, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, )
[torch error] paddle.nn.functional.unfold(Tensor([349526, 3, 64, 64],"float32"), 3, 1, tuple(1,1,), 1, ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 20280 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:33:01.701050 47113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:33:01.702194 47113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([349526, 3, 64, 64],"float32"), 3, tuple(1,1,), 1, 1, )
[torch error] paddle.nn.functional.unfold(Tensor([349526, 3, 64, 64],"float32"), 3, tuple(1,1,), 1, 1, ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 39144 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:34:13.309306 47651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:34:13.310444 47651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([349526, 3, 64, 64],"float32"), 3, tuple(1,1,), tuple(1,1,), tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([349526, 3, 64, 64],"float32"), 3, tuple(1,1,), tuple(1,1,), tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 61398 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:35:31.740274 48411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:35:31.741351 48411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.unfold(Tensor([349526, 3, 64, 64],"float32"), tuple(3,3,), tuple(1,1,), tuple(1,1,), tuple(1,1,), )
[torch error] paddle.nn.functional.unfold(Tensor([349526, 3, 64, 64],"float32"), tuple(3,3,), tuple(1,1,), tuple(1,1,), tuple(1,1,), ) 
 CUDA out of memory. Tried to allocate 144.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 46.19 GiB is free. Process 90188 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0210 14:36:50.085443 48974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:36:50.087743 48974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(1.0, Tensor([2, 3, 357913942],"float64"), None, )
[torch error] paddle.normal(1.0, Tensor([2, 3, 357913942],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=float, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:37:48.592257 49740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:37:48.593343 49740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(1.0, Tensor([2, 63161284, 17],"float64"), None, )
[torch error] paddle.normal(1.0, Tensor([2, 63161284, 17],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=float, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:38:40.423406 50261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:38:40.424629 50261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(1.0, Tensor([42107523, 3, 17],"float64"), None, )
[torch error] paddle.normal(1.0, Tensor([42107523, 3, 17],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=float, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:39:30.093873 50804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:39:30.095403 50804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(complex(1.0,1.0), Tensor([2, 1073741825],"float64"), None, )
[torch error] paddle.normal(complex(1.0,1.0), Tensor([2, 1073741825],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=complex, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:40:26.928730 51119 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:40:26.929807 51119 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(complex(1.0,1.0), Tensor([429496730, 5],"float64"), None, )
[torch error] paddle.normal(complex(1.0,1.0), Tensor([429496730, 5],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=complex, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:41:19.790300 51647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:41:19.791379 51647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(mean=0.0, std=Tensor([1000, 2147484],"float64"), shape=None, name=None, )
[torch error] paddle.normal(mean=0.0, std=Tensor([1000, 2147484],"float64"), shape=None, name=None, ) 
 normal() received an invalid combination of arguments - got (mean=float, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:42:16.201855 52153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:42:16.202898 52153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(mean=0.0, std=Tensor([1073741825, 2],"float64"), shape=None, name=None, )
[torch error] paddle.normal(mean=0.0, std=Tensor([1073741825, 2],"float64"), shape=None, name=None, ) 
 normal() received an invalid combination of arguments - got (mean=float, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:43:13.204391 52690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:43:13.206179 52690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(mean=Tensor([1000, 2],"float64"), std=Tensor([1000, 2147484],"float64"), shape=None, name=None, )
[torch error] paddle.normal(mean=Tensor([1000, 2],"float64"), std=Tensor([1000, 2147484],"float64"), shape=None, name=None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:44:08.203212 53415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:44:08.204493 53415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(mean=Tensor([1000, 2],"float64"), std=Tensor([1073741825, 2],"float64"), shape=None, name=None, )
[torch error] paddle.normal(mean=Tensor([1000, 2],"float64"), std=Tensor([1073741825, 2],"float64"), shape=None, name=None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:44:58.721781 53926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:44:58.722896 53926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(mean=Tensor([1000, 2147484],"float64"), std=0.5, shape=None, name=None, )
[torch error] paddle.normal(mean=Tensor([1000, 2147484],"float64"), std=0.5, shape=None, name=None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=float, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:45:53.906666 54237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:45:53.907737 54237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(mean=Tensor([1000, 2147484],"float64"), std=Tensor([1000, 2],"float64"), shape=None, name=None, )
[torch error] paddle.normal(mean=Tensor([1000, 2147484],"float64"), std=Tensor([1000, 2],"float64"), shape=None, name=None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:46:44.362816 54757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:46:44.363992 54757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(mean=Tensor([1000, 2147484],"float64"), std=Tensor([1000, 2147484],"float64"), shape=None, name=None, )
[torch error] paddle.normal(mean=Tensor([1000, 2147484],"float64"), std=Tensor([1000, 2147484],"float64"), shape=None, name=None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:48:09.816532 55263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:48:09.817713 55263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(mean=Tensor([1073741825, 2],"float64"), std=0.5, shape=None, name=None, )
[torch error] paddle.normal(mean=Tensor([1073741825, 2],"float64"), std=0.5, shape=None, name=None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=float, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:48:59.004406 56049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:48:59.005625 56049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(mean=Tensor([1073741825, 2],"float64"), std=Tensor([1000, 2],"float64"), shape=None, name=None, )
[torch error] paddle.normal(mean=Tensor([1073741825, 2],"float64"), std=Tensor([1000, 2],"float64"), shape=None, name=None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:49:53.216328 56347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:49:53.217521 56347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(mean=Tensor([1073741825, 2],"float64"), std=Tensor([1073741825, 2],"float64"), shape=None, name=None, )
[torch error] paddle.normal(mean=Tensor([1073741825, 2],"float64"), std=Tensor([1073741825, 2],"float64"), shape=None, name=None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:51:28.369088 56872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:51:28.385473 56872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([1, 100],"float64"), Tensor([1, 2147483649],"float64"), None, )
[torch error] paddle.normal(Tensor([1, 100],"float64"), Tensor([1, 2147483649],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:52:23.730703 57664 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:52:23.731830 57664 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([1, 100],"float64"), Tensor([21474837, 100],"float64"), None, )
[torch error] paddle.normal(Tensor([1, 100],"float64"), Tensor([21474837, 100],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:53:17.963131 58202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:53:17.964222 58202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([1, 2147483649],"float64"), Tensor([1, 100],"float64"), None, )
[torch error] paddle.normal(Tensor([1, 2147483649],"float64"), Tensor([1, 100],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:54:15.094516 58722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:54:15.099220 58722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([1, 2147483649],"float64"), Tensor([1, 2147483649],"float64"), None, )
[torch error] paddle.normal(Tensor([1, 2147483649],"float64"), Tensor([1, 2147483649],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:55:42.838591 59234 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:55:42.840183 59234 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([100],"float64"), Tensor([4294967295],"float32"), None, )
[torch error] paddle.normal(Tensor([100],"float64"), Tensor([4294967295],"float32"), None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:57:03.011873 60013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:57:03.013024 60013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([2, 3, 4, 89478486],"float64"), 0.0, None, )
[torch error] paddle.normal(Tensor([2, 3, 4, 89478486],"float64"), 0.0, None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=float, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:57:52.824025 60585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:57:52.825619 60585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([2, 3, 71582789, 5],"float64"), 0.0, None, )
[torch error] paddle.normal(Tensor([2, 3, 71582789, 5],"float64"), 0.0, None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=float, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:58:50.916332 61090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:58:50.917449 61090 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([2, 53687092, 4, 5],"float64"), 0.0, None, )
[torch error] paddle.normal(Tensor([2, 53687092, 4, 5],"float64"), 0.0, None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=float, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 14:59:39.855260 61615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 14:59:39.856333 61615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([2147483649],"float64"), Tensor([100],"float32"), None, )
[torch error] paddle.normal(Tensor([2147483649],"float64"), Tensor([100],"float32"), None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 15:00:32.248420 62084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:00:32.249514 62084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([2147483649],"float64"), Tensor([4294967295],"float32"), None, )
[torch error] paddle.normal(Tensor([2147483649],"float64"), Tensor([4294967295],"float32"), None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 15:02:34.744803 62342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:02:34.746191 62342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([21474837, 100],"float64"), Tensor([1, 100],"float64"), None, )
[torch error] paddle.normal(Tensor([21474837, 100],"float64"), Tensor([1, 100],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 15:03:23.651216 63385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:03:23.652695 63385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([21474837, 100],"float64"), Tensor([21474837, 100],"float64"), None, )
[torch error] paddle.normal(Tensor([21474837, 100],"float64"), Tensor([21474837, 100],"float64"), None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 15:04:57.723969 63897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:04:57.725226 63897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.normal(Tensor([35791395, 3, 4, 5],"float64"), 0.0, None, )
[torch error] paddle.normal(Tensor([35791395, 3, 4, 5],"float64"), 0.0, None, ) 
 normal() received an invalid combination of arguments - got (mean=Tensor, size=NoneType, std=float, ), but expected one of:
 * (Tensor mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (Tensor mean, float std = 1, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, Tensor std, *, torch.Generator generator = None, Tensor out = None)
 * (float mean, float std, tuple of ints size, *, torch.Generator generator = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0210 15:05:44.754475 64702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:05:44.755667 64702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 10250519, 419],"float32"), )
[Pass] paddle.ones_like(Tensor([1, 10250519, 419],"float32"), )

W0210 15:07:00.135344 65212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:07:00.136238 65212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 1048576, 128, 32],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 1048576, 128, 32],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 15:10:30.356259 67036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:10:30.357128 67036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 1073741825, 2],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([1, 1073741825, 2],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 15:14:43.992514 69385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:14:43.993886 69385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 128, 2097152, 16],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 128, 2097152, 16],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 15:16:00.419411 69896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:16:00.420310 69896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 128, 8, 4194304],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 128, 8, 4194304],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 15:20:42.000478 72234 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:20:42.001499 72234 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 14608733, 294],"float32"), )
[Pass] paddle.ones_like(Tensor([1, 14608733, 294],"float32"), )

W0210 15:25:11.382905 74896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:25:11.384065 74896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 16777216, 16, 16],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 16777216, 16, 16],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 15:28:43.362033 76734 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:28:43.362982 76734 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 2492727, 1723],"float32"), )
[Pass] paddle.ones_like(Tensor([1, 2492727, 1723],"float32"), )

W0210 15:33:23.693704 79048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:33:23.695350 79048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 262144, 128, 128],"float16"), )
[accuracy error] paddle.ones_like(Tensor([1, 262144, 128, 128],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 15:37:17.102010 81109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:37:17.102880 81109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 262144, 128, 128],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 262144, 128, 128],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 15:50:53.419389 88115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:50:53.420533 88115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 3, 2, 715827883],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([1, 3, 2, 715827883],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 15:56:21.053987 91174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:56:21.055001 91174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 3, 357913942, 4],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([1, 3, 357913942, 4],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 15:57:31.237453 91733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:57:31.238736 91733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 3, 715827883],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([1, 3, 715827883],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 15:58:25.971262 92278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 15:58:25.972329 92278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 32, 1048576, 128],"float16"), )
[accuracy error] paddle.ones_like(Tensor([1, 32, 1048576, 128],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 16:00:05.177734 92800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 16:00:05.178570 92800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 32, 1048576, 128],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 32, 1048576, 128],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 16:14:21.699249 100300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 16:14:21.700224 100300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 32, 128, 1048576],"float16"), )
[accuracy error] paddle.ones_like(Tensor([1, 32, 128, 1048576],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 16:19:12.496541 102861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 16:19:12.497892 102861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 32, 128, 1048576],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 32, 128, 1048576],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 16:32:42.605168 109850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 16:32:42.606007 109850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 32, 16, 8388608],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 32, 16, 8388608],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 16:37:37.350411 112191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 16:37:37.351262 112191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 32, 16777216, 8],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 32, 16777216, 8],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 16:42:27.307727 114892 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 16:42:27.308629 114892 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 32, 4194304, 32],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 32, 4194304, 32],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 16:47:08.936419 117234 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 16:47:08.937359 117234 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 32, 8, 16777216],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 32, 8, 16777216],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 16:51:48.319173 119569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 16:51:48.320228 119569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 32, 8388608, 16],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 32, 8388608, 16],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 16:56:33.501732 122286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 16:56:33.502642 122286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 33554432, 8, 16],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 33554432, 8, 16],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 17:01:24.441041 124636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:01:24.442101 124636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 40, 107374183],"float32"), )
[Pass] paddle.ones_like(Tensor([1, 40, 107374183],"float32"), )

W0210 17:06:16.414521 127208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:06:16.415540 127208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 4294967295],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 4294967295],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[1., 1., 1., ..., 1., 1., 1.]], dtype=float32)

W0210 17:10:04.163066 129271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:10:04.164335 129271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 536870912, 2, 4],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([1, 536870912, 2, 4],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 17:14:49.684664 131858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:14:49.685976 131858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 64, 67108864],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 64, 67108864],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],...

W0210 17:16:16.469385 132396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:16:16.470263 132396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 67108864, 8, 8],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1, 67108864, 8, 8],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 17:20:57.550119 135098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:20:57.551522 135098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 8103712, 530],"float32"), )
[Pass] paddle.ones_like(Tensor([1, 8103712, 530],"float32"), )

W0210 17:25:46.903613 137695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:25:46.904462 137695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 8711902, 493],"float32"), )
[Pass] paddle.ones_like(Tensor([1, 8711902, 493],"float32"), )

W0210 17:29:27.090982 139539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:29:27.091977 139539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 8947849, 480],"float32"), )
[Pass] paddle.ones_like(Tensor([1, 8947849, 480],"float32"), )

W0210 17:33:02.349979 141570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:33:02.351174 141570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1, 9586981, 448],"float32"), )
[Pass] paddle.ones_like(Tensor([1, 9586981, 448],"float32"), )

W0210 17:36:52.528505 143410 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:36:52.529424 143410 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([10, 214748365],"float64"), )
[accuracy error] paddle.ones_like(Tensor([10, 214748365],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483650 / 2147483650 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0210 17:40:17.533524 145463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:40:17.534931 145463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([10, 429496730],"float32"), )
[Pass] paddle.ones_like(Tensor([10, 429496730],"float32"), )

W0210 17:44:45.212636 147468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:44:45.214301 147468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1073741824, 2, 2],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([1073741824, 2, 2],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 17:48:43.284024 149520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:48:43.285539 149520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1073741824, 2, 2],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([1073741824, 2, 2],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 17:49:54.112116 150297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:49:54.113384 150297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1073741824, 2, 2],"int32"), )
[accuracy error] paddle.ones_like(Tensor([1073741824, 2, 2],"int32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1
Max relative difference: 1.
 x: array([[[0, 0],
        [0, 0]],
...
 y: array([[[1, 1],
        [1, 1]],
...

W0210 17:51:14.617547 150848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:51:14.618475 150848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([107374183, 5, 4],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([107374183, 5, 4],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 17:57:13.442884 154211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:57:13.444170 154211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([126621, 64, 530],"float32"), )
[Pass] paddle.ones_like(Tensor([126621, 64, 530],"float32"), )

W0210 17:58:30.698623 154710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 17:58:30.699494 154710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([134217728, 32],"bfloat16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([134217728, 32],"bfloat16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:02:08.915854 156542 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:02:08.916996 156542 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([134217728, 32],"bool"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([134217728, 32],"bool"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:03:16.191512 157320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:03:16.192818 157320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([134217728, 32],"float16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([134217728, 32],"float16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:04:40.538391 157871 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:04:40.539906 157871 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([134217728, 32],"float32"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([134217728, 32],"float32"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:05:50.259610 158635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:05:50.261114 158635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([134217728, 32],"int16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([134217728, 32],"int16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:07:13.451210 159200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:07:13.452338 159200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([134217728, 32],"int32"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([134217728, 32],"int32"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:08:24.073230 159964 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:08:24.074427 159964 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([136124, 64, 493],"float32"), )
[Pass] paddle.ones_like(Tensor([136124, 64, 493],"float32"), )

W0210 18:09:41.917297 160514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:09:41.918180 160514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([139811, 64, 480],"float32"), )
[Pass] paddle.ones_like(Tensor([139811, 64, 480],"float32"), )

W0210 18:13:12.140893 162350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:13:12.141765 162350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1431655765, 3],"bfloat16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([1431655765, 3],"bfloat16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:16:56.928759   930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:16:56.931490   930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1431655765, 3],"bool"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([1431655765, 3],"bool"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:17:59.541179  1484 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:17:59.542193  1484 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1431655765, 3],"float16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([1431655765, 3],"float16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:19:24.547672  2005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:19:24.548923  2005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1431655765, 3],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([1431655765, 3],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:20:54.239753  2785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:20:54.241043  2785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1431655765, 3],"float32"), )
[accuracy error] paddle.ones_like(Tensor([1431655765, 3],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[1., 1., 1.],
       [1., 1., 1.],
       [1., 1., 1.],...

W0210 18:22:20.515218  3576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:22:20.516178  3576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1431655765, 3],"float32"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([1431655765, 3],"float32"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:27:09.741175  6196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:27:09.742321  6196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1431655765, 3],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([1431655765, 3],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:28:21.696899  6954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:28:21.698829  6954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1431655765, 3],"int16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([1431655765, 3],"int16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:29:29.994020  7530 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:29:29.995118  7530 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([1431655765, 3],"int32"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([1431655765, 3],"int32"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:30:46.981657  8076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:30:46.982761  8076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([143165577, 3, 5],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([143165577, 3, 5],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:31:41.783021  8847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:31:41.784143  8847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([149797, 64, 448],"float32"), )
[Pass] paddle.ones_like(Tensor([149797, 64, 448],"float32"), )

W0210 18:33:01.527227  9391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:33:01.528147  9391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([153391690, 28],"float32"), )
[Pass] paddle.ones_like(Tensor([153391690, 28],"float32"), )

W0210 18:36:44.306329 11245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:36:44.307369 11245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([16, 16384, 128, 128],"float32"), )
[accuracy error] paddle.ones_like(Tensor([16, 16384, 128, 128],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 18:40:29.326514 13083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:40:29.327404 13083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([16, 32, 128, 65536],"float32"), )
[accuracy error] paddle.ones_like(Tensor([16, 32, 128, 65536],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 18:45:46.291134 15922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:45:46.292045 15922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([16, 32, 65536, 128],"float32"), )
[accuracy error] paddle.ones_like(Tensor([16, 32, 65536, 128],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 18:50:38.038587 18498 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:50:38.039685 18498 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([16777217, 128],"int64"), dtype="int64", )
[torch error] paddle.ones_like(Tensor([16777217, 128],"int64"), dtype="int64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 18:54:47.788859 20841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:54:47.790154 20841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([178956971, 12],"float64"), )
[accuracy error] paddle.ones_like(Tensor([178956971, 12],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0210 18:55:49.410686 21362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 18:55:49.411671 21362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([178956971, 3, 2, 4],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([178956971, 3, 2, 4],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:00:03.930402 23465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:00:03.931363 23465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([178956971, 3, 4],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([178956971, 3, 4],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:00:53.836151 24009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:00:53.837539 24009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([178956971, 4, 3],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([178956971, 4, 3],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:01:49.584479 24527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:01:49.585796 24527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 1, 1073741824, 2],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 1, 1073741824, 2],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:03:09.611845 25038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:03:09.613602 25038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 1, 5, 429496730],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 1, 5, 429496730],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:04:34.903472 25823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:04:34.904701 25823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 1073741824, 2],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([2, 1073741824, 2],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:05:56.688576 26573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:05:56.689844 26573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 1073741824, 2],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 1073741824, 2],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:07:16.414285 27344 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:07:16.416028 27344 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 1073741824, 2],"int32"), )
[accuracy error] paddle.ones_like(Tensor([2, 1073741824, 2],"int32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1
Max relative difference: 1.
 x: array([[[0, 0],
        [0, 0],
        [0, 0],...
 y: array([[[1, 1],
        [1, 1],
        [1, 1],...

W0210 19:08:42.462097 28101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:08:42.463003 28101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 1073741825],"float64"), )
[accuracy error] paddle.ones_like(Tensor([2, 1073741825],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483650 / 2147483650 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.]])

W0210 19:14:56.844910 31473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:14:56.845835 31473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 1073741825],"float64"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([2, 1073741825],"float64"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:19:05.641557 33800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:19:05.648118 33800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 1073741825],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 1073741825],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:20:01.279800 34098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:20:01.280921 34098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 1073741825],"int64"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([2, 1073741825],"int64"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:20:47.451555 34630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:20:47.452734 34630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 1073741825],"int64"), dtype="int64", )
[torch error] paddle.ones_like(Tensor([2, 1073741825],"int64"), dtype="int64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:21:33.833039 35145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:21:33.834326 35145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 107374183, 5, 4],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([2, 107374183, 5, 4],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:22:57.393452 35438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:22:57.394556 35438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 107374183, 5, 4],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 107374183, 5, 4],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:24:18.643814 36201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:24:18.644903 36201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2, 1073741824],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([2, 2, 1073741824],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:25:48.145896 36984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:25:48.146956 36984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2, 1073741824],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 2, 1073741824],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:27:07.514422 37788 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:27:07.515530 37788 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2, 1073741824],"int32"), )
[accuracy error] paddle.ones_like(Tensor([2, 2, 1073741824],"int32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1
Max relative difference: 1.
 x: array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],
...
 y: array([[[1, 1, 1, ..., 1, 1, 1],
        [1, 1, 1, ..., 1, 1, 1]],
...

W0210 19:28:29.843390 38347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:28:29.844216 38347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2, 536870913],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 2, 536870913],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:34:36.040122 41946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:34:36.041239 41946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2147483648],"bfloat16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([2, 2147483648],"bfloat16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:35:50.431447 42263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:35:50.433815 42263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2147483648],"bool"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([2, 2147483648],"bool"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:36:55.148680 43030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:36:55.149888 43030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2147483648],"float16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([2, 2147483648],"float16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:38:23.865099 43565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:38:23.866232 43565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2147483648],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([2, 2147483648],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:39:51.562816 44351 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:39:51.563905 44351 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2147483648],"float32"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([2, 2147483648],"float32"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:41:03.708640 45144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:41:03.709816 45144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2147483648],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 2147483648],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:42:22.315768 45695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:42:22.316933 45695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2147483648],"int16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([2, 2147483648],"int16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:43:26.906877 46462 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:43:26.908007 46462 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 2147483648],"int32"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([2, 2147483648],"int32"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:44:37.286757 46986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:44:37.287848 46986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 214748365, 5, 2],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 214748365, 5, 2],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:45:56.167610 47536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:45:56.168565 47536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 214748365, 5],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 214748365, 5],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:46:51.922740 48308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:46:51.924062 48308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 268435456, 8],"float32"), )
[accuracy error] paddle.ones_like(Tensor([2, 268435456, 8],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],...

W0210 19:48:14.698050 48834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:48:14.699131 48834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 268435457, 4],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 268435457, 4],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:52:30.569741 51411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:52:30.570991 51411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 3, 178956971, 4],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([2, 3, 178956971, 4],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:53:53.922291 51724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:53:53.923427 51724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 3, 178956971, 4],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 3, 178956971, 4],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:55:10.922716 52496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:55:10.923733 52496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 3, 357913942],"float64"), )
[accuracy error] paddle.ones_like(Tensor([2, 3, 357913942],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],...
 y: array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.]],...

W0210 19:56:03.959395 53498 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:56:03.960304 53498 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 3, 357913942],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 3, 357913942],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 19:59:43.185689 55340 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 19:59:43.186712 55340 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 3, 5, 143165577],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([2, 3, 5, 143165577],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:01:22.543112 55853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:01:22.544471 55853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 3, 5, 143165577],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 3, 5, 143165577],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:02:33.790190 56642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:02:33.791683 56642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 3, 5, 71582789],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 3, 5, 71582789],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:03:22.704253 57201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:03:22.705459 57201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 3, 715827883],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([2, 3, 715827883],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:04:47.433549 57706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:04:47.434863 57706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 3, 715827883],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 3, 715827883],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:06:06.481122 58499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:06:06.482388 58499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 3, 89478486, 4],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 3, 89478486, 4],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:06:52.743311 59077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:06:52.745002 59077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 357913942, 3],"float64"), )
[accuracy error] paddle.ones_like(Tensor([2, 357913942, 3],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],...
 y: array([[[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],...

W0210 20:07:46.797551 59577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:07:46.798506 59577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 357913942, 3],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 357913942, 3],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:11:48.197952 61660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:11:48.199627 61660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 4, 268435457],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 4, 268435457],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:12:44.749991 62192 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:12:44.751255 62192 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 429496730, 5],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([2, 429496730, 5],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:14:09.170347 62712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:14:09.171855 62712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 429496730, 5],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 429496730, 5],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:15:20.045943 63475 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:15:20.047127 63475 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 5, 214748365],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 5, 214748365],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:16:22.255838 64056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:16:22.278424 64056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 536870912, 4],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([2, 536870912, 4],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:17:55.056612 64596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:17:55.057641 64596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 536870912, 4],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 536870912, 4],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:19:18.332827 65373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:19:18.334036 65373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 536870913, 2],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 536870913, 2],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:20:08.612947 66159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:20:08.614264 66159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 53687092, 5, 4],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2, 53687092, 5, 4],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:20:56.279109 66699 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:20:56.280145 66699 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 715827883, 3],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([2, 715827883, 3],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:22:19.138994 67006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:22:19.140136 67006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 715827883, 3],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([2, 715827883, 3],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:23:30.697531 67798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:23:30.698616 67798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2, 8, 268435456],"float32"), )
[accuracy error] paddle.ones_like(Tensor([2, 8, 268435456],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],...

W0210 20:24:51.758846 68344 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:24:51.760003 68344 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2097152, 32, 8, 8],"float32"), )
[accuracy error] paddle.ones_like(Tensor([2097152, 32, 8, 8],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 20:30:37.270660 71476 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:30:37.272084 71476 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2147483648, 2],"float32"), )
[accuracy error] paddle.ones_like(Tensor([2147483648, 2],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 y: array([[1., 1.],
       [1., 1.],
       [1., 1.],...

W0210 20:35:30.751112 74199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:35:30.752022 74199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2147483649],"float64"), )
[accuracy error] paddle.ones_like(Tensor([2147483649],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([0., 0., 0., ..., 0., 0., 0.])
 y: array([1., 1., 1., ..., 1., 1., 1.])

W0210 20:39:45.014503 76800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:39:45.015369 76800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2147483649],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([2147483649],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:43:24.946369 78679 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:43:24.947542 78679 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([2147483649],"int64"), dtype="int32", )
[torch error] paddle.ones_like(Tensor([2147483649],"int64"), dtype="int32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 20:44:12.831566 79211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:44:12.832543 79211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([214748365, 5, 2],"float64"), )
[accuracy error] paddle.ones_like(Tensor([214748365, 5, 2],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483650 / 2147483650 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...
 y: array([[[1., 1.],
        [1., 1.],
        [1., 1.],...

W0210 20:45:08.211410 79714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:45:08.212270 79714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([223697, 40, 480],"float32"), )
[Pass] paddle.ones_like(Tensor([223697, 40, 480],"float32"), )

W0210 20:49:40.155476 81809 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:49:40.156558 81809 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([228262, 64, 294],"float32"), )
[Pass] paddle.ones_like(Tensor([228262, 64, 294],"float32"), )

W0210 20:53:18.257284 83631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:53:18.258441 83631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([238609295, 3, 3],"float64"), )
[accuracy error] paddle.ones_like(Tensor([238609295, 3, 3],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483655 / 2147483655 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]],...
 y: array([[[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]],...

W0210 20:56:51.496297 85715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 20:56:51.497376 85715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([256263, 40, 419],"float32"), )
[Pass] paddle.ones_like(Tensor([256263, 40, 419],"float32"), )

W0210 21:01:05.247746 87806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:01:05.248670 87806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([262144, 128, 8, 16],"float32"), )
[accuracy error] paddle.ones_like(Tensor([262144, 128, 8, 16],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 21:04:49.331511 89626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:04:49.332430 89626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([268435457, 8],"float64"), )
[accuracy error] paddle.ones_like(Tensor([268435457, 8],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483656 / 2147483656 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0210 21:09:12.966166 92196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:09:12.967053 92196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([28, 153391690],"float32"), )
[Pass] paddle.ones_like(Tensor([28, 153391690],"float32"), )

W0210 21:13:19.498909 94056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:13:19.499810 94056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([286331153, 3, 5],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([286331153, 3, 5],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 21:16:57.387771 95914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:16:57.389238 95914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([286331153, 3, 5],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([286331153, 3, 5],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 21:18:09.107853 96704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:18:09.108839 96704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([3, 1431655765],"float32"), )
[accuracy error] paddle.ones_like(Tensor([3, 1431655765],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)

W0210 21:19:26.886381 97463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:19:26.887224 97463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([32768, 32, 128, 32],"float32"), )
[accuracy error] paddle.ones_like(Tensor([32768, 32, 128, 32],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 21:24:24.628413 100051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:24:24.629354 100051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([357913942, 12],"float32"), )
[Pass] paddle.ones_like(Tensor([357913942, 12],"float32"), )

W0210 21:29:01.751148 102433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:29:01.752053 102433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([357913942, 2, 3],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([357913942, 2, 3],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 21:32:31.683780 104508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:32:31.684827 104508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([357913942, 3, 2],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([357913942, 3, 2],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 21:33:20.353112 104813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:33:20.354142 104813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([357913942, 3, 4],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([357913942, 3, 4],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 21:34:48.130915 105334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:34:48.132323 105334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([357913942, 3, 4],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([357913942, 3, 4],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 21:35:59.108211 106126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:35:59.109367 106126 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([35791395, 3, 5, 4],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([35791395, 3, 5, 4],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 21:36:54.308387 106683 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:36:54.309525 106683 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([38949, 64, 1723],"float32"), )
[Pass] paddle.ones_like(Tensor([38949, 64, 1723],"float32"), )

W0210 21:38:20.811795 107209 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:38:20.813113 107209 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([4, 1073741824],"float16"), )
[accuracy error] paddle.ones_like(Tensor([4, 1073741824],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float16)
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.]], dtype=float16)

W0210 21:42:21.171017 109276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:42:21.171934 109276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([4, 1073741824],"float32"), )
[accuracy error] paddle.ones_like(Tensor([4, 1073741824],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)

W0210 21:55:35.635573 116307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:55:35.636440 116307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([4, 268435457, 2],"float64"), )
[accuracy error] paddle.ones_like(Tensor([4, 268435457, 2],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483656 / 2147483656 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...
 y: array([[[1., 1.],
        [1., 1.],
        [1., 1.],...

W0210 21:59:51.044185 118656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 21:59:51.045138 118656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([4, 5, 107374183],"float64"), )
[accuracy error] paddle.ones_like(Tensor([4, 5, 107374183],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483660 / 2147483660 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],...

W0210 22:04:04.992419 120974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:04:04.993323 120974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([4, 5, 214748365],"float32"), )
[Pass] paddle.ones_like(Tensor([4, 5, 214748365],"float32"), )

W0210 22:08:21.059355 123012 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:08:21.060323 123012 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([4, 536870912, 2],"float32"), )
[accuracy error] paddle.ones_like(Tensor([4, 536870912, 2],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0.],
        [0., 0.],
        [0., 0.],...
 y: array([[[1., 1.],
        [1., 1.],
        [1., 1.],...

W0210 22:13:19.939291 125612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:13:19.940210 125612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([4, 536870913],"float64"), )
[accuracy error] paddle.ones_like(Tensor([4, 536870913],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.]])

W0210 22:17:41.014282 128191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:17:41.015152 128191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([4294967295, 1],"float32"), )
[accuracy error] paddle.ones_like(Tensor([4294967295, 1],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[1.],
       [1.],
       [1.],...

W0210 22:21:51.071209 130049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:21:51.072088 130049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([4294967295],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([4294967295],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 22:27:23.200390 133251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:27:23.201503 133251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([4294967295],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([4294967295],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 22:28:33.474400 134036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:28:33.475423 134036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([429496730, 1, 5, 2],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([429496730, 1, 5, 2],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 22:29:48.650352 134573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:29:48.651360 134573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([429496730, 5, 2],"float32"), )
[Pass] paddle.ones_like(Tensor([429496730, 5, 2],"float32"), )

W0210 22:31:07.021965 135354 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:31:07.023137 135354 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([5, 429496730],"float64"), )
[accuracy error] paddle.ones_like(Tensor([5, 429496730],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483650 / 2147483650 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0210 22:34:31.705229 137211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:34:31.706122 137211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([524288, 32, 16, 16],"float32"), )
[accuracy error] paddle.ones_like(Tensor([524288, 32, 16, 16],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 22:38:32.833524 139241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:38:32.834663 139241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([536870912, 8],"float16"), )
[accuracy error] paddle.ones_like(Tensor([536870912, 8],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0210 22:43:32.490929 141625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:43:32.491971 141625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([536870912, 8],"float32"), )
[accuracy error] paddle.ones_like(Tensor([536870912, 8],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0210 22:56:49.674768 148657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 22:56:49.675843 148657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([536870913, 2, 2],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([536870913, 2, 2],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:02:04.635756 151756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:02:04.637143 151756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([536870913, 4],"float64"), )
[accuracy error] paddle.ones_like(Tensor([536870913, 4],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.],...
 y: array([[1., 1., 1., 1.],
       [1., 1., 1., 1.],
       [1., 1., 1., 1.],...

W0210 23:02:59.900566 152069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:02:59.901384 152069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([6, 715827883],"float32"), )
[Pass] paddle.ones_like(Tensor([6, 715827883],"float32"), )

W0210 23:07:02.576845 154113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:07:02.577709 154113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([62319, 40, 1723],"float32"), )
[Pass] paddle.ones_like(Tensor([62319, 40, 1723],"float32"), )

W0210 23:11:16.633963 156193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:11:16.635068 156193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([64, 33554433],"float64"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([64, 33554433],"float64"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:14:33.216930 158302 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:14:33.217974 158302 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([64, 33554433],"int64"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([64, 33554433],"int64"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:15:19.271674 158600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:15:19.272799 158600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([64, 67108864],"bfloat16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([64, 67108864],"bfloat16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:16:31.749697 159130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:16:31.750687 159130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([64, 67108864],"bool"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([64, 67108864],"bool"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:17:34.377764 159677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:17:34.378799 159677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([64, 67108864],"float16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([64, 67108864],"float16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:18:57.491856 160211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:18:57.493044 160211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([64, 67108864],"float32"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([64, 67108864],"float32"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:20:09.043329 161006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:20:09.044446 161006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([64, 67108864],"int16"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([64, 67108864],"int16"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:21:31.427903 161769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:21:31.429036 161769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([64, 67108864],"int32"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([64, 67108864],"int32"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:22:50.380865 162328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:22:50.381860 162328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([67108864, 8, 8],"float32"), )
[accuracy error] paddle.ones_like(Tensor([67108864, 8, 8],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],...

W0210 23:24:06.056419 163005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:24:06.057228 163005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([67108865, 32],"float64"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([67108865, 32],"float64"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:28:17.622601  1472 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:28:17.623805  1472 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([67108865, 32],"int64"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([67108865, 32],"int64"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:29:11.058156  1931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:29:11.059226  1931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([715827883, 2, 3],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([715827883, 2, 3],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:30:33.885123  2380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:30:33.886272  2380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([715827883, 2, 3],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([715827883, 2, 3],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:31:58.937422  2819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:31:58.938551  2819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([715827883, 3, 2],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([715827883, 3, 2],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:33:30.190017  3485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:33:30.191428  3485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([715827883, 3, 2],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([715827883, 3, 2],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:34:40.109555  4162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:34:40.110746  4162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([715827883, 3],"float64"), )
[accuracy error] paddle.ones_like(Tensor([715827883, 3],"float64"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[1., 1., 1.],
       [1., 1., 1.],
       [1., 1., 1.],...

W0210 23:35:34.000131  4818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:35:34.000968  4818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([715827883, 3],"float64"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([715827883, 3],"float64"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:39:14.952219  6347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:39:14.953440  6347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([715827883, 3],"float64"), dtype="float64", )
[torch error] paddle.ones_like(Tensor([715827883, 3],"float64"), dtype="float64", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:40:09.639982  6781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:40:09.641096  6781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([715827883, 3],"int64"), dtype="bool", )
[torch error] paddle.ones_like(Tensor([715827883, 3],"int64"), dtype="bool", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:41:01.137200  7214 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:41:01.138362  7214 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([71582789, 3, 5, 4],"float16"), dtype="float16", )
[torch error] paddle.ones_like(Tensor([71582789, 3, 5, 4],"float16"), dtype="float16", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:42:30.965590  7462 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:42:30.966925  7462 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([71582789, 3, 5, 4],"float32"), dtype="float32", )
[torch error] paddle.ones_like(Tensor([71582789, 3, 5, 4],"float32"), dtype="float32", ) 
 ones_like(): argument 'dtype' must be torch.dtype, not str

W0210 23:43:43.881951  8124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:43:43.883124  8124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([8, 536870912],"float32"), )
[accuracy error] paddle.ones_like(Tensor([8, 536870912],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0210 23:45:04.374892  8781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:45:04.375809  8781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([8192, 32, 128, 128],"float16"), )
[accuracy error] paddle.ones_like(Tensor([8192, 32, 128, 128],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0210 23:49:54.609351 10729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0210 23:49:54.610234 10729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ones_like(Tensor([8192, 32, 128, 128],"float32"), )
[accuracy error] paddle.ones_like(Tensor([8192, 32, 128, 128],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],
         [1., 1., 1., ..., 1., 1., 1.],...

W0211 00:03:08.434173 16554 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:03:08.435117 16554 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([20, 107374183],"float64"), Tensor([50],"float64"), )
[torch error] paddle.outer(Tensor([20, 107374183],"float64"), Tensor([50],"float64"), ) 
 outer: Expected 1-D argument self, but got 2-D

W0211 00:07:16.165692 18559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:07:16.166900 18559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([20, 50],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.outer(Tensor([20, 50],"float64"), Tensor([2147483649],"float64"), ) 
 outer: Expected 1-D argument self, but got 2-D

W0211 00:08:11.487093 19006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:08:11.488356 19006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([21474837, 10, 10],"float64"), Tensor([2, 10],"float64"), )
[torch error] paddle.outer(Tensor([21474837, 10, 10],"float64"), Tensor([2, 10],"float64"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:09:07.120177 19451 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:09:07.121285 19451 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([21474837, 10, 10],"int64"), Tensor([2, 10],"int64"), )
[torch error] paddle.outer(Tensor([21474837, 10, 10],"int64"), Tensor([2, 10],"int64"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:09:51.519425 19677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:09:51.520697 19677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([42949673, 10, 10],"int32"), Tensor([2, 10],"int32"), )
[torch error] paddle.outer(Tensor([42949673, 10, 10],"int32"), Tensor([2, 10],"int32"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:11:03.532462 20109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:11:03.533627 20109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([42949673, 50],"float64"), Tensor([50],"float64"), )
[torch error] paddle.outer(Tensor([42949673, 50],"float64"), Tensor([50],"float64"), ) 
 outer: Expected 1-D argument self, but got 2-D

W0211 00:12:00.601651 20572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:12:00.603183 20572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 10, 10],"float64"), Tensor([2, 1073741825],"float64"), )
[torch error] paddle.outer(Tensor([5, 10, 10],"float64"), Tensor([2, 1073741825],"float64"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:12:52.832206 21007 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:12:52.833510 21007 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 10, 10],"float64"), Tensor([214748365, 10],"float64"), )
[torch error] paddle.outer(Tensor([5, 10, 10],"float64"), Tensor([214748365, 10],"float64"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:13:42.230333 21441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:13:42.231513 21441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 10, 10],"int32"), Tensor([2, 2147483648],"int32"), )
[torch error] paddle.outer(Tensor([5, 10, 10],"int32"), Tensor([2, 2147483648],"int32"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:15:22.880003 21886 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:15:22.881254 21886 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 10, 10],"int32"), Tensor([429496730, 10],"int32"), )
[torch error] paddle.outer(Tensor([5, 10, 10],"int32"), Tensor([429496730, 10],"int32"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:16:33.876374 22566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:16:33.877565 22566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 10, 10],"int64"), Tensor([2, 1073741825],"int64"), )
[torch error] paddle.outer(Tensor([5, 10, 10],"int64"), Tensor([2, 1073741825],"int64"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:17:23.276124 23017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:17:23.277285 23017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 10, 10],"int64"), Tensor([214748365, 10],"int64"), )
[torch error] paddle.outer(Tensor([5, 10, 10],"int64"), Tensor([214748365, 10],"int64"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:18:10.565323 23464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:18:10.566356 23464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 10, 42949673],"float64"), Tensor([2, 10],"float64"), )
[torch error] paddle.outer(Tensor([5, 10, 42949673],"float64"), Tensor([2, 10],"float64"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:19:04.761001 23896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:19:04.762665 23896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 10, 42949673],"int64"), Tensor([2, 10],"int64"), )
[torch error] paddle.outer(Tensor([5, 10, 42949673],"int64"), Tensor([2, 10],"int64"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:19:54.308959 24136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:19:54.310216 24136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 10, 85899346],"int32"), Tensor([2, 10],"int32"), )
[torch error] paddle.outer(Tensor([5, 10, 85899346],"int32"), Tensor([2, 10],"int32"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:21:12.378142 24583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:21:12.379114 24583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 42949673, 10],"float64"), Tensor([2, 10],"float64"), )
[torch error] paddle.outer(Tensor([5, 42949673, 10],"float64"), Tensor([2, 10],"float64"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:22:21.166289 25250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:22:21.167577 25250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 42949673, 10],"int64"), Tensor([2, 10],"int64"), )
[torch error] paddle.outer(Tensor([5, 42949673, 10],"int64"), Tensor([2, 10],"int64"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:23:27.050426 25693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:23:27.051632 25693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.outer(Tensor([5, 85899346, 10],"int32"), Tensor([2, 10],"int32"), )
[torch error] paddle.outer(Tensor([5, 85899346, 10],"int32"), Tensor([2, 10],"int32"), ) 
 outer: Expected 1-D argument self, but got 3-D

W0211 00:25:05.727483 26305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:25:05.728435 26305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([10, 429496730],"float32"), 0, )
[paddle error] paddle.pdist(Tensor([10, 429496730],"float32"), 0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
4   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
13  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
14  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 160.000000GB memory on GPU 0, 33.590759GB memory has been allocated and available memory is only 45.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 00:26:36.561743 26964 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:26:36.563344 26964 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([10, 429496730],"float32"), 1.0, )
[paddle error] paddle.pdist(Tensor([10, 429496730],"float32"), 1.0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
4   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
13  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
14  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 160.000000GB memory on GPU 0, 33.590759GB memory has been allocated and available memory is only 45.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 00:28:11.550889 27849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:28:11.551714 27849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([10, 429496730],"float32"), 1.5, )
[paddle error] paddle.pdist(Tensor([10, 429496730],"float32"), 1.5, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
4   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
13  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
14  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 160.000000GB memory on GPU 0, 33.590759GB memory has been allocated and available memory is only 45.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 00:29:55.083063 28502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:29:55.084200 28502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([10, 429496730],"float32"), 2.0, )
[paddle error] paddle.pdist(Tensor([10, 429496730],"float32"), 2.0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
4   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
13  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
14  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 160.000000GB memory on GPU 0, 33.590759GB memory has been allocated and available memory is only 45.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 00:31:27.790098 29178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:31:27.791052 29178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([10, 429496730],"float32"), 2.5, )
[paddle error] paddle.pdist(Tensor([10, 429496730],"float32"), 2.5, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
4   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
13  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
14  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 160.000000GB memory on GPU 0, 33.590759GB memory has been allocated and available memory is only 45.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 00:33:02.558444 29845 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:33:02.559823 29845 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([10, 429496730],"float32"), 3.0, )
[paddle error] paddle.pdist(Tensor([10, 429496730],"float32"), 3.0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
4   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
13  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
14  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 160.000000GB memory on GPU 0, 33.590759GB memory has been allocated and available memory is only 45.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 00:34:35.178018 30706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:34:35.178844 30706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([10, 429496730],"float32"), math.inf, )
[paddle error] paddle.pdist(Tensor([10, 429496730],"float32"), math.inf, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
4   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
13  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
14  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 160.000000GB memory on GPU 0, 33.590759GB memory has been allocated and available memory is only 45.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 00:36:00.257970 31403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:36:00.258865 31403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([107374183, 20],"float64"), 2.0, )
[torch error] paddle.pdist(Tensor([107374183, 20],"float64"), 2.0, ) 
 CUDA out of memory. Tried to allocate 42949673.04 GiB. GPU 0 has a total capacity of 79.18 GiB of which 62.19 GiB is free. Process 85607 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 00:37:05.800415 32070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:37:05.801383 32070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([214748365, 20],"float32"), 0, )
[torch error] paddle.pdist(Tensor([214748365, 20],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 85899345.68 GiB. GPU 0 has a total capacity of 79.18 GiB of which 62.19 GiB is free. Process 129119 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 00:38:25.295109 32297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:38:25.296108 32297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([214748365, 20],"float32"), 1.0, )
[torch error] paddle.pdist(Tensor([214748365, 20],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 85899345.68 GiB. GPU 0 has a total capacity of 79.18 GiB of which 62.19 GiB is free. Process 27173 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 00:39:43.057053 32962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:39:43.058022 32962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([214748365, 20],"float32"), 1.5, )
[torch error] paddle.pdist(Tensor([214748365, 20],"float32"), 1.5, ) 
 CUDA out of memory. Tried to allocate 85899345.68 GiB. GPU 0 has a total capacity of 79.18 GiB of which 62.19 GiB is free. Process 74042 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 00:41:10.504624 33629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:41:10.505636 33629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([214748365, 20],"float32"), 2.0, )
[torch error] paddle.pdist(Tensor([214748365, 20],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 85899345.68 GiB. GPU 0 has a total capacity of 79.18 GiB of which 62.19 GiB is free. Process 149907 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 00:42:32.546537 34295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:42:32.547639 34295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([214748365, 20],"float32"), 2.5, )
[torch error] paddle.pdist(Tensor([214748365, 20],"float32"), 2.5, ) 
 CUDA out of memory. Tried to allocate 85899345.68 GiB. GPU 0 has a total capacity of 79.18 GiB of which 62.19 GiB is free. Process 46051 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 00:43:52.973897 34759 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:43:52.975350 34759 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([214748365, 20],"float32"), 3.0, )
[torch error] paddle.pdist(Tensor([214748365, 20],"float32"), 3.0, ) 
 CUDA out of memory. Tried to allocate 85899345.68 GiB. GPU 0 has a total capacity of 79.18 GiB of which 62.19 GiB is free. Process 107599 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 00:45:02.886633 35425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:45:02.887727 35425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([214748365, 20],"float32"), math.inf, )
[torch error] paddle.pdist(Tensor([214748365, 20],"float32"), math.inf, ) 
 CUDA out of memory. Tried to allocate 85899345.68 GiB. GPU 0 has a total capacity of 79.18 GiB of which 62.19 GiB is free. Process 156961 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 00:46:22.847543 35860 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:46:22.848780 35860 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pdist(Tensor([50, 42949673],"float64"), 2.0, )
[paddle error] paddle.pdist(Tensor([50, 42949673],"float64"), 2.0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::SubtractRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
4   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
13  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
14  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 800.000001GB memory on GPU 0, 33.590759GB memory has been allocated and available memory is only 45.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 00:47:27.627663 36525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 00:47:27.628715 36525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 65, in main
    print(str(res.stdout.read(), encoding="utf-8"), flush=True)
KeyboardInterrupt
