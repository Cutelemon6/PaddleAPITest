test begin: paddle.squeeze(Tensor([1, 4294967295, 1, 1],"float32"), list[1,2,], )
[Pass] paddle.squeeze(Tensor([1, 4294967295, 1, 1],"float32"), list[1,2,], )

W0205 10:03:13.737128 89199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:03:13.738193 89199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1, 4294967295],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([1, 4294967295],"float32"), axis=-1, )

W0205 10:06:58.733420 90258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:06:58.734649 90258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1, 536870913, 4],"float64"), axis=0, )
[Pass] paddle.squeeze(Tensor([1, 536870913, 4],"float64"), axis=0, )

W0205 10:10:23.098326 90967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:10:23.099311 90967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1, 6, 1, 715827883],"float32"), list[], )
[accuracy error] paddle.squeeze(Tensor([1, 6, 1, 715827883],"float32"), list[], ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (6, 715827883), (1, 6, 1, 715827883) mismatch)
 x: array([[0.501002, 0.787556, 0.011134, ..., 0.431484, 0.398936, 0.908241],
       [0.368149, 0.570172, 0.90157 , ..., 0.822996, 0.086595, 0.137148],
       [0.654342, 0.353504, 0.188255, ..., 0.777915, 0.657287, 0.802497],...
 y: array([[[[0.501002, 0.787556, 0.011134, ..., 0.431484, 0.398936,
          0.908241]],
...

W0205 10:13:42.146623 91567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:13:42.147589 91567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1, 6, 1, 715827883],"float32"), list[1,2,], )
[Pass] paddle.squeeze(Tensor([1, 6, 1, 715827883],"float32"), list[1,2,], )

W0205 10:15:25.623772 91932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:15:25.625137 91932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1, 6, 715827883, 1],"float32"), list[], )
[accuracy error] paddle.squeeze(Tensor([1, 6, 715827883, 1],"float32"), list[], ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (6, 715827883), (1, 6, 715827883, 1) mismatch)
 x: array([[0.483237, 0.819532, 0.666336, ..., 0.403851, 0.420357, 0.508116],
       [0.77376 , 0.868616, 0.270769, ..., 0.551455, 0.998575, 0.506986],
       [0.159303, 0.504585, 0.239424, ..., 0.781955, 0.983597, 0.293371],...
 y: array([[[[0.483237],
         [0.819532],
         [0.666336],...

W0205 10:19:09.116250 92707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:19:09.117275 92707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1, 6, 715827883, 1],"float32"), list[1,2,], )
[Pass] paddle.squeeze(Tensor([1, 6, 715827883, 1],"float32"), list[1,2,], )

W0205 10:20:50.567853 93020 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:20:50.569080 93020 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1, 67108865, 32],"float64"), axis=list[1,], )
[Pass] paddle.squeeze(Tensor([1, 67108865, 32],"float64"), axis=list[1,], )

W0205 10:24:17.918139 93825 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:24:17.919040 93825 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1, 8, 16, 128, 262144],"float32"), axis=0, )
[Pass] paddle.squeeze(Tensor([1, 8, 16, 128, 262144],"float32"), axis=0, )

W0205 10:27:40.048043 94425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:27:40.049609 94425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1, 8, 16, 524288, 64],"float32"), axis=0, )
[Pass] paddle.squeeze(Tensor([1, 8, 16, 524288, 64],"float32"), axis=0, )

W0205 10:31:24.277642 95278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:31:24.278739 95278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1, 8, 65536, 128, 64],"float32"), axis=0, )
[Pass] paddle.squeeze(Tensor([1, 8, 65536, 128, 64],"float32"), axis=0, )

W0205 10:34:58.598883 96043 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:34:58.599951 96043 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([10, 10, 21474837],"float64"), )
[Pass] paddle.squeeze(Tensor([10, 10, 21474837],"float64"), )

W0205 10:38:18.202266 96767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:38:18.203372 96767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([10, 10, 21474837],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([10, 10, 21474837],"float64"), axis=-1, )

W0205 10:41:16.749234 97375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:41:16.750192 97375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([10, 20, 21474837],"float32"), )
[Pass] paddle.squeeze(Tensor([10, 20, 21474837],"float32"), )

W0205 10:44:34.991549 97987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:44:34.992777 97987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([10, 21474837, 10],"float64"), )
[Pass] paddle.squeeze(Tensor([10, 21474837, 10],"float64"), )

W0205 10:47:57.424770 98709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:47:57.425711 98709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([10, 21474837, 10],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([10, 21474837, 10],"float64"), axis=-1, )

W0205 10:50:47.165087 99333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:50:47.166008 99333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([10, 429496730, 1],"float32"), )
[Pass] paddle.squeeze(Tensor([10, 429496730, 1],"float32"), )

W0205 10:53:59.602576 99928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:53:59.603502 99928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([100, 21474837],"float64"), 1, )
[Pass] paddle.squeeze(Tensor([100, 21474837],"float64"), 1, )

W0205 10:57:12.313374 100653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:57:12.314218 100653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([100, 21474837],"float64"), -1, )
[Pass] paddle.squeeze(Tensor([100, 21474837],"float64"), -1, )

W0205 11:00:03.358502 101272 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:00:03.359445 101272 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([100, 21474837],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([100, 21474837],"float64"), axis=-1, )

W0205 11:02:55.745213 101826 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:02:55.746055 101826 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([128, 1, 33554432],"float32"), )
[Pass] paddle.squeeze(Tensor([128, 1, 33554432],"float32"), )

W0205 11:06:09.466377 102681 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:06:09.467321 102681 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([128, 3356, 10000],"float32"), )
[Pass] paddle.squeeze(Tensor([128, 3356, 10000],"float32"), )

W0205 11:09:47.995949 103741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:09:47.996897 103741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1431655765, 3, 1],"float32"), )
[Pass] paddle.squeeze(Tensor([1431655765, 3, 1],"float32"), )

W0205 11:13:38.123021 104669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:13:38.124241 104669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1431655765, 3],"float32"), )
[Pass] paddle.squeeze(Tensor([1431655765, 3],"float32"), )

W0205 11:17:17.800171 105474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:17:17.801074 105474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([1431655765, 3],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([1431655765, 3],"float32"), axis=-1, )

W0205 11:20:55.390094 106430 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:20:55.391032 106430 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([178956971, 3, 4],"float64"), axis=0, )
[Pass] paddle.squeeze(Tensor([178956971, 3, 4],"float64"), axis=0, )

W0205 11:24:12.311230 107266 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:24:12.312211 107266 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 1, 2, 536870913],"float64"), 1, )
[Pass] paddle.squeeze(Tensor([2, 1, 2, 536870913],"float64"), 1, )

W0205 11:27:20.329782 107925 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:27:20.330632 107925 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 1, 536870913, 2],"float64"), 1, )
[Pass] paddle.squeeze(Tensor([2, 1, 536870913, 2],"float64"), 1, )

W0205 11:30:09.661695 108537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:30:09.662617 108537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 1000, 1, 2147484],"float32"), axis=list[2,3,], )
[Pass] paddle.squeeze(Tensor([2, 1000, 1, 2147484],"float32"), axis=list[2,3,], )

W0205 11:33:24.560633 109161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:33:24.562167 109161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 1000, 2147484, 1],"float32"), axis=list[2,3,], )
[Pass] paddle.squeeze(Tensor([2, 1000, 2147484, 1],"float32"), axis=list[2,3,], )

W0205 11:37:18.629159 109873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:37:18.630074 109873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 1024, 1, 2097152],"float32"), axis=list[2,3,], )
[Pass] paddle.squeeze(Tensor([2, 1024, 1, 2097152],"float32"), axis=list[2,3,], )

W0205 11:40:58.546494 110691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:40:58.547459 110691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 1024, 2097152, 1],"float32"), axis=list[2,3,], )
[Pass] paddle.squeeze(Tensor([2, 1024, 2097152, 1],"float32"), axis=list[2,3,], )

W0205 11:44:42.439225 111404 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:44:42.440292 111404 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 1073741825],"float64"), )
[Pass] paddle.squeeze(Tensor([2, 1073741825],"float64"), )

W0205 11:48:24.489979 112237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:48:24.491420 112237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 1073741825],"float64"), 1, )
[Pass] paddle.squeeze(Tensor([2, 1073741825],"float64"), 1, )

W0205 11:51:31.363315 113001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:51:31.364403 113001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 1073741825],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 1073741825],"float64"), axis=-1, )

W0205 11:54:27.465334 113547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:54:27.466256 113547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 107374183, 2, 5],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 107374183, 2, 5],"float64"), axis=-1, )

W0205 11:57:28.519850 114257 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:57:28.520788 114257 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 1073742, 10, 10, 10],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 1073742, 10, 10, 10],"float64"), axis=-1, )

W0205 12:00:23.701428 115099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:00:23.702464 115099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 2, 2, 268435457],"float64"), -1, )
[Pass] paddle.squeeze(Tensor([2, 2, 2, 268435457],"float64"), -1, )

W0205 12:03:25.048058 115690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:03:25.049058 115690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 2, 2, 268435457],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 2, 2, 268435457],"float64"), axis=-1, )

W0205 12:06:21.892764 116329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:06:21.894218 116329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 2, 536870913, 1],"float64"), -1, )
[Pass] paddle.squeeze(Tensor([2, 2, 536870913, 1],"float64"), -1, )

W0205 12:09:26.657052 116982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:09:26.658111 116982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 2, 536870913, 1],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 2, 536870913, 1],"float64"), axis=-1, )

W0205 12:12:21.752144 117621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:12:21.753105 117621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 2147483648, 1, 1],"float32"), axis=list[2,3,], )
[Pass] paddle.squeeze(Tensor([2, 2147483648, 1, 1],"float32"), axis=list[2,3,], )

W0205 12:15:53.675230 118289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:15:53.676105 118289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 2147483648, 1],"float32"), )
[Pass] paddle.squeeze(Tensor([2, 2147483648, 1],"float32"), )

W0205 12:19:43.211532 119123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:19:43.212453 119123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 2147483648],"float32"), )
[Pass] paddle.squeeze(Tensor([2, 2147483648],"float32"), )

W0205 12:23:33.510454 119930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:23:33.511516 119930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 2147483648],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([2, 2147483648],"float32"), axis=1, )

W0205 12:27:28.805384 120877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:27:28.806322 120877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 2147483648],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 2147483648],"float32"), axis=-1, )

W0205 12:31:29.067520 121575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:31:29.068408 121575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 2147483648],"float32"), axis=list[1,], )
[Pass] paddle.squeeze(Tensor([2, 2147483648],"float32"), axis=list[1,], )

W0205 12:35:27.504840 122369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:35:27.505924 122369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 268435457, 2, 2],"float64"), 1, )
[Pass] paddle.squeeze(Tensor([2, 268435457, 2, 2],"float64"), 1, )

W0205 12:39:03.840449 123245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:39:03.841428 123245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 3, 10, 10, 3579140],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 3, 10, 10, 3579140],"float64"), axis=-1, )

W0205 12:42:11.199873 123885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:42:11.200964 123885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 3, 10, 3579140, 10],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 3, 10, 3579140, 10],"float64"), axis=-1, )

W0205 12:45:03.431711 124483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:45:03.432602 124483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 3, 2, 178956971],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 3, 2, 178956971],"float64"), axis=-1, )

W0205 12:48:02.456910 125067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:48:02.458011 125067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 3, 3579140, 10, 10],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 3, 3579140, 10, 10],"float64"), axis=-1, )

W0205 12:51:15.841778 125661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:51:15.842698 125661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 3, 715827883],"float32"), )
[Pass] paddle.squeeze(Tensor([2, 3, 715827883],"float32"), )

W0205 12:54:33.864332 126233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:54:33.865329 126233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 3, 71582789, 5],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 3, 71582789, 5],"float64"), axis=-1, )

W0205 12:58:12.107858 127023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:58:12.108889 127023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 536870913, 2, 1],"float64"), -1, )
[Pass] paddle.squeeze(Tensor([2, 536870913, 2, 1],"float64"), -1, )

W0205 13:01:19.595180 127642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:01:19.596043 127642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2, 536870913, 2, 1],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2, 536870913, 2, 1],"float64"), axis=-1, )

W0205 13:04:30.703547 128277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:04:30.704468 128277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2147483648, 2, 1],"float32"), axis=2, )
[Pass] paddle.squeeze(Tensor([2147483648, 2, 1],"float32"), axis=2, )

W0205 13:08:10.579578 128983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:08:10.580772 128983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2147483648, 2],"float32"), )
[Pass] paddle.squeeze(Tensor([2147483648, 2],"float32"), )

W0205 13:12:35.148986 129857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:12:35.150171 129857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2147483648, 2],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2147483648, 2],"float32"), axis=-1, )

W0205 13:16:11.892709 130605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:16:11.893507 130605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2147483649, 1],"float64"), 1, )
[Pass] paddle.squeeze(Tensor([2147483649, 1],"float64"), 1, )

W0205 13:19:46.227797 131444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:19:46.228781 131444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2147483649, 1],"float64"), -1, )
[Pass] paddle.squeeze(Tensor([2147483649, 1],"float64"), -1, )

W0205 13:22:50.569521 132049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:22:50.570420 132049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2147483649, 1],"float64"), axis=1, )
[Pass] paddle.squeeze(Tensor([2147483649, 1],"float64"), axis=1, )

W0205 13:25:46.321045 132638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:25:46.321936 132638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2147483649, 1],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2147483649, 1],"float64"), axis=-1, )

W0205 13:29:04.189965 133304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:29:04.191020 133304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2147483649, 1],"int64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([2147483649, 1],"int64"), axis=-1, )

W0205 13:32:19.587248 133900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:32:19.588687 133900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2147483649],"float64"), axis=0, )
[Pass] paddle.squeeze(Tensor([2147483649],"float64"), axis=0, )

W0205 13:35:59.470082 134596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:35:59.471908 134596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([214748365, 20, 1],"float32"), )
[Pass] paddle.squeeze(Tensor([214748365, 20, 1],"float32"), )

W0205 13:39:27.881202 135330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:39:27.882118 135330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([21474837, 10, 10],"float64"), )
[Pass] paddle.squeeze(Tensor([21474837, 10, 10],"float64"), )

W0205 13:42:42.509720 136068 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:42:42.510993 136068 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([21474837, 10, 10],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([21474837, 10, 10],"float64"), axis=-1, )

W0205 13:45:54.070237 136709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:45:54.071561 136709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([268435456, 16, 1],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([268435456, 16, 1],"float32"), axis=-1, )

W0205 13:49:19.991217 137351 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:49:19.992123 137351 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([26843546, 10, 8, 1, 2],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([26843546, 10, 8, 1, 2],"float32"), axis=-1, )

W0205 13:53:02.469233 138158 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:53:02.470157 138158 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([2684355, 1, 40, 40],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([2684355, 1, 40, 40],"float32"), axis=1, )

W0205 13:56:44.567471 138895 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:56:44.568404 138895 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([298262, 1, 3, 1600, 3],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([298262, 1, 3, 1600, 3],"float32"), axis=1, )

W0205 14:00:46.516978 139724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:00:46.517892 139724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([298262, 1, 3, 3, 1600],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([298262, 1, 3, 3, 1600],"float32"), axis=1, )

W0205 14:04:34.905997 140566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:04:34.907270 140566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 11930465, 40, 3],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 11930465, 40, 3],"float32"), axis=1, )

W0205 14:08:22.626137 141288 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:08:22.627683 141288 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 298262, 1600, 3],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 298262, 1600, 3],"float32"), axis=1, )

W0205 14:12:23.723896 142080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:12:23.724900 142080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 298262, 3, 1600],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 298262, 3, 1600],"float32"), axis=1, )

W0205 14:16:03.286648 142894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:16:03.287521 142894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 3, 11930465, 40],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 3, 11930465, 40],"float32"), axis=1, )

W0205 14:19:55.657231 143659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:19:55.658905 143659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 3, 159072863, 3],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 3, 159072863, 3],"float32"), axis=1, )

W0205 14:23:45.231798 144423 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:23:45.232951 144423 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 3, 1600, 298262],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 3, 1600, 298262],"float32"), axis=1, )

W0205 14:27:19.206748 145102 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:27:19.207706 145102 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 3, 298262, 1600],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 3, 298262, 1600],"float32"), axis=1, )

W0205 14:30:53.767632 145850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:30:53.768489 145850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 3, 3, 159072863],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 3, 3, 159072863],"float32"), axis=1, )

W0205 14:34:33.562426 146615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:34:33.563652 146615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 3, 40, 11930465],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 3, 40, 11930465],"float32"), axis=1, )

W0205 14:38:26.182993 148277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:38:26.183984 148277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 35791395, 40],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 35791395, 40],"float32"), axis=1, )

W0205 14:42:18.259284 150517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:42:18.260159 150517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 40, 11930465, 3],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 40, 11930465, 3],"float32"), axis=1, )

W0205 14:45:54.434620 151299 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:45:54.435492 151299 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 40, 35791395],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 40, 35791395],"float32"), axis=1, )

W0205 14:49:32.227125 151979 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:49:32.228034 151979 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 40, 40, 894785],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 40, 40, 894785],"float32"), axis=1, )

W0205 14:53:24.765640 152743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:53:24.766562 152743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1, 894785, 40, 40],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 1, 894785, 40, 40],"float32"), axis=1, )

W0205 14:57:00.020527 153416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:57:00.021572 153416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1431655765, 1],"float32"), axis=2, )
[Pass] paddle.squeeze(Tensor([3, 1431655765, 1],"float32"), axis=2, )

W0205 15:00:48.631047 154127 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:00:48.632171 154127 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1431655765],"float32"), axis=list[1,], )
[Pass] paddle.squeeze(Tensor([3, 1431655765],"float32"), axis=list[1,], )

W0205 15:04:35.687414 154927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:04:35.688239 154927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 1431655765],"float32"), list[-1,], )
[Pass] paddle.squeeze(Tensor([3, 1431655765],"float32"), list[-1,], )

W0205 15:08:55.711004 155710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:08:55.711814 155710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 2, 2, 178956971],"int64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([3, 2, 2, 178956971],"int64"), axis=-1, )

W0205 15:13:06.757969 156694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:13:06.758797 156694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 2, 357913942, 1],"int64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([3, 2, 357913942, 1],"int64"), axis=-1, )

W0205 15:16:28.206897 157361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:16:28.207800 157361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 2, 715827883],"float32"), axis=2, )
[Pass] paddle.squeeze(Tensor([3, 2, 715827883],"float32"), axis=2, )

W0205 15:19:58.987709 157959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:19:58.988714 157959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 298262, 3, 40, 40],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 298262, 3, 40, 40],"float32"), axis=1, )

W0205 15:24:34.132052 158871 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:24:34.133066 158871 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 298262, 40, 40, 3],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 298262, 40, 40, 3],"float32"), axis=1, )

W0205 15:28:15.656881 159566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:28:15.657919 159566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 357913942, 2, 1],"int64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([3, 357913942, 2, 1],"int64"), axis=-1, )

W0205 15:31:51.781980 160391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:31:51.782821 160391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 894785, 40, 40],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 894785, 40, 40],"float32"), axis=1, )

W0205 15:35:14.754673 161023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:35:14.755548 161023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 99421, 3, 1600, 3],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 99421, 3, 1600, 3],"float32"), axis=1, )

W0205 15:38:50.187232 161725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:38:50.188186 161725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([3, 99421, 3, 3, 1600],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([3, 99421, 3, 3, 1600],"float32"), axis=1, )

W0205 15:42:33.617336 162545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:42:33.618286 162545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([306783379, 7, 1],"float64"), axis=2, )
[Pass] paddle.squeeze(Tensor([306783379, 7, 1],"float64"), axis=2, )

W0205 15:45:51.326030   402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:45:51.326958   402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([357913942, 1, 6],"float64"), axis=1, )
[Pass] paddle.squeeze(Tensor([357913942, 1, 6],"float64"), axis=1, )

W0205 15:48:41.463197  1284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:48:41.464128  1284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([357913942, 12, 1],"float32"), axis=list[2,], )
[Pass] paddle.squeeze(Tensor([357913942, 12, 1],"float32"), axis=list[2,], )

W0205 15:51:59.689249  2044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:51:59.690096  2044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([390451573, 11, 1],"float32"), axis=list[2,], )
[Pass] paddle.squeeze(Tensor([390451573, 11, 1],"float32"), axis=list[2,], )

W0205 15:55:43.989341  3124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:55:43.991015  3124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 1, 536870913],"float64"), axis=1, )
[Pass] paddle.squeeze(Tensor([4, 1, 536870913],"float64"), axis=1, )

W0205 15:59:10.841090  4258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:59:10.842159  4258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 1048577, 512, 1],"float64"), -1, )
[Pass] paddle.squeeze(Tensor([4, 1048577, 512, 1],"float64"), -1, )

W0205 16:02:12.190450  5114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:02:12.191293  5114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 1073741824],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([4, 1073741824],"float32"), axis=1, )

W0205 16:05:26.795323  5822 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:05:26.796129  5822 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 1073741824],"float32"), list[-1,], )
[Pass] paddle.squeeze(Tensor([4, 1073741824],"float32"), list[-1,], )

W0205 16:09:03.582857  6882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:09:03.583762  6882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 512, 1048577, 1],"float64"), -1, )
[Pass] paddle.squeeze(Tensor([4, 512, 1048577, 1],"float64"), -1, )

W0205 16:12:28.962790  8005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:12:28.963985  8005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 512, 512, 2049],"float64"), -1, )
[Pass] paddle.squeeze(Tensor([4, 512, 512, 2049],"float64"), -1, )

W0205 16:15:22.669091  8937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:15:22.670079  8937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 536870913, 1],"float64"), axis=2, )
[Pass] paddle.squeeze(Tensor([4, 536870913, 1],"float64"), axis=2, )

W0205 16:18:44.831360  9904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:18:44.832505  9904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 536870913],"float64"), axis=1, )
[Pass] paddle.squeeze(Tensor([4, 536870913],"float64"), axis=1, )

W0205 16:21:48.010262 10747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:21:48.011149 10747 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 536870913],"int64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([4, 536870913],"int64"), axis=-1, )

W0205 16:24:43.243045 11552 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:24:43.243894 11552 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 7, 76695845],"float64"), axis=2, )
[Pass] paddle.squeeze(Tensor([4, 7, 76695845],"float64"), axis=2, )

W0205 16:28:11.080386 12501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:28:11.081326 12501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4, 89478486, 6],"float64"), axis=1, )
[Pass] paddle.squeeze(Tensor([4, 89478486, 6],"float64"), axis=1, )

W0205 16:31:07.328389 13227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:31:07.329432 13227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4096, 8, 16, 128, 64],"float32"), axis=0, )
[Pass] paddle.squeeze(Tensor([4096, 8, 16, 128, 64],"float32"), axis=0, )

W0205 16:34:19.696756 14054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:34:19.697702 14054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4194304, 1024, 1, 1],"float32"), axis=list[2,3,], )
[Pass] paddle.squeeze(Tensor([4194304, 1024, 1, 1],"float32"), axis=list[2,3,], )

W0205 16:38:04.785804 15043 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:38:04.787230 15043 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4294967295, 1],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([4294967295, 1],"float32"), axis=1, )

W0205 16:42:14.667766 16255 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:42:14.668690 16255 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4294967295, 1],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([4294967295, 1],"float32"), axis=-1, )

W0205 16:45:46.771633 17270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:45:46.772550 17270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4294967295, 1],"float32"), axis=list[1,], )
[Pass] paddle.squeeze(Tensor([4294967295, 1],"float32"), axis=list[1,], )

W0205 16:49:38.910199 18329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:49:38.911743 18329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4294967295, 1],"float32"), list[-1,], )
[Pass] paddle.squeeze(Tensor([4294967295, 1],"float32"), list[-1,], )

W0205 16:53:30.122655 19444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:53:30.123445 19444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4294967295],"float32"), )
[Pass] paddle.squeeze(Tensor([4294967295],"float32"), )

W0205 16:57:23.711481 20486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:57:23.712384 20486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4294967295],"float32"), axis=0, )
[Pass] paddle.squeeze(Tensor([4294967295],"float32"), axis=0, )

W0205 17:01:05.978605 21579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:01:05.979532 21579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4294967295],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([4294967295],"float32"), axis=-1, )

W0205 17:04:42.925670 22540 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:04:42.926823 22540 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([429496730, 1, 10],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([429496730, 1, 10],"float32"), axis=1, )

W0205 17:08:39.481983 23605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:08:39.482964 23605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([429496730, 5],"float64"), )
[Pass] paddle.squeeze(Tensor([429496730, 5],"float64"), )

W0205 17:11:54.241732 24583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:11:54.242869 24583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([429496730, 5],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([429496730, 5],"float64"), axis=-1, )

W0205 17:15:01.352634 25422 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:15:01.353551 25422 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([4294968, 1000, 1, 1],"float32"), axis=list[2,3,], )
[Pass] paddle.squeeze(Tensor([4294968, 1000, 1, 1],"float32"), axis=list[2,3,], )

W0205 17:18:34.545111 26312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:18:34.546572 26312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([429497, 1, 10000],"float32"), )
[Pass] paddle.squeeze(Tensor([429497, 1, 10000],"float32"), )

W0205 17:22:22.000633 27526 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:22:22.001662 27526 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([5, 1, 429496730],"float64"), axis=1, )
[Pass] paddle.squeeze(Tensor([5, 1, 429496730],"float64"), axis=1, )

W0205 17:25:40.287592 28505 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:25:40.288646 28505 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([5, 1, 858993459],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([5, 1, 858993459],"float32"), axis=1, )

W0205 17:28:56.242348 29426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:28:56.243316 29426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([5, 10, 42949673, 1, 2],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([5, 10, 42949673, 1, 2],"float32"), axis=-1, )

W0205 17:32:35.374085 30464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:32:35.374953 30464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([5, 10, 8, 1, 10737419],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([5, 10, 8, 1, 10737419],"float32"), axis=-1, )

W0205 17:36:33.447435 31473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:36:33.449227 31473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([5, 10, 8, 5368710, 2],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([5, 10, 8, 5368710, 2],"float32"), axis=-1, )

W0205 17:40:19.216364 32556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:40:19.217356 32556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([5, 107374183, 4],"float64"), axis=1, )
[Pass] paddle.squeeze(Tensor([5, 107374183, 4],"float64"), axis=1, )

W0205 17:43:35.465063 33535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:43:35.466121 33535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([5, 429496730],"float64"), axis=1, )
[Pass] paddle.squeeze(Tensor([5, 429496730],"float64"), axis=1, )

W0205 17:46:41.380254 34392 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:46:41.381274 34392 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([5, 53687092, 8, 1, 2],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([5, 53687092, 8, 1, 2],"float32"), axis=-1, )

W0205 17:49:59.921298 35306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:49:59.922235 35306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([5, 85899346, 10],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([5, 85899346, 10],"float32"), axis=1, )

W0205 17:53:59.487536 36292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:53:59.488474 36292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([536870912, 1, 8],"float32"), list[1,], )
[Pass] paddle.squeeze(Tensor([536870912, 1, 8],"float32"), list[1,], )

W0205 17:58:00.846760 37459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:58:00.847654 37459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([536870913, 1, 2, 2],"float64"), 1, )
[Pass] paddle.squeeze(Tensor([536870913, 1, 2, 2],"float64"), 1, )

W0205 18:01:18.498545 38424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:01:18.501776 38424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([536870913, 1, 4],"float64"), axis=1, )
[Pass] paddle.squeeze(Tensor([536870913, 1, 4],"float64"), axis=1, )

W0205 18:04:23.110649 39244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:04:23.111577 39244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([536870913, 2, 2, 1],"float64"), -1, )
[Pass] paddle.squeeze(Tensor([536870913, 2, 2, 1],"float64"), -1, )

W0205 18:07:11.310626 40105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:07:11.311498 40105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([536870913, 2, 2, 1],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([536870913, 2, 2, 1],"float64"), axis=-1, )

W0205 18:10:15.122119 40923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:10:15.122979 40923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([536870913, 2, 2, 1],"int64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([536870913, 2, 2, 1],"int64"), axis=-1, )

W0205 18:13:18.056931 42881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:13:18.058035 42881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([67108865, 1, 32],"float64"), axis=list[1,], )
[Pass] paddle.squeeze(Tensor([67108865, 1, 32],"float64"), axis=list[1,], )

W0205 18:16:41.247884 44447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:16:41.248971 44447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([7, 306783379],"float64"), axis=1, )
[Pass] paddle.squeeze(Tensor([7, 306783379],"float64"), axis=1, )

W0205 18:19:53.118638 45332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:19:53.119576 45332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([715827883, 3],"float64"), axis=0, )
[Pass] paddle.squeeze(Tensor([715827883, 3],"float64"), axis=0, )

W0205 18:23:09.358870 46313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:23:09.359812 46313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([715827883, 6, 1, 1],"float32"), list[], )
[accuracy error] paddle.squeeze(Tensor([715827883, 6, 1, 1],"float32"), list[], ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

(shapes (715827883, 6), (715827883, 6, 1, 1) mismatch)
 x: array([[0.487975, 0.734793, 0.93649 , 0.728521, 0.314803, 0.560411],
       [0.245245, 0.169493, 0.575551, 0.617125, 0.595195, 0.709328],
       [0.243962, 0.870537, 0.19225 , 0.313865, 0.832763, 0.375026],...
 y: array([[[[0.487975]],

        [[0.734793]],...

W0205 18:26:35.987516 47200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:26:35.988426 47200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([715827883, 6, 1, 1],"float32"), list[1,2,], )
[Pass] paddle.squeeze(Tensor([715827883, 6, 1, 1],"float32"), list[1,2,], )

W0205 18:28:20.654440 47637 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:28:20.655479 47637 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([71582789, 3, 2, 5],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([71582789, 3, 2, 5],"float64"), axis=-1, )

W0205 18:31:35.604758 48720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:31:35.605675 48720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([715828, 3, 10, 10, 10],"float64"), axis=-1, )
[Pass] paddle.squeeze(Tensor([715828, 3, 10, 10, 10],"float64"), axis=-1, )

W0205 18:34:33.784211 49579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:34:33.785110 49579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([8, 1, 536870912],"float32"), list[1,], )
[Pass] paddle.squeeze(Tensor([8, 1, 536870912],"float32"), list[1,], )

W0205 18:37:59.394215 50435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:37:59.395150 50435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([8, 11, 48806447],"float32"), axis=list[2,], )
[Pass] paddle.squeeze(Tensor([8, 11, 48806447],"float32"), axis=list[2,], )

W0205 18:41:36.106165 51439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:41:36.107050 51439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([8, 12, 44739243],"float32"), axis=list[2,], )
[Pass] paddle.squeeze(Tensor([8, 12, 44739243],"float32"), axis=list[2,], )

W0205 18:45:25.545352 52547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:45:25.546497 52547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([8, 16, 33554432],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([8, 16, 33554432],"float32"), axis=-1, )

W0205 18:49:23.352177 53650 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:49:23.353137 53650 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([8, 536870912, 1],"float32"), axis=-1, )
[Pass] paddle.squeeze(Tensor([8, 536870912, 1],"float32"), axis=-1, )

W0205 18:53:17.522346 54729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:53:17.523249 54729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([8, 536870912, 1],"float32"), axis=list[2,], )
[Pass] paddle.squeeze(Tensor([8, 536870912, 1],"float32"), axis=list[2,], )

W0205 18:56:57.388630 55758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:56:57.389530 55758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([8, 67108864, 8],"float32"), list[1,], )
[Pass] paddle.squeeze(Tensor([8, 67108864, 8],"float32"), list[1,], )

W0205 19:00:33.164085 56771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:00:33.165184 56771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([8193, 512, 512, 1],"float64"), -1, )
[Pass] paddle.squeeze(Tensor([8193, 512, 512, 1],"float64"), -1, )

W0205 19:03:50.146811 57772 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:03:50.147666 57772 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([894785, 1, 3, 40, 40],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([894785, 1, 3, 40, 40],"float32"), axis=1, )

W0205 19:07:12.953294 58587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:07:12.954212 58587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.squeeze(Tensor([894785, 1, 40, 40, 3],"float32"), axis=1, )
[Pass] paddle.squeeze(Tensor([894785, 1, 40, 40, 3],"float32"), axis=1, )

W0205 19:10:59.466534 59697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:10:59.467453 59697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 1, 32],"float16"),Tensor([1, 1, 1, 4294967295],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 1, 32],"float16"),Tensor([1, 1, 1, 4294967295],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 1, 32] at entry 0 and [1, 1, 1, 4294967295] at entry 1

W0205 19:14:57.282739 60708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:14:57.283918 60708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 1, 32],"float16"),Tensor([1, 1, 134217728, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 1, 32],"float16"),Tensor([1, 1, 134217728, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 1, 32] at entry 0 and [1, 1, 134217728, 32] at entry 1

W0205 19:16:19.313158 61155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:16:19.314463 61155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 1, 32],"float16"),Tensor([1, 134217728, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 1, 32],"float16"),Tensor([1, 134217728, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 1, 32] at entry 0 and [1, 134217728, 1, 32] at entry 1

W0205 19:17:44.043973 61568 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:17:44.045074 61568 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 1, 32],"float16"),Tensor([134217728, 1, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 1, 32],"float16"),Tensor([134217728, 1, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 1, 32] at entry 0 and [134217728, 1, 1, 32] at entry 1

W0205 19:19:13.802160 61994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:19:13.803393 61994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 1, 4294967295],"float16"),Tensor([1, 1, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 1, 4294967295],"float16"),Tensor([1, 1, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 1, 4294967295] at entry 0 and [1, 1, 1, 32] at entry 1

W0205 19:20:38.048341 62426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:20:38.049613 62426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 1, 4294967295],"float16"),Tensor([1, 1, 1, 4294967295],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([1, 1, 1, 4294967295],"float16"),Tensor([1, 1, 1, 4294967295],"float16"),], axis=-1, )

W0205 19:23:37.234483 62840 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:23:37.235337 62840 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 134217728, 32],"float16"),Tensor([1, 1, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 134217728, 32],"float16"),Tensor([1, 1, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 134217728, 32] at entry 0 and [1, 1, 1, 32] at entry 1

W0205 19:40:52.676704 68185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:40:52.678085 68185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 134217728, 32],"float16"),Tensor([1, 1, 134217728, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([1, 1, 134217728, 32],"float16"),Tensor([1, 1, 134217728, 32],"float16"),], axis=-1, )

W0205 19:43:48.730631 68517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:43:48.731462 68517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 134217728, 32],"float16"),Tensor([1, 1, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 134217728, 32],"float16"),Tensor([1, 1, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 134217728, 32] at entry 0 and [1, 1, 64, 32] at entry 1

W0205 20:01:10.441061 73897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:01:10.442134 73897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 64, 32],"float16"),Tensor([1, 1, 134217728, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 64, 32],"float16"),Tensor([1, 1, 134217728, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 64, 32] at entry 0 and [1, 1, 134217728, 32] at entry 1

W0205 20:02:38.153654 74342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:02:38.154870 74342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 64, 32],"float16"),Tensor([1, 1, 64, 67108864],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 64, 32],"float16"),Tensor([1, 1, 64, 67108864],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 64, 32] at entry 0 and [1, 1, 64, 67108864] at entry 1

W0205 20:04:05.732692 74773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:04:05.733912 74773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 64, 32],"float16"),Tensor([1, 2097152, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 64, 32],"float16"),Tensor([1, 2097152, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 64, 32] at entry 0 and [1, 2097152, 64, 32] at entry 1

W0205 20:05:30.735271 75198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:05:30.736380 75198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 64, 32],"float16"),Tensor([2097152, 1, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 64, 32],"float16"),Tensor([2097152, 1, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 64, 32] at entry 0 and [2097152, 1, 64, 32] at entry 1

W0205 20:06:57.792070 75621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:06:57.793223 75621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 64, 67108864],"float16"),Tensor([1, 1, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 1, 64, 67108864],"float16"),Tensor([1, 1, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 1, 64, 67108864] at entry 0 and [1, 1, 64, 32] at entry 1

W0205 20:08:28.562229 75959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:08:28.564167 75959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1, 64, 67108864],"float16"),Tensor([1, 1, 64, 67108864],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([1, 1, 64, 67108864],"float16"),Tensor([1, 1, 64, 67108864],"float16"),], axis=-1, )

W0205 20:11:18.071310 76478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:11:18.072180 76478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1],"float32"),Tensor([1, 4294967295],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([1, 1],"float32"),Tensor([1, 4294967295],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [1, 1] at entry 0 and [1, 4294967295] at entry 1

W0205 20:28:13.007534 81691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:28:13.008756 81691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1],"float32"),Tensor([4294967295, 1],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([1, 1],"float32"),Tensor([4294967295, 1],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [1, 1] at entry 0 and [4294967295, 1] at entry 1

W0205 20:29:26.138164 81994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:29:26.139459 81994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1048576, 4096],"float32"),Tensor([1, 1048576, 4096],"float32"),], axis=0, )
[paddle error] paddle.stack(list[Tensor([1, 1048576, 4096],"float32"),Tensor([1, 1048576, 4096],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:31:48.755877 82319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:31:48.756803 82319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 1048576, 4096],"float32"),Tensor([1, 300, 4096],"float32"),], axis=0, )
[torch error] paddle.stack(list[Tensor([1, 1048576, 4096],"float32"),Tensor([1, 300, 4096],"float32"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [1, 1048576, 4096] at entry 0 and [1, 300, 4096] at entry 1

W0205 20:33:07.051868 83035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:33:07.053030 83035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 128, 33554432],"float32"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([1, 128, 33554432],"float32"),], axis=-1, )

W0205 20:34:28.131640 83459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:34:28.132671 83459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 134217728, 1, 32],"float16"),Tensor([1, 1, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 134217728, 1, 32],"float16"),Tensor([1, 1, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 134217728, 1, 32] at entry 0 and [1, 1, 1, 32] at entry 1

W0205 20:38:26.366890 84484 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:38:26.368525 84484 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 134217728, 1, 32],"float16"),Tensor([1, 134217728, 1, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([1, 134217728, 1, 32],"float16"),Tensor([1, 134217728, 1, 32],"float16"),], axis=-1, )

W0205 20:41:23.600472 84927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:41:23.601505 84927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 134217728, 32],"float32"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([1, 134217728, 32],"float32"),], axis=-1, )

W0205 20:58:16.455533 90220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:58:16.456652 90220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:03:18.655970 91352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:03:18.658629 91352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 134217728, 8, 4] at entry 0 and [1, 2, 8, 4] at entry 1

W0205 21:04:32.264263 92065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:04:32.265364 92065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 134217728, 8, 4] at entry 0 and [1, 4, 8, 4] at entry 1

W0205 21:05:49.603396 92484 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:05:49.604552 92484 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1073741825],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1073741825],"float64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 1] at entry 0 and [1, 2, 1073741825] at entry 2

W0205 21:06:43.538024 92809 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:06:43.539291 92809 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 1] at entry 0 and [1, 2147483649, 1] at entry 2

W0205 21:07:39.518541 93097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:07:39.519954 93097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 1] at entry 0 and [1073741825, 2, 1] at entry 2

W0205 21:08:28.966390 93403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:08:28.967738 93403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 1] at entry 0 and [1, 2, 1073741825] at entry 1

W0205 21:09:22.203104 93677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:09:22.204188 93677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 1] at entry 0 and [1, 2147483649, 1] at entry 1

W0205 21:10:11.477072 93880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:10:11.478166 93880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 1] at entry 0 and [1073741825, 2, 1] at entry 1

W0205 21:11:00.303388 94151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:11:00.304623 94151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 1073741825] at entry 0 and [1, 2, 1] at entry 1

W0205 21:11:58.015678 94443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:11:58.016634 94443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1073741825],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1073741825],"float64"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 56949 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:14:12.947028 94653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:14:12.952320 94653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 536870912, 4],"float32"),Tensor([1, 2, 536870912, 4],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([1, 2, 536870912, 4],"float32"),Tensor([1, 2, 536870912, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:16:44.786792 95356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:16:44.787632 95356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 536870912, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 536870912, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 536870912, 4] at entry 0 and [1, 2, 8, 4] at entry 1

W0205 21:17:54.740994 96086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:17:54.742163 96086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 8, 268435456],"float32"),Tensor([1, 2, 8, 268435456],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([1, 2, 8, 268435456],"float32"),Tensor([1, 2, 8, 268435456],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:20:28.096494 96421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:20:28.097301 96421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 8, 268435456],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 8, 268435456],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 8, 268435456] at entry 0 and [1, 2, 8, 4] at entry 1

W0205 21:21:41.339589 97145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:21:41.340747 97145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 8, 4] at entry 0 and [1, 134217728, 8, 4] at entry 1

W0205 21:22:51.258306 97539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:22:51.259470 97539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 2, 536870912, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 2, 536870912, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 8, 4] at entry 0 and [1, 2, 536870912, 4] at entry 1

W0205 21:24:16.355307 97852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:24:16.356480 97852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 2, 8, 268435456],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 2, 8, 268435456],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 8, 4] at entry 0 and [1, 2, 8, 268435456] at entry 1

W0205 21:25:27.952665 98276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:25:27.953783 98276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2, 8, 4],"float32"),Tensor([67108864, 2, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2, 8, 4],"float32"),Tensor([67108864, 2, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2, 8, 4] at entry 0 and [67108864, 2, 8, 4] at entry 1

W0205 21:26:37.929469 98598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:26:37.930518 98598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2],"float32"),Tensor([1, 4294967295],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([1, 2],"float32"),Tensor([1, 4294967295],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [1, 2] at entry 0 and [1, 4294967295] at entry 1

W0205 21:27:48.472370 98999 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:27:48.473480 98999 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2],"float32"),Tensor([2147483648, 2],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([1, 2],"float32"),Tensor([2147483648, 2],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [1, 2] at entry 0 and [2147483648, 2] at entry 1

W0205 21:29:04.829949 99312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:29:04.831238 99312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2097152, 64, 32],"float16"),Tensor([1, 1, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2097152, 64, 32],"float16"),Tensor([1, 1, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2097152, 64, 32] at entry 0 and [1, 1, 64, 32] at entry 1

W0205 21:30:30.866410 99731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:30:30.868125 99731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2097152, 64, 32],"float16"),Tensor([1, 2097152, 64, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([1, 2097152, 64, 32],"float16"),Tensor([1, 2097152, 64, 32],"float16"),], axis=-1, )

W0205 21:33:13.899039 100135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:33:13.899959 100135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 2147483649, 1] at entry 0 and [1, 2, 1] at entry 1

W0205 21:50:22.271327 105509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:50:22.272625 105509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 90301 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:52:25.746443 105707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:52:25.747574 105707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, )
[paddle error] paddle.stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:54:10.623164 106295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:54:10.623989 106295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 1170 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:57:33.100610 106836 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:57:33.101563 106836 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [1, 2147483649] at entry 0 and [1, 32] at entry 1

W0205 21:58:27.163838 107835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:58:27.164881 107835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 2147483649] at entry 0 and [1, 32] at entry 1

W0205 21:59:22.141497 108024 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:59:22.189287 108024 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 300, 14316558],"float32"),Tensor([1, 300, 14316558],"float32"),], axis=0, )
[paddle error] paddle.stack(list[Tensor([1, 300, 14316558],"float32"),Tensor([1, 300, 14316558],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:01:47.756536 108298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:01:47.759021 108298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 300, 14316558],"float32"),Tensor([1, 300, 4096],"float32"),], axis=0, )
[torch error] paddle.stack(list[Tensor([1, 300, 14316558],"float32"),Tensor([1, 300, 4096],"float32"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [1, 300, 14316558] at entry 0 and [1, 300, 4096] at entry 1

W0205 22:03:00.705870 108994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:03:00.707026 108994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 300, 4096],"float32"),Tensor([1, 1048576, 4096],"float32"),], axis=0, )
[torch error] paddle.stack(list[Tensor([1, 300, 4096],"float32"),Tensor([1, 1048576, 4096],"float32"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [1, 300, 4096] at entry 0 and [1, 1048576, 4096] at entry 1

W0205 22:04:11.899492 109397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:04:11.900542 109397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 300, 4096],"float32"),Tensor([1, 300, 14316558],"float32"),], axis=0, )
[torch error] paddle.stack(list[Tensor([1, 300, 4096],"float32"),Tensor([1, 300, 14316558],"float32"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [1, 300, 4096] at entry 0 and [1, 300, 14316558] at entry 1

W0205 22:05:24.369230 109724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:05:24.370946 109724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 300, 4096],"float32"),Tensor([3496, 300, 4096],"float32"),], axis=0, )
[torch error] paddle.stack(list[Tensor([1, 300, 4096],"float32"),Tensor([3496, 300, 4096],"float32"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [1, 300, 4096] at entry 0 and [3496, 300, 4096] at entry 1

W0205 22:06:39.084111 110038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:06:39.085285 110038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [1, 2147483649] at entry 1

W0205 22:07:28.376641 110443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:07:28.377782 110443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [1, 2147483649] at entry 1

W0205 22:08:16.344846 110639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:08:16.346297 110639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [1, 2147483649] at entry 2

W0205 22:09:08.948239 110922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:09:08.949268 110922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [1, 2147483649] at entry 3

W0205 22:10:03.017222 111191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:10:03.018512 111191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [1, 2147483649] at entry 4

W0205 22:10:53.696274 111499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:10:53.697341 111499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [1, 2147483649] at entry 5

W0205 22:11:44.404536 111699 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:11:44.405562 111699 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [1, 2147483649] at entry 6

W0205 22:12:33.655540 111977 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:12:33.656590 111977 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [1, 2147483649] at entry 7

W0205 22:13:22.008776 112233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:13:22.010064 112233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [1, 2147483649] at entry 8

W0205 22:14:14.717172 112417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:14:14.718451 112417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 2147483649],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [1, 2147483649] at entry 9

W0205 22:15:06.301280 112705 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:15:06.302510 112705 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [67108865, 32] at entry 9

W0205 22:16:01.086972 112973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:16:01.088060 112973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [67108865, 32] at entry 8

W0205 22:16:52.138576 113264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:16:52.139875 113264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [67108865, 32] at entry 7

W0205 22:17:40.773972 113460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:17:40.775404 113460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [67108865, 32] at entry 6

W0205 22:18:34.056595 113716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:18:34.057819 113716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [67108865, 32] at entry 5

W0205 22:19:27.727312 114001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:19:27.728464 114001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [67108865, 32] at entry 4

W0205 22:20:33.259436 114191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:20:33.260535 114191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [67108865, 32] at entry 3

W0205 22:21:25.372874 114581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:21:25.374138 114581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [67108865, 32] at entry 2

W0205 22:22:13.266170 114777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:22:13.267343 114777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [67108865, 32] at entry 1

W0205 22:23:04.888417 115055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:23:04.889772 115055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1, 32] at entry 0 and [67108865, 32] at entry 1

W0205 22:23:59.242811 115328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:23:59.244056 115328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4, 268435456, 4],"float32"),Tensor([1, 4, 268435456, 4],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([1, 4, 268435456, 4],"float32"),Tensor([1, 4, 268435456, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:26:28.641623 115601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:26:28.642455 115601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4, 268435456, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 4, 268435456, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 4, 268435456, 4] at entry 0 and [1, 4, 8, 4] at entry 1

W0205 22:27:37.722896 116227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:27:37.723987 116227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4, 8, 134217728],"float32"),Tensor([1, 4, 8, 134217728],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([1, 4, 8, 134217728],"float32"),Tensor([1, 4, 8, 134217728],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:30:06.985858 116625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:30:06.988131 116625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4, 8, 134217728],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 4, 8, 134217728],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 4, 8, 134217728] at entry 0 and [1, 4, 8, 4] at entry 1

W0205 22:31:18.083724 117332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:31:18.084931 117332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 4, 8, 4] at entry 0 and [1, 134217728, 8, 4] at entry 1

W0205 22:32:27.021742 117658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:32:27.022958 117658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 4, 268435456, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 4, 268435456, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 4, 8, 4] at entry 0 and [1, 4, 268435456, 4] at entry 1

W0205 22:33:40.323601 117959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:33:40.324697 117959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 4, 8, 134217728],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 4, 8, 134217728],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 4, 8, 4] at entry 0 and [1, 4, 8, 134217728] at entry 1

W0205 22:34:52.769656 118356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:34:52.770794 118356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1, 4, 8, 4] at entry 0 and [33554432, 4, 8, 4] at entry 1

W0205 22:36:07.486702 118670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:36:07.487778 118670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4294967295],"float32"),], axis=0, )
[Pass] paddle.stack(list[Tensor([1, 4294967295],"float32"),], axis=0, )

W0205 22:37:31.838219 119076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:37:31.839064 119076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4294967295],"float32"),Tensor([1, 1],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([1, 4294967295],"float32"),Tensor([1, 1],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [1, 4294967295] at entry 0 and [1, 1] at entry 1

W0205 22:41:12.381424 119817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:41:12.382465 119817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4294967295],"float32"),Tensor([1, 2],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([1, 4294967295],"float32"),Tensor([1, 2],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [1, 4294967295] at entry 0 and [1, 2] at entry 1

W0205 22:42:28.028729 120132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:42:28.029780 120132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1, 4294967295],"float32"),Tensor([1, 4294967295],"float32"),], -1, )
[paddle error] paddle.stack(list[Tensor([1, 4294967295],"float32"),Tensor([1, 4294967295],"float32"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:45:01.005097 120349 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:45:01.006003 120349 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 11

W0205 22:46:23.517868 120868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:46:23.519052 120868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 10

W0205 22:47:46.936728 121184 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:47:46.937937 121184 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 9

W0205 22:49:09.313007 121500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:49:09.314328 121500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 8

W0205 22:50:34.332595 121790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:50:34.333734 121790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 7

W0205 22:51:57.396064 122094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:51:57.397240 122094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 6

W0205 22:53:21.625734 122339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:53:21.626901 122339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 5

W0205 22:54:53.310568 122642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:54:53.311868 122642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 5

W0205 22:56:15.252714 122960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:56:15.253906 122960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 4

W0205 22:57:45.917004 123275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:57:45.918154 123275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 4

W0205 22:59:08.598728 123593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:59:08.599804 123593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 3

W0205 23:00:38.268963 123895 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:00:38.270169 123895 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 3

W0205 23:02:03.179271 124200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:02:03.180460 124200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 2

W0205 23:03:34.080335 124517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:03:34.081559 124517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 2

W0205 23:05:03.489542 124835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:05:03.490684 124835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([4294967295],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([4294967295],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0205 23:06:33.672936 125151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:06:33.674331 125151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0205 23:08:03.835846 125455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:08:03.837286 125455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([1],"float16"),Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0205 23:09:26.450745 125759 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:09:26.451946 125759 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 12

W0205 23:10:45.264597 126004 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:10:45.265781 126004 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 11

W0205 23:11:56.020823 126309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:11:56.021947 126309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 11

W0205 23:13:06.351912 126539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:13:06.353003 126539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 10

W0205 23:14:22.572063 126842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:14:22.573184 126842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 10

W0205 23:15:42.119745 127047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:15:42.120867 127047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 10

W0205 23:17:05.229938 127362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:17:05.231138 127362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 9

W0205 23:18:30.620955 127667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:18:30.622290 127667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 9

W0205 23:19:41.949489 127970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:19:41.950592 127970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 9

W0205 23:20:59.790196 128202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:20:59.791394 128202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 9

W0205 23:22:10.731755 128506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:22:10.732879 128506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 8

W0205 23:23:21.625887 128725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:23:21.627100 128725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 8

W0205 23:24:31.594914 128956 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:24:31.596149 128956 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 8

W0205 23:25:44.823525 129260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:25:44.825110 129260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 8

W0205 23:26:55.909333 129463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:26:55.910413 129463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 7

W0205 23:28:09.920317 129693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:28:09.921597 129693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 7

W0205 23:29:22.387477 129995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:29:22.388782 129995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 7

W0205 23:30:36.391887 130213 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:30:36.393492 130213 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 7

W0205 23:31:56.133106 130516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:31:56.134670 130516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 6

W0205 23:33:13.101136 130734 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:33:13.102562 130734 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 6

W0205 23:34:26.356812 131049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:34:26.358062 131049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 6

W0205 23:35:39.777768 131266 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:35:39.779254 131266 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 6

W0205 23:36:53.653015 131569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:36:53.654183 131569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 5

W0205 23:38:09.105906 131787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:38:09.107108 131787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 5

W0205 23:39:25.882146 132112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:39:25.883440 132112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 5

W0205 23:40:44.029654 132334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:40:44.030791 132334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 5

W0205 23:42:01.306139 132636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:42:01.307293 132636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 5

W0205 23:43:17.496289 132957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:43:17.497501 132957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 4

W0205 23:44:29.198752 133175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:44:29.199937 133175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 4

W0205 23:45:46.841513 133477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:45:46.842744 133477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 4

W0205 23:46:57.386178 133710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:46:57.387293 133710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 4

W0205 23:48:13.257503 133914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:48:13.258600 133914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 4

W0205 23:49:27.044023 134216 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:49:27.045220 134216 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 3

W0205 23:50:37.736038 134444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:50:37.737131 134444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 3

W0205 23:51:54.389636 134751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:51:54.390822 134751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 3

W0205 23:53:16.984830 134955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:53:16.985996 134955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 3

W0205 23:54:28.091775 135257 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:54:28.092861 135257 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 3

W0205 23:55:46.987622 135461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:55:46.988794 135461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 2

W0205 23:57:03.842257 135762 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:57:03.843348 135762 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 2

W0205 23:58:22.184283 136051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:58:22.185478 136051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 2

W0205 23:59:40.150571 136269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:59:40.151721 136269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 2

W0206 00:00:48.856740 136572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:00:48.858012 136572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 2

W0206 00:02:01.532244 136789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:02:01.533547 136789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 2

W0206 00:03:16.870960 137095 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:03:16.872138 137095 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0206 00:04:29.412405 137298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:04:29.413746 137298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),], 1, )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),], 1, ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0206 00:05:40.903823 137501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:05:40.905097 137501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0206 00:06:58.321722 137803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:06:58.322988 137803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0206 00:08:29.826395 138008 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:08:29.827947 138008 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0206 00:09:41.008760 138396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:09:41.009855 138396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0206 00:10:56.749456 138616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:10:56.750635 138616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0206 00:12:12.028401 138834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:12:12.029543 138834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0206 00:13:22.321190 139151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:13:22.322253 139151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [4294967295] at entry 1

W0206 00:14:39.502123 139369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:14:39.503383 139369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [2147483649] at entry 1

W0206 00:15:33.741344 139672 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:15:33.742578 139672 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"int64"),Tensor([2147483649],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([1],"int64"),Tensor([2147483649],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [2147483649] at entry 1

W0206 00:16:23.267014 139901 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:16:23.268246 139901 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1],"int64"),Tensor([2147483649],"int64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([1],"int64"),Tensor([2147483649],"int64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [1] at entry 0 and [2147483649] at entry 1

W0206 00:17:09.970984 140019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:17:09.972040 140019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([10, 10, 10],"float64"),Tensor([10, 10, 21474837],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([10, 10, 10],"float64"),Tensor([10, 10, 21474837],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [10, 10, 10] at entry 0 and [10, 10, 21474837] at entry 1

W0206 00:18:02.518083 140251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:18:02.519218 140251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([10, 10, 10],"float64"),Tensor([10, 21474837, 10],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([10, 10, 10],"float64"),Tensor([10, 21474837, 10],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [10, 10, 10] at entry 0 and [10, 21474837, 10] at entry 1

W0206 00:18:50.799510 140441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:18:50.800693 140441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([10, 10, 10],"float64"),Tensor([21474837, 10, 10],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([10, 10, 10],"float64"),Tensor([21474837, 10, 10],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [10, 10, 10] at entry 0 and [21474837, 10, 10] at entry 1

W0206 00:19:42.770403 140583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:19:42.771867 140583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([10, 10, 21474837],"float64"),Tensor([10, 10, 10],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([10, 10, 21474837],"float64"),Tensor([10, 10, 10],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [10, 10, 21474837] at entry 0 and [10, 10, 10] at entry 1

W0206 00:20:32.085974 140787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:20:32.087157 140787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([10, 10, 21474837],"float64"),Tensor([10, 10, 21474837],"float64"),], -1, )
[paddle error] paddle.stack(list[Tensor([10, 10, 21474837],"float64"),Tensor([10, 10, 21474837],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 00:22:14.737722 140975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:22:14.738595 140975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([10, 21474837, 10],"float64"),Tensor([10, 10, 10],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([10, 21474837, 10],"float64"),Tensor([10, 10, 10],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [10, 21474837, 10] at entry 0 and [10, 10, 10] at entry 1

W0206 00:23:09.791621 141278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:23:09.793037 141278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([10, 21474837, 10],"float64"),Tensor([10, 21474837, 10],"float64"),], -1, )
[paddle error] paddle.stack(list[Tensor([10, 21474837, 10],"float64"),Tensor([10, 21474837, 10],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 00:25:01.703238 141479 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:25:01.704119 141479 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([10],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([10],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [10] at entry 0 and [4294967295] at entry 1

W0206 00:26:16.434513 141870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:26:16.435596 141870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([10],"float32"),Tensor([4294967295],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([10],"float32"),Tensor([4294967295],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [10] at entry 0 and [4294967295] at entry 1

W0206 00:27:32.880386 142074 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:27:32.881605 142074 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1048576, 128, 32],"float32"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([1048576, 128, 32],"float32"),], axis=-1, )

W0206 00:28:56.866637 142377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:28:56.867473 142377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1048576, 2, 64, 32],"float16"),Tensor([1048576, 2, 64, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([1048576, 2, 64, 32],"float16"),Tensor([1048576, 2, 64, 32],"float16"),], axis=-1, )

W0206 00:34:16.534276 143061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:34:16.535661 143061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1048576, 2, 64, 32],"float16"),Tensor([2, 2, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1048576, 2, 64, 32],"float16"),Tensor([2, 2, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1048576, 2, 64, 32] at entry 0 and [2, 2, 64, 32] at entry 1

W0206 00:51:36.441125 146192 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:51:36.442077 146192 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1073741825, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1073741825, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [1073741825, 2, 1] at entry 0 and [1, 2, 1] at entry 1

W0206 00:52:25.541819 146236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:52:25.543100 146236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([1073741825, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([1073741825, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 11915 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:54:35.958501 146277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:54:35.959647 146277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([11184811, 6, 8, 8],"float32"),Tensor([11184811, 6, 8, 8],"float32"),Tensor([11184811, 6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([11184811, 6, 8, 8],"float32"),Tensor([11184811, 6, 8, 8],"float32"),Tensor([11184811, 6, 8, 8],"float32"),], axis=-4, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 58871 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:57:48.355497 146334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:57:48.356590 146334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([11184811, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([11184811, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [11184811, 6, 8, 8] at entry 0 and [2, 6, 8, 8] at entry 1

W0206 00:59:01.529547 146448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:59:01.530885 146448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 14

W0206 01:00:16.540166 146493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:00:16.541309 146493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 13

W0206 01:01:39.273319 146531 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:01:39.274654 146531 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 12

W0206 01:02:55.519548 146591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:02:55.520759 146591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 11

W0206 01:04:10.471921 146646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:04:10.473106 146646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 10

W0206 01:05:22.438508 146688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:05:22.439571 146688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 9

W0206 01:06:39.939352 146717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:06:39.940649 146717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 8

W0206 01:07:57.169790 146772 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:07:57.171018 146772 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 8

W0206 01:09:07.642984 146814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:09:07.643962 146814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 7

W0206 01:10:29.108069 146843 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:10:29.109618 146843 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 7

W0206 01:11:52.349913 146885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:11:52.351322 146885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 6

W0206 01:13:03.752575 146942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:13:03.753786 146942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 6

W0206 01:14:19.007570 146985 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:14:19.008787 146985 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 5

W0206 01:15:30.456954 147027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:15:30.458154 147027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 5

W0206 01:16:43.326763 147081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:16:43.327967 147081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 4

W0206 01:18:01.743394 147124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:18:01.744602 147124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 4

W0206 01:19:12.911798 147166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:19:12.913019 147166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 3

W0206 01:20:30.468816 147223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:20:30.469906 147223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 3

W0206 01:21:46.102182 147265 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:21:46.103426 147265 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 2

W0206 01:22:56.286563 147307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:22:56.287699 147307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 2

W0206 01:24:08.170455 147363 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:24:08.171669 147363 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 1

W0206 01:25:20.696918 147406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:25:20.698241 147406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([12],"float32"),Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [12] at entry 0 and [4294967295] at entry 1

W0206 01:26:36.212850 147448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:26:36.214138 147448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([120],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([120],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [120] at entry 0 and [4294967295] at entry 1

W0206 01:27:55.466560 147504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:27:55.467725 147504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 128],"float32"),Tensor([128, 33554432],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([128, 128],"float32"),Tensor([128, 33554432],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [128, 128] at entry 0 and [128, 33554432] at entry 1

W0206 01:29:06.950338 147547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:29:06.951467 147547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 128],"float32"),Tensor([33554432, 128],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([128, 128],"float32"),Tensor([33554432, 128],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [128, 128] at entry 0 and [33554432, 128] at entry 1

W0206 01:30:36.182341 147589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:30:36.183655 147589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 33554432],"float16"),Tensor([128, 33554432],"float16"),Tensor([128, 33554432],"float16"),], axis=1, )
[paddle error] paddle.stack(list[Tensor([128, 33554432],"float16"),Tensor([128, 33554432],"float16"),Tensor([128, 33554432],"float16"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_stack(_object*, _object*, _object*)
1   stack_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
2   paddle::experimental::stack(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
3   void phi::funcs::StackRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, int, phi::DenseTensor*)
4   void phi::funcs::LaunchStackKernel<phi::GPUContext, phi::dtype::float16, long, (phi::funcs::SegmentedArraySize)4>(phi::GPUContext const&, long, long, long, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, phi::DenseTensor*)
5   phi::dtype::float16* phi::DeviceContext::Alloc<phi::dtype::float16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 24.000000GB memory on GPU 0, 73.584900GB memory has been allocated and available memory is only 5.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:34:38.311818 147658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:34:38.312629 147658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 33554432],"float16"),Tensor([128, 512],"float16"),Tensor([128, 512],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 33554432],"float16"),Tensor([128, 512],"float16"),Tensor([128, 512],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [128, 33554432] at entry 0 and [128, 512] at entry 1

W0206 01:36:14.660656 147771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:36:14.661531 147771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 33554432],"float32"),Tensor([128, 128],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([128, 33554432],"float32"),Tensor([128, 128],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [128, 33554432] at entry 0 and [128, 128] at entry 1

W0206 01:37:31.576453 147813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:37:31.577555 147813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 33554432],"float32"),Tensor([128, 33554432],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([128, 33554432],"float32"),Tensor([128, 33554432],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:39:52.983486 147855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:39:52.986126 147855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 33554432],"int32"),Tensor([128, 33554432],"int32"),Tensor([128, 33554432],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 33554432],"int32"),Tensor([128, 33554432],"int32"),Tensor([128, 33554432],"int32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 91867 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:43:12.555883 147939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:43:12.556973 147939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 33554432],"int32"),Tensor([128, 512],"int32"),Tensor([128, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 33554432],"int32"),Tensor([128, 512],"int32"),Tensor([128, 512],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [128, 33554432] at entry 0 and [128, 512] at entry 1

W0206 01:44:26.321455 148051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:44:26.322425 148051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 512],"float16"),Tensor([128, 33554432],"float16"),Tensor([128, 512],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 512],"float16"),Tensor([128, 33554432],"float16"),Tensor([128, 512],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [128, 512] at entry 0 and [128, 33554432] at entry 1

W0206 01:45:53.728137 148092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:45:53.729173 148092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 512],"float16"),Tensor([128, 512],"float16"),Tensor([128, 33554432],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 512],"float16"),Tensor([128, 512],"float16"),Tensor([128, 33554432],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [128, 512] at entry 0 and [128, 33554432] at entry 2

W0206 01:47:17.803535 148134 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:47:17.804826 148134 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 512],"float16"),Tensor([128, 512],"float16"),Tensor([8388608, 512],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 512],"float16"),Tensor([128, 512],"float16"),Tensor([8388608, 512],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [128, 512] at entry 0 and [8388608, 512] at entry 2

W0206 01:48:47.920488 148189 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:48:47.921675 148189 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 512],"float16"),Tensor([8388608, 512],"float16"),Tensor([128, 512],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 512],"float16"),Tensor([8388608, 512],"float16"),Tensor([128, 512],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [128, 512] at entry 0 and [8388608, 512] at entry 1

W0206 01:50:17.854122 148232 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:50:17.855108 148232 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 512],"int32"),Tensor([128, 33554432],"int32"),Tensor([128, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 512],"int32"),Tensor([128, 33554432],"int32"),Tensor([128, 512],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [128, 512] at entry 0 and [128, 33554432] at entry 1

W0206 01:51:36.129351 148275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:51:36.130570 148275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 512],"int32"),Tensor([128, 512],"int32"),Tensor([128, 33554432],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 512],"int32"),Tensor([128, 512],"int32"),Tensor([128, 33554432],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [128, 512] at entry 0 and [128, 33554432] at entry 2

W0206 01:52:54.663259 148333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:52:54.664501 148333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 512],"int32"),Tensor([128, 512],"int32"),Tensor([8388608, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 512],"int32"),Tensor([128, 512],"int32"),Tensor([8388608, 512],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [128, 512] at entry 0 and [8388608, 512] at entry 2

W0206 01:54:22.592900 148375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:54:22.593917 148375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([128, 512],"int32"),Tensor([8388608, 512],"int32"),Tensor([128, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([128, 512],"int32"),Tensor([8388608, 512],"int32"),Tensor([128, 512],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [128, 512] at entry 0 and [8388608, 512] at entry 1

W0206 01:55:41.235745 148417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:55:41.236814 148417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([134217728, 1, 1, 32],"float16"),Tensor([1, 1, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([134217728, 1, 1, 32],"float16"),Tensor([1, 1, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [134217728, 1, 1, 32] at entry 0 and [1, 1, 1, 32] at entry 1

W0206 01:57:06.159823 148473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:57:06.160879 148473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([134217728, 1, 1, 32],"float16"),Tensor([134217728, 1, 1, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([134217728, 1, 1, 32],"float16"),Tensor([134217728, 1, 1, 32],"float16"),], axis=-1, )

W0206 02:00:04.335848 148514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:00:04.337075 148514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([134217728, 1, 8, 4],"float32"),Tensor([134217728, 1, 8, 4],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([134217728, 1, 8, 4],"float32"),Tensor([134217728, 1, 8, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:17:50.722379 149020 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:17:50.723359 149020 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([134217728, 1, 8, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([134217728, 1, 8, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [134217728, 1, 8, 4] at entry 0 and [2, 1, 8, 4] at entry 1

W0206 02:19:00.554371 149076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:19:00.555505 149076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([134217728, 32],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 120706 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:24:28.329039 149117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:24:28.330193 149117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [134217728, 32] at entry 0 and [4, 32] at entry 1

W0206 02:25:43.398037 149258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:25:43.399101 149258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([134217729, 16],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 101548 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:29:12.959326 149300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:29:12.960441 149300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [134217729, 16] at entry 0 and [4, 16] at entry 1

W0206 02:30:08.017570 149397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:30:08.018654 149397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 11

W0206 02:31:18.970016 149426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:31:18.971063 149426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 10

W0206 02:32:30.543347 149455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:32:30.544441 149455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 9

W0206 02:33:49.949381 149497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:33:49.950618 149497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 8

W0206 02:35:01.931919 149538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:35:01.933107 149538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 7

W0206 02:36:18.440963 149580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:36:18.442227 149580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 6

W0206 02:37:30.237697 149635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:37:30.238847 149635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 5

W0206 02:38:39.958930 149677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:38:39.960060 149677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 4

W0206 02:39:53.613404 149719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:39:53.614912 149719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 3

W0206 02:41:03.847421 149775 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:41:03.848608 149775 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 2

W0206 02:42:13.655783 149817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:42:13.656937 149817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([15],"float32"),Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [15] at entry 0 and [4294967295] at entry 1

W0206 02:43:24.717972 149872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:43:24.719028 149872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 148032 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:46:41.482194 149928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:46:41.483270 149928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([153391690, 28],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 63084 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:52:00.558559 150028 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:52:00.559687 150028 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [153391690, 28] at entry 0 and [28, 28] at entry 1

W0206 02:53:12.450572 150211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:53:12.451814 150211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [153391690, 28] at entry 0 and [28, 28] at entry 1

W0206 02:54:25.145334 150267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:54:25.146319 150267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([16],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([16],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [16] at entry 0 and [4294967295] at entry 1

W0206 02:55:41.724323 150323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:55:41.725455 150323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([16777216, 8, 1, 32],"float16"),Tensor([16777216, 8, 1, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([16777216, 8, 1, 32],"float16"),Tensor([16777216, 8, 1, 32],"float16"),], axis=-1, )

W0206 02:58:26.575062 150379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:58:26.575892 150379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([16777216, 8, 1, 32],"float16"),Tensor([2, 8, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([16777216, 8, 1, 32],"float16"),Tensor([2, 8, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [16777216, 8, 1, 32] at entry 0 and [2, 8, 1, 32] at entry 1

W0206 03:15:27.773757 150982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:15:27.774962 150982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1, 536870912, 4],"float32"),Tensor([2, 1, 536870912, 4],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([2, 1, 536870912, 4],"float32"),Tensor([2, 1, 536870912, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:17:49.235529 151053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:17:49.237871 151053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1, 536870912, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 1, 536870912, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 1, 536870912, 4] at entry 0 and [2, 1, 8, 4] at entry 1

W0206 03:19:05.453408 151136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:19:05.454419 151136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1, 8, 268435456],"float32"),Tensor([2, 1, 8, 268435456],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([2, 1, 8, 268435456],"float32"),Tensor([2, 1, 8, 268435456],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:21:34.814194 151179 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:21:34.816671 151179 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1, 8, 268435456],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 1, 8, 268435456],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 1, 8, 268435456] at entry 0 and [2, 1, 8, 4] at entry 1

W0206 03:22:48.433368 151249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:22:48.434504 151249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1, 8, 4],"float32"),Tensor([134217728, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 1, 8, 4],"float32"),Tensor([134217728, 1, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 1, 8, 4] at entry 0 and [134217728, 1, 8, 4] at entry 1

W0206 03:24:02.803910 151291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:24:02.805034 151291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 1, 536870912, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 1, 536870912, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 1, 8, 4] at entry 0 and [2, 1, 536870912, 4] at entry 1

W0206 03:25:15.878445 151360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:25:15.879573 151360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 1, 8, 268435456],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 1, 8, 268435456],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 1, 8, 4] at entry 0 and [2, 1, 8, 268435456] at entry 1

W0206 03:26:33.626631 151403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:26:33.627784 151403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 1, 8, 4] at entry 0 and [2, 67108864, 8, 4] at entry 1

W0206 03:27:46.199597 151444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:27:46.200764 151444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1],"float32"),Tensor([2, 2147483648],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([2, 1],"float32"),Tensor([2, 2147483648],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [2, 1] at entry 0 and [2, 2147483648] at entry 1

W0206 03:29:04.881804 151486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:29:04.882983 151486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1],"float32"),Tensor([4294967295, 1],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([2, 1],"float32"),Tensor([4294967295, 1],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [2, 1] at entry 0 and [4294967295, 1] at entry 1

W0206 03:30:15.801513 151529 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:30:15.802654 151529 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1048576, 64, 32],"float16"),Tensor([2, 1048576, 64, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([2, 1048576, 64, 32],"float16"),Tensor([2, 1048576, 64, 32],"float16"),], axis=-1, )

W0206 03:32:59.271113 151570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:32:59.272003 151570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1048576, 64, 32],"float16"),Tensor([2, 2, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 1048576, 64, 32],"float16"),Tensor([2, 2, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 1048576, 64, 32] at entry 0 and [2, 2, 64, 32] at entry 1

W0206 03:50:12.560277 152131 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:50:12.561327 152131 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1048576, 64, 32],"float16"),Tensor([2, 8, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 1048576, 64, 32],"float16"),Tensor([2, 8, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 1048576, 64, 32] at entry 0 and [2, 8, 64, 32] at entry 1

W0206 03:51:36.720619 152174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:51:36.721654 152174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], -1, )
[paddle error] paddle.stack(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:53:15.068825 152243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:53:15.069710 152243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 1073741825],"float64"),Tensor([2, 5],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([2, 1073741825],"float64"),Tensor([2, 5],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [2, 1073741825] at entry 0 and [2, 5] at entry 1

W0206 03:54:03.718549 152313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:54:03.719666 152313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 1, 1073741824],"float16"),Tensor([2, 2, 1, 1073741824],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([2, 2, 1, 1073741824],"float16"),Tensor([2, 2, 1, 1073741824],"float16"),], axis=-1, )

W0206 03:56:45.890993 152355 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:56:45.891919 152355 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 1, 1073741824],"float16"),Tensor([2, 2, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 1, 1073741824],"float16"),Tensor([2, 2, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 1, 1073741824] at entry 0 and [2, 2, 1, 32] at entry 1

W0206 04:13:56.578383 152944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:13:56.579368 152944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 1, 32],"float16"),Tensor([2, 2, 1, 1073741824],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 1, 32],"float16"),Tensor([2, 2, 1, 1073741824],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 1, 32] at entry 0 and [2, 2, 1, 1073741824] at entry 1

W0206 04:15:20.274083 153000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:15:20.275314 153000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 1, 32],"float16"),Tensor([2, 2, 33554432, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 1, 32],"float16"),Tensor([2, 2, 33554432, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 1, 32] at entry 0 and [2, 2, 33554432, 32] at entry 1

W0206 04:16:44.341662 153055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:16:44.342728 153055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 1, 32],"float16"),Tensor([2, 67108864, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 1, 32],"float16"),Tensor([2, 67108864, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 1, 32] at entry 0 and [2, 67108864, 1, 32] at entry 1

W0206 04:18:08.006968 153130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:18:08.008157 153130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 1, 32],"float16"),Tensor([67108864, 2, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 1, 32],"float16"),Tensor([67108864, 2, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 1, 32] at entry 0 and [67108864, 2, 1, 32] at entry 1

W0206 04:19:32.792104 153181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:19:32.793195 153181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 134217728, 8],"float32"),Tensor([2, 2, 134217728, 8],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([2, 2, 134217728, 8],"float32"),Tensor([2, 2, 134217728, 8],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 04:21:57.092159 153223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:21:57.093125 153223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 134217728, 8],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 134217728, 8],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 134217728, 8] at entry 0 and [2, 2, 8, 8] at entry 1

W0206 04:23:15.668252 153308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:23:15.677704 153308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 33554432, 32],"float16"),Tensor([2, 2, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 33554432, 32],"float16"),Tensor([2, 2, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 33554432, 32] at entry 0 and [2, 2, 1, 32] at entry 1

W0206 04:24:38.847157 153363 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:24:38.848282 153363 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 33554432, 32],"float16"),Tensor([2, 2, 33554432, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([2, 2, 33554432, 32],"float16"),Tensor([2, 2, 33554432, 32],"float16"),], axis=-1, )

W0206 04:27:34.357735 153430 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:27:34.358553 153430 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 33554432, 32],"float16"),Tensor([2, 2, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 33554432, 32],"float16"),Tensor([2, 2, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 33554432, 32] at entry 0 and [2, 2, 64, 32] at entry 1

W0206 04:44:45.803691 153966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:44:45.805176 153966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 64, 16777216],"float16"),Tensor([2, 2, 64, 16777216],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([2, 2, 64, 16777216],"float16"),Tensor([2, 2, 64, 16777216],"float16"),], axis=-1, )

W0206 04:47:28.920426 154021 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:47:28.921329 154021 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 64, 16777216],"float16"),Tensor([2, 2, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 64, 16777216],"float16"),Tensor([2, 2, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 64, 16777216] at entry 0 and [2, 2, 64, 32] at entry 1

W0206 05:05:19.680567 154484 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:05:19.681764 154484 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 64, 32],"float16"),Tensor([1048576, 2, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 64, 32],"float16"),Tensor([1048576, 2, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 64, 32] at entry 0 and [1048576, 2, 64, 32] at entry 1

W0206 05:06:55.805087 154526 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:06:55.806361 154526 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 64, 32],"float16"),Tensor([2, 1048576, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 64, 32],"float16"),Tensor([2, 1048576, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 64, 32] at entry 0 and [2, 1048576, 64, 32] at entry 1

W0206 05:08:40.756628 154567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:08:40.757936 154567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 64, 32],"float16"),Tensor([2, 2, 33554432, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 64, 32],"float16"),Tensor([2, 2, 33554432, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 64, 32] at entry 0 and [2, 2, 33554432, 32] at entry 1

W0206 05:10:26.033579 154609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:10:26.034857 154609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 64, 32],"float16"),Tensor([2, 2, 64, 16777216],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 64, 32],"float16"),Tensor([2, 2, 64, 16777216],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 64, 32] at entry 0 and [2, 2, 64, 16777216] at entry 1

W0206 05:12:08.177699 154665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:12:08.178844 154665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 8, 134217728],"float32"),Tensor([2, 2, 8, 134217728],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([2, 2, 8, 134217728],"float32"),Tensor([2, 2, 8, 134217728],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:14:51.195174 154707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:14:51.197672 154707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 8, 134217728],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 8, 134217728],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 8, 134217728] at entry 0 and [2, 2, 8, 8] at entry 1

W0206 05:16:01.727146 154777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:16:01.728479 154777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 8, 8],"float32"),Tensor([2, 2, 134217728, 8],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 8, 8],"float32"),Tensor([2, 2, 134217728, 8],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 8, 8] at entry 0 and [2, 2, 134217728, 8] at entry 1

W0206 05:17:10.261687 154820 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:17:10.265744 154820 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 8, 8],"float32"),Tensor([2, 2, 8, 134217728],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 8, 8],"float32"),Tensor([2, 2, 8, 134217728],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 8, 8] at entry 0 and [2, 2, 8, 134217728] at entry 1

W0206 05:18:28.029132 154848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:18:28.030436 154848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 8, 8] at entry 0 and [2, 33554432, 8, 8] at entry 1

W0206 05:19:45.098990 154890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:19:45.100090 154890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2, 8, 8],"float32"),Tensor([33554432, 2, 8, 8],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 2, 8, 8],"float32"),Tensor([33554432, 2, 8, 8],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 2, 8, 8] at entry 0 and [33554432, 2, 8, 8] at entry 1

W0206 05:20:55.205047 154932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:20:55.206087 154932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2],"float32"),Tensor([2, 2147483648],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([2, 2],"float32"),Tensor([2, 2147483648],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [2, 2] at entry 0 and [2, 2147483648] at entry 1

W0206 05:22:05.050029 154960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:22:05.051144 154960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2],"float32"),Tensor([2147483648, 2],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([2, 2],"float32"),Tensor([2147483648, 2],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [2, 2] at entry 0 and [2147483648, 2] at entry 1

W0206 05:23:16.673746 155002 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:23:16.674938 155002 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2147483648],"float16"),Tensor([2, 2147483648],"float16"),Tensor([2, 2147483648],"float16"),], axis=1, )
[paddle error] paddle.stack(list[Tensor([2, 2147483648],"float16"),Tensor([2, 2147483648],"float16"),Tensor([2, 2147483648],"float16"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_stack(_object*, _object*, _object*)
1   stack_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
2   paddle::experimental::stack(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
3   void phi::funcs::StackRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, int, phi::DenseTensor*)
4   void phi::funcs::LaunchStackKernel<phi::GPUContext, phi::dtype::float16, long, (phi::funcs::SegmentedArraySize)4>(phi::GPUContext const&, long, long, long, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, phi::DenseTensor*)
5   phi::dtype::float16* phi::DeviceContext::Alloc<phi::dtype::float16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 24.000000GB memory on GPU 0, 73.584900GB memory has been allocated and available memory is only 5.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:27:29.356818 155040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:27:29.357889 155040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2147483648],"float16"),Tensor([2, 512],"float16"),Tensor([2, 512],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 2147483648],"float16"),Tensor([2, 512],"float16"),Tensor([2, 512],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 2147483648] at entry 0 and [2, 512] at entry 1

W0206 05:29:03.384940 155156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:29:03.386181 155156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2147483648],"float32"),Tensor([2, 1],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([2, 2147483648],"float32"),Tensor([2, 1],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [2, 2147483648] at entry 0 and [2, 1] at entry 1

W0206 05:30:19.755122 155198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:30:19.756237 155198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2147483648],"float32"),Tensor([2, 2],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([2, 2147483648],"float32"),Tensor([2, 2],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [2, 2147483648] at entry 0 and [2, 2] at entry 1

W0206 05:31:37.559909 155240 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:31:37.560953 155240 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2147483648],"float32"),Tensor([2, 2147483648],"float32"),], -1, )
[paddle error] paddle.stack(list[Tensor([2, 2147483648],"float32"),Tensor([2, 2147483648],"float32"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:34:10.505225 155282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:34:10.507398 155282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2147483648],"int32"),Tensor([2, 2147483648],"int32"),Tensor([2, 2147483648],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 2147483648],"int32"),Tensor([2, 2147483648],"int32"),Tensor([2, 2147483648],"int32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 116498 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:37:33.328526 155353 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:37:33.329706 155353 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 2147483648],"int32"),Tensor([2, 512],"int32"),Tensor([2, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 2147483648],"int32"),Tensor([2, 512],"int32"),Tensor([2, 512],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 2147483648] at entry 0 and [2, 512] at entry 1

W0206 05:38:50.243512 155464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:38:50.244750 155464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 67939 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:42:15.304061 155507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:42:15.305117 155507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 142480 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:47:36.873358 155623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:47:36.874382 155623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 268435456, 8] at entry 0 and [2, 8, 8] at entry 1

W0206 05:48:51.119750 155786 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:48:51.120862 155786 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 268435456, 8] at entry 0 and [2, 8, 8] at entry 1

W0206 05:50:01.380311 155828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:50:01.381399 155828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 3, 4],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 3, 4],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 3, 4] at entry 0 and [2, 3, 715827883] at entry 1

W0206 05:51:10.831815 155884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:51:10.832899 155884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 3, 4],"float32"),Tensor([2, 536870912, 4],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 3, 4],"float32"),Tensor([2, 536870912, 4],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 3, 4] at entry 0 and [2, 536870912, 4] at entry 1

W0206 05:52:26.627450 155926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:52:26.628564 155926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 3, 4],"float32"),Tensor([357913942, 3, 4],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 3, 4],"float32"),Tensor([357913942, 3, 4],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 3, 4] at entry 0 and [357913942, 3, 4] at entry 1

W0206 05:53:34.513708 155969 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:53:34.514806 155969 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 3, 715827883] at entry 0 and [2, 3, 4] at entry 1

W0206 05:54:45.536593 156025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:54:45.537859 156025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, )
[paddle error] paddle.stack(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:57:07.753294 156080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:57:07.755793 156080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 33554432, 8, 8] at entry 0 and [2, 2, 8, 8] at entry 1

W0206 05:58:25.258924 156150 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:58:25.259965 156150 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:00:50.520572 156193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:00:50.521445 156193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),], axis=-4, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 39501 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:04:10.261265 156276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:04:10.262364 156276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 33554432, 8, 8] at entry 0 and [2, 6, 8, 8] at entry 1

W0206 06:05:22.596271 156387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:05:22.597389 156387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 4, 134217728, 4],"float32"),Tensor([2, 4, 134217728, 4],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([2, 4, 134217728, 4],"float32"),Tensor([2, 4, 134217728, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:07:44.810025 156430 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:07:44.812475 156430 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 4, 134217728, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 4, 134217728, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 4, 134217728, 4] at entry 0 and [2, 4, 8, 4] at entry 1

W0206 06:08:55.741222 156513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:08:55.742295 156513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 4, 134217728, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 4, 134217728, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 4, 8, 4] at entry 0 and [2, 4, 134217728, 4] at entry 1

W0206 06:10:06.129667 156566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:10:06.130741 156566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 4, 8, 67108864],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 4, 8, 67108864],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 4, 8, 4] at entry 0 and [2, 4, 8, 67108864] at entry 1

W0206 06:11:15.859479 156598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:11:15.860641 156598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 4, 8, 4] at entry 0 and [2, 67108864, 8, 4] at entry 1

W0206 06:12:33.858237 156654 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:12:33.859341 156654 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 4, 8, 4] at entry 0 and [33554432, 4, 8, 4] at entry 1

W0206 06:13:43.727485 156697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:13:43.728555 156697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 4, 8, 67108864],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 4, 8, 67108864],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 4, 8, 67108864] at entry 0 and [2, 4, 8, 4] at entry 1

W0206 06:14:53.732352 156752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:14:53.733543 156752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 4, 8, 67108864],"float32"),Tensor([2, 4, 8, 67108864],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([2, 4, 8, 67108864],"float32"),Tensor([2, 4, 8, 67108864],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:17:29.676431 156794 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:17:29.677345 156794 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 5],"float64"),Tensor([2, 1073741825],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([2, 5],"float64"),Tensor([2, 1073741825],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [2, 5] at entry 0 and [2, 1073741825] at entry 1

W0206 06:18:21.766876 156891 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:18:21.768180 156891 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 5],"float64"),Tensor([429496730, 5],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([2, 5],"float64"),Tensor([429496730, 5],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [2, 5] at entry 0 and [429496730, 5] at entry 1

W0206 06:19:16.651886 156933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:19:16.653343 156933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 512],"float16"),Tensor([2, 2147483648],"float16"),Tensor([2, 512],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 512],"float16"),Tensor([2, 2147483648],"float16"),Tensor([2, 512],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 512] at entry 0 and [2, 2147483648] at entry 1

W0206 06:20:47.651854 156962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:20:47.653013 156962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 512],"float16"),Tensor([2, 512],"float16"),Tensor([2, 2147483648],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 512],"float16"),Tensor([2, 512],"float16"),Tensor([2, 2147483648],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 512] at entry 0 and [2, 2147483648] at entry 2

W0206 06:22:10.927341 157032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:22:10.928504 157032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 512],"float16"),Tensor([2, 512],"float16"),Tensor([8388608, 512],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 512],"float16"),Tensor([2, 512],"float16"),Tensor([8388608, 512],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 512] at entry 0 and [8388608, 512] at entry 2

W0206 06:23:39.587148 157088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:23:39.588233 157088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 512],"float16"),Tensor([8388608, 512],"float16"),Tensor([2, 512],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 512],"float16"),Tensor([8388608, 512],"float16"),Tensor([2, 512],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 512] at entry 0 and [8388608, 512] at entry 1

W0206 06:25:08.887800 157143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:25:08.889055 157143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 512],"int32"),Tensor([2, 2147483648],"int32"),Tensor([2, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 512],"int32"),Tensor([2, 2147483648],"int32"),Tensor([2, 512],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 512] at entry 0 and [2, 2147483648] at entry 1

W0206 06:26:21.762238 157199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:26:21.763370 157199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 512],"int32"),Tensor([2, 512],"int32"),Tensor([2, 2147483648],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 512],"int32"),Tensor([2, 512],"int32"),Tensor([2, 2147483648],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 512] at entry 0 and [2, 2147483648] at entry 2

W0206 06:27:30.376933 157228 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:27:30.378047 157228 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 512],"int32"),Tensor([2, 512],"int32"),Tensor([8388608, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 512],"int32"),Tensor([2, 512],"int32"),Tensor([8388608, 512],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 512] at entry 0 and [8388608, 512] at entry 2

W0206 06:28:47.683758 157283 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:28:47.684883 157283 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 512],"int32"),Tensor([8388608, 512],"int32"),Tensor([2, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 512],"int32"),Tensor([8388608, 512],"int32"),Tensor([2, 512],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 512] at entry 0 and [8388608, 512] at entry 1

W0206 06:30:04.364730 157327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:30:04.366079 157327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 536870912, 4],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2, 536870912, 4],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2, 536870912, 4] at entry 0 and [2, 3, 4] at entry 1

W0206 06:31:17.885056 157383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:31:17.911406 157383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 536870912, 4],"float32"),Tensor([2, 536870912, 4],"float32"),], axis=1, )
[paddle error] paddle.stack(list[Tensor([2, 536870912, 4],"float32"),Tensor([2, 536870912, 4],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:33:46.787293 157425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:33:46.789865 157425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 44739243, 8],"float32"),Tensor([2, 6, 44739243, 8],"float32"),Tensor([2, 6, 44739243, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 44739243, 8],"float32"),Tensor([2, 6, 44739243, 8],"float32"),Tensor([2, 6, 44739243, 8],"float32"),], axis=-4, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 143297 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:37:06.475350 157522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:37:06.485718 157522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 44739243, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 44739243, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 6, 44739243, 8] at entry 0 and [2, 6, 8, 8] at entry 1

W0206 06:38:29.376753 157621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:38:29.377890 157621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 8, 44739243],"float32"),Tensor([2, 6, 8, 44739243],"float32"),Tensor([2, 6, 8, 44739243],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 8, 44739243],"float32"),Tensor([2, 6, 8, 44739243],"float32"),Tensor([2, 6, 8, 44739243],"float32"),], axis=-4, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 62150 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:41:52.385726 157677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:41:52.386744 157677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 8, 44739243],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 8, 44739243],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 6, 8, 44739243] at entry 0 and [2, 6, 8, 8] at entry 1

W0206 06:43:13.112517 157788 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:43:13.115265 157788 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([11184811, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([11184811, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 6, 8, 8] at entry 0 and [11184811, 6, 8, 8] at entry 1

W0206 06:44:33.422114 157830 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:44:33.423225 157830 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 6, 8, 8] at entry 0 and [2, 33554432, 8, 8] at entry 1

W0206 06:46:04.671058 157885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:46:04.672237 157885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 44739243, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 44739243, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 6, 8, 8] at entry 0 and [2, 6, 44739243, 8] at entry 1

W0206 06:47:33.942711 157941 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:47:33.943939 157941 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 44739243],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 44739243],"float32"),Tensor([2, 6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 6, 8, 8] at entry 0 and [2, 6, 8, 44739243] at entry 1

W0206 06:49:05.335006 157997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:49:05.336215 157997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([11184811, 6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([11184811, 6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 6, 8, 8] at entry 0 and [11184811, 6, 8, 8] at entry 2

W0206 06:50:25.125907 158040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:50:25.127125 158040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 6, 8, 8] at entry 0 and [2, 33554432, 8, 8] at entry 2

W0206 06:51:44.686791 158083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:51:44.688067 158083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 44739243, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 44739243, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 6, 8, 8] at entry 0 and [2, 6, 44739243, 8] at entry 2

W0206 06:53:12.173252 158138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:53:12.174535 158138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 44739243],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 8],"float32"),Tensor([2, 6, 8, 44739243],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [2, 6, 8, 8] at entry 0 and [2, 6, 8, 44739243] at entry 2

W0206 06:54:22.977171 158194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:54:22.978355 158194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 67108864, 1, 32],"float16"),Tensor([2, 2, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 67108864, 1, 32],"float16"),Tensor([2, 2, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 67108864, 1, 32] at entry 0 and [2, 2, 1, 32] at entry 1

W0206 06:55:53.420413 158236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:55:53.421808 158236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 67108864, 1, 32],"float16"),Tensor([2, 67108864, 1, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([2, 67108864, 1, 32],"float16"),Tensor([2, 67108864, 1, 32],"float16"),], axis=-1, )

W0206 06:58:44.889932 158304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:58:44.890952 158304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 67108864, 1, 32],"float16"),Tensor([2, 8, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 67108864, 1, 32],"float16"),Tensor([2, 8, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 67108864, 1, 32] at entry 0 and [2, 8, 1, 32] at entry 1

W0206 07:15:59.203439 158908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:15:59.220415 158908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 67108864, 8, 4] at entry 0 and [2, 1, 8, 4] at entry 1

W0206 07:17:18.570947 158963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:17:18.572077 158963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 67108864, 8, 4] at entry 0 and [2, 4, 8, 4] at entry 1

W0206 07:18:38.725629 158993 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:18:38.726644 158993 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:21:08.926599 159061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:21:08.927604 159061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 1, 268435456],"float16"),Tensor([2, 8, 1, 268435456],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([2, 8, 1, 268435456],"float16"),Tensor([2, 8, 1, 268435456],"float16"),], axis=-1, )

W0206 07:24:08.730069 159147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:24:08.731017 159147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 1, 268435456],"float16"),Tensor([2, 8, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 1, 268435456],"float16"),Tensor([2, 8, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 1, 268435456] at entry 0 and [2, 8, 1, 32] at entry 1

W0206 07:41:09.227345 159803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:41:09.228508 159803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 1, 32],"float16"),Tensor([16777216, 8, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 1, 32],"float16"),Tensor([16777216, 8, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 1, 32] at entry 0 and [16777216, 8, 1, 32] at entry 1

W0206 07:42:31.838536 159847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:42:31.839679 159847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 1, 32],"float16"),Tensor([2, 67108864, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 1, 32],"float16"),Tensor([2, 67108864, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 1, 32] at entry 0 and [2, 67108864, 1, 32] at entry 1

W0206 07:43:56.987011 159917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:43:56.988416 159917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 1, 32],"float16"),Tensor([2, 8, 1, 268435456],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 1, 32],"float16"),Tensor([2, 8, 1, 268435456],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 1, 32] at entry 0 and [2, 8, 1, 268435456] at entry 1

W0206 07:45:28.101943 159986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:45:28.103201 159986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 1, 32],"float16"),Tensor([2, 8, 8388608, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 1, 32],"float16"),Tensor([2, 8, 8388608, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 1, 32] at entry 0 and [2, 8, 8388608, 32] at entry 1

W0206 07:46:52.376396 160057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:46:52.377554 160057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 41253 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:50:14.317405 160125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:50:14.318622 160125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 99531 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:55:36.181466 160265 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:55:36.184335 160265 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 268435456] at entry 0 and [2, 8, 8] at entry 1

W0206 07:56:51.136952 160461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:56:51.138134 160461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 268435456] at entry 0 and [2, 8, 8] at entry 1

W0206 07:58:04.169220 160510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:58:04.170231 160510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 64, 32],"float16"),Tensor([2, 1048576, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 64, 32],"float16"),Tensor([2, 1048576, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 64, 32] at entry 0 and [2, 1048576, 64, 32] at entry 1

W0206 07:59:33.744325 160560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:59:33.745950 160560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 64, 32],"float16"),Tensor([2, 8, 64, 4194304],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 64, 32],"float16"),Tensor([2, 8, 64, 4194304],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 64, 32] at entry 0 and [2, 8, 64, 4194304] at entry 1

W0206 08:01:00.725179 160629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:01:00.726176 160629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 64, 32],"float16"),Tensor([2, 8, 8388608, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 64, 32],"float16"),Tensor([2, 8, 8388608, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 64, 32] at entry 0 and [2, 8, 8388608, 32] at entry 1

W0206 08:02:25.136161 160691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:02:25.137368 160691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 64, 32],"float16"),Tensor([262144, 8, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 64, 32],"float16"),Tensor([262144, 8, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 64, 32] at entry 0 and [262144, 8, 64, 32] at entry 1

W0206 08:03:48.485813 160756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:03:48.487002 160756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 64, 4194304] at entry 0 and [2, 8, 64, 32] at entry 1

W0206 08:05:16.987515 160799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:05:16.988659 160799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 64, 4194304],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 64, 4194304],"float16"),], axis=-1, )

W0206 08:08:01.588757 160869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:08:01.589638 160869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 268435456, 8] at entry 1

W0206 08:24:44.606436 161510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:24:44.607661 161510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 268435456, 8] at entry 1

W0206 08:26:02.133894 161563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:26:02.135116 161563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 8, 268435456] at entry 1

W0206 08:27:17.955453 161623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:27:17.956744 161623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 8, 268435456] at entry 1

W0206 08:28:28.676669 161678 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:28:28.677861 161678 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 268435456, 8] at entry 2

W0206 08:29:40.550405 161735 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:29:40.551517 161735 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 268435456, 8] at entry 2

W0206 08:30:56.494267 161790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:30:56.495427 161790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 8, 268435456] at entry 2

W0206 08:32:12.201881 161839 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:32:12.203555 161839 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 8, 268435456] at entry 2

W0206 08:33:23.082288 161890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:33:23.083465 161890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 268435456, 8] at entry 3

W0206 08:34:39.508481 161959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:34:39.509565 161959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 8, 268435456] at entry 3

W0206 08:35:53.255072 162003 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:35:53.256227 162003 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 268435456, 8] at entry 4

W0206 08:37:06.086082 162071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:37:06.087164 162071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 8, 268435456] at entry 4

W0206 08:38:21.217916 162113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:38:21.219173 162113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 268435456, 8] at entry 5

W0206 08:39:33.046904 162156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:39:33.047971 162156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [2, 8, 268435456] at entry 5

W0206 08:40:43.387749 162184 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:40:43.388909 162184 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [67108864, 8, 8] at entry 5

W0206 08:42:00.974419 162226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:42:00.975643 162226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [67108864, 8, 8] at entry 4

W0206 08:43:12.484736 162268 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:43:12.485898 162268 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [67108864, 8, 8] at entry 3

W0206 08:44:47.172654 162311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:44:47.173874 162311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [67108864, 8, 8] at entry 2

W0206 08:46:06.207603 162366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:46:06.208793 162366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [67108864, 8, 8] at entry 2

W0206 08:47:16.154681 162434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:47:16.155726 162434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [67108864, 8, 8] at entry 1

W0206 08:48:31.645689 162464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:48:31.647117 162464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8] at entry 0 and [67108864, 8, 8] at entry 1

W0206 08:49:42.593847 162534 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:49:42.594880 162534 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8388608, 32],"float16"),Tensor([2, 8, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 8388608, 32],"float16"),Tensor([2, 8, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8388608, 32] at entry 0 and [2, 8, 1, 32] at entry 1

W0206 08:51:07.682010 162577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:51:07.683418 162577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8388608, 32],"float16"),Tensor([2, 8, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2, 8, 8388608, 32],"float16"),Tensor([2, 8, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2, 8, 8388608, 32] at entry 0 and [2, 8, 64, 32] at entry 1

W0206 08:52:39.484350 162633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:52:39.485337 162633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2, 8, 8388608, 32],"float16"),Tensor([2, 8, 8388608, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([2, 8, 8388608, 32],"float16"),Tensor([2, 8, 8388608, 32],"float16"),], axis=-1, )

W0206 08:55:30.244933 162691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:55:30.245886 162691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [2] at entry 0 and [4294967295] at entry 5

W0206 09:12:10.926142 163109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:12:10.927390 163109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([4294967295],"float32"),Tensor([2],"float32"),], )
[torch error] paddle.stack(list[Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([4294967295],"float32"),Tensor([2],"float32"),], ) 
 stack expects each tensor to be equal size, but got [2] at entry 0 and [4294967295] at entry 4

W0206 09:13:28.855242 163138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:13:28.856436 163138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([4294967295],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),], )
[torch error] paddle.stack(list[Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([4294967295],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),], ) 
 stack expects each tensor to be equal size, but got [2] at entry 0 and [4294967295] at entry 3

W0206 09:14:44.809896 163180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:14:44.811362 163180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2],"float32"),Tensor([2],"float32"),Tensor([4294967295],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),], )
[torch error] paddle.stack(list[Tensor([2],"float32"),Tensor([2],"float32"),Tensor([4294967295],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),], ) 
 stack expects each tensor to be equal size, but got [2] at entry 0 and [4294967295] at entry 2

W0206 09:16:01.763432 163233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:16:01.764696 163233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2],"float32"),Tensor([4294967295],"float32"),], 0, )
[torch error] paddle.stack(list[Tensor([2],"float32"),Tensor([4294967295],"float32"),], 0, ) 
 stack expects each tensor to be equal size, but got [2] at entry 0 and [4294967295] at entry 1

W0206 09:17:14.971359 163264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:17:14.972647 163264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2],"float32"),Tensor([4294967295],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([2],"float32"),Tensor([4294967295],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [2] at entry 0 and [4294967295] at entry 1

W0206 09:18:25.368742 163306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:18:25.369864 163306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2],"float32"),Tensor([4294967295],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),], )
[torch error] paddle.stack(list[Tensor([2],"float32"),Tensor([4294967295],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),], ) 
 stack expects each tensor to be equal size, but got [2] at entry 0 and [4294967295] at entry 1

W0206 09:19:41.997514 163360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:19:41.998641 163360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2097152, 1, 64, 32],"float16"),Tensor([1, 1, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2097152, 1, 64, 32],"float16"),Tensor([1, 1, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2097152, 1, 64, 32] at entry 0 and [1, 1, 64, 32] at entry 1

W0206 09:21:06.604966 163405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:21:06.606091 163405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2097152, 1, 64, 32],"float16"),Tensor([2097152, 1, 64, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([2097152, 1, 64, 32],"float16"),Tensor([2097152, 1, 64, 32],"float16"),], axis=-1, )

W0206 09:23:48.852195 163448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:23:48.853094 163448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483648, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2147483648, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 150133 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:42:31.587224  1579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:42:31.588217  1579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483648, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([2147483648, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [2147483648, 1, 2] at entry 0 and [5, 1, 2] at entry 1

W0206 09:43:43.604452  2478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:43:43.605520  2478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483648, 2],"float32"),Tensor([1, 2],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([2147483648, 2],"float32"),Tensor([1, 2],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [2147483648, 2] at entry 0 and [1, 2] at entry 1

W0206 09:45:02.156170  2869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:45:02.157321  2869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483648, 2],"float32"),Tensor([2, 2],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([2147483648, 2],"float32"),Tensor([2, 2],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [2147483648, 2] at entry 0 and [2, 2] at entry 1

W0206 09:46:26.124473  3194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:46:26.125851  3194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),], -1, )
[paddle error] paddle.stack(list[Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 09:48:58.703480  3616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:48:58.705852  3616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], 0, )
[paddle error] paddle.stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], 0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 09:50:38.058265  4332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:50:38.060846  4332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], 0, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 44257 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:52:41.655650  4854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:52:41.656800  4854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [2147483649, 1, 1] at entry 0 and [5, 1, 1] at entry 1

W0206 09:53:39.545887  5436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:53:39.547060  5436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [2147483649, 1, 1] at entry 0 and [5, 1, 1] at entry 1

W0206 09:54:27.606628  5716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:54:27.607888  5716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"float64"),], 0, )
[Pass] paddle.stack(list[Tensor([2147483649],"float64"),], 0, )

W0206 09:55:27.656308  5915 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:55:27.657368  5915 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"float64"),Tensor([1],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([2147483649],"float64"),Tensor([1],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [2147483649] at entry 0 and [1] at entry 1

W0206 09:58:14.884071  6760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:58:14.955515  6760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], 0, )
[paddle error] paddle.stack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], 0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 09:59:55.821087  7049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:59:55.823822  7049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], -1, )
[paddle error] paddle.stack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:01:37.393424  7447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:01:37.394317  7447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], 1, )
[torch error] paddle.stack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 94284 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:04:52.551512  8003 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:04:52.552625  8003 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),], 1, )
[torch error] paddle.stack(list[Tensor([2147483649],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),], 1, ) 
 stack expects each tensor to be equal size, but got [2147483649] at entry 0 and [252] at entry 1

W0206 10:05:43.082121  8935 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:05:43.083308  8935 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"float64"),Tensor([5],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([2147483649],"float64"),Tensor([5],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [2147483649] at entry 0 and [5] at entry 1

W0206 10:06:30.307142  9219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:06:30.308351  9219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"int64"),Tensor([1],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([2147483649],"int64"),Tensor([1],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [2147483649] at entry 0 and [1] at entry 1

W0206 10:07:16.487473  9419 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:07:16.488679  9419 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"int64"),Tensor([1],"int64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([2147483649],"int64"),Tensor([1],"int64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [2147483649] at entry 0 and [1] at entry 1

W0206 10:08:09.725801  9691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:08:09.726795  9691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], axis=0, )
[paddle error] paddle.stack(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:09:44.191565  9981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:09:44.192576  9981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], axis=1, )
[paddle error] paddle.stack(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:11:15.675952 10458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:11:15.676890 10458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([21474837, 10, 10],"float64"),Tensor([10, 10, 10],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([21474837, 10, 10],"float64"),Tensor([10, 10, 10],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [21474837, 10, 10] at entry 0 and [10, 10, 10] at entry 1

W0206 10:12:09.358186 10903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:12:09.359186 10903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([21474837, 10, 10],"float64"),Tensor([21474837, 10, 10],"float64"),], -1, )
[paddle error] paddle.stack(list[Tensor([21474837, 10, 10],"float64"),Tensor([21474837, 10, 10],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:13:45.769187 11196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:13:45.771991 11196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([252],"float64"),Tensor([2147483649],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),], 1, )
[torch error] paddle.stack(list[Tensor([252],"float64"),Tensor([2147483649],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),], 1, ) 
 stack expects each tensor to be equal size, but got [252] at entry 0 and [2147483649] at entry 1

W0206 10:14:32.981484 11671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:14:32.982571 11671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([252],"float64"),Tensor([252],"float64"),Tensor([2147483649],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),], 1, )
[torch error] paddle.stack(list[Tensor([252],"float64"),Tensor([252],"float64"),Tensor([2147483649],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),], 1, ) 
 stack expects each tensor to be equal size, but got [252] at entry 0 and [2147483649] at entry 2

W0206 10:15:23.488509 11948 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:15:23.489684 11948 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([2147483649],"float64"),Tensor([252],"float64"),], 1, )
[torch error] paddle.stack(list[Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([2147483649],"float64"),Tensor([252],"float64"),], 1, ) 
 stack expects each tensor to be equal size, but got [252] at entry 0 and [2147483649] at entry 3

W0206 10:16:21.884788 12147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:16:21.886075 12147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([2147483649],"float64"),], 1, )
[torch error] paddle.stack(list[Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([252],"float64"),Tensor([2147483649],"float64"),], 1, ) 
 stack expects each tensor to be equal size, but got [252] at entry 0 and [2147483649] at entry 4

W0206 10:17:15.883037 12459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:17:15.884299 12459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([262144, 8, 64, 32],"float16"),Tensor([2, 8, 64, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([262144, 8, 64, 32],"float16"),Tensor([2, 8, 64, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [262144, 8, 64, 32] at entry 0 and [2, 8, 64, 32] at entry 1

W0206 10:18:48.414834 12752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:18:48.415880 12752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([262144, 8, 64, 32],"float16"),Tensor([262144, 8, 64, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([262144, 8, 64, 32],"float16"),Tensor([262144, 8, 64, 32],"float16"),], axis=-1, )

W0206 10:21:39.043306 13210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:21:39.044265 13210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),], )
[paddle error] paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:38:55.416869 18729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:38:55.417833 18729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),], ) 
 CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 143082 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:41:34.440899 19233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:41:34.442427 19233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 31508 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:44:55.101110 20114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:44:55.102227 20114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([268435457, 8],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 112729 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:49:30.233814 21064 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:49:30.235720 21064 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),], ) 
 stack expects each tensor to be equal size, but got [268435457, 8] at entry 0 and [4, 8] at entry 1

W0206 10:51:00.972190 22448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:51:00.974872 22448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], ) 
 stack expects each tensor to be equal size, but got [268435457, 8] at entry 0 and [4, 8] at entry 1

W0206 10:52:31.964170 22866 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:52:31.968514 22866 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [268435457, 8] at entry 0 and [4, 8] at entry 1

W0206 10:53:43.029160 23280 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:53:43.033735 23280 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [268435457, 8] at entry 0 and [4, 8] at entry 1

W0206 10:55:02.036608 23580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:55:02.038344 23580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 110093 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:58:30.779201 23981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:58:30.780267 23981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 153391690],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 48992 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:03:59.806818 24978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:03:59.807822 24978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 153391690] at entry 0 and [28, 28] at entry 1

W0206 11:05:15.884862 26536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:05:15.886914 26536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 153391690] at entry 0 and [28, 28] at entry 1

W0206 11:06:28.178897 26854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:06:28.179963 26854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [153391690, 28] at entry 1

W0206 11:07:44.157831 27187 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:07:44.159049 27187 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [153391690, 28] at entry 1

W0206 11:08:51.989979 27595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:08:51.991205 27595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [28, 153391690] at entry 1

W0206 11:10:07.360512 27907 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:10:07.361726 27907 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [28, 153391690] at entry 1

W0206 11:11:18.231663 28308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:11:18.232911 28308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [153391690, 28] at entry 2

W0206 11:12:29.348958 28620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:12:29.350262 28620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [153391690, 28] at entry 2

W0206 11:13:44.978930 28920 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:13:44.980212 28920 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [28, 153391690] at entry 2

W0206 11:15:00.686728 29313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:15:00.687955 29313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [28, 153391690] at entry 2

W0206 11:16:21.477793 29632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:16:21.478996 29632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [153391690, 28] at entry 3

W0206 11:17:37.010764 30017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:17:37.012176 30017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [28, 153391690] at entry 3

W0206 11:18:55.229322 30414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:18:55.230605 30414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [153391690, 28] at entry 4

W0206 11:20:04.759455 30728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:20:04.760710 30728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),Tensor([28, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [28, 153391690] at entry 4

W0206 11:21:15.427522 31120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:21:15.428628 31120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([153391690, 28],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [153391690, 28] at entry 5

W0206 11:22:27.227895 31436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:22:27.228962 31436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 28],"float32"),Tensor([28, 153391690],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [28, 28] at entry 0 and [28, 153391690] at entry 5

W0206 11:23:37.676225 31755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:23:37.677439 31755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 178956971, 8],"float32"),Tensor([3, 178956971, 8],"float32"),], )
[paddle error] paddle.stack(list[Tensor([3, 178956971, 8],"float32"),Tensor([3, 178956971, 8],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:26:16.358469 32137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:26:16.359397 32137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 178956971, 8],"float32"),Tensor([3, 8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([3, 178956971, 8],"float32"),Tensor([3, 8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [3, 178956971, 8] at entry 0 and [3, 8, 8] at entry 1

W0206 11:27:29.415792 32852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:27:29.417204 32852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),Tensor([3, 2, 357913942],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),Tensor([3, 2, 357913942],"int64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [3, 2, 3] at entry 0 and [3, 2, 357913942] at entry 2

W0206 11:28:18.426319 33162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:28:18.427407 33162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),Tensor([3, 238609295, 3],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),Tensor([3, 238609295, 3],"int64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [3, 2, 3] at entry 0 and [3, 238609295, 3] at entry 2

W0206 11:29:09.901932 33441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:29:09.903045 33441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),Tensor([357913942, 2, 3],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),Tensor([357913942, 2, 3],"int64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [3, 2, 3] at entry 0 and [357913942, 2, 3] at entry 2

W0206 11:29:59.823725 33706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:29:59.825042 33706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([3, 2, 357913942],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([3, 2, 357913942],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [3, 2, 3] at entry 0 and [3, 2, 357913942] at entry 1

W0206 11:30:47.171180 33899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:30:47.172500 33899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([3, 238609295, 3],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([3, 238609295, 3],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [3, 2, 3] at entry 0 and [3, 238609295, 3] at entry 1

W0206 11:31:36.329430 34161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:31:36.330675 34161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([357913942, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([3, 2, 3],"int64"),Tensor([357913942, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [3, 2, 3] at entry 0 and [357913942, 2, 3] at entry 1

W0206 11:32:22.663180 34425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:32:22.664368 34425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 2, 357913942],"int64"),Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([3, 2, 357913942],"int64"),Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [3, 2, 357913942] at entry 0 and [3, 2, 3] at entry 1

W0206 11:33:15.516202 34600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:33:15.517271 34600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 2, 357913942],"int64"),Tensor([3, 2, 357913942],"int64"),Tensor([3, 2, 357913942],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([3, 2, 357913942],"int64"),Tensor([3, 2, 357913942],"int64"),Tensor([3, 2, 357913942],"int64"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 69926 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:35:23.289469 34880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:35:23.290571 34880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 238609295, 3],"int64"),Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([3, 238609295, 3],"int64"),Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [3, 238609295, 3] at entry 0 and [3, 2, 3] at entry 1

W0206 11:36:09.326519 35445 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:36:09.327766 35445 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 238609295, 3],"int64"),Tensor([3, 238609295, 3],"int64"),Tensor([3, 238609295, 3],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([3, 238609295, 3],"int64"),Tensor([3, 238609295, 3],"int64"),Tensor([3, 238609295, 3],"int64"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 50706 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:38:12.110150 35719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:38:12.111250 35719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 8, 178956971],"float32"),Tensor([3, 8, 178956971],"float32"),], )
[paddle error] paddle.stack(list[Tensor([3, 8, 178956971],"float32"),Tensor([3, 8, 178956971],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:40:38.448130 36308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:40:38.449072 36308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 8, 178956971],"float32"),Tensor([3, 8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([3, 8, 178956971],"float32"),Tensor([3, 8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [3, 8, 178956971] at entry 0 and [3, 8, 8] at entry 1

W0206 11:41:57.121888 36983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:41:57.123334 36983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 8, 8],"float32"),Tensor([3, 178956971, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([3, 8, 8],"float32"),Tensor([3, 178956971, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [3, 8, 8] at entry 0 and [3, 178956971, 8] at entry 1

W0206 11:43:06.917598 37313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:43:06.918695 37313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 8, 8],"float32"),Tensor([3, 8, 178956971],"float32"),], )
[torch error] paddle.stack(list[Tensor([3, 8, 8],"float32"),Tensor([3, 8, 178956971],"float32"),], ) 
 stack expects each tensor to be equal size, but got [3, 8, 8] at entry 0 and [3, 8, 178956971] at entry 1

W0206 11:44:26.133750 37704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:44:26.134958 37704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([3, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [3, 8, 8] at entry 0 and [67108864, 8, 8] at entry 1

W0206 11:45:36.862018 38017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:45:36.863139 38017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3],"float32"),Tensor([3],"float32"),Tensor([4294967295],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([3],"float32"),Tensor([3],"float32"),Tensor([4294967295],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [3] at entry 0 and [4294967295] at entry 2

W0206 11:46:47.997109 38421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:46:47.998330 38421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3],"float32"),Tensor([4294967295],"float32"),], 1, )
[torch error] paddle.stack(list[Tensor([3],"float32"),Tensor([4294967295],"float32"),], 1, ) 
 stack expects each tensor to be equal size, but got [3] at entry 0 and [4294967295] at entry 1

W0206 11:47:58.238817 38727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:47:58.239881 38727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3],"float32"),Tensor([4294967295],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([3],"float32"),Tensor([4294967295],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [3] at entry 0 and [4294967295] at entry 1

W0206 11:49:15.471823 39032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:49:15.473073 39032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3],"float32"),Tensor([4294967295],"float32"),Tensor([3],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([3],"float32"),Tensor([4294967295],"float32"),Tensor([3],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [3] at entry 0 and [4294967295] at entry 1

W0206 11:50:24.627270 39443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:50:24.628545 39443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([33554432, 128],"float32"),Tensor([128, 128],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([33554432, 128],"float32"),Tensor([128, 128],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [33554432, 128] at entry 0 and [128, 128] at entry 1

W0206 11:51:38.580588 39749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:51:38.581696 39749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([33554432, 128],"float32"),Tensor([33554432, 128],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([33554432, 128],"float32"),Tensor([33554432, 128],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:53:59.291517 40147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:53:59.292469 40147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([33554432, 2, 8, 8],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([33554432, 2, 8, 8],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [33554432, 2, 8, 8] at entry 0 and [2, 2, 8, 8] at entry 1

W0206 11:55:13.439131 40738 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:55:13.440140 40738 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([33554432, 2, 8, 8],"float32"),Tensor([33554432, 2, 8, 8],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([33554432, 2, 8, 8],"float32"),Tensor([33554432, 2, 8, 8],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:57:40.933487 41146 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:57:40.934479 41146 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [33554432, 4, 8, 4] at entry 0 and [1, 4, 8, 4] at entry 1

W0206 11:58:51.006836 41840 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:58:51.007889 41840 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [33554432, 4, 8, 4] at entry 0 and [2, 4, 8, 4] at entry 1

W0206 12:00:01.711658 42150 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:00:01.712824 42150 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:02:35.809022 42468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:02:35.809954 42468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3496, 300, 4096],"float32"),Tensor([1, 300, 4096],"float32"),], axis=0, )
[torch error] paddle.stack(list[Tensor([3496, 300, 4096],"float32"),Tensor([1, 300, 4096],"float32"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [3496, 300, 4096] at entry 0 and [1, 300, 4096] at entry 1

W0206 12:03:46.969802 43244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:03:46.971036 43244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([3496, 300, 4096],"float32"),Tensor([3496, 300, 4096],"float32"),], axis=0, )
[paddle error] paddle.stack(list[Tensor([3496, 300, 4096],"float32"),Tensor([3496, 300, 4096],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.003418GB memory on GPU 0, 65.600525GB memory has been allocated and available memory is only 13.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:06:10.789224 43556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:06:10.791812 43556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([357913942, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([357913942, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),Tensor([3, 2, 3],"int64"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [357913942, 2, 3] at entry 0 and [3, 2, 3] at entry 1

W0206 12:06:54.622095 44252 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:06:54.623293 44252 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([357913942, 2, 3],"int64"),Tensor([357913942, 2, 3],"int64"),Tensor([357913942, 2, 3],"int64"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([357913942, 2, 3],"int64"),Tensor([357913942, 2, 3],"int64"),Tensor([357913942, 2, 3],"int64"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 146416 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:08:51.868114 44416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:08:51.869241 44416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([357913942, 3, 4],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([357913942, 3, 4],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [357913942, 3, 4] at entry 0 and [2, 3, 4] at entry 1

W0206 12:10:02.599525 44979 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:10:02.600804 44979 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([357913942, 3, 4],"float32"),Tensor([357913942, 3, 4],"float32"),], axis=1, )
[paddle error] paddle.stack(list[Tensor([357913942, 3, 4],"float32"),Tensor([357913942, 3, 4],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:12:27.345353 45371 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:12:27.346246 45371 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 69625 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:17:42.777418 45976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:17:42.778479 45976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 1073741824] at entry 0 and [4, 32] at entry 1

W0206 12:18:58.783447 47496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:18:58.784754 47496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 1

W0206 12:19:51.091470 47813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:19:51.092630 47813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 2

W0206 12:20:44.939018 48086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:20:44.940239 48086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 3

W0206 12:21:38.309171 48380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:21:38.310351 48380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 4

W0206 12:22:34.333976 48659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:22:34.335310 48659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 5

W0206 12:23:31.265388 48953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:23:31.266631 48953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 6

W0206 12:24:24.351811 49145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:24:24.352998 49145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 7

W0206 12:25:17.604079 49417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:25:17.605312 49417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 8

W0206 12:26:09.146526 49704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:26:09.147646 49704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 9

W0206 12:26:56.621006 49995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:26:56.622171 49995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 10

W0206 12:27:44.853919 50163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:27:44.854979 50163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([134217729, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [134217729, 16] at entry 11

W0206 12:28:32.287218 50435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:28:32.288368 50435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 11

W0206 12:29:25.708359 50630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:29:25.709539 50630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 10

W0206 12:30:14.914888 50912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:30:14.916015 50912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 9

W0206 12:31:09.058074 51175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:31:09.059340 51175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 8

W0206 12:32:03.646400 51447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:32:03.648039 51447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 7

W0206 12:32:53.583056 51738 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:32:53.584245 51738 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 6

W0206 12:33:44.637805 51933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:33:44.638990 51933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 5

W0206 12:34:33.544132 52204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:34:33.545264 52204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 4

W0206 12:35:21.395117 52478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:35:21.396183 52478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 3

W0206 12:36:14.015255 52657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:36:14.016317 52657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 2

W0206 12:37:06.998245 52958 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:37:06.999547 52958 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 16],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 16] at entry 0 and [4, 536870913] at entry 1

W0206 12:38:00.760435 53243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:38:00.761557 53243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 1

W0206 12:39:19.198305 53428 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:39:19.199438 53428 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 1

W0206 12:40:36.597673 53832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:40:36.598770 53832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 2

W0206 12:41:48.196333 54243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:41:48.197505 54243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 2

W0206 12:43:02.488853 54556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:43:02.489966 54556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 3

W0206 12:44:12.467315 54954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:44:12.468451 54954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 3

W0206 12:45:23.383621 55283 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:45:23.384678 55283 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 4

W0206 12:46:33.712009 55595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:46:33.713047 55595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 4

W0206 12:47:44.087149 55989 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:47:44.088201 55989 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 5

W0206 12:49:00.166337 56303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:49:00.167444 56303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 5

W0206 12:50:16.008222 56618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:50:16.009431 56618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 6

W0206 12:51:32.693457 57021 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:51:32.694622 57021 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 6

W0206 12:52:47.183651 57426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:52:47.184896 57426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 7

W0206 12:54:05.074560 57751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:54:05.075845 57751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 7

W0206 12:55:16.751391 58155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:55:16.752570 58155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 8

W0206 12:56:27.143138 58479 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:56:27.144347 58479 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 8

W0206 12:57:36.685019 58783 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:57:36.686277 58783 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 9

W0206 12:58:52.624814 59169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:58:52.626111 59169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 9

W0206 13:00:03.794226 59492 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:00:03.795382 59492 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 10

W0206 13:01:13.995857 59893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:01:13.996948 59893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 10

W0206 13:02:23.500931 60191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:02:23.502133 60191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 11

W0206 13:03:39.058218 60510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:03:39.059458 60510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 11

W0206 13:04:49.860278 60913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:04:49.861367 60913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 12

W0206 13:05:58.509690 61224 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:05:58.510880 61224 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 12

W0206 13:07:16.546833 61545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:07:16.547904 61545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 13

W0206 13:08:32.703034 61938 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:08:32.704185 61938 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 13

W0206 13:09:42.294896 62258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:09:42.295946 62258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 14

W0206 13:10:57.739245 62668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:10:57.740335 62668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 14

W0206 13:12:14.618813 62994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:12:14.619889 62994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 15

W0206 13:13:25.131975 63406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:13:25.133111 63406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 15

W0206 13:14:35.536573 63713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:14:35.537642 63713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 16

W0206 13:15:45.854333 64111 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:15:45.855417 64111 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 16

W0206 13:16:55.976190 64421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:16:55.977344 64421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 17

W0206 13:18:09.327476 64719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:18:09.328719 64719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 17

W0206 13:19:21.952422 65124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:19:21.953612 65124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 18

W0206 13:20:33.010064 65448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:20:33.011125 65448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 18

W0206 13:21:43.136014 65846 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:21:43.137054 65846 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 19

W0206 13:22:54.468161 66156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:22:54.469237 66156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 19

W0206 13:24:05.711791 66468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:24:05.712877 66468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 20

W0206 13:25:17.634831 66867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:25:17.635916 66867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 20

W0206 13:26:28.135152 67179 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:26:28.136279 67179 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 21

W0206 13:27:46.716681 67506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:27:46.717901 67506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 21

W0206 13:29:08.239044 67917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:29:08.240180 67917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([134217728, 32],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [134217728, 32] at entry 22

W0206 13:30:18.523380 68329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:30:18.524470 68329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 32],"float32"),Tensor([4, 1073741824],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 1073741824] at entry 22

W0206 13:31:28.831102 68647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:31:28.832283 68647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 11

W0206 13:32:17.563750 68953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:32:17.564812 68953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 11

W0206 13:33:05.642299 69225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:33:05.643559 69225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 10

W0206 13:33:55.986322 69490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:33:55.987521 69490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 10

W0206 13:34:43.691887 69692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:34:43.693075 69692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 9

W0206 13:35:34.304093 69960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:35:34.305371 69960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 9

W0206 13:36:29.814469 70234 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:36:29.815755 70234 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 8

W0206 13:37:22.069847 70448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:37:22.071192 70448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 8

W0206 13:38:15.577894 70726 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:38:15.579121 70726 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 7

W0206 13:39:10.512964 71027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:39:10.514189 71027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 7

W0206 13:40:00.927381 71312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:40:00.928807 71312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 6

W0206 13:40:49.425751 71483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:40:49.427065 71483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 6

W0206 13:41:37.837921 71762 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:41:37.839166 71762 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 5

W0206 13:42:32.471961 72043 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:42:32.473449 72043 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 5

W0206 13:43:19.850770 72321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:43:19.851847 72321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 4

W0206 13:44:13.886637 72501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:44:13.887887 72501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 4

W0206 13:45:10.972600 72785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:45:10.973737 72785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 3

W0206 13:46:06.452226 73090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:46:06.453447 73090 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 3

W0206 13:46:57.692992 73358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:46:57.694679 73358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 3

W0206 13:47:48.676676 73548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:47:48.677932 73548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 3

W0206 13:48:38.676353 73836 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:48:38.677510 73836 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 2

W0206 13:49:27.325717 74105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:49:27.326893 74105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 2

W0206 13:50:23.655750 74299 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:50:23.657059 74299 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 2

W0206 13:51:14.098815 74592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:51:14.099993 74592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 2

W0206 13:52:00.237243 74856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:52:00.238409 74856 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 1

W0206 13:52:53.034947 75048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:52:53.036188 75048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 1

W0206 13:53:48.354573 75320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:53:48.355798 75320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [4, 536870913] at entry 1

W0206 13:54:42.697962 75611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:54:42.699178 75611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 1

W0206 13:55:30.034304 75896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:55:30.035463 75896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 1

W0206 13:56:19.014941 76077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:56:19.016095 76077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 32] at entry 0 and [67108865, 32] at entry 1

W0206 13:57:13.702925 76355 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:57:13.704124 76355 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),Tensor([4, 4, 268435456],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),Tensor([4, 4, 268435456],"int32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [4, 4, 2] at entry 0 and [4, 4, 268435456] at entry 2

W0206 13:58:52.518915 76648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:58:52.520757 76648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),Tensor([4, 536870912, 2],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),Tensor([4, 536870912, 2],"int32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [4, 4, 2] at entry 0 and [4, 536870912, 2] at entry 2

W0206 14:00:39.789026 77093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:00:39.791028 77093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),Tensor([536870912, 4, 2],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),Tensor([536870912, 4, 2],"int32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [4, 4, 2] at entry 0 and [536870912, 4, 2] at entry 2

W0206 14:02:39.570595 77638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:02:39.572381 77638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([4, 4, 268435456],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([4, 4, 268435456],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [4, 4, 2] at entry 0 and [4, 4, 268435456] at entry 1

W0206 14:04:49.717934 78166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:04:49.719828 78166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([4, 536870912, 2],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([4, 536870912, 2],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [4, 4, 2] at entry 0 and [4, 536870912, 2] at entry 1

W0206 14:07:00.098896 78695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:07:00.100746 78695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([536870912, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([4, 4, 2],"int32"),Tensor([536870912, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [4, 4, 2] at entry 0 and [536870912, 4, 2] at entry 1

W0206 14:08:50.076290 79331 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:08:50.077497 79331 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4, 268435456],"int32"),Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([4, 4, 268435456],"int32"),Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [4, 4, 268435456] at entry 0 and [4, 4, 2] at entry 1

W0206 14:10:11.585219 79769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:10:11.586413 79769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4, 268435456],"int32"),Tensor([4, 4, 268435456],"int32"),Tensor([4, 4, 268435456],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([4, 4, 268435456],"int32"),Tensor([4, 4, 268435456],"int32"),Tensor([4, 4, 268435456],"int32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 163791 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:13:44.252110 80166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:13:44.253172 80166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 11

W0206 14:14:35.429644 81149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:14:35.430733 81149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 11

W0206 14:15:24.464591 81421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:15:24.465776 81421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 10

W0206 14:16:16.742988 81597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:16:16.744102 81597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 10

W0206 14:17:05.490658 81880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:17:05.491797 81880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 9

W0206 14:17:54.104512 82126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:17:54.105834 82126 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 9

W0206 14:18:42.577785 82317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:18:42.578938 82317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 8

W0206 14:19:44.121141 82590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:19:44.122360 82590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 8

W0206 14:20:33.755697 82869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:20:33.756884 82869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 7

W0206 14:21:22.883159 83147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:21:22.884328 83147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 7

W0206 14:22:16.857249 83321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:22:16.858458 83321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 6

W0206 14:23:06.482533 83607 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:23:06.483657 83607 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 6

W0206 14:23:58.284756 83879 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:23:58.286243 83879 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 5

W0206 14:24:47.127275 84059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:24:47.128448 84059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 5

W0206 14:25:38.048245 84325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:25:38.049350 84325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 4

W0206 14:26:30.579020 84589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:26:30.580219 84589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 4

W0206 14:27:22.724264 84794 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:27:22.725459 84794 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 3

W0206 14:28:11.265627 85074 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:28:11.266671 85074 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 3

W0206 14:29:06.181723 85343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:29:06.182927 85343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 2

W0206 14:29:55.877274 85615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:29:55.878428 85615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 2

W0206 14:30:43.361734 85817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:30:43.362743 85817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [4, 536870913] at entry 1

W0206 14:31:39.230399 86095 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:31:39.231602 86095 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 4] at entry 0 and [536870913, 4] at entry 1

W0206 14:32:36.468338 86354 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:32:36.469646 86354 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 5],"float64"),Tensor([4, 536870913],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([4, 5],"float64"),Tensor([4, 536870913],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [4, 5] at entry 0 and [4, 536870913] at entry 1

W0206 14:33:34.026176 86620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:33:34.027370 86620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 5],"float64"),Tensor([429496730, 5],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([4, 5],"float64"),Tensor([429496730, 5],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [4, 5] at entry 0 and [429496730, 5] at entry 1

W0206 14:34:28.192867 86910 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:34:28.194494 86910 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870912, 2],"int32"),Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([4, 536870912, 2],"int32"),Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [4, 536870912, 2] at entry 0 and [4, 4, 2] at entry 1

W0206 14:35:41.354830 87091 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:35:41.356295 87091 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870912, 2],"int32"),Tensor([4, 536870912, 2],"int32"),Tensor([4, 536870912, 2],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([4, 536870912, 2],"int32"),Tensor([4, 536870912, 2],"int32"),Tensor([4, 536870912, 2],"int32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 35871 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:39:03.051004 87469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:39:03.052160 87469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),Tensor([4, 16],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 536870913] at entry 0 and [4, 16] at entry 1

W0206 14:39:58.804330 88424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:39:58.805447 88424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 536870913] at entry 0 and [4, 32] at entry 1

W0206 14:40:48.168493 88611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:40:48.169559 88611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 536870913] at entry 0 and [4, 32] at entry 1

W0206 14:41:38.994091 88886 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:41:38.995293 88886 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 536870913] at entry 0 and [4, 32] at entry 1

W0206 14:42:31.654278 89170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:42:31.655313 89170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 536870913] at entry 0 and [4, 4] at entry 1

W0206 14:43:28.195330 89371 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:43:28.196470 89371 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 5],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 5],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [4, 536870913] at entry 0 and [4, 5] at entry 1

W0206 14:44:19.158360 89630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:44:19.190479 89630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], )
[paddle error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:46:03.994576 89924 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:46:03.995500 89924 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], -1, )
[paddle error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:47:45.965492 90385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:47:45.966521 90385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], ) 
 CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 99970 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:50:34.646855 90901 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:50:34.647943 90901 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 63226 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:53:52.384732 91728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:53:52.385897 91728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 75970 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:57:21.486937 92501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:57:21.488049 92501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 536870913] at entry 0 and [4, 8] at entry 1

W0206 14:58:21.697937 93470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:58:21.698947 93470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 536870913] at entry 0 and [4, 8] at entry 1

W0206 14:59:10.225448 93756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:59:10.226678 93756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 536870913] at entry 0 and [4, 8] at entry 1

W0206 14:59:59.841774 94037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:59:59.843101 94037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 536870913] at entry 0 and [4, 8] at entry 1

W0206 15:00:55.313210 94217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:00:55.314221 94217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 1

W0206 15:01:43.065233 94499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:01:43.066321 94499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 1

W0206 15:02:35.916944 94767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:02:35.918192 94767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 1

W0206 15:03:24.936434 95060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:03:24.937485 95060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 1

W0206 15:04:20.184250 95226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:04:20.185392 95226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 1

W0206 15:05:09.037449 95512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:05:09.038663 95512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 1

W0206 15:05:57.951573 95793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:05:57.952785 95793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 1

W0206 15:06:46.634696 95953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:06:46.635895 95953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 1

W0206 15:07:41.294561 96233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:07:41.295789 96233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 2

W0206 15:08:29.300187 96534 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:08:29.301399 96534 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 2

W0206 15:09:21.040650 96707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:09:21.041828 96707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 2

W0206 15:10:08.328116 96978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:10:08.329228 96978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 2

W0206 15:10:58.483958 97237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:10:58.485101 97237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 2

W0206 15:11:47.867394 97429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:11:47.868547 97429 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 2

W0206 15:12:35.899551 97695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:12:35.900960 97695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 3

W0206 15:13:29.812522 97953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:13:29.813760 97953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 3

W0206 15:14:25.625003 98152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:14:25.626268 98152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 3

W0206 15:15:13.303404 98431 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:15:13.304598 98431 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),], )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),], ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 3

W0206 15:16:08.094451 98702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:16:08.095608 98702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 3

W0206 15:16:57.100096 98975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:16:57.101336 98975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 3

W0206 15:17:47.839200 99163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:17:47.840385 99163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 4

W0206 15:18:45.587756 99442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:18:45.588888 99442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 4

W0206 15:19:34.644115 99701 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:19:34.645218 99701 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 4

W0206 15:20:26.068702 99980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:20:26.069859 99980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 4

W0206 15:21:18.451531 100161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:21:18.452744 100161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 5

W0206 15:22:06.709501 100431 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:22:06.710685 100431 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 5

W0206 15:22:54.966809 100695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:22:54.968042 100695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 5

W0206 15:23:41.175081 100881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:23:41.176190 100881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 5

W0206 15:24:35.412997 101141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:24:35.414147 101141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 6

W0206 15:25:30.219554 101440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:25:30.220882 101440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 6

W0206 15:26:24.186111 101627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:26:24.187354 101627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 6

W0206 15:27:18.322142 101911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:27:18.323375 101911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 6

W0206 15:28:07.738323 102191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:28:07.739518 102191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 7

W0206 15:29:04.983249 102470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:29:04.984521 102470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 7

W0206 15:30:00.443989 102771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:30:00.445206 102771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 7

W0206 15:30:55.606549 102977 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:30:55.607736 102977 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 7

W0206 15:31:50.925652 103249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:31:50.926784 103249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 8

W0206 15:32:46.896764 103547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:32:46.897903 103547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 8

W0206 15:33:41.510653 103821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:33:41.511826 103821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 8

W0206 15:34:33.417140 104093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:34:33.418193 104093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 8

W0206 15:35:25.870644 104371 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:35:25.871788 104371 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 9

W0206 15:36:19.554977 104571 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:36:19.556219 104571 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 9

W0206 15:37:10.361439 104853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:37:10.362754 104853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 9

W0206 15:38:05.997653 105126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:38:05.998797 105126 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 9

W0206 15:38:54.853432 105392 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:38:54.854491 105392 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 10

W0206 15:39:47.950376 105596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:39:47.951663 105596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 10

W0206 15:40:44.215013 105850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:40:44.216205 105850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 10

W0206 15:41:38.939270 106135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:41:38.940528 106135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),Tensor([4, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 10

W0206 15:42:29.039918 106415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:42:29.041018 106415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 11

W0206 15:43:18.246956 106617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:43:18.248051 106617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([268435457, 8],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [268435457, 8] at entry 11

W0206 15:44:11.254789 106883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:44:11.256038 106883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 11

W0206 15:45:00.231660 107168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:45:00.232847 107168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 8],"float64"),Tensor([4, 536870913],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4, 8] at entry 0 and [4, 536870913] at entry 11

W0206 15:45:47.894150 107348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:45:47.895375 107348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295, 1],"float32"),], axis=0, )
[Pass] paddle.stack(list[Tensor([4294967295, 1],"float32"),], axis=0, )

W0206 15:47:11.114820 107617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:47:11.115826 107617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295, 1],"float32"),Tensor([1, 1],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([4294967295, 1],"float32"),Tensor([1, 1],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [4294967295, 1] at entry 0 and [1, 1] at entry 1

W0206 15:50:54.938848 108733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:50:54.939975 108733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295, 1],"float32"),Tensor([2, 1],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([4294967295, 1],"float32"),Tensor([2, 1],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [4294967295, 1] at entry 0 and [2, 1] at entry 1

W0206 15:52:06.002460 109052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:52:06.003629 109052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295, 1],"float32"),Tensor([4294967295, 1],"float32"),], -1, )
[paddle error] paddle.stack(list[Tensor([4294967295, 1],"float32"),Tensor([4294967295, 1],"float32"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:54:38.580343 109435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:54:38.581331 109435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 15:56:01.377943 110132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:56:01.379292 110132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 15:57:24.922019 110458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:57:24.923337 110458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),Tensor([1],"float16"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 15:58:55.916154 110883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:58:55.917393 110883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),], )
[Pass] paddle.stack(list[Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),], )

W0206 16:01:43.932126 111334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:01:43.933080 111334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 152307 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:25:01.368257 116449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:25:01.369278 116449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.19 GiB is free. Process 33162 has 72.99 GiB memory in use. Of the allocated memory 72.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:38:05.736059 118595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:38:05.737112 118595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),], )
[Pass] paddle.stack(list[Tensor([4294967295],"float32"),], )

W0206 16:39:26.040824 122315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:39:26.041783 122315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 16:42:51.259928 123275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:42:51.261291 123275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),], 1, )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),], 1, ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 16:44:08.081723 123586 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:44:08.082842 123586 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 16:45:15.608390 123987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:45:15.609658 123987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 16:46:25.726475 124278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:46:25.727604 124278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 16:47:46.030287 124587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:47:46.031428 124587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 16:48:56.821290 125020 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:48:56.822662 125020 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 16:50:07.543988 125332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:50:07.545231 125332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 16:51:17.882329 125725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:51:17.883476 125725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [1] at entry 1

W0206 16:52:32.216677 126043 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:52:32.217942 126043 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([10],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [10] at entry 1

W0206 16:53:49.710186 126362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:53:49.711324 126362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([10],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([10],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [10] at entry 1

W0206 16:55:02.556875 126766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:55:02.558115 126766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [12] at entry 1

W0206 16:56:21.555641 127077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:56:21.556720 127077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),Tensor([12],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [12] at entry 1

W0206 16:57:31.183861 127482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:57:31.185197 127482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([120],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([120],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [120] at entry 1

W0206 16:58:42.228404 127793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:58:42.229704 127793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),Tensor([15],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [15] at entry 1

W0206 16:59:52.382616 128184 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:59:52.383970 128184 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([16],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([16],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [16] at entry 1

W0206 17:01:03.353209 128506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:01:03.354557 128506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([2],"float32"),], 0, )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([2],"float32"),], 0, ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [2] at entry 1

W0206 17:02:20.138872 128823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:02:20.139964 128823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([2],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([2],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [2] at entry 1

W0206 17:03:39.573832 129235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:03:39.574954 129235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),Tensor([2],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [2] at entry 1

W0206 17:04:50.783193 129669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:04:50.784554 129669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([3],"float32"),], 1, )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([3],"float32"),], 1, ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [3] at entry 1

W0206 17:06:10.741829 129983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:06:10.742853 129983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([3],"float32"),], -1, )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([3],"float32"),], -1, ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [3] at entry 1

W0206 17:07:21.967847 130389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:07:21.969643 130389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([3],"float32"),Tensor([3],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([3],"float32"),Tensor([3],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [3] at entry 1

W0206 17:08:42.500388 130712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:08:42.501475 130712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[paddle error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:11:13.312350 131117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:11:13.313197 131117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], 0, )
[paddle error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], 0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:13:54.127457 131819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:13:54.129787 131819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], 1, )
[paddle error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:16:24.017275 132527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:16:24.018234 132527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], -1, )
[paddle error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:18:47.656666 133229 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:18:47.657637 133229 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], axis=1, )
[paddle error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:21:21.262651 133937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:21:21.263494 133937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 29700 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:24:32.590318 134667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:24:32.591435 134667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 27874 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:27:43.000870 135625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:27:43.001976 135625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 32150 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:33:00.298507 136477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:33:00.300978 136477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 49275 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:38:31.151255 137908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:38:31.152379 137908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 38747 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:43:45.951961 139525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:43:45.952965 139525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 105481 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:49:13.593185 140961 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:49:13.594306 140961 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 113804 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:54:26.340502 142486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:54:26.343133 142486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 126153 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:59:46.538491 143878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:59:46.539633 143878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 52738 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:05:11.330049 145385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:05:11.331149 145385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([6],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([6],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [6] at entry 1

W0206 18:06:29.165944 146929 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:06:29.167093 146929 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([84],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([84],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [84] at entry 1

W0206 18:07:43.563093 147241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:07:43.564232 147241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [4294967295] at entry 0 and [9] at entry 1

W0206 18:08:57.581812 147655 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:08:57.582949 147655 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([4294967295],"int32"),], 1, )
[Pass] paddle.stack(list[Tensor([4294967295],"int32"),], 1, )

W0206 18:10:16.788458 147970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:10:16.789407 147970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([429496730, 2, 5],"float16"),Tensor([429496730, 2, 5],"float16"),Tensor([429496730, 2, 5],"float16"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([429496730, 2, 5],"float16"),Tensor([429496730, 2, 5],"float16"),Tensor([429496730, 2, 5],"float16"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_stack(_object*, _object*, _object*)
1   stack_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
2   paddle::experimental::stack(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
3   void phi::funcs::StackRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, int, phi::DenseTensor*)
4   void phi::funcs::LaunchStackKernel<phi::GPUContext, phi::dtype::float16, long, (phi::funcs::SegmentedArraySize)4>(phi::GPUContext const&, long, long, long, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, phi::DenseTensor*)
5   phi::dtype::float16* phi::DeviceContext::Alloc<phi::dtype::float16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 24.000000GB memory on GPU 0, 73.598572GB memory has been allocated and available memory is only 5.586304GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:18:10.373402 149319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:18:10.374445 149319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([429496730, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([429496730, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [429496730, 2, 5] at entry 0 and [5, 2, 5] at entry 1

W0206 18:19:48.178174 150595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:19:48.179473 150595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([429496730, 5],"float64"),Tensor([2, 5],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([429496730, 5],"float64"),Tensor([2, 5],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [429496730, 5] at entry 0 and [2, 5] at entry 1

W0206 18:20:40.647019 151041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:20:40.648167 151041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([429496730, 5],"float64"),Tensor([4, 5],"float64"),], -1, )
[torch error] paddle.stack(list[Tensor([429496730, 5],"float64"),Tensor([4, 5],"float64"),], -1, ) 
 stack expects each tensor to be equal size, but got [429496730, 5] at entry 0 and [4, 5] at entry 1

W0206 18:21:31.558741 151314 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:21:31.559904 151314 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([429496730, 5],"float64"),Tensor([429496730, 5],"float64"),], -1, )
[paddle error] paddle.stack(list[Tensor([429496730, 5],"float64"),Tensor([429496730, 5],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:23:15.630508 151506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:23:15.631573 151506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 1] at entry 0 and [2147483649, 1, 1] at entry 1

W0206 18:24:08.023746 152057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:24:08.024972 152057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 1] at entry 0 and [2147483649, 1, 1] at entry 1

W0206 18:24:58.230743 152329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:24:58.232030 152329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 1] at entry 0 and [2147483649, 1, 1] at entry 2

W0206 18:25:50.965814 152522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:25:50.967049 152522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),Tensor([5, 1, 429496730],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),Tensor([5, 1, 429496730],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 1] at entry 0 and [5, 1, 429496730] at entry 2

W0206 18:26:44.299607 152807 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:26:44.300737 152807 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),Tensor([5, 429496730, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),Tensor([5, 429496730, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 1] at entry 0 and [5, 429496730, 1] at entry 2

W0206 18:27:33.130826 153098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:27:33.131956 153098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 1, 429496730],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 1, 429496730],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 1] at entry 0 and [5, 1, 429496730] at entry 1

W0206 18:28:25.700668 153327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:28:25.702013 153327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 1] at entry 0 and [5, 1, 429496730] at entry 1

W0206 18:29:16.561769 153558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:29:16.562813 153558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 429496730, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 429496730, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 1] at entry 0 and [5, 429496730, 1] at entry 1

W0206 18:30:10.457881 153837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:30:10.462296 153837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 429496730, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 1],"float64"),Tensor([5, 429496730, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 1] at entry 0 and [5, 429496730, 1] at entry 1

W0206 18:31:07.269001 154123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:31:07.270285 154123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 1, 2] at entry 0 and [2147483648, 1, 2] at entry 1

W0206 18:32:26.503127 154417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:32:26.504258 154417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 1, 2] at entry 0 and [2147483648, 1, 2] at entry 2

W0206 18:33:44.000803 154730 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:33:44.002599 154730 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),Tensor([5, 1, 858993459],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),Tensor([5, 1, 858993459],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 1, 2] at entry 0 and [5, 1, 858993459] at entry 2

W0206 18:34:56.644129 155153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:34:56.645392 155153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),Tensor([5, 429496730, 2],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),Tensor([5, 429496730, 2],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 1, 2] at entry 0 and [5, 429496730, 2] at entry 2

W0206 18:36:11.313448 155461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:36:11.314626 155461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([5, 1, 858993459],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([5, 1, 858993459],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 1, 2] at entry 0 and [5, 1, 858993459] at entry 1

W0206 18:37:28.048403 155893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:37:28.049629 155893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([5, 429496730, 2],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 1, 2],"float32"),Tensor([5, 429496730, 2],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 1, 2] at entry 0 and [5, 429496730, 2] at entry 1

W0206 18:38:44.643040 156227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:38:44.644500 156227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 429496730] at entry 0 and [5, 1, 1] at entry 1

W0206 18:39:33.720286 156631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:39:33.721419 156631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 1, 429496730] at entry 0 and [5, 1, 1] at entry 1

W0206 18:40:29.711406 156852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:40:29.712965 156852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 429496730],"float64"),], 0, )
[paddle error] paddle.stack(list[Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 429496730],"float64"),], 0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:42:08.222539 157081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:42:08.223456 157081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 429496730],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 429496730],"float64"),Tensor([5, 1, 429496730],"float64"),], 0, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 115709 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:44:18.012301 157643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:44:18.013407 157643 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 858993459],"float32"),Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 1, 858993459],"float32"),Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 1, 858993459] at entry 0 and [5, 1, 2] at entry 1

W0206 18:45:31.586326 158217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:45:31.587812 158217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 1, 858993459],"float32"),Tensor([5, 1, 858993459],"float32"),Tensor([5, 1, 858993459],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 1, 858993459],"float32"),Tensor([5, 1, 858993459],"float32"),Tensor([5, 1, 858993459],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 29952 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:48:53.189391 158543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:48:53.190487 158543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 171798692, 5],"float16"),Tensor([5, 171798692, 5],"float16"),Tensor([5, 171798692, 5],"float16"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([5, 171798692, 5],"float16"),Tensor([5, 171798692, 5],"float16"),Tensor([5, 171798692, 5],"float16"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_stack(_object*, _object*, _object*)
1   stack_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
2   paddle::experimental::stack(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
3   void phi::funcs::StackRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, int, phi::DenseTensor*)
4   void phi::funcs::LaunchStackKernel<phi::GPUContext, phi::dtype::float16, long, (phi::funcs::SegmentedArraySize)4>(phi::GPUContext const&, long, long, long, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, phi::DenseTensor*)
5   phi::dtype::float16* phi::DeviceContext::Alloc<phi::dtype::float16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 24.000000GB memory on GPU 0, 73.598572GB memory has been allocated and available memory is only 5.586304GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:53:07.718746 159513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:53:07.719961 159513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 171798692, 5],"float16"),Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 171798692, 5],"float16"),Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 171798692, 5] at entry 0 and [5, 2, 5] at entry 1

W0206 18:54:41.737010 160767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:54:41.738159 160767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 2, 429496730],"float16"),Tensor([5, 2, 429496730],"float16"),Tensor([5, 2, 429496730],"float16"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([5, 2, 429496730],"float16"),Tensor([5, 2, 429496730],"float16"),Tensor([5, 2, 429496730],"float16"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_stack(_object*, _object*, _object*)
1   stack_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
2   paddle::experimental::stack(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
3   void phi::funcs::StackRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, int, phi::DenseTensor*)
4   void phi::funcs::LaunchStackKernel<phi::GPUContext, phi::dtype::float16, long, (phi::funcs::SegmentedArraySize)4>(phi::GPUContext const&, long, long, long, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, phi::DenseTensor*)
5   phi::dtype::float16* phi::DeviceContext::Alloc<phi::dtype::float16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 24.000000GB memory on GPU 0, 73.598572GB memory has been allocated and available memory is only 5.586304GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:59:03.251089 161181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:59:03.252161 161181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 2, 429496730],"float16"),Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 2, 429496730],"float16"),Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 2, 429496730] at entry 0 and [5, 2, 5] at entry 1

W0206 19:00:43.148818 162432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:00:43.150162 162432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([429496730, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([429496730, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 2, 5] at entry 0 and [429496730, 2, 5] at entry 1

W0206 19:02:07.395857 162870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:02:07.396906 162870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([5, 171798692, 5],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([5, 171798692, 5],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 2, 5] at entry 0 and [5, 171798692, 5] at entry 1

W0206 19:03:38.146745 163292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:03:38.147938 163292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([5, 2, 429496730],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([5, 2, 429496730],"float16"),Tensor([5, 2, 5],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 2, 5] at entry 0 and [5, 2, 429496730] at entry 1

W0206 19:05:03.035698 163744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:05:03.036881 163744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),Tensor([429496730, 2, 5],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),Tensor([429496730, 2, 5],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 2, 5] at entry 0 and [429496730, 2, 5] at entry 2

W0206 19:06:32.973816   758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:06:32.975114   758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),Tensor([5, 171798692, 5],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),Tensor([5, 171798692, 5],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 2, 5] at entry 0 and [5, 171798692, 5] at entry 2

W0206 19:07:57.387403  1226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:07:57.388571  1226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),Tensor([5, 2, 429496730],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 2, 5],"float16"),Tensor([5, 2, 5],"float16"),Tensor([5, 2, 429496730],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 2, 5] at entry 0 and [5, 2, 429496730] at entry 2

W0206 19:09:27.745819  1604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:09:27.746927  1604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 4],"float64"),Tensor([5, 429496730],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 4],"float64"),Tensor([5, 429496730],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 4] at entry 0 and [5, 429496730] at entry 1

W0206 19:10:19.383903  2036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:10:19.385128  2036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 4],"float64"),Tensor([536870913, 4],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 4],"float64"),Tensor([536870913, 4],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 4] at entry 0 and [536870913, 4] at entry 1

W0206 19:11:09.200613  2310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:11:09.201756  2310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 429496730, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 429496730, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 429496730, 1] at entry 0 and [5, 1, 1] at entry 1

W0206 19:11:58.872562  2600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:11:58.873836  2600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 429496730, 1],"float64"),Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 429496730, 1],"float64"),Tensor([5, 1, 1],"float64"),Tensor([5, 1, 1],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 429496730, 1] at entry 0 and [5, 1, 1] at entry 1

W0206 19:12:49.303439  2782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:12:49.304502  2782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 429496730, 1],"float64"),Tensor([5, 429496730, 1],"float64"),], 0, )
[paddle error] paddle.stack(list[Tensor([5, 429496730, 1],"float64"),Tensor([5, 429496730, 1],"float64"),], 0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:14:28.954782  3054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:14:28.955696  3054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 429496730, 1],"float64"),Tensor([5, 429496730, 1],"float64"),Tensor([5, 429496730, 1],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 429496730, 1],"float64"),Tensor([5, 429496730, 1],"float64"),Tensor([5, 429496730, 1],"float64"),], 0, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 61480 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:16:42.725158  3499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:16:42.726212  3499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 429496730, 2],"float32"),Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 429496730, 2],"float32"),Tensor([5, 1, 2],"float32"),Tensor([5, 1, 2],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [5, 429496730, 2] at entry 0 and [5, 1, 2] at entry 1

W0206 19:17:57.904233  4184 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:17:57.905452  4184 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 429496730, 2],"float32"),Tensor([5, 429496730, 2],"float32"),Tensor([5, 429496730, 2],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([5, 429496730, 2],"float32"),Tensor([5, 429496730, 2],"float32"),Tensor([5, 429496730, 2],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 8852 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:21:26.164386  4443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:21:26.165418  4443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 429496730],"float64"),Tensor([5, 4],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5, 429496730],"float64"),Tensor([5, 4],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5, 429496730] at entry 0 and [5, 4] at entry 1

W0206 19:22:16.273483  5358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:22:16.280531  5358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5, 429496730],"float64"),Tensor([5, 429496730],"float64"),], 0, )
[paddle error] paddle.stack(list[Tensor([5, 429496730],"float64"),Tensor([5, 429496730],"float64"),], 0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:23:59.499742  5617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:23:59.500655  5617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [5] at entry 0 and [2147483649] at entry 1

W0206 19:24:46.074021  6069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:24:46.075166  6069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([536870912, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),Tensor([4, 4, 2],"int32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [536870912, 4, 2] at entry 0 and [4, 4, 2] at entry 1

W0206 19:26:00.914889  6348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:26:00.916282  6348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 4, 2],"int32"),Tensor([536870912, 4, 2],"int32"),Tensor([536870912, 4, 2],"int32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([536870912, 4, 2],"int32"),Tensor([536870912, 4, 2],"int32"),Tensor([536870912, 4, 2],"int32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 103281 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:29:16.985935  6660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:29:16.987032  6660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 27549 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:32:41.623665  7623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:32:41.624646  7623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], ) 
 CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 124241 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:37:00.960654  8613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:37:00.961781  8613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 113539 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:42:17.327139  9797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:42:17.330139  9797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 17188 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:47:35.397565 11305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:47:35.398706 11305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 98171 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:52:53.445676 12822 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:52:53.446794 12822 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 145573 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:58:24.165742 14243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:58:24.166890 14243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 58160 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:04:03.968526 15783 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:04:03.971294 15783 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [536870912, 8] at entry 0 and [8, 8] at entry 1

W0206 20:05:18.564342 17418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:05:18.565914 17418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [536870912, 8] at entry 0 and [8, 8] at entry 1

W0206 20:06:29.972045 17736 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:06:29.973258 17736 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [536870912, 8] at entry 0 and [8, 8] at entry 1

W0206 20:07:50.353921 18060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:07:50.355029 18060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [536870912, 8] at entry 0 and [8, 8] at entry 1

W0206 20:09:00.801681 18480 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:09:00.803421 18480 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [536870912, 8] at entry 0 and [8, 8] at entry 1

W0206 20:10:21.507331 18779 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:10:21.508608 18779 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [536870912, 8] at entry 0 and [8, 8] at entry 1

W0206 20:11:33.424630 19195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:11:33.425818 19195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [536870912, 8] at entry 0 and [8, 8] at entry 1

W0206 20:12:50.691285 19508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:12:50.692430 19508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),Tensor([4, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [536870913, 4] at entry 0 and [4, 4] at entry 1

W0206 20:13:39.754962 19899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:13:39.756672 19899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([5, 4],"float64"),], 0, )
[torch error] paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([5, 4],"float64"),], 0, ) 
 stack expects each tensor to be equal size, but got [536870913, 4] at entry 0 and [5, 4] at entry 1

W0206 20:14:29.472596 20170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:14:29.474002 20170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),], 0, )
[paddle error] paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),], 0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:16:21.054522 20336 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:16:21.057504 20336 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 75462 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:19:43.665472 20900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:19:43.668084 20900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([536870913, 4],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 16523 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:23:05.593693 21889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:23:05.594826 21889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [536870913, 4] at entry 0 and [8, 4] at entry 1

W0206 20:23:59.785640 22868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:23:59.786981 22868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),], )
[paddle error] paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:25:42.692607 23048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:25:42.693557 23048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),], axis=2, )
[paddle error] paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:27:26.677168 23585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:27:26.678066 23585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([536870913, 4],"int64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 89869 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:30:45.002974 24034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:30:45.004033 24034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),], )
[torch error] paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),], ) 
 stack expects each tensor to be equal size, but got [536870913, 4] at entry 0 and [8, 4] at entry 1

W0206 20:31:34.851907 25012 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:31:34.853021 25012 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),], axis=2, )
[torch error] paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),], axis=2, ) 
 stack expects each tensor to be equal size, but got [536870913, 4] at entry 0 and [8, 4] at entry 1

W0206 20:32:40.018848 25289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:32:40.020216 25289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [536870913, 4] at entry 0 and [8, 4] at entry 1

W0206 20:33:27.192035 25589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:33:27.193243 25589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5478275, 28, 28],"float32"),Tensor([5478275, 28, 28],"float32"),Tensor([5478275, 28, 28],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([5478275, 28, 28],"float32"),Tensor([5478275, 28, 28],"float32"),Tensor([5478275, 28, 28],"float32"),], axis=-4, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 37192 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:36:54.206059 25781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:36:54.207098 25781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([5478275, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([5478275, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [5478275, 28, 28] at entry 0 and [6, 28, 28] at entry 1

W0206 20:38:06.661692 26784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:38:06.662833 26784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 25565282, 28],"float32"),Tensor([6, 25565282, 28],"float32"),Tensor([6, 25565282, 28],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 25565282, 28],"float32"),Tensor([6, 25565282, 28],"float32"),Tensor([6, 25565282, 28],"float32"),], axis=-4, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 71066 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:41:27.827126 27195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:41:27.828219 27195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 25565282, 28],"float32"),Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 25565282, 28],"float32"),Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 25565282, 28] at entry 0 and [6, 28, 28] at entry 1

W0206 20:42:41.209859 28079 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:42:41.210932 28079 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 28, 25565282],"float32"),Tensor([6, 28, 25565282],"float32"),Tensor([6, 28, 25565282],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 28, 25565282],"float32"),Tensor([6, 28, 25565282],"float32"),Tensor([6, 28, 25565282],"float32"),], axis=-4, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 83949 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:45:55.428315 28470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:45:55.429455 28470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 28, 25565282],"float32"),Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 28, 25565282],"float32"),Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 28, 25565282] at entry 0 and [6, 28, 28] at entry 1

W0206 20:47:16.243199 29330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:47:16.244194 29330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([5478275, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([5478275, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 28, 28] at entry 0 and [5478275, 28, 28] at entry 1

W0206 20:48:30.521102 29743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:48:30.522392 29743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([6, 25565282, 28],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([6, 25565282, 28],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 28, 28] at entry 0 and [6, 25565282, 28] at entry 1

W0206 20:49:42.469389 30065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:49:42.470564 30065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([6, 28, 25565282],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([6, 28, 25565282],"float32"),Tensor([6, 28, 28],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 28, 28] at entry 0 and [6, 28, 25565282] at entry 1

W0206 20:50:54.885493 30458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:50:54.886729 30458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),Tensor([5478275, 28, 28],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),Tensor([5478275, 28, 28],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 28, 28] at entry 0 and [5478275, 28, 28] at entry 2

W0206 20:52:06.370126 30783 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:52:06.371191 30783 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),Tensor([6, 25565282, 28],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),Tensor([6, 25565282, 28],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 28, 28] at entry 0 and [6, 25565282, 28] at entry 2

W0206 20:53:16.591516 31180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:53:16.592705 31180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),Tensor([6, 28, 25565282],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 28, 28],"float32"),Tensor([6, 28, 28],"float32"),Tensor([6, 28, 25565282],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 28, 28] at entry 0 and [6, 28, 25565282] at entry 2

W0206 20:54:27.962455 31501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:54:27.963532 31501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),Tensor([6, 8, 89478486],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),Tensor([6, 8, 89478486],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 8, 8] at entry 0 and [6, 8, 89478486] at entry 2

W0206 20:55:37.347476 31812 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:55:37.348681 31812 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),Tensor([6, 89478486, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),Tensor([6, 89478486, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 8, 8] at entry 0 and [6, 89478486, 8] at entry 2

W0206 20:56:47.959061 32203 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:56:47.960299 32203 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 8, 8] at entry 0 and [67108864, 8, 8] at entry 2

W0206 20:57:59.138832 32496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:57:59.139895 32496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([6, 8, 89478486],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([6, 8, 89478486],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 8, 8] at entry 0 and [6, 8, 89478486] at entry 1

W0206 20:59:10.119067 32821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:59:10.120234 32821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([6, 89478486, 8],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([6, 89478486, 8],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 8, 8] at entry 0 and [6, 89478486, 8] at entry 1

W0206 21:00:26.037839 33204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:00:26.039036 33204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 8, 8] at entry 0 and [67108864, 8, 8] at entry 1

W0206 21:01:42.105137 33514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:01:42.106316 33514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 8, 89478486],"float32"),Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 8, 89478486],"float32"),Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 8, 89478486] at entry 0 and [6, 8, 8] at entry 1

W0206 21:02:54.938913 33934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:02:54.939988 33934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 8, 89478486],"float32"),Tensor([6, 8, 89478486],"float32"),Tensor([6, 8, 89478486],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 8, 89478486],"float32"),Tensor([6, 8, 89478486],"float32"),Tensor([6, 8, 89478486],"float32"),], axis=-4, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 96275 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:06:16.442335 34260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:06:16.443480 34260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 89478486, 8],"float32"),Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 89478486, 8],"float32"),Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [6, 89478486, 8] at entry 0 and [6, 8, 8] at entry 1

W0206 21:07:29.524463 35240 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:07:29.525835 35240 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6, 89478486, 8],"float32"),Tensor([6, 89478486, 8],"float32"),Tensor([6, 89478486, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([6, 89478486, 8],"float32"),Tensor([6, 89478486, 8],"float32"),Tensor([6, 89478486, 8],"float32"),], axis=-4, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 103650 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:10:40.161442 35568 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:10:40.162600 35568 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([6],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([6],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [6] at entry 0 and [4294967295] at entry 1

W0206 21:11:53.652818 36550 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:11:53.654071 36550 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 2, 1, 32],"float16"),Tensor([2, 2, 1, 32],"float16"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([67108864, 2, 1, 32],"float16"),Tensor([2, 2, 1, 32],"float16"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [67108864, 2, 1, 32] at entry 0 and [2, 2, 1, 32] at entry 1

W0206 21:13:20.328506 36861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:13:20.329802 36861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 2, 1, 32],"float16"),Tensor([67108864, 2, 1, 32],"float16"),], axis=-1, )
[Pass] paddle.stack(list[Tensor([67108864, 2, 1, 32],"float16"),Tensor([67108864, 2, 1, 32],"float16"),], axis=-1, )

W0206 21:16:05.126544 37287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:16:05.127476 37287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 2, 8, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.stack(list[Tensor([67108864, 2, 8, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, ) 
 stack expects each tensor to be equal size, but got [67108864, 2, 8, 4] at entry 0 and [1, 2, 8, 4] at entry 1

W0206 21:32:58.270567 42522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:32:58.271725 42522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 2, 8, 4],"float32"),Tensor([67108864, 2, 8, 4],"float32"),], axis=-1, )
[paddle error] paddle.stack(list[Tensor([67108864, 2, 8, 4],"float32"),Tensor([67108864, 2, 8, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:35:27.270807 42852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:35:27.271855 42852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [67108864, 8, 8] at entry 0 and [2, 8, 8] at entry 1

W0206 21:36:43.075913 43544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:36:43.076987 43544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [67108864, 8, 8] at entry 0 and [2, 8, 8] at entry 1

W0206 21:38:04.591966 43979 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:38:04.592941 43979 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([3, 8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([3, 8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [67108864, 8, 8] at entry 0 and [3, 8, 8] at entry 1

W0206 21:39:15.326496 44377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:39:15.327924 44377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),Tensor([6, 8, 8],"float32"),], axis=-4, ) 
 stack expects each tensor to be equal size, but got [67108864, 8, 8] at entry 0 and [6, 8, 8] at entry 1

W0206 21:40:28.846662 44697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:40:28.848184 44697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], )
[paddle error] paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:42:53.500762 45030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:42:53.501636 45030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 119405 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:46:08.756106 45733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:46:08.757122 45733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-4, )
[torch error] paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-4, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 42844 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:49:22.294557 46721 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:49:22.295634 46721 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 104771 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:54:52.884037 47603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:54:52.885066 47603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [67108865, 32] at entry 0 and [1, 32] at entry 1

W0206 21:55:45.388613 49180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:55:45.389724 49180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),Tensor([1, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [67108865, 32] at entry 0 and [1, 32] at entry 1

W0206 21:56:37.862912 49458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:56:37.863911 49458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),], ) 
 stack expects each tensor to be equal size, but got [67108865, 32] at entry 0 and [4, 32] at entry 1

W0206 21:57:30.440788 49730 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:57:30.441777 49730 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], ) 
 stack expects each tensor to be equal size, but got [67108865, 32] at entry 0 and [4, 32] at entry 1

W0206 21:58:22.112414 49916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:58:22.113595 49916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),Tensor([4, 32],"float64"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [67108865, 32] at entry 0 and [4, 32] at entry 1

W0206 21:59:15.541132 50210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:59:15.542613 50210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),], )
[paddle error] paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:00:56.344179 50496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:00:56.345170 50496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=0, )
[paddle error] paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:02:49.202344 50943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:02:49.203434 50943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),], )
[torch error] paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),], ) 
 CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 121529 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:05:32.149914 51510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:05:32.150903 51510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 149291 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:08:53.996416 52322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:08:53.997522 52322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=1, )
[torch error] paddle.stack(list[Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),Tensor([67108865, 32],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 76464 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:12:12.051956 53201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:12:12.054540 53201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 4516 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:15:30.833351 54153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:15:30.834463 54153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 268435457] at entry 0 and [8, 4] at entry 1

W0206 22:16:28.876255 55054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:16:28.877213 55054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),], )
[paddle error] paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:18:10.835742 55327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:18:10.836614 55327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),], axis=2, )
[paddle error] paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:19:51.636987 55869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:19:51.637957 55869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 268435457],"int64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 71472 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:23:10.548295 56322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:23:10.549386 56322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),], )
[torch error] paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),], ) 
 stack expects each tensor to be equal size, but got [8, 268435457] at entry 0 and [8, 4] at entry 1

W0206 22:24:07.698704 57282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:24:07.699925 57282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),], axis=2, )
[torch error] paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),], axis=2, ) 
 stack expects each tensor to be equal size, but got [8, 268435457] at entry 0 and [8, 4] at entry 1

W0206 22:24:57.679562 57567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:24:57.680760 57567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 268435457] at entry 0 and [8, 4] at entry 1

W0206 22:25:44.264559 57750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:25:44.265761 57750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 1

W0206 22:26:32.038663 58011 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:26:32.039731 58011 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 1

W0206 22:27:26.311621 58188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:27:26.313012 58188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 2

W0206 22:28:15.196039 58472 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:28:15.197075 58472 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 2

W0206 22:29:05.331300 58760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:29:05.332408 58760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 3

W0206 22:30:03.501442 59013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:30:03.502702 59013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 3

W0206 22:30:53.144626 59292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:30:53.145716 59292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 4

W0206 22:31:46.360647 59512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:31:46.362099 59512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 4

W0206 22:32:40.427683 59785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:32:40.428928 59785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 5

W0206 22:33:29.701785 60051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:33:29.702936 60051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 5

W0206 22:34:18.123051 60249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:34:18.124107 60249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 6

W0206 22:35:08.563755 60522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:35:08.564857 60522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 6

W0206 22:35:57.285529 60808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:35:57.286758 60808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 7

W0206 22:36:45.630558 61001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:36:45.631737 61001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 7

W0206 22:37:40.589192 61283 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:37:40.590364 61283 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 8

W0206 22:38:37.398422 61556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:38:37.399657 61556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 8

W0206 22:39:33.036947 61847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:39:33.038153 61847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 9

W0206 22:40:22.508404 62036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:40:22.509562 62036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 9

W0206 22:41:17.657449 62314 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:41:17.658663 62314 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 10

W0206 22:42:13.207705 62593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:42:13.208985 62593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 10

W0206 22:43:02.884902 62863 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:43:02.886132 62863 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 11

W0206 22:43:51.753348 63057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:43:51.754508 63057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 11

W0206 22:44:40.387908 63322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:44:40.389101 63322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 12

W0206 22:45:38.281976 63587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:45:38.283110 63587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 12

W0206 22:46:27.328845 63878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:46:27.329895 63878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 13

W0206 22:47:16.540953 64072 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:47:16.542016 64072 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 13

W0206 22:48:06.141124 64352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:48:06.142191 64352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 14

W0206 22:48:55.874063 64604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:48:55.875221 64604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 14

W0206 22:49:42.575477 64796 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:49:42.576622 64796 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 15

W0206 22:50:30.915550 65083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:50:30.916739 65083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 15

W0206 22:51:19.648684 65249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:51:19.649905 65249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 16

W0206 22:52:08.405229 65516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:52:08.406352 65516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 16

W0206 22:53:01.084702 65781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:53:01.085860 65781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 17

W0206 22:53:50.046108 65965 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:53:50.047238 65965 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 17

W0206 22:54:39.796087 66245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:54:39.797116 66245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 18

W0206 22:55:28.934609 66525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:55:28.935765 66525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 18

W0206 22:56:22.305447 66705 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:56:22.306519 66705 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 19

W0206 22:57:16.115903 66989 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:57:16.117110 66989 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),Tensor([8, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 19

W0206 22:58:11.121549 67301 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:58:11.122802 67301 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([536870913, 4],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 20

W0206 22:59:00.946205 67582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:59:00.947301 67582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 4],"float64"),Tensor([8, 268435457],"float64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 20

W0206 22:59:50.007649 67777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:59:50.008818 67777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),], )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),], ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 1

W0206 23:00:40.384640 68029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:00:40.385807 68029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),], axis=2, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),], axis=2, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 1

W0206 23:01:27.044633 68294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:01:27.045708 68294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 1

W0206 23:02:11.748924 68485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:02:11.750416 68485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),], )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),], ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 1

W0206 23:02:58.510589 68741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:02:58.511798 68741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),], axis=2, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),], axis=2, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 1

W0206 23:03:45.003238 68918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:03:45.004293 68918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 1

W0206 23:04:31.175786 69194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:04:31.176829 69194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 2

W0206 23:05:22.129871 69355 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:05:22.131181 69355 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 2

W0206 23:06:12.945165 69638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:06:12.946444 69638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 3

W0206 23:07:04.827276 69904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:07:04.828506 69904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 3

W0206 23:07:52.092044 70196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:07:52.093209 70196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 4

W0206 23:08:43.602593 70376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:08:43.603797 70376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 4

W0206 23:09:30.708213 70648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:09:30.709445 70648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 5

W0206 23:10:22.278240 70835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:10:22.279421 70835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 5

W0206 23:11:10.032511 71106 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:11:10.033802 71106 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 6

W0206 23:11:58.037935 71384 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:11:58.039207 71384 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 6

W0206 23:12:47.713125 71561 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:12:47.714375 71561 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 7

W0206 23:13:35.469385 71831 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:13:35.470747 71831 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 7

W0206 23:14:25.990443 72098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:14:25.991616 72098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 8

W0206 23:15:13.726512 72303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:15:13.727818 72303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 8

W0206 23:16:03.069682 72555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:16:03.071067 72555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 9

W0206 23:16:49.807274 72748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:16:49.808398 72748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 9

W0206 23:17:39.481283 73014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:17:39.482481 73014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 10

W0206 23:18:28.103942 73280 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:18:28.105218 73280 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 10

W0206 23:19:15.595312 73452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:19:15.596403 73452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 11

W0206 23:20:01.954062 73712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:20:01.955132 73712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 11

W0206 23:20:49.245510 73884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:20:49.246593 73884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 12

W0206 23:21:37.948163 74136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:21:37.949313 74136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 12

W0206 23:22:24.633131 74401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:22:24.634513 74401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 13

W0206 23:23:16.558175 74579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:23:16.559345 74579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 13

W0206 23:24:04.278623 74851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:24:04.279771 74851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 14

W0206 23:24:56.809373 75115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:24:56.811075 75115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 14

W0206 23:25:45.805025 75308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:25:45.806325 75308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 15

W0206 23:26:35.153671 75565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:26:35.154891 75565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 15

W0206 23:27:24.109993 75844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:27:24.111181 75844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 16

W0206 23:28:13.213024 76039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:28:13.214259 76039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 16

W0206 23:29:04.524952 76304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:29:04.526222 76304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 17

W0206 23:29:52.092571 76570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:29:52.093729 76570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 17

W0206 23:30:40.723692 76764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:30:40.725051 76764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 18

W0206 23:31:29.376811 77028 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:31:29.378036 77028 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 18

W0206 23:32:20.196051 77221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:32:20.197222 77221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 19

W0206 23:33:07.865954 77488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:33:07.867110 77488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),Tensor([8, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 19

W0206 23:33:58.091238 77766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:33:58.092280 77766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([536870913, 4],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [536870913, 4] at entry 20

W0206 23:34:46.010231 77932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:34:46.011379 77932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),], axis=0, )
[torch error] paddle.stack(list[Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 4],"int64"),Tensor([8, 268435457],"int64"),], axis=0, ) 
 stack expects each tensor to be equal size, but got [8, 4] at entry 0 and [8, 268435457] at entry 20

W0206 23:35:34.497777 78213 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:35:34.499032 78213 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 46612 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:38:56.115235 78491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:38:56.116305 78491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], ) 
 CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 141641 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:43:12.180037 79395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:43:12.181190 79395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 133183 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:48:50.058115 80611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:48:50.059103 80611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 56361 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:54:16.089674 82154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:54:16.090776 82154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], axis=-3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 120756 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:59:31.879093 83703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:59:31.880234 83703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 13845 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:04:53.038460 85195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:04:53.039568 85195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.19 GiB is free. Process 75968 has 64.99 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:10:37.772920 86629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:10:37.775924 86629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 536870912] at entry 0 and [8, 8] at entry 1

W0207 00:11:52.916726 88294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:11:52.917879 88294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 536870912] at entry 0 and [8, 8] at entry 1

W0207 00:13:04.648161 88604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:13:04.649418 88604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 536870912] at entry 0 and [8, 8] at entry 1

W0207 00:14:14.667591 88930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:14:14.668946 88930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 536870912] at entry 0 and [8, 8] at entry 1

W0207 00:15:36.399787 89325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:15:36.401016 89325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 536870912] at entry 0 and [8, 8] at entry 1

W0207 00:16:47.887420 89727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:16:47.888741 89727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 536870912] at entry 0 and [8, 8] at entry 1

W0207 00:18:08.867926 90059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:18:08.868880 90059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 536870912] at entry 0 and [8, 8] at entry 1

W0207 00:19:20.065675 90487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:19:20.066896 90487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 1

W0207 00:20:40.563449 90792 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:20:40.564707 90792 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 1

W0207 00:21:59.097033 91231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:21:59.098145 91231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 1

W0207 00:23:10.263305 91565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:23:10.264539 91565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 1

W0207 00:24:20.323165 91952 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:24:20.324455 91952 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 1

W0207 00:25:31.156247 92257 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:25:31.157459 92257 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 1

W0207 00:26:40.978826 92581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:26:40.980201 92581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 1

W0207 00:27:51.124796 92992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:27:51.125988 92992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 1

W0207 00:29:03.028201 93297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:29:03.029394 93297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 1

W0207 00:30:14.925426 93609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:30:14.926661 93609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 1

W0207 00:31:26.855446 94012 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:31:26.856623 94012 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 1

W0207 00:32:37.997453 94326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:32:37.998522 94326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 1

W0207 00:33:48.455626 94698 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:33:48.456773 94698 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 1

W0207 00:35:05.819511 95014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:35:05.820827 95014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 1

W0207 00:36:23.519532 95422 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:36:23.520804 95422 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 2

W0207 00:37:35.734970 95750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:37:35.736032 95750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 2

W0207 00:38:53.409085 96165 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:38:53.410298 96165 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 2

W0207 00:40:02.509793 96471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:40:02.510885 96471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 2

W0207 00:41:20.005160 96781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:41:20.006358 96781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 2

W0207 00:42:31.156208 97193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:42:31.157428 97193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 2

W0207 00:43:50.864357 97492 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:43:50.865594 97492 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 2

W0207 00:45:02.876240 97909 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:45:02.877501 97909 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 2

W0207 00:46:13.697263 98235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:46:13.698541 98235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 2

W0207 00:47:28.167626 98631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:47:28.169065 98631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 2

W0207 00:48:45.319005 98943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:48:45.320231 98943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 2

W0207 00:49:57.662089 99355 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:49:57.663336 99355 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 2

W0207 00:51:11.374679 99669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:51:11.375909 99669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 2

W0207 00:52:28.835680 100053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:52:28.836974 100053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 2

W0207 00:53:40.960880 100387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:53:40.962170 100387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 3

W0207 00:54:54.153398 100778 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:54:54.154601 100778 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 3

W0207 00:56:12.690348 101089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:56:12.691812 101089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 3

W0207 00:57:29.519644 101506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:57:29.520900 101506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 3

W0207 00:58:44.183094 101813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:58:44.184185 101813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 3

W0207 01:00:03.347155 102211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:00:03.348348 102211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 3

W0207 01:01:19.545192 102549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:01:19.546383 102549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 3

W0207 01:02:36.414989 102947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:02:36.416165 102947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 3

W0207 01:03:49.403759 103350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:03:49.404922 103350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 3

W0207 01:05:03.409416 103675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:05:03.410564 103675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 3

W0207 01:06:16.741753 104075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:06:16.742866 104075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 3

W0207 01:07:28.942520 104387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:07:28.943782 104387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 3

W0207 01:08:42.032439 104698 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:08:42.033663 104698 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 4

W0207 01:09:58.207726 105105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:09:58.209029 105105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 4

W0207 01:11:17.863684 105422 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:11:17.865054 105422 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 4

W0207 01:12:30.219699 105839 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:12:30.221158 105839 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 4

W0207 01:13:46.238965 106151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:13:46.240207 106151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 4

W0207 01:15:05.352797 106548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:15:05.354008 106548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 4

W0207 01:16:22.313392 106965 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:16:22.314543 106965 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 4

W0207 01:17:33.320847 107278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:17:33.322026 107278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 4

W0207 01:18:44.147454 107576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:18:44.148507 107576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 4

W0207 01:19:54.514110 107986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:19:54.515487 107986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 4

W0207 01:21:05.596235 108292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:21:05.597388 108292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 5

W0207 01:22:16.733448 108691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:22:16.734562 108691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 5

W0207 01:23:35.289422 109009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:23:35.290745 109009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 5

W0207 01:24:47.694242 109420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:24:47.695392 109420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 5

W0207 01:26:07.203863 109725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:26:07.205092 109725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 5

W0207 01:27:18.954609 110144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:27:18.955910 110144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], axis=-3, )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], axis=-3, ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 5

W0207 01:28:30.922924 110437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:28:30.924296 110437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 5

W0207 01:29:44.471374 110736 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:29:44.472445 110736 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 5

W0207 01:30:59.480368 111137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:30:59.481587 111137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 6

W0207 01:32:16.272718 111435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:32:16.273820 111435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 6

W0207 01:33:27.742518 111840 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:33:27.743808 111840 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 6

W0207 01:34:42.944986 112144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:34:42.946202 112144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 6

W0207 01:35:54.547794 112537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:35:54.548907 112537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 7

W0207 01:37:07.154634 112705 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:37:07.155706 112705 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 7

W0207 01:38:17.396435 112747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:38:17.397636 112747 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 7

W0207 01:39:39.331974 112789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:39:39.333434 112789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 7

W0207 01:40:50.061800 112831 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:40:50.062999 112831 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 8

W0207 01:42:06.713687 112873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:42:06.714841 112873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 8

W0207 01:43:25.989202 112927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:43:25.990394 112927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 8

W0207 01:44:36.834234 112971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:44:36.835356 112971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 8

W0207 01:45:47.662824 113000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:45:47.664006 113000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 9

W0207 01:46:58.608628 113055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:46:58.609738 113055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 9

W0207 01:48:09.031329 113084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:48:09.032385 113084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 9

W0207 01:49:24.005606 113111 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:49:24.006814 113111 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 9

W0207 01:50:38.307324 113153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:50:38.308436 113153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 10

W0207 01:51:48.745234 113208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:51:48.746482 113208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 10

W0207 01:53:09.470992 113237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:53:09.472276 113237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 10

W0207 01:54:21.794884 113278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:54:21.795989 113278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 10

W0207 01:55:39.605940 113320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:55:39.607170 113320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [536870912, 8] at entry 11

W0207 01:56:50.776423 113362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:56:50.777494 113362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], )
[torch error] paddle.stack(list[Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], ) 
 stack expects each tensor to be equal size, but got [8, 8] at entry 0 and [8, 536870912] at entry 11

W0207 01:58:00.264458 113417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:58:00.265661 113417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8388608, 512],"float16"),Tensor([128, 512],"float16"),Tensor([128, 512],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([8388608, 512],"float16"),Tensor([128, 512],"float16"),Tensor([128, 512],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [8388608, 512] at entry 0 and [128, 512] at entry 1

W0207 01:59:24.343073 113460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:59:24.344049 113460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8388608, 512],"float16"),Tensor([2, 512],"float16"),Tensor([2, 512],"float16"),], axis=1, )
[torch error] paddle.stack(list[Tensor([8388608, 512],"float16"),Tensor([2, 512],"float16"),Tensor([2, 512],"float16"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [8388608, 512] at entry 0 and [2, 512] at entry 1

W0207 02:00:55.607506 113502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:00:55.608485 113502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8388608, 512],"float16"),Tensor([8388608, 512],"float16"),Tensor([8388608, 512],"float16"),], axis=1, )
[paddle error] paddle.stack(list[Tensor([8388608, 512],"float16"),Tensor([8388608, 512],"float16"),Tensor([8388608, 512],"float16"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_stack(_object*, _object*, _object*)
1   stack_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
2   paddle::experimental::stack(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, int)
3   void phi::funcs::StackRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, int, phi::DenseTensor*)
4   void phi::funcs::LaunchStackKernel<phi::GPUContext, phi::dtype::float16, long, (phi::funcs::SegmentedArraySize)4>(phi::GPUContext const&, long, long, long, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, phi::DenseTensor*)
5   phi::dtype::float16* phi::DeviceContext::Alloc<phi::dtype::float16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 24.000000GB memory on GPU 0, 73.584900GB memory has been allocated and available memory is only 5.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 02:04:57.379215 113558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:04:57.380368 113558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8388608, 512],"int32"),Tensor([128, 512],"int32"),Tensor([128, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([8388608, 512],"int32"),Tensor([128, 512],"int32"),Tensor([128, 512],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [8388608, 512] at entry 0 and [128, 512] at entry 1

W0207 02:06:18.520594 113656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:06:18.521627 113656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8388608, 512],"int32"),Tensor([2, 512],"int32"),Tensor([2, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([8388608, 512],"int32"),Tensor([2, 512],"int32"),Tensor([2, 512],"int32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [8388608, 512] at entry 0 and [2, 512] at entry 1

W0207 02:07:36.396752 113685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:07:36.397745 113685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([8388608, 512],"int32"),Tensor([8388608, 512],"int32"),Tensor([8388608, 512],"int32"),], axis=1, )
[torch error] paddle.stack(list[Tensor([8388608, 512],"int32"),Tensor([8388608, 512],"int32"),Tensor([8388608, 512],"int32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 22317 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:10:47.126168 113726 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:10:47.127226 113726 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([84],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([84],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [84] at entry 0 and [4294967295] at entry 1

W0207 02:11:59.356073 113811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:11:59.357172 113811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 1

W0207 02:13:18.182768 113839 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:13:18.183887 113839 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 2

W0207 02:14:29.427106 113893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:14:29.428308 113893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 3

W0207 02:15:42.209527 113923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:15:42.210660 113923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 4

W0207 02:16:55.873070 113951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:16:55.874260 113951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 5

W0207 02:18:13.106868 114005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:18:13.108145 114005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 6

W0207 02:19:25.677907 114049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:19:25.679119 114049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 7

W0207 02:20:43.614035 114092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:20:43.615307 114092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 8

W0207 02:21:59.467197 114160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:21:59.468369 114160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 9

W0207 02:23:16.054625 114216 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:23:16.055883 114216 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),Tensor([9],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 10

W0207 02:24:28.555389 114258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:24:28.556463 114258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.stack(list[Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([9],"float32"),Tensor([4294967295],"float32"),], ) 
 stack expects each tensor to be equal size, but got [9] at entry 0 and [4294967295] at entry 11

W0207 02:25:46.787897 114313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:25:46.789124 114313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 157906 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:31:12.778326 114358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:31:12.779462 114358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [102261127, 3, 14] at entry 0 and [14, 3, 14] at entry 1

W0207 02:32:29.271906 114483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:32:29.273156 114483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 21913099, 14],"float32"),), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 129571 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:37:58.620435 114537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:37:58.621505 114537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 21913099, 14] at entry 0 and [14, 3, 14] at entry 1

W0207 02:39:19.802143 114666 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:39:19.803248 114666 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 102261127],"float32"),), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 125818 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:44:31.561482 114721 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:44:31.562616 114721 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 102261127] at entry 0 and [14, 3, 14] at entry 1

W0207 02:45:49.703028 114847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:45:49.704242 114847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 1

W0207 02:46:55.953897 114889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:46:55.955396 114889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 1

W0207 02:48:07.533986 114918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:48:07.535125 114918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 1

W0207 02:49:28.684731 114959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:49:28.685859 114959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 2

W0207 02:50:40.278424 115016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:50:40.279552 115016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 2

W0207 02:51:51.414166 115057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:51:51.415227 115057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 2

W0207 02:53:11.176618 115085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:53:11.177809 115085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 3

W0207 02:54:22.143226 115154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:54:22.144400 115154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 3

W0207 02:55:31.929013 115183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:55:31.930089 115183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 3

W0207 02:56:42.371773 115198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:56:42.373054 115198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 4

W0207 02:57:58.644765 115244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:57:58.645874 115244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 4

W0207 02:59:08.778748 115281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:59:08.779840 115281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 4

W0207 03:00:25.790982 115309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:00:25.793330 115309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 5

W0207 03:01:39.505231 115350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:01:39.506351 115350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 5

W0207 03:02:52.621796 115379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:02:52.622926 115379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 5

W0207 03:04:11.478281 115407 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:04:11.479782 115407 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 6

W0207 03:05:27.730669 115462 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:05:27.732295 115462 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 6

W0207 03:06:36.631395 115504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:06:36.632423 115504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 6

W0207 03:07:45.851686 115546 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:07:45.852777 115546 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 7

W0207 03:09:04.775954 115588 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:09:04.777094 115588 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 7

W0207 03:10:16.331255 115630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:10:16.332679 115630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 7

W0207 03:11:36.357249 115659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:11:36.358724 115659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 8

W0207 03:12:49.881240 115700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:12:49.882422 115700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 8

W0207 03:13:58.156085 115742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:13:58.157263 115742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 8

W0207 03:15:13.805919 115784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:15:13.807484 115784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 9

W0207 03:16:28.441617 115814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:16:28.442852 115814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 9

W0207 03:17:39.936846 115842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:17:39.938073 115842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 9

W0207 03:18:54.218115 115883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:18:54.219221 115883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 10

W0207 03:20:05.365648 115939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:20:05.366832 115939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 10

W0207 03:21:15.862289 115981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:21:15.863474 115981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 10

W0207 03:22:33.476796 116023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:22:33.478049 116023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 11

W0207 03:23:45.881404 116065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:23:45.882423 116065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 11

W0207 03:25:01.907622 116120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:25:01.909013 116120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 11

W0207 03:26:18.629292 116163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:26:18.630527 116163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 12

W0207 03:27:28.694361 116205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:27:28.695614 116205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 12

W0207 03:28:38.602914 116246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:28:38.604120 116246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 12

W0207 03:29:51.460361 116275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:29:51.461444 116275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 13

W0207 03:31:10.998607 116317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:31:10.999918 116317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 13

W0207 03:32:21.308799 116360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:32:21.309988 116360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 13

W0207 03:33:37.827857 116415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:33:37.829466 116415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 14

W0207 03:34:48.337069 116471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:34:48.338127 116471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 14

W0207 03:35:59.800633 116513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:35:59.801880 116513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 14

W0207 03:37:17.019905 116554 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:37:17.021095 116554 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 15

W0207 03:38:28.104341 116610 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:38:28.105428 116610 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 15

W0207 03:39:39.724391 116639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:39:39.725459 116639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 15

W0207 03:40:51.228150 116680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:40:51.229266 116680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 16

W0207 03:42:09.840735 116736 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:42:09.841940 116736 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 16

W0207 03:43:28.761242 116765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:43:28.762363 116765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 16

W0207 03:44:46.567147 116806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:44:46.568264 116806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 17

W0207 03:45:57.128574 116862 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:45:57.129743 116862 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 17

W0207 03:47:14.666366 116891 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:47:14.667943 116891 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 17

W0207 03:48:31.569904 116932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:48:31.571148 116932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 18

W0207 03:49:41.351320 116988 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:49:41.352380 116988 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 18

W0207 03:51:00.703033 117017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:51:00.704277 117017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 18

W0207 03:52:09.449499 117072 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:52:09.450668 117072 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 19

W0207 03:53:18.931778 117114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:53:18.932950 117114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 19

W0207 03:54:30.321617 117156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:54:30.322885 117156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 19

W0207 03:55:44.290021 117198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:55:44.291333 117198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 20

W0207 03:57:00.008808 117241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:57:00.010057 117241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 20

W0207 03:58:22.719672 117269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:58:22.720927 117269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 20

W0207 03:59:35.988777 117324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:59:35.989845 117324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 21

W0207 04:00:52.158974 117367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:00:52.160285 117367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 21

W0207 04:02:08.385160 117410 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:02:08.386296 117410 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 21

W0207 04:03:25.501155 117465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:03:25.502419 117465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 22

W0207 04:04:42.609191 117520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:04:42.610357 117520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 22

W0207 04:05:59.260020 117549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:05:59.261278 117549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 22

W0207 04:07:16.203967 117603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:07:16.205355 117603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 23

W0207 04:08:32.797819 117646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:08:32.799070 117646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 23

W0207 04:09:44.586045 117675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:09:44.587096 117675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 23

W0207 04:10:55.585723 117703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:10:55.586961 117703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 24

W0207 04:12:05.217015 117758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:12:05.218202 117758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 24

W0207 04:13:23.657148 117800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:13:23.658367 117800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 24

W0207 04:14:44.581686 117829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:14:44.582937 117829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 25

W0207 04:16:02.299178 117883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:16:02.300428 117883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 25

W0207 04:17:12.391422 117928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:17:12.392478 117928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 25

W0207 04:18:31.960618 117956 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:18:31.961725 117956 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 26

W0207 04:19:43.443358 118035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:19:43.444497 118035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 26

W0207 04:20:55.565440 118067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:20:55.566628 118067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 26

W0207 04:22:07.278062 118109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:22:07.279181 118109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 27

W0207 04:23:18.098081 118163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:23:18.099272 118163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 27

W0207 04:24:31.852367 118206 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:24:31.853446 118206 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 27

W0207 04:25:42.370301 118248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:25:42.371366 118248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 28

W0207 04:26:54.489915 118303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:26:54.491021 118303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 28

W0207 04:28:10.983023 118346 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:28:10.984308 118346 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 28

W0207 04:29:30.334358 118388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:29:30.335556 118388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 29

W0207 04:30:41.780864 118430 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:30:41.782152 118430 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 29

W0207 04:31:51.708356 118473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:31:51.709518 118473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 29

W0207 04:33:10.070941 118514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:33:10.072094 118514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 30

W0207 04:34:26.265774 118569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:34:26.267113 118569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 30

W0207 04:35:46.304448 118612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:35:46.305678 118612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),Tensor([14, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 30

W0207 04:36:57.493842 118678 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:36:57.494930 118678 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([102261127, 3, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [102261127, 3, 14] at entry 31

W0207 04:38:07.600441 118711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:38:07.601657 118711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 21913099, 14],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 21913099, 14] at entry 31

W0207 04:39:24.463079 118752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:39:24.464176 118752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 14],"float32"),Tensor([14, 3, 102261127],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [14, 3, 14] at entry 0 and [14, 3, 102261127] at entry 31

W0207 04:40:35.150305 118808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:40:35.151440 118808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([3, 224, 224],"float32"),Tensor([3, 224, 6391321],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([3, 224, 224],"float32"),Tensor([3, 224, 6391321],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [3, 224, 224] at entry 0 and [3, 224, 6391321] at entry 1

W0207 04:41:51.989656 118851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:41:51.990754 118851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([3, 224, 224],"float32"),Tensor([3, 6391321, 224],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([3, 224, 224],"float32"),Tensor([3, 6391321, 224],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [3, 224, 224] at entry 0 and [3, 6391321, 224] at entry 1

W0207 04:43:05.930902 118892 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:43:05.932091 118892 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([3, 224, 224],"float32"),Tensor([85599, 224, 224],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([3, 224, 224],"float32"),Tensor([85599, 224, 224],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [3, 224, 224] at entry 0 and [85599, 224, 224] at entry 1

W0207 04:44:20.911659 118947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:44:20.912691 118947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([3, 224, 6391321],"float32"),Tensor([3, 224, 224],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([3, 224, 6391321],"float32"),Tensor([3, 224, 224],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [3, 224, 6391321] at entry 0 and [3, 224, 224] at entry 1

W0207 04:45:35.163458 118982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:45:35.164541 118982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([3, 224, 6391321],"float32"),Tensor([3, 224, 6391321],"float32"),), axis=0, )
[paddle error] paddle.stack(tuple(Tensor([3, 224, 6391321],"float32"),Tensor([3, 224, 6391321],"float32"),), axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:48:11.799142 119019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:48:11.799979 119019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([3, 6391321, 224],"float32"),Tensor([3, 224, 224],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([3, 6391321, 224],"float32"),Tensor([3, 224, 224],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [3, 6391321, 224] at entry 0 and [3, 224, 224] at entry 1

W0207 04:49:23.367204 119102 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:49:23.368310 119102 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([3, 6391321, 224],"float32"),Tensor([3, 6391321, 224],"float32"),), axis=0, )
[paddle error] paddle.stack(tuple(Tensor([3, 6391321, 224],"float32"),Tensor([3, 6391321, 224],"float32"),), axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:51:56.036391 119144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:51:56.039129 119144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([85599, 224, 224],"float32"),Tensor([3, 224, 224],"float32"),), axis=0, )
[torch error] paddle.stack(tuple(Tensor([85599, 224, 224],"float32"),Tensor([3, 224, 224],"float32"),), axis=0, ) 
 stack expects each tensor to be equal size, but got [85599, 224, 224] at entry 0 and [3, 224, 224] at entry 1

W0207 04:53:14.664376 119228 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:53:14.691533 119228 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(tuple(Tensor([85599, 224, 224],"float32"),Tensor([85599, 224, 224],"float32"),), axis=0, )
[paddle error] paddle.stack(tuple(Tensor([85599, 224, 224],"float32"),Tensor([85599, 224, 224],"float32"),), axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:55:38.022871 119270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:55:38.023844 119270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(x=list[Tensor([219131, 140, 140],"float32"),Tensor([219131, 140, 140],"float32"),], axis=1, )
[paddle error] paddle.stack(x=list[Tensor([219131, 140, 140],"float32"),Tensor([219131, 140, 140],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:58:02.097385 119342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:58:02.100106 119342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(x=list[Tensor([219131, 140, 140],"float32"),Tensor([58, 140, 140],"float32"),], axis=1, )
[torch error] paddle.stack(x=list[Tensor([219131, 140, 140],"float32"),Tensor([58, 140, 140],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [219131, 140, 140] at entry 0 and [58, 140, 140] at entry 1

W0207 04:59:22.170136 119437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:59:22.171730 119437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(x=list[Tensor([58, 140, 140],"float32"),Tensor([219131, 140, 140],"float32"),], axis=1, )
[torch error] paddle.stack(x=list[Tensor([58, 140, 140],"float32"),Tensor([219131, 140, 140],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [58, 140, 140] at entry 0 and [219131, 140, 140] at entry 1

W0207 05:00:34.839680 119480 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:00:34.840770 119480 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(x=list[Tensor([58, 140, 140],"float32"),Tensor([58, 140, 528937],"float32"),], axis=1, )
[torch error] paddle.stack(x=list[Tensor([58, 140, 140],"float32"),Tensor([58, 140, 528937],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [58, 140, 140] at entry 0 and [58, 140, 528937] at entry 1

W0207 05:01:44.919858 119522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:01:44.921183 119522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(x=list[Tensor([58, 140, 140],"float32"),Tensor([58, 528937, 140],"float32"),], axis=1, )
[torch error] paddle.stack(x=list[Tensor([58, 140, 140],"float32"),Tensor([58, 528937, 140],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [58, 140, 140] at entry 0 and [58, 528937, 140] at entry 1

W0207 05:02:54.656200 119563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:02:54.657356 119563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(x=list[Tensor([58, 140, 528937],"float32"),Tensor([58, 140, 140],"float32"),], axis=1, )
[torch error] paddle.stack(x=list[Tensor([58, 140, 528937],"float32"),Tensor([58, 140, 140],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [58, 140, 528937] at entry 0 and [58, 140, 140] at entry 1

W0207 05:04:15.822316 119593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:04:15.823607 119593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(x=list[Tensor([58, 140, 528937],"float32"),Tensor([58, 140, 528937],"float32"),], axis=1, )
[paddle error] paddle.stack(x=list[Tensor([58, 140, 528937],"float32"),Tensor([58, 140, 528937],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:06:39.900264 119634 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:06:39.901225 119634 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(x=list[Tensor([58, 528937, 140],"float32"),Tensor([58, 140, 140],"float32"),], axis=1, )
[torch error] paddle.stack(x=list[Tensor([58, 528937, 140],"float32"),Tensor([58, 140, 140],"float32"),], axis=1, ) 
 stack expects each tensor to be equal size, but got [58, 528937, 140] at entry 0 and [58, 140, 140] at entry 1

W0207 05:07:50.301265 119705 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:07:50.302510 119705 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.stack(x=list[Tensor([58, 528937, 140],"float32"),Tensor([58, 528937, 140],"float32"),], axis=1, )
[paddle error] paddle.stack(x=list[Tensor([58, 528937, 140],"float32"),Tensor([58, 528937, 140],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:10:14.195700 119746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:10:14.196666 119746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.std(Tensor([1, 107374183, 4, 10],"float32"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([1, 107374183, 4, 10],"float32"), list[1,3,], True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4 / 4 (100%)
Max absolute difference: 0.22617179
Max relative difference: 0.7834847
 x: array([[0.062506, 0.062535, 0.062502, 0.062538]], dtype=float32)
 y: array([[0.288671, 0.288676, 0.288674, 0.288681]], dtype=float32)

W0207 05:11:30.230753 119817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:11:30.231637 119817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:11:30.268527 119817 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 143165577, 10],"float32"), list[1,3,], True, False, )
[Pass] paddle.std(Tensor([1, 3, 143165577, 10],"float32"), list[1,3,], True, False, )

W0207 05:13:48.882781 119886 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:13:48.883872 119886 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:13:48.918689 119886 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 4, 178956971],"float64"), 2, True, False, )
[Pass] paddle.std(Tensor([1, 3, 4, 178956971],"float64"), 2, True, False, )

W0207 05:14:47.487597 119942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:14:47.488528 119942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:14:47.528275 119942 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 4, 178956971],"float64"), list[1,2,], True, False, )
[Pass] paddle.std(Tensor([1, 3, 4, 178956971],"float64"), list[1,2,], True, False, )

W0207 05:16:12.459565 119984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:16:12.460616 119984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:16:12.499017 119984 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 4, 178956971],"float64"), list[1,3,], False, False, )
[Pass] paddle.std(Tensor([1, 3, 4, 178956971],"float64"), list[1,3,], False, False, )

W0207 05:17:15.078223 120026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:17:15.079100 120026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:17:15.118126 120026 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 4, 178956971],"float64"), list[1,3,], True, False, )
[Pass] paddle.std(Tensor([1, 3, 4, 178956971],"float64"), list[1,3,], True, False, )

W0207 05:20:34.266508 120097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:20:34.267457 120097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:20:34.303736 120097 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 4, 178956971],"float64"), tuple(1,3,), True, False, )
[Pass] paddle.std(Tensor([1, 3, 4, 178956971],"float64"), tuple(1,3,), True, False, )

W0207 05:23:53.814985 120167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:23:53.815814 120167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:23:53.849503 120167 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 4, 357913942],"float32"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([1, 3, 4, 357913942],"float32"), list[1,3,], True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4 / 4 (100%)
Max absolute difference: 0.22617896
Max relative difference: 0.7834912
 x: array([[0.062501, 0.062523, 0.06254 , 0.062502]], dtype=float32)
 y: array([[0.288671, 0.288682, 0.288675, 0.288681]], dtype=float32)

W0207 05:27:32.415153 120237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:27:32.416080 120237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:27:32.450738 120237 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 71582789, 10],"float64"), 2, True, False, )
[Pass] paddle.std(Tensor([1, 3, 71582789, 10],"float64"), 2, True, False, )

W0207 05:31:28.368781 120363 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:31:28.369691 120363 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:31:28.404464 120363 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 71582789, 10],"float64"), list[1,2,], True, False, )
[Pass] paddle.std(Tensor([1, 3, 71582789, 10],"float64"), list[1,2,], True, False, )

W0207 05:32:37.611832 120391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:32:37.613550 120391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:32:37.658236 120391 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 71582789, 10],"float64"), list[1,3,], False, False, )
[Pass] paddle.std(Tensor([1, 3, 71582789, 10],"float64"), list[1,3,], False, False, )

W0207 05:34:39.554976 120447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:34:39.555905 120447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:34:39.593308 120447 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 71582789, 10],"float64"), list[1,3,], True, False, )
[Pass] paddle.std(Tensor([1, 3, 71582789, 10],"float64"), list[1,3,], True, False, )

W0207 05:35:35.598721 120475 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:35:35.599740 120475 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:35:35.635658 120475 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 3, 71582789, 10],"float64"), tuple(1,3,), True, False, )
[Pass] paddle.std(Tensor([1, 3, 71582789, 10],"float64"), tuple(1,3,), True, False, )

W0207 05:36:37.281589 120503 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:36:37.282570 120503 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:36:37.325739 120503 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 53687092, 4, 10],"float64"), 2, True, False, )
[accuracy error] paddle.std(Tensor([1, 53687092, 4, 10],"float64"), 2, True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2 / 536870920 (3.73e-07%)
Max absolute difference: 0.28555417
Max relative difference: 1.2514326
 x: array([[[0.420922, 0.172268, 0.275714, ..., 0.190893, 0.406301,
         0.208333],
        [0.392264, 0.102246, 0.132852, ..., 0.248716, 0.157522,...
 y: array([[[0.420922, 0.172268, 0.275714, ..., 0.190893, 0.406301,
         0.208333],
        [0.392264, 0.102246, 0.132852, ..., 0.248716, 0.157522,...

W0207 05:37:34.058740 120544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:37:34.059952 120544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:37:34.125828 120544 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 53687092, 4, 10],"float64"), list[1,2,], True, False, )
[Pass] paddle.std(Tensor([1, 53687092, 4, 10],"float64"), list[1,2,], True, False, )

W0207 05:39:17.285362 120587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:39:17.286315 120587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:39:17.333731 120587 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 53687092, 4, 10],"float64"), list[1,3,], False, False, )
[Pass] paddle.std(Tensor([1, 53687092, 4, 10],"float64"), list[1,3,], False, False, )

W0207 05:40:33.859020 120615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:40:33.859908 120615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:40:33.896025 120615 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 53687092, 4, 10],"float64"), list[1,3,], True, False, )
[Pass] paddle.std(Tensor([1, 53687092, 4, 10],"float64"), list[1,3,], True, False, )

W0207 05:42:25.890228 120671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:42:25.891182 120671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:42:25.931927 120671 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([1, 53687092, 4, 10],"float64"), tuple(1,3,), True, False, )
[Pass] paddle.std(Tensor([1, 53687092, 4, 10],"float64"), tuple(1,3,), True, False, )

W0207 05:44:22.936655 120700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:44:22.937690 120700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:44:22.972040 120700 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([120, 35791395],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738878410 (unix time) try "date -d @1738878410" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d7b3) received by PID 120755 (TID 0x7f5f0ecc8740) from PID 120755 ***]


W0207 05:46:50.047534 120755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:46:50.048444 120755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:46:50.513659 120755 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([16, 268435456],"float32"), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738878524 (unix time) try "date -d @1738878524" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d7eb) received by PID 120811 (TID 0x7eff89335740) from PID 120811 ***]


W0207 05:48:44.221673 120811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:48:44.222669 120811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:48:44.416247 120811 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([17895698, 3, 4, 10],"float64"), 2, True, False, )
[accuracy error] paddle.std(Tensor([17895698, 3, 4, 10],"float64"), 2, True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 22 / 536870940 (4.1e-06%)
Max absolute difference: 0.75015139
Max relative difference: 20.57806101
 x: array([[[0.377382, 0.075381, 0.222005, ..., 0.226433, 0.160493,
         0.202867],
        [0.377112, 0.32761 , 0.326288, ..., 0.35901 , 0.349294,...
 y: array([[[0.377382, 0.075381, 0.222005, ..., 0.226433, 0.160493,
         0.202867],
        [0.377112, 0.32761 , 0.326288, ..., 0.35901 , 0.349294,...

W0207 05:50:23.444252 120894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:50:23.445101 120894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:50:23.506487 120894 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([17895698, 3, 4, 10],"float64"), list[1,2,], True, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738878726 (unix time) try "date -d @1738878726" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d868) received by PID 120936 (TID 0x7f00b2d0e740) from PID 120936 ***]


W0207 05:52:06.563000 120936 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:52:06.563999 120936 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:52:06.900527 120936 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([17895698, 3, 4, 10],"float64"), list[1,3,], False, False, )
[accuracy error] paddle.std(Tensor([17895698, 3, 4, 10],"float64"), list[1,3,], False, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 3 / 71582792 (4.19e-06%)
Max absolute difference: 0.29553841
Max relative difference: 0.94854129
 x: array([[0.274442, 0.31626 , 0.272628, 0.247715],
       [0.340911, 0.249335, 0.265108, 0.310838],
       [0.285   , 0.293699, 0.277435, 0.290857],...
 y: array([[0.274442, 0.31626 , 0.272628, 0.247715],
       [0.340911, 0.249335, 0.265108, 0.310838],
       [0.285   , 0.293699, 0.277435, 0.290857],...

W0207 05:53:34.248003 120993 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:53:34.248991 120993 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:53:34.284222 120993 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([17895698, 3, 4, 10],"float64"), list[1,3,], True, False, )
[accuracy error] paddle.std(Tensor([17895698, 3, 4, 10],"float64"), list[1,3,], True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 3 / 71582792 (4.19e-06%)
Max absolute difference: 0.34128116
Max relative difference: 1.26248775
 x: array([[0.309234, 0.305024, 0.315947, 0.292554],
       [0.31419 , 0.272539, 0.257813, 0.28001 ],
       [0.242519, 0.316166, 0.25133 , 0.320143],...
 y: array([[0.309234, 0.305024, 0.315947, 0.292554],
       [0.31419 , 0.272539, 0.257813, 0.28001 ],
       [0.242519, 0.316166, 0.25133 , 0.320143],...

W0207 05:54:32.649072 121021 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:54:32.650068 121021 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:54:32.687887 121021 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([17895698, 3, 4, 10],"float64"), tuple(1,3,), True, False, )
[accuracy error] paddle.std(Tensor([17895698, 3, 4, 10],"float64"), tuple(1,3,), True, False, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 3 / 71582792 (4.19e-06%)
Max absolute difference: 0.3511509
Max relative difference: 1.27426911
 x: array([[0.281167, 0.266577, 0.284106, 0.315494],
       [0.295541, 0.24514 , 0.246207, 0.287485],
       [0.249567, 0.31609 , 0.300676, 0.31058 ],...
 y: array([[0.281167, 0.266577, 0.284106, 0.315494],
       [0.295541, 0.24514 , 0.246207, 0.287485],
       [0.249567, 0.31609 , 0.300676, 0.31058 ],...

W0207 05:55:37.419034 121062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:55:37.419957 121062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:55:37.467010 121062 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([28633116, 150],"float32"), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738879018 (unix time) try "date -d @1738879018" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d903) received by PID 121091 (TID 0x7f32090fa740) from PID 121091 ***]


W0207 05:56:58.023254 121091 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:56:58.024169 121091 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:56:58.372997 121091 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([3, 1431655765],"float32"), )
[accuracy error] paddle.std(Tensor([3, 1431655765],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1 / 1 (100%)
Max absolute difference: 0.28980252
Max relative difference: 1.003914
 x: array(0.578475, dtype=float32)
 y: array(0.288673, dtype=float32)

W0207 05:58:50.446301 121147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:58:50.447248 121147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 05:58:50.485852 121147 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.std(Tensor([35791395, 120],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738879212 (unix time) try "date -d @1738879212" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d957) received by PID 121175 (TID 0x7f7358d1d740) from PID 121175 ***]


W0207 06:00:12.244488 121175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:00:12.245365 121175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 06:00:12.509541 121175 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([35791395, 3, 4, 10],"float32"), list[1,3,], True, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738879328 (unix time) try "date -d @1738879328" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d981) received by PID 121217 (TID 0x7f00d74f3740) from PID 121217 ***]


W0207 06:02:08.691236 121217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:02:08.692078 121217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 06:02:08.950340 121217 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([400, 10737419],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738879440 (unix time) try "date -d @1738879440" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d9ab) received by PID 121259 (TID 0x7f2b9e17e740) from PID 121259 ***]


W0207 06:03:59.957953 121259 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:03:59.958910 121259 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 06:04:00.290954 121259 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([4294967295],"float32"), )
[paddle error] paddle.std(Tensor([4294967295],"float32"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:117)


W0207 06:05:51.221877 121314 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:05:51.222811 121314 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.std(Tensor([429496730, 10],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738879627 (unix time) try "date -d @1738879627" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1da0c) received by PID 121356 (TID 0x7fc61dd61740) from PID 121356 ***]


W0207 06:07:07.340631 121356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:07:07.341538 121356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 06:07:07.391238 121356 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([477218589, 9],"float32"), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738879741 (unix time) try "date -d @1738879741" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1da36) received by PID 121398 (TID 0x7f88b3587740) from PID 121398 ***]


W0207 06:09:00.793272 121398 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:09:00.794164 121398 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 06:09:00.830844 121398 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([51130564, 84],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738879856 (unix time) try "date -d @1738879856" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1da61) received by PID 121441 (TID 0x7fa279733740) from PID 121441 ***]


W0207 06:10:56.336598 121441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:10:56.337525 121441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 06:10:56.595317 121441 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([6, 715827883],"float32"), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738879977 (unix time) try "date -d @1738879977" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1da98) received by PID 121496 (TID 0x7fba26ce8740) from PID 121496 ***]


W0207 06:12:57.065413 121496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:12:57.066388 121496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 06:12:57.308426 121496 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([84, 51130564],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738880090 (unix time) try "date -d @1738880090" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1dab5) received by PID 121525 (TID 0x7f0e692d4740) from PID 121525 ***]


W0207 06:14:50.014083 121525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:14:50.015046 121525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 06:14:50.276396 121525 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.std(Tensor([858993459, 5],"float32"), )
[accuracy error] paddle.std(Tensor([858993459, 5],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1 / 1 (100%)
Max absolute difference: 0.28979817
Max relative difference: 1.0038937
 x: array(0.578472, dtype=float32)
 y: array(0.288674, dtype=float32)

W0207 06:16:48.230515 121593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:16:48.231520 121593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
W0207 06:16:48.271648 121593 dygraph_functions.cc:85677] got different data type, run type promotion automatically, this may cause data type been changed.

test begin: paddle.sum(Tensor([1, 107374183, 4, 10],"float32"), list[1,3,], keepdim=False, name=None, )
[accuracy error] paddle.sum(Tensor([1, 107374183, 4, 10],"float32"), list[1,3,], keepdim=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4 / 4 (100%)
Max absolute difference: 5.201038e+08
Max relative difference: 0.9687506
 x: array([[16777216., 16777216., 16777216., 16777216.]], dtype=float32)
 y: array([[5.368721e+08, 5.368739e+08, 5.368646e+08, 5.368810e+08]],
      dtype=float32)

W0207 06:18:10.976470 121623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:18:10.977411 121623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 14, 10956550, 14],"int64"), axis=list[1,3,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 14, 10956550, 14],"int64"), axis=list[1,3,], keepdim=False, name=None, )

W0207 06:20:01.759310 121679 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:20:01.760224 121679 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 14, 10956550, 14],"int64"), axis=list[1,3,], keepdim=True, name=None, )
[Pass] paddle.sum(Tensor([1, 14, 10956550, 14],"int64"), axis=list[1,3,], keepdim=True, name=None, )

W0207 06:20:58.196332 121708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:20:58.197250 121708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 14, 5, 30678338],"int64"), axis=list[1,3,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 14, 5, 30678338],"int64"), axis=list[1,3,], keepdim=False, name=None, )

W0207 06:21:52.396642 121722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:21:52.397536 121722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 14, 5, 30678338],"int64"), axis=list[1,3,], keepdim=True, name=None, )
[Pass] paddle.sum(Tensor([1, 14, 5, 30678338],"int64"), axis=list[1,3,], keepdim=True, name=None, )

W0207 06:23:40.283650 121763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:23:40.284570 121763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 2, 2147483648],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([1, 2, 2147483648],"float32"), axis=-1, )

W0207 06:25:48.583096 121832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:25:48.584084 121832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 2147483648, 2],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([1, 2147483648, 2],"float32"), axis=-1, )

W0207 06:27:04.124073 121861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:27:04.125093 121861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 2147483649],"int64"), axis=0, )
[Pass] paddle.sum(Tensor([1, 2147483649],"int64"), axis=0, )

W0207 06:29:01.268126 121931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:29:01.269090 121931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 286331153, 3, 5],"float32"), )
[Pass] paddle.sum(Tensor([1, 286331153, 3, 5],"float32"), )

W0207 06:32:23.442307 121986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:32:23.443185 121986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 143165577, 10],"float32"), list[1,3,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 3, 143165577, 10],"float32"), list[1,3,], keepdim=False, name=None, )

W0207 06:33:41.675927 122016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:33:41.676990 122016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 286331153, 5],"float32"), )
[Pass] paddle.sum(Tensor([1, 3, 286331153, 5],"float32"), )

W0207 06:35:01.143410 122058 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:35:01.144309 122058 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 3, 477218589],"float32"), )
[Pass] paddle.sum(Tensor([1, 3, 3, 477218589],"float32"), )

W0207 06:36:23.729537 122086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:36:23.731187 122086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 4, 178956971],"float64"), 2, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 3, 4, 178956971],"float64"), 2, keepdim=False, name=None, )

W0207 06:37:19.606292 122128 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:37:19.607197 122128 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 4, 178956971],"float64"), list[1,2,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 3, 4, 178956971],"float64"), list[1,2,], keepdim=False, name=None, )

W0207 06:38:42.350342 122156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:38:42.351401 122156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 4, 178956971],"float64"), list[1,3,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 3, 4, 178956971],"float64"), list[1,3,], keepdim=False, name=None, )

W0207 06:39:52.734254 122184 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:39:52.735504 122184 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 4, 178956971],"float64"), tuple(1,3,), keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 3, 4, 178956971],"float64"), tuple(1,3,), keepdim=False, name=None, )

W0207 06:43:11.151008 122268 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:43:11.151932 122268 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 4, 357913942],"float32"), list[1,3,], keepdim=False, name=None, )
[accuracy error] paddle.sum(Tensor([1, 3, 4, 357913942],"float32"), list[1,3,], keepdim=False, name=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4 / 4 (100%)
Max absolute difference: 5.2009104e+08
Max relative difference: 0.9687498
 x: array([[16777216., 16777216., 16777216., 16777216.]], dtype=float32)
 y: array([[5.368568e+08, 5.368683e+08, 5.368549e+08, 5.368594e+08]],
      dtype=float32)

W0207 06:46:56.626369 122338 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:46:56.627336 122338 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 71582789, 10],"float64"), 2, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 3, 71582789, 10],"float64"), 2, keepdim=False, name=None, )

W0207 06:51:00.257678 122434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:51:00.258737 122434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 71582789, 10],"float64"), list[1,2,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 3, 71582789, 10],"float64"), list[1,2,], keepdim=False, name=None, )

W0207 06:52:01.603780 122463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:52:01.604903 122463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 71582789, 10],"float64"), list[1,3,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 3, 71582789, 10],"float64"), list[1,3,], keepdim=False, name=None, )

W0207 06:54:05.946549 122533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:54:05.947481 122533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 3, 71582789, 10],"float64"), tuple(1,3,), keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 3, 71582789, 10],"float64"), tuple(1,3,), keepdim=False, name=None, )

W0207 06:55:19.712217 122575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:55:19.713603 122575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 30678338, 5, 14],"int64"), axis=list[1,3,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 30678338, 5, 14],"int64"), axis=list[1,3,], keepdim=False, name=None, )

W0207 06:56:18.110848 122618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:56:18.111799 122618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 30678338, 5, 14],"int64"), axis=list[1,3,], keepdim=True, name=None, )
[Pass] paddle.sum(Tensor([1, 30678338, 5, 14],"int64"), axis=list[1,3,], keepdim=True, name=None, )

W0207 06:58:33.797888 122700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:58:33.798871 122700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 4294967295],"float32"), )
[Pass] paddle.sum(Tensor([1, 4294967295],"float32"), )

W0207 07:01:06.908917 122758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:01:06.909904 122758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 4294967295],"float32"), axis=0, )
[Pass] paddle.sum(Tensor([1, 4294967295],"float32"), axis=0, )

W0207 07:02:26.635468 122799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:02:26.636510 122799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 4294967295],"float32"), axis=1, )
[Pass] paddle.sum(Tensor([1, 4294967295],"float32"), axis=1, )

W0207 07:06:10.603212 122911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:06:10.604282 122911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 4294967295],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([1, 4294967295],"float32"), axis=-1, )

W0207 07:07:37.930688 122954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:07:37.931548 122954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 53687092, 4, 10],"float64"), 2, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 53687092, 4, 10],"float64"), 2, keepdim=False, name=None, )

W0207 07:08:31.720388 123009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:08:31.721304 123009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 53687092, 4, 10],"float64"), list[1,2,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 53687092, 4, 10],"float64"), list[1,2,], keepdim=False, name=None, )

W0207 07:10:00.547155 123052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:10:00.548131 123052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 53687092, 4, 10],"float64"), list[1,3,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 53687092, 4, 10],"float64"), list[1,3,], keepdim=False, name=None, )

W0207 07:11:23.716408 123093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:11:23.717943 123093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1, 53687092, 4, 10],"float64"), tuple(1,3,), keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1, 53687092, 4, 10],"float64"), tuple(1,3,), keepdim=False, name=None, )

W0207 07:13:20.905645 123136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:13:20.907048 123136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 10, 21474837],"float64"), name=None, )
[Pass] paddle.sum(Tensor([10, 10, 21474837],"float64"), name=None, )

W0207 07:15:27.672631 123190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:15:27.673687 123190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 107374183, 2],"float64"), axis=-1, )
[Pass] paddle.sum(Tensor([10, 107374183, 2],"float64"), axis=-1, )

W0207 07:16:31.814059 123219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:16:31.815176 123219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 20, 10737419],"float64"), axis=-1, )
[Pass] paddle.sum(Tensor([10, 20, 10737419],"float64"), axis=-1, )

W0207 07:18:48.805760 123288 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:18:48.806774 123288 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 20, 21474837],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([10, 20, 21474837],"float32"), axis=-1, )

W0207 07:20:03.511158 123318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:20:03.512183 123318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 214748365, 2],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([10, 214748365, 2],"float32"), axis=-1, )

W0207 07:21:30.198263 123359 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:21:30.199879 123359 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 214748365],"float64"), axis=-1, )
[Pass] paddle.sum(Tensor([10, 214748365],"float64"), axis=-1, )

W0207 07:23:39.380924 123416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:23:39.381879 123416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 214748365],"float64"), axis=-1, keepdim=True, )
[Pass] paddle.sum(Tensor([10, 214748365],"float64"), axis=-1, keepdim=True, )

W0207 07:24:28.515036 123456 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:24:28.515884 123456 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 214748365],"int64"), )
[Pass] paddle.sum(Tensor([10, 214748365],"int64"), )

W0207 07:25:21.233316 123485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:25:21.234284 123485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 2651215, 9, 9],"float64"), Tensor([2],"int64"), )
[torch error] paddle.sum(Tensor([10, 2651215, 9, 9],"float64"), Tensor([2],"int64"), ) 
 sum() received an invalid combination of arguments - got (dim=Tensor, input=Tensor, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 07:29:47.468936 123583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:29:47.469933 123583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 42949673, 5],"float64"), name=None, )
[Pass] paddle.sum(Tensor([10, 42949673, 5],"float64"), name=None, )

W0207 07:30:41.241902 123611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:30:41.242821 123611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 429496730],"float32"), )
[Pass] paddle.sum(Tensor([10, 429496730],"float32"), )

W0207 07:32:00.072587 123665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:32:00.073499 123665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 429496730],"float32"), axis=list[], keepdim=False, )
[Pass] paddle.sum(Tensor([10, 429496730],"float32"), axis=list[], keepdim=False, )

W0207 07:33:19.087617 123695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:33:19.088541 123695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 429496730],"float32"), name=None, )
[Pass] paddle.sum(Tensor([10, 429496730],"float32"), name=None, )

W0207 07:34:35.603690 123724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:34:35.604573 123724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 5, 4772186, 9],"float64"), Tensor([2],"int64"), )
[torch error] paddle.sum(Tensor([10, 5, 4772186, 9],"float64"), Tensor([2],"int64"), ) 
 sum() received an invalid combination of arguments - got (dim=Tensor, input=Tensor, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 07:35:23.567497 123778 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:35:23.568496 123778 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 5, 9, 4772186],"float64"), Tensor([2],"int64"), )
[torch error] paddle.sum(Tensor([10, 5, 9, 4772186],"float64"), Tensor([2],"int64"), ) 
 sum() received an invalid combination of arguments - got (dim=Tensor, input=Tensor, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 07:36:13.344790 123821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:36:13.346484 123821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10, 5, 9, 9],"float64"), Tensor([2147483649],"int64"), )
[torch error] paddle.sum(Tensor([10, 5, 9, 9],"float64"), Tensor([2147483649],"int64"), ) 
 sum() received an invalid combination of arguments - got (dim=Tensor, input=Tensor, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 07:36:56.336465 123835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:36:56.337633 123835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([100, 1, 21474837],"float64"), None, None, False, None, )
[Pass] paddle.sum(Tensor([100, 1, 21474837],"float64"), None, None, False, None, )

W0207 07:37:51.379474 123877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:37:51.380440 123877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([100, 1, 42949673],"float32"), None, None, False, None, )
[Pass] paddle.sum(Tensor([100, 1, 42949673],"float32"), None, None, False, None, )

W0207 07:39:09.613710 123906 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:39:09.614692 123906 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([100, 21474837, 1],"float64"), None, None, False, None, )
[Pass] paddle.sum(Tensor([100, 21474837, 1],"float64"), None, None, False, None, )

W0207 07:40:06.949522 123961 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:40:06.950774 123961 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([100, 42949673, 1],"float32"), None, None, False, None, )
[Pass] paddle.sum(Tensor([100, 42949673, 1],"float32"), None, None, False, None, )

W0207 07:41:22.849289 124003 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:41:22.850314 124003 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([100, 42949673],"float32"), )
[Pass] paddle.sum(Tensor([100, 42949673],"float32"), )

W0207 07:42:37.532079 124045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:42:37.533057 124045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1000, 4294968],"float16"), )
[accuracy error] paddle.sum(Tensor([1000, 4294968],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array(2048., dtype=float16)
 y: array(inf, dtype=float16)

W0207 07:44:03.896661 124101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:44:03.897653 124101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1000, 4294968],"float32"), )
[Pass] paddle.sum(Tensor([1000, 4294968],"float32"), )

W0207 07:47:10.567874 124197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:47:10.568907 124197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1000, 4294968],"float32"), 0, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1000, 4294968],"float32"), 0, keepdim=False, name=None, )

W0207 07:48:24.667605 124227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:48:24.668538 124227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10000, 143166, 3],"float32"), 0, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([10000, 143166, 3],"float32"), 0, keepdim=False, name=None, )

W0207 07:49:39.639008 124268 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:49:39.639950 124268 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10000, 2, 107375],"float64"), 0, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([10000, 2, 107375],"float64"), 0, keepdim=False, name=None, )

W0207 07:50:32.345340 124323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:50:32.346197 124323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10000, 2, 214749],"float32"), 0, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([10000, 2, 214749],"float32"), 0, keepdim=False, name=None, )

W0207 07:51:54.678462 124352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:51:54.679441 124352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10000, 71583, 3],"float64"), 0, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([10000, 71583, 3],"float64"), 0, keepdim=False, name=None, )

W0207 07:52:52.379055 124381 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:52:52.379966 124381 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([100000, 21475],"float64"), 0, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([100000, 21475],"float64"), 0, keepdim=False, name=None, )

W0207 07:53:47.699484 124435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:53:47.700520 124435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1000000, 2148],"float64"), 0, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1000000, 2148],"float64"), 0, keepdim=False, name=None, )

W0207 07:54:43.774775 124465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:54:43.775719 124465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1024, 1024, 2049],"float64"), None, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1024, 1024, 2049],"float64"), None, keepdim=False, name=None, )

W0207 07:55:36.781777 124492 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:55:36.782732 124492 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1024, 1024, 4096],"float32"), None, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1024, 1024, 4096],"float32"), None, keepdim=False, name=None, )

W0207 07:56:53.474103 124521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:56:53.475409 124521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1024, 262145, 8],"float64"), None, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1024, 262145, 8],"float64"), None, keepdim=False, name=None, )

W0207 07:57:53.326503 124575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:57:53.327411 124575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1024, 4194304],"float16"), )
[accuracy error] paddle.sum(Tensor([1024, 4194304],"float16"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array(2048., dtype=float16)
 y: array(inf, dtype=float16)

W0207 07:59:19.785276 124618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:59:19.786464 124618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1024, 4194304],"float32"), )
[Pass] paddle.sum(Tensor([1024, 4194304],"float32"), )

W0207 08:01:42.964401 124688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:01:42.965358 124688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1024, 524288, 8],"float32"), None, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([1024, 524288, 8],"float32"), None, keepdim=False, name=None, )

W0207 08:03:06.547312 124730 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:03:06.548355 124730 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1048576, 32, 128],"float32"), axis=0, )
[Pass] paddle.sum(Tensor([1048576, 32, 128],"float32"), axis=0, )

W0207 08:04:21.372476 124786 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:04:21.373494 124786 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1048576, 32, 128],"float32"), axis=1, )
[Pass] paddle.sum(Tensor([1048576, 32, 128],"float32"), axis=1, )

W0207 08:05:35.851821 124841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:05:35.852742 124841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([10700, 128, 56, 56],"float32"), axis=tuple(0,2,3,), )
[Pass] paddle.sum(Tensor([10700, 128, 56, 56],"float32"), axis=tuple(0,2,3,), )

W0207 08:07:01.656829 124885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:07:01.657764 124885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1073741824, 2, 2],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([1073741824, 2, 2],"float32"), axis=-1, )

W0207 08:08:36.433930 124940 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:08:36.435139 124940 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1073741824, 4],"float16"), axis=0, keepdim=True, )
[accuracy error] paddle.sum(Tensor([1073741824, 4],"float16"), axis=0, keepdim=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[2048., 2048., 2048., 2048.]], dtype=float16)
 y: array([[inf, inf, inf, inf]], dtype=float16)

W0207 08:11:17.959780 124997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:11:17.960759 124997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1073741824, 4],"float16"), axis=1, keepdim=True, )
[Pass] paddle.sum(Tensor([1073741824, 4],"float16"), axis=1, keepdim=True, )

W0207 08:13:27.701414 125067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:13:27.702369 125067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1073741824, 4],"float32"), )
[Pass] paddle.sum(Tensor([1073741824, 4],"float32"), )

W0207 08:16:40.582098 125149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:16:40.583102 125149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1073741824, 4],"float32"), axis=0, )
[accuracy error] paddle.sum(Tensor([1073741824, 4],"float32"), axis=0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4 / 4 (100%)
Max absolute difference: 5.2010253e+08
Max relative difference: 0.96875054
 x: array([16777216., 16777216., 16777216., 16777216.], dtype=float32)
 y: array([5.368797e+08, 5.368645e+08, 5.368755e+08, 5.368755e+08],
      dtype=float32)

W0207 08:18:06.047926 125207 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:18:06.049288 125207 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1073741824, 4],"float32"), axis=0, keepdim=True, )
[accuracy error] paddle.sum(Tensor([1073741824, 4],"float32"), axis=0, keepdim=True, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4 / 4 (100%)
Max absolute difference: 5.2010893e+08
Max relative difference: 0.9687509
 x: array([[16777216., 16777216., 16777216., 16777216.]], dtype=float32)
 y: array([[5.368620e+08, 5.368732e+08, 5.368799e+08, 5.368861e+08]],
      dtype=float32)

W0207 08:20:14.313055 125300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:20:14.313994 125300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1073741824, 4],"float32"), axis=1, keepdim=True, )
[Pass] paddle.sum(Tensor([1073741824, 4],"float32"), axis=1, keepdim=True, )

W0207 08:22:34.628890 125347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:22:34.630128 125347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1073741825, 2],"float64"), axis=1, )
[Pass] paddle.sum(Tensor([1073741825, 2],"float64"), axis=1, )

W0207 08:24:07.331817 125444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:24:07.332695 125444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1073741825, 2],"float64"), axis=-1, keepdim=True, )
[Pass] paddle.sum(Tensor([1073741825, 2],"float64"), axis=-1, keepdim=True, )

W0207 08:26:02.109027 125502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:26:02.110056 125502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([107374183, 2, 10],"float64"), None, "float64", False, None, )
[torch error] paddle.sum(Tensor([107374183, 2, 10],"float64"), None, "float64", False, None, ) 
 sum() received an invalid combination of arguments - got (keepdim=bool, dtype=str, input=Tensor, dim=NoneType, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 08:27:47.571441 125590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:27:47.572536 125590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([107374183, 20, 2],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([107374183, 20, 2],"float32"), axis=-1, )

W0207 08:29:05.552383 125612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:29:05.553349 125612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([107374183, 20],"float64"), )
[Pass] paddle.sum(Tensor([107374183, 20],"float64"), )

W0207 08:31:09.275072 125696 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:31:09.276279 125696 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([107374183, 20],"float64"), axis=-1, )
[Pass] paddle.sum(Tensor([107374183, 20],"float64"), axis=-1, )

W0207 08:32:05.419148 125739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:32:05.420048 125739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([107374183, 20],"float64"), axis=-1, keepdim=True, )
[Pass] paddle.sum(Tensor([107374183, 20],"float64"), axis=-1, keepdim=True, )

W0207 08:33:09.301559 125768 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:33:09.302615 125768 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([12, 178956971],"int64"), )
[Pass] paddle.sum(Tensor([12, 178956971],"int64"), )

W0207 08:34:06.410008 125819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:34:06.410986 125819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([120, 35791395],"float32"), 0, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([120, 35791395],"float32"), 0, keepdim=False, name=None, )

W0207 08:38:35.733402 125919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:38:35.734335 125919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([128, 1048576, 32],"float32"), axis=0, )
[Pass] paddle.sum(Tensor([128, 1048576, 32],"float32"), axis=0, )

W0207 08:39:57.329032 125963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:39:57.330246 125963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([128, 32, 1048576],"float32"), axis=0, )
[Pass] paddle.sum(Tensor([128, 32, 1048576],"float32"), axis=0, )

W0207 08:41:11.927438 126018 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:41:11.928354 126018 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([128, 33554432],"float32"), )
[Pass] paddle.sum(Tensor([128, 33554432],"float32"), )

W0207 08:42:32.684162 126073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:42:32.685278 126073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([131072, 128, 256],"float32"), )
[Pass] paddle.sum(Tensor([131072, 128, 256],"float32"), )

W0207 08:43:52.893402 126103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:43:52.894336 126103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([134217729, 16],"int64"), axis=0, )
[Pass] paddle.sum(Tensor([134217729, 16],"int64"), axis=0, )

W0207 08:44:43.179039 126145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:44:43.180155 126145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1398102, 3072],"float32"), axis=1, )
[Pass] paddle.sum(Tensor([1398102, 3072],"float32"), axis=1, )

W0207 08:46:13.614348 126200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:46:13.615466 126200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"bool"), axis=0, keepdim=True, )
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=0, keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 08:47:22.454099 126243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:47:22.455137 126243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"bool"), axis=1, keepdim=False, )
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=1, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 08:48:36.205794 126285 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:48:36.207007 126285 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"bool"), axis=-1, keepdim=False, )
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=-1, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 08:49:48.630903 126313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:49:48.631821 126313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"bool"), axis=list[0,], keepdim=True, )
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=list[0,], keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 08:50:53.682896 126354 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:50:53.683871 126354 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"bool"), axis=list[1,], keepdim=False, )
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=list[1,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 08:52:00.015344 126396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:52:00.016268 126396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"bool"), axis=list[-1,], keepdim=False, )
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=list[-1,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 08:53:04.836120 126425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:53:04.837029 126425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"bool"), axis=None, keepdim=False, )
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=None, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 08:54:16.914324 126466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:54:16.915273 126466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"bool"), axis=None, keepdim=True, )
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=None, keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 08:55:30.666760 126521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:55:30.667742 126521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"bool"), axis=tuple(0,1,), keepdim=False, )
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=tuple(0,1,), keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 08:56:41.404827 126551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:56:41.405768 126551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"float16"), axis=1, )
[Pass] paddle.sum(Tensor([1431655765, 3],"float16"), axis=1, )

W0207 08:58:09.694820 126592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:58:09.695749 126592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"float32"), axis=0, )
[accuracy error] paddle.sum(Tensor([1431655765, 3],"float32"), axis=0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 3 / 3 (100%)
Max absolute difference: 6.9906643e+08
Max relative difference: 0.97656304
 x: array([16777216., 16777216., 16777216.], dtype=float32)
 y: array([7.158196e+08, 7.158436e+08, 7.158259e+08], dtype=float32)

W0207 09:02:00.484066 126704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:02:00.485095 126704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([1431655765, 3],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([1431655765, 3],"float32"), axis=-1, )

W0207 09:04:07.436519 126775 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:04:07.437533 126775 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([143165577, 3, 2, 5],"float32"), axis=list[1,3,], keepdim=False, )
[Pass] paddle.sum(Tensor([143165577, 3, 2, 5],"float32"), axis=list[1,3,], keepdim=False, )

W0207 09:06:11.342798 126837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:06:11.343817 126837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([143165577, 3, 2, 5],"float32"), axis=list[1,3,], keepdim=True, )
[Pass] paddle.sum(Tensor([143165577, 3, 2, 5],"float32"), axis=list[1,3,], keepdim=True, )

W0207 09:07:44.077382 126886 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:07:44.078305 126886 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([14316558, 3, 10, 10],"float32"), )
[Pass] paddle.sum(Tensor([14316558, 3, 10, 10],"float32"), )

W0207 09:09:07.925885 126928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:09:07.926751 126928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([14316558, 3, 10, 10],"float32"), name=None, )
[Pass] paddle.sum(Tensor([14316558, 3, 10, 10],"float32"), name=None, )

W0207 09:10:23.680980 126957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:10:23.682013 126957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([16, 134217729],"float64"), -1, keepdim=True, name=None, )
[Pass] paddle.sum(Tensor([16, 134217729],"float64"), -1, keepdim=True, name=None, )

W0207 09:11:17.245003 127011 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:11:17.245957 127011 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([16, 2097152, 128],"float32"), axis=0, )
[Pass] paddle.sum(Tensor([16, 2097152, 128],"float32"), axis=0, )

W0207 09:12:41.495211 127042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:12:41.496207 127042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([16, 268435456],"float32"), 1, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([16, 268435456],"float32"), 1, keepdim=False, name=None, )

W0207 09:14:14.844990 127070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:14:14.845891 127070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([16, 268435456],"float32"), -1, keepdim=True, name=None, )
[Pass] paddle.sum(Tensor([16, 268435456],"float32"), -1, keepdim=True, name=None, )

W0207 09:15:35.809891 127137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:15:35.811111 127137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([16, 32, 8388608],"float32"), axis=0, )
[Pass] paddle.sum(Tensor([16, 32, 8388608],"float32"), axis=0, )

W0207 09:16:52.628621 127181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:16:52.629561 127181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([16, 4194304, 64],"float32"), axis=0, )
[Pass] paddle.sum(Tensor([16, 4194304, 64],"float32"), axis=0, )

W0207 09:18:20.667650 127223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:18:20.668610 127223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([16777216, 256],"float32"), )
[Pass] paddle.sum(Tensor([16777216, 256],"float32"), )

W0207 09:19:47.706787 127278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:19:47.707959 127278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([16777216, 256],"float32"), -1, keepdim=True, name=None, )
[Pass] paddle.sum(Tensor([16777216, 256],"float32"), -1, keepdim=True, name=None, )

W0207 09:21:08.622758 127308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:21:08.623652 127308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([178956971, 3, 4, 1, 1, 1],"int64"), )
[paddle error] paddle.sum(Tensor([178956971, 3, 4, 1, 1, 1],"int64"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 09:22:04.815848 127336 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:22:04.816788 127336 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([17895698, 3, 4, 10],"float64"), 2, keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([17895698, 3, 4, 10],"float64"), 2, keepdim=False, name=None, )

W0207 09:23:00.565521 127390 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:23:00.566493 127390 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([17895698, 3, 4, 10],"float64"), list[1,2,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([17895698, 3, 4, 10],"float64"), list[1,2,], keepdim=False, name=None, )

W0207 09:24:32.941121 127433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:24:32.942027 127433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([17895698, 3, 4, 10],"float64"), list[1,3,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([17895698, 3, 4, 10],"float64"), list[1,3,], keepdim=False, name=None, )

W0207 09:25:38.838060 127488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:25:38.839006 127488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([17895698, 3, 4, 10],"float64"), tuple(1,3,), keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([17895698, 3, 4, 10],"float64"), tuple(1,3,), keepdim=False, name=None, )

W0207 09:26:47.636483 127530 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:26:47.637537 127530 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 10, 214748365],"float32"), )
[Pass] paddle.sum(Tensor([2, 10, 214748365],"float32"), )

W0207 09:28:10.571768 127559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:28:10.573235 127559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 10, 214748365],"float32"), name=None, )
[Pass] paddle.sum(Tensor([2, 10, 214748365],"float32"), name=None, )

W0207 09:29:25.543897 127601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:29:25.544999 127601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741824, 2],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([2, 1073741824, 2],"float32"), axis=-1, )

W0207 09:30:49.856963 127656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:30:49.857820 127656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"float64"), 0, keepdim=False, dtype=None, )
[Pass] paddle.sum(Tensor([2, 1073741825],"float64"), 0, keepdim=False, dtype=None, )

W0207 09:32:59.240170 127740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:32:59.241685 127740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"float64"), 0, keepdim=True, dtype="float32", )
[torch error] paddle.sum(Tensor([2, 1073741825],"float64"), 0, keepdim=True, dtype="float32", ) 
 sum() received an invalid combination of arguments - got (keepdim=bool, dtype=str, input=Tensor, dim=int, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 09:34:52.304342 127810 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:34:52.305713 127810 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"float64"), 1, keepdim=False, dtype=None, )
[Pass] paddle.sum(Tensor([2, 1073741825],"float64"), 1, keepdim=False, dtype=None, )

W0207 09:35:46.526391 128175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:35:46.527338 128175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"float64"), -1, keepdim=True, dtype="float32", )
[torch error] paddle.sum(Tensor([2, 1073741825],"float64"), -1, keepdim=True, dtype="float32", ) 
 sum() received an invalid combination of arguments - got (keepdim=bool, dtype=str, input=Tensor, dim=int, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 09:36:35.743252 128576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:36:35.744570 128576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"float64"), -1, keepdim=True, dtype=None, )
[Pass] paddle.sum(Tensor([2, 1073741825],"float64"), -1, keepdim=True, dtype=None, )

W0207 09:37:41.027230 128745 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:37:41.028275 128745 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"float64"), axis=1, )
[Pass] paddle.sum(Tensor([2, 1073741825],"float64"), axis=1, )

W0207 09:38:44.572480 129026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:38:44.573622 129026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"float64"), axis=-1, keepdim=True, )
[Pass] paddle.sum(Tensor([2, 1073741825],"float64"), axis=-1, keepdim=True, )

W0207 09:39:37.612622 129305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:39:37.613463 129305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"float64"), None, keepdim=False, dtype="float32", )
[torch error] paddle.sum(Tensor([2, 1073741825],"float64"), None, keepdim=False, dtype="float32", ) 
 sum() received an invalid combination of arguments - got (keepdim=bool, dtype=str, input=Tensor, dim=NoneType, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 09:40:25.141494 129541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:40:25.142881 129541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"float64"), None, keepdim=True, dtype="float32", )
[torch error] paddle.sum(Tensor([2, 1073741825],"float64"), None, keepdim=True, dtype="float32", ) 
 sum() received an invalid combination of arguments - got (keepdim=bool, dtype=str, input=Tensor, dim=NoneType, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 09:41:14.449379 129815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:41:14.458950 129815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"float64"), None, keepdim=True, dtype=None, )
[Pass] paddle.sum(Tensor([2, 1073741825],"float64"), None, keepdim=True, dtype=None, )

W0207 09:42:07.547812 130008 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:42:07.548828 130008 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"int64"), )
[Pass] paddle.sum(Tensor([2, 1073741825],"int64"), )

W0207 09:43:01.459313 130295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:43:01.460251 130295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"int64"), axis=0, )
[Pass] paddle.sum(Tensor([2, 1073741825],"int64"), axis=0, )

W0207 09:49:34.723161 131984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:49:34.724133 131984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 1073741825],"int64"), axis=1, keepdim=True, )
[Pass] paddle.sum(Tensor([2, 1073741825],"int64"), axis=1, keepdim=True, )

W0207 09:51:27.997130 132468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:51:27.998117 132468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=-1, keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=-1, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 09:54:03.007264 133138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:54:03.008244 133138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=2, keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=2, keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 09:55:16.067466 133425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:55:16.068845 133425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 09:56:29.875485 133724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:56:29.876395 133724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[0,1,2,3,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[0,1,2,3,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 09:57:35.176591 134125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:57:35.177986 134125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[0,2,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[0,2,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 09:58:53.211472 134405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:58:53.212532 134405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[-1,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[-1,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 09:59:57.921808 134797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:59:57.922775 134797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[2,], keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[2,], keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:01:03.106217 135102 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:01:03.107210 135102 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=None, keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=None, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:02:08.048434 135399 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:02:08.049346 135399 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=None, keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=None, keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:03:18.670840 135690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:03:18.671785 135690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=tuple(0,2,), keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=tuple(0,2,), keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:04:31.036430 136092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:04:31.037415 136092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 134217728, 16],"float32"), axis=1, )
[accuracy error] paddle.sum(Tensor([2, 134217728, 16],"float32"), axis=1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 32 / 32 (100%)
Max absolute difference: 50337424.
Max relative difference: 0.7500215
 x: array([[16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216.],...
 y: array([[67113088., 67110568., 67106536., 67108280., 67107992., 67110112.,
        67111168., 67109312., 67105328., 67105240., 67101596., 67105456.,
        67107104., 67111616., 67110416., 67106984.],...

W0207 10:05:46.289444 136400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:05:46.290344 136400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2, 1073741824],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([2, 2, 1073741824],"float32"), axis=-1, )

W0207 10:07:09.864285 136803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:07:09.865199 136803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"bool"), axis=0, keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=0, keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:08:18.478042 137110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:08:18.478966 137110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"bool"), axis=1, keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=1, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:09:24.749843 137482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:09:24.750928 137482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"bool"), axis=-1, keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=-1, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:10:36.964632 137779 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:10:36.965548 137779 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"bool"), axis=list[0,], keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=list[0,], keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:11:43.659194 138092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:11:43.660384 138092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"bool"), axis=list[1,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=list[1,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:12:54.511559 138395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:12:54.512472 138395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"bool"), axis=list[-1,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=list[-1,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:14:02.436343 138788 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:14:02.437291 138788 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"bool"), axis=None, keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=None, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:15:09.462539 139098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:15:09.463394 139098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"bool"), axis=None, keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=None, keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:16:17.262385 139408 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:16:17.263335 139408 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"bool"), axis=tuple(0,1,), keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=tuple(0,1,), keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:17:29.348024 139774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:17:29.348924 139774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"float32"), )
[Pass] paddle.sum(Tensor([2, 2147483648],"float32"), )

W0207 10:18:56.250753 140075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:18:56.251632 140075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"float32"), 0, keepdim=False, dtype=None, )
[Pass] paddle.sum(Tensor([2, 2147483648],"float32"), 0, keepdim=False, dtype=None, )

W0207 10:20:19.695246 140517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:20:19.696283 140517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"float32"), 0, keepdim=True, dtype="float32", )
[torch error] paddle.sum(Tensor([2, 2147483648],"float32"), 0, keepdim=True, dtype="float32", ) 
 sum() received an invalid combination of arguments - got (keepdim=bool, dtype=str, input=Tensor, dim=int, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 10:22:52.005947 141240 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:22:52.007313 141240 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"float32"), 1, keepdim=False, dtype=None, )
[Pass] paddle.sum(Tensor([2, 2147483648],"float32"), 1, keepdim=False, dtype=None, )

W0207 10:24:19.652707 141632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:24:19.654126 141632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"float32"), axis=0, )
[Pass] paddle.sum(Tensor([2, 2147483648],"float32"), axis=0, )

W0207 10:25:35.498746 142045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:25:35.499696 142045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"float32"), axis=1, )
[Pass] paddle.sum(Tensor([2, 2147483648],"float32"), axis=1, )

W0207 10:28:04.778427 142655 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:28:04.779431 142655 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"float32"), axis=-1, )
[Pass] paddle.sum(Tensor([2, 2147483648],"float32"), axis=-1, )

W0207 10:29:27.763105 143074 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:29:27.763980 143074 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"float32"), axis=1, keepdim=True, )
[Pass] paddle.sum(Tensor([2, 2147483648],"float32"), axis=1, keepdim=True, )

W0207 10:30:42.444315 143485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:30:42.445850 143485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"float32"), None, keepdim=False, dtype="float32", )
[torch error] paddle.sum(Tensor([2, 2147483648],"float32"), None, keepdim=False, dtype="float32", ) 
 sum() received an invalid combination of arguments - got (keepdim=bool, dtype=str, input=Tensor, dim=NoneType, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
 * (Tensor input, tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0207 10:31:52.077486 143799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:31:52.078912 143799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 2147483648],"float32"), None, keepdim=True, dtype=None, )
[Pass] paddle.sum(Tensor([2, 2147483648],"float32"), None, keepdim=True, dtype=None, )

W0207 10:33:07.670265 144178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:33:07.671129 144178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 214748365, 10],"float32"), )
[Pass] paddle.sum(Tensor([2, 214748365, 10],"float32"), )

W0207 10:34:23.464499 144496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:34:23.465704 144496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 214748365, 10],"float32"), name=None, )
[Pass] paddle.sum(Tensor([2, 214748365, 10],"float32"), name=None, )

W0207 10:35:50.548878 144898 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:35:50.549986 144898 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), )
[paddle error] paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 10:37:13.483086 145329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:37:13.483937 145329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147374573 / 2147484096 (100%)
Max absolute difference: 7.3922544
Max relative difference: 31.53283
 x: array([[[[[[[[5.555602, 5.776992, 1.368242, 3.32275 ],
             [2.859302, 5.982134, 4.136272, 7.142719],
             [7.312438, 7.85028 , 4.934845, 7.673523]],...
 y: array([[[[[[[[1.181093, 1.412138, 0.778217, 1.277185],
             [0.89359 , 0.818805, 1.306087, 1.209513],
             [1.148071, 0.801366, 0.539998, 0.942475]],...

W0207 10:38:32.457126 145681 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:38:32.458422 145681 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1431655852 / 1431656064 (100%)
Max absolute difference: 7.0057664
Max relative difference: 12.045873
 x: array([[[[[[[[1.457727, 3.721226, 1.518448, 4.560008],
             [5.600197, 7.19983 , 3.925166, 4.642611],
             [0.531399, 4.489006, 4.443373, 0.647608]],...
 y: array([[[[[[[[1.099679, 1.645675, 1.814322, 2.137809],
             [1.476526, 1.724465, 0.81892 , 1.272908],
             [1.479333, 1.433319, 2.227211, 1.373027]],...

W0207 10:41:31.821887 146519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:41:31.823235 146519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 3456 / 3456 (100%)
Max absolute difference: 622473.1
Max relative difference: 1.
 x: array([[[[[[[[4.005881e-01, 7.841707e-01, 5.795918e+00,
              6.486546e-01],
             [6.480033e-01, 2.888905e+00, 2.102931e-01,...
 y: array([[[[[[[[620964.5 , 621320.4 , 621162.75, 621693.1 ],
             [621287.1 , 621187.75, 621569.9 , 621162.75],
             [621239.56, 621281.9 , 621412.5 , 621382.75]],...

W0207 10:44:01.634464 147253 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:44:01.635371 147253 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147375000 / 2147484096 (100%)
Max absolute difference: 7.2012854
Max relative difference: 72.29055
 x: array([[[[[[[[5.488074, 7.323628, 4.321001, 4.895936],
             [7.355869, 5.999878, 3.043482, 2.084504],
             [0.343192, 2.041   , 1.087551, 1.581964]],...
 y: array([[[[[[[[1.14218 , 1.099406, 1.120649, 1.687937],
             [0.962667, 0.986398, 1.189304, 1.134307],
             [1.1933  , 0.684719, 0.642408, 1.325204]],...

W0207 10:45:16.599566 147678 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:45:16.600463 147678 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1431655753 / 1431656064 (100%)
Max absolute difference: 2.9980218
Max relative difference: 1.
 x: array([[[[[[[[0.694067, 2.098695, 0.794357, 0.651046],
             [1.916711, 1.789043, 2.303585, 1.602984],
             [1.884872, 1.812971, 1.129633, 1.222951]],...
 y: array([[[[[[[[0.694067, 2.098695, 0.794357, 0.651046],
             [1.916711, 1.789043, 2.303585, 1.602984],
             [1.884872, 1.812971, 1.129633, 1.222951]],...

W0207 10:48:11.542989 148496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:48:11.544119 148496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 1242757, 2, 3, 4, 2, 3, 4],"float32"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073741975 / 1073742048 (100%)
Max absolute difference: 3.9895494
Max relative difference: 1.
 x: array([[[[[[[[1.68649 , 1.563042, 3.119295, 1.457648],
             [1.83319 , 3.008085, 2.890845, 2.3177  ],
             [2.158978, 1.391886, 2.023351, 1.812433]],...
 y: array([[[[[[[[1.68649 , 1.563042, 3.119295, 1.457648],
             [1.83319 , 3.008085, 2.890845, 2.3177  ],
             [2.158978, 1.391886, 2.023351, 1.812433]],...

W0207 10:50:26.379029 149101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:50:26.379905 149101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=-1, keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=-1, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:52:27.715574 149636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:52:27.716573 149636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=2, keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=2, keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:53:39.833258 150045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:53:39.834254 150045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:54:44.797147 150358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:54:44.798079 150358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[0,1,2,3,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[0,1,2,3,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:55:49.572340 150657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:55:49.573356 150657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[0,2,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[0,2,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:57:01.778663 151057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:57:01.779644 151057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[-1,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[-1,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:58:12.166417 151343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:58:12.167346 151343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[2,], keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[2,], keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 10:59:25.850370 151569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:59:25.851296 151569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=None, keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=None, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:00:30.194856 151980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:00:30.195806 151980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=None, keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=None, keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:01:36.929388 152274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:01:36.930311 152274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=tuple(0,2,), keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=tuple(0,2,), keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:02:48.237083 152560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:02:48.237957 152560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=-1, keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=-1, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:03:53.477545 152949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:03:53.478534 152949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=2, keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=2, keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:05:04.829407 153248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:05:04.830405 153248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:06:13.322839 153547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:06:13.323797 153547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[0,1,2,3,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[0,1,2,3,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:07:25.867105 153838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:07:25.868151 153838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[0,2,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[0,2,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:08:32.074754 154249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:08:32.075636 154249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[-1,], keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[-1,], keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:09:44.129534 154540 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:09:44.130551 154540 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[2,], keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[2,], keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:10:49.941958 154845 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:10:49.942845 154845 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=None, keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=None, keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:12:00.977284 155241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:12:00.978494 155241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=None, keepdim=True, )
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=None, keepdim=True, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:13:05.522781 155547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:13:05.523809 155547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=tuple(0,2,), keepdim=False, )
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=tuple(0,2,), keepdim=False, ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, input dtype should be the same as out dtype (at ../paddle/phi/kernels/kps/reduce_kernel.cu:263)


W0207 11:14:17.016059 155845 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:14:17.016999 155845 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 11:15:29.802284 156137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:15:29.803267 156137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147373669 / 2147484096 (100%)
Max absolute difference: 1.9999824
Max relative difference: 1.
 x: array([[[[[[[[0., 0., 0., 0.],
             [0., 0., 0., 0.],
             [0., 0., 0., 0.]],...
 y: array([[[[[[[[0.29794 , 0.499953, 0.770251, 0.555084],
             [0.439356, 1.121668, 0.518254, 1.788367],
             [1.50984 , 0.522858, 0.913541, 1.154618]],...

W0207 11:16:55.818786 156546 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:16:55.820307 156546 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1431516095 / 1431656064 (100%)
Max absolute difference: 7.935356
Max relative difference: 719.156
 x: array([[[[[[[[2.387983e+00, 2.049112e+00, 6.556748e+00,
              9.792476e-01],
             [5.151440e+00, 6.793247e+00, 3.673519e+00,...
 y: array([[[[[[[[1.556685, 0.970303, 1.057408, 1.517642],
             [1.010472, 0.863074, 1.745627, 1.365423],
             [2.142092, 0.875044, 0.952113, 1.680641]],...

W0207 11:19:54.075420 157415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:19:54.076351 157415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073574586 / 1073742048 (100%)
Max absolute difference: 7.8886824
Max relative difference: 196.79355
 x: array([[[[[[[[4.374952, 6.615574, 6.228786, 3.228167],
             [5.138072, 5.97631 , 3.478294, 0.404321],
             [6.426723, 5.009077, 1.262454, 3.262711]],...
 y: array([[[[[[[[2.324418, 2.701548, 1.483721, 1.859059],
             [1.727454, 1.917548, 0.725347, 1.442346],
             [1.965148, 1.89607 , 2.280579, 1.395826]],...

W0207 11:22:13.911569 158084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:22:13.912479 158084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147263680 / 2147484096 (100%)
Max absolute difference: 7.9890013
Max relative difference: 29396.035
 x: array([[[[[[[[2.857074, 0.713419, 1.562788, 5.626915],
             [6.365136, 1.627472, 7.706875, 2.785651],
             [2.268142, 4.64256 , 3.875189, 7.039666]],...
 y: array([[[[[[[[0.895766, 1.008283, 0.870747, 0.778566],
             [0.910084, 1.053589, 0.383244, 1.445066],
             [0.77413 , 0.497086, 0.505038, 1.412765]],...

W0207 11:24:27.193687 158673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:24:27.194555 158673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1401829661 / 1431656064 (97.9%)
Max absolute difference: 2.9988399
Max relative difference: 1.
 x: array([[[[[[[[1.283651, 1.656991, 2.038063, 1.399566],
             [2.47879 , 1.227547, 1.970599, 2.659849],
             [1.571935, 2.138514, 0.701376, 0.775853]],...
 y: array([[[[[[[[1.283651, 1.656991, 2.038063, 1.399566],
             [2.47879 , 1.227547, 1.970599, 2.659849],
             [1.571935, 2.138514, 0.701376, 0.775853]],...

W0207 11:27:16.728210 159502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:27:16.729076 159502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 1242757, 2, 3, 4],"float32"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 3384 / 3456 (97.9%)
Max absolute difference: 622794.6
Max relative difference: 1.
 x: array([[[[[[[[621491.  , 621550.9 , 621331.75, 621181.8 ],
             [621527.2 , 621579.06, 621706.7 , 620831.5 ],
             [621255.6 , 620902.44, 621779.9 , 621524.9 ]],...
 y: array([[[[[[[[621495.25, 621544.4 , 621330.6 , 621198.25],
             [621550.4 , 621590.25, 621711.4 , 620843.4 ],
             [621262.1 , 620895.7 , 621773.9 , 621533.44]],...

W0207 11:29:42.888070 160186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:29:42.889307 160186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 11:31:01.815284 160501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:31:01.816228 160501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147374706 / 2147484096 (100%)
Max absolute difference: 6.752489
Max relative difference: 77.67984
 x: array([[[[[[[[3.492107, 0.04308 , 3.292586, ..., 0.      ,
              0.      , 0.      ],
             [0.      , 0.      , 0.      , ..., 0.      ,...
 y: array([[[[[[[[0.710614, 0.926719, 1.173469, ..., 1.331077,
              0.229461, 0.515587],
             [0.295178, 1.440981, 0.932364, ..., 0.600426,...

W0207 11:32:16.721832 160870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:32:16.723726 160870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1431655820 / 1431656064 (100%)
Max absolute difference: 7.119074
Max relative difference: 8.420349
 x: array([[[[[[[[3.83962 , 6.659767, 4.324474, ..., 0.      ,
              0.      , 0.      ],
             [0.      , 0.      , 0.      , ..., 0.      ,...
 y: array([[[[[[[[0.685686, 1.214733, 1.598632, ..., 1.419265,
              1.428132, 1.408328],
             [1.588866, 2.141299, 1.281264, ..., 2.071241,...

W0207 11:35:19.139602 161700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:35:19.140487 161700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073742047 / 1073742048 (100%)
Max absolute difference: 7.1288104
Max relative difference: 9.425459
 x: array([[[[[[[[4.48534, 1.08361, 1.81618, ..., 0.     , 0.     ,
              0.     ],
             [0.     , 0.     , 0.     , ..., 0.     , 0.     ,...
 y: array([[[[[[[[2.6008  , 2.45409 , 2.105042, ..., 2.401259,
              2.360248, 1.376336],
             [1.59464 , 1.683496, 1.27636 , ..., 2.006529,...

W0207 11:37:42.920712 162333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:37:42.921784 162333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147374907 / 2147484096 (100%)
Max absolute difference: 6.863777
Max relative difference: 23.3244
 x: array([[[[[[[[0.417227, 0.151049, 0.737758, ..., 0.      ,
              0.      , 0.      ],
             [0.      , 0.      , 0.      , ..., 0.      ,...
 y: array([[[[[[[[0.316688, 1.152272, 1.119563, ..., 1.297271,
              0.413073, 1.848521],
             [0.058407, 1.172405, 0.824665, ..., 0.30856 ,...

W0207 11:39:53.304687 162873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:39:53.305724 162873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1401829645 / 1431656064 (97.9%)
Max absolute difference: 2.9986868
Max relative difference: 1.
 x: array([[[[[[[[1.766471, 1.302751, 1.190339, ..., 2.197561,
              1.16514 , 2.268855],
             [1.054286, 1.912856, 2.39726 , ..., 1.303966,...
 y: array([[[[[[[[1.766471, 1.302751, 1.190339, ..., 2.197561,
              1.16514 , 2.268855],
             [1.054286, 1.912856, 2.39726 , ..., 1.303966,...

W0207 11:42:46.163496 163666 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:42:46.164426 163666 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 1242757],"float32"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1051372422 / 1073742048 (97.9%)
Max absolute difference: 3.9882252
Max relative difference: 1.
 x: array([[[[[[[[2.513512, 1.196962, 2.516791, ..., 1.713378,
              0.649932, 2.514621],
             [1.872636, 1.975269, 2.91485 , ..., 1.763007,...
 y: array([[[[[[[[2.513512, 1.196962, 2.516791, ..., 1.713378,
              0.649932, 2.514621],
             [1.872636, 1.975269, 2.91485 , ..., 1.763007,...

W0207 11:45:09.027591   832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:45:09.028570   832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073688208 / 1073742912 (100%)
Max absolute difference: 7.17867228
Max relative difference: 36.03636833
 x: array([[[[[[[[0.410371, 7.444058, 1.82012 , ..., 0.      ,
              0.      , 0.      ],
             [0.      , 0.      , 0.      , ..., 0.      ,...
 y: array([[[[[[[[0.07565 , 0.791125, 0.586755, ..., 1.23454 ,
              0.371883, 0.302172],
             [1.58019 , 1.258347, 0.768809, ..., 0.883322,...

W0207 11:46:55.328003  1406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:46:55.329022  1406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 715828502 / 715828608 (100%)
Max absolute difference: 7.23715622
Max relative difference: 16.652379
 x: array([[[[[[[[7.253038, 2.472451, 2.43137 , ..., 0.      ,
              0.      , 0.      ],
             [0.      , 0.      , 0.      , ..., 0.      ,...
 y: array([[[[[[[[2.029784, 1.057631, 1.075737, ..., 2.001803,
              1.512157, 0.952808],
             [1.643078, 1.280738, 2.311048, ..., 1.983041,...

W0207 11:49:18.735687  2089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:49:18.736565  2089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 536871456 / 536871456 (100%)
Max absolute difference: 6.66043628
Max relative difference: 6.95455628
 x: array([[[[[[[[7.34765 , 2.160979, 1.738202, ..., 0.      ,
              0.      , 0.      ],
             [0.      , 0.      , 0.      , ..., 0.      ,...
 y: array([[[[[[[[2.411779, 2.77425 , 2.400752, ..., 1.473516,
              2.20342 , 2.28119 ],
             [1.825984, 1.681863, 1.285277, ..., 2.870435,...

W0207 11:51:16.720775  2518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:51:16.721846  2518 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073688056 / 1073742912 (100%)
Max absolute difference: 7.19389229
Max relative difference: 23.06628968
 x: array([[[[[[[[5.937427, 4.599417, 3.542561, ..., 0.      ,
              0.      , 0.      ],
             [0.      , 0.      , 0.      , ..., 0.      ,...
 y: array([[[[[[[[1.493365, 0.537358, 1.319189, ..., 0.825407,
              1.892303, 0.590852],
             [1.409361, 1.456376, 1.732469, ..., 0.312444,...

W0207 11:52:56.632048  3058 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:52:56.633013  3058 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 700915399 / 715828608 (97.9%)
Max absolute difference: 2.99787401
Max relative difference: 1.
 x: array([[[[[[[[2.099508, 1.309713, 2.215064, ..., 0.823293,
              1.176118, 2.127156],
             [2.539612, 1.45175 , 1.100635, ..., 1.714538,...
 y: array([[[[[[[[2.099508, 1.309713, 2.215064, ..., 0.823293,
              1.176118, 2.127156],
             [2.539612, 1.45175 , 1.100635, ..., 1.714538,...

W0207 11:55:18.148998  3729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:55:18.149878  3729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"float64"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 525686634 / 536871456 (97.9%)
Max absolute difference: 3.98881909
Max relative difference: 1.
 x: array([[[[[[[[1.972965, 1.924336, 2.148781, ..., 2.757927,
              2.17639 , 1.965368],
             [2.642427, 1.527154, 1.634092, ..., 2.268589,...
 y: array([[[[[[[[1.972965, 1.924336, 2.148781, ..., 2.757927,
              2.17639 , 1.965368],
             [2.642427, 1.527154, 1.634092, ..., 2.268589,...

W0207 11:57:20.301837  4293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:57:20.303090  4293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"int64"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 621379],"int64"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 11:58:55.337198  4756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:58:55.338068  4756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073632244 / 1073742336 (100%)
Max absolute difference: 7.98425669
Max relative difference: 9252.56837167
 x: array([[[[[[[[7.814883, 6.099884, 7.221013, 2.566168],
             [2.104422, 2.470692, 4.823459, 6.56199 ],
             [3.176497, 4.696332, 4.375413, 2.564806],...
 y: array([[[[[[[[1.362277, 1.422907, 1.582127, 0.743923],
             [1.024035, 0.605008, 0.60803 , 0.845969],
             [1.078207, 1.463434, 0.835184, 0.940952],...

W0207 12:00:01.277148  5023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:00:01.278158  5023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 715758432 / 715828224 (100%)
Max absolute difference: 7.94532045
Max relative difference: 796.90728471
 x: array([[[[[[[[1.005055e+00, 3.608677e+00, 6.245238e+00,
              3.117154e+00],
             [4.680314e+00, 8.980535e-01, 1.667759e+00,...
 y: array([[[[[[[[1.283428, 1.209094, 1.921708, 1.740016],
             [1.826605, 1.092863, 1.058562, 1.414474],
             [1.163672, 1.896906, 2.007546, 0.873032],...

W0207 12:02:22.353682  5724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:02:22.354557  5724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 536787115 / 536871168 (100%)
Max absolute difference: 7.86188536
Max relative difference: 128.98753654
 x: array([[[[[[[[1.604819, 6.587878, 5.221704, 5.898577],
             [4.252212, 7.385115, 4.771672, 4.138934],
             [1.786993, 4.894731, 1.628684, 5.545271],...
 y: array([[[[[[[[0.716911, 2.674274, 1.442821, 1.540913],
             [2.014022, 1.657385, 1.826159, 1.172477],
             [2.059662, 2.045567, 3.208112, 2.777397],...

W0207 12:04:15.235622  6275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:04:15.236562  6275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073632101 / 1073742336 (100%)
Max absolute difference: 7.99439022
Max relative difference: 26858.43689856
 x: array([[[[[[[[5.798247, 4.733539, 5.710204, 5.467986],
             [1.787607, 7.057921, 0.851738, 5.449297],
             [7.411463, 1.324287, 2.637462, 6.993631],...
 y: array([[[[[[[[0.826976, 0.534041, 0.405234, 1.776554],
             [1.347482, 1.440839, 0.708739, 0.967717],
             [1.682856, 0.821508, 0.968223, 1.120557],...

W0207 12:05:54.767351  6732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:05:54.768318  6732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 700915036 / 715828224 (97.9%)
Max absolute difference: 2.99863079
Max relative difference: 1.
 x: array([[[[[[[[1.610034, 1.949618, 1.432962, 1.476289],
             [0.693882, 1.395881, 2.214972, 1.263724],
             [1.861622, 1.641941, 1.130614, 0.790043],...
 y: array([[[[[[[[1.610034, 1.949618, 1.432962, 1.476289],
             [0.693882, 1.395881, 2.214972, 1.263724],
             [1.861622, 1.641941, 1.130614, 0.790043],...

W0207 12:08:25.301448  7417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:08:25.303220  7417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"float64"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 525686352 / 536871168 (97.9%)
Max absolute difference: 3.99006849
Max relative difference: 1.
 x: array([[[[[[[[1.150994, 2.094072, 2.360864, 0.776044],
             [2.21235 , 1.057436, 1.731495, 1.661831],
             [1.182158, 2.03558 , 1.844485, 2.569435],...
 y: array([[[[[[[[1.150994, 2.094072, 2.360864, 0.776044],
             [2.21235 , 1.057436, 1.731495, 1.661831],
             [1.182158, 2.03558 , 1.844485, 2.569435],...

W0207 12:10:29.670076  7998 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:10:29.671083  7998 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"int64"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 466034, 4],"int64"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 12:12:11.833289  8543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:12:11.834198  8543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 12:13:34.922842  8729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:13:34.923849  8729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147264396 / 2147484672 (100%)
Max absolute difference: 7.9892435
Max relative difference: 18691.797
 x: array([[[[[[[[7.781703, 4.46353 , 3.64027 , 2.970708],
             [2.773692, 1.448927, 2.682579, 0.929262],
             [0.370386, 1.358926, 1.347723, 1.509145],...
 y: array([[[[[[[[1.047969, 1.044698, 1.859236, 1.428256],
             [0.886487, 1.292013, 1.022202, 1.499223],
             [0.621728, 0.418035, 0.671523, 0.277315],...

W0207 12:14:51.019665  9152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:14:51.020603  9152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1431516550 / 1431656448 (100%)
Max absolute difference: 7.9276457
Max relative difference: 1181.2466
 x: array([[[[[[[[1.462685, 5.790667, 0.247518, 0.533586],
             [6.226779, 3.480387, 2.353903, 4.57709 ],
             [3.64329 , 0.337415, 0.680957, 1.839317],...
 y: array([[[[[[[[1.181655, 1.376171, 2.382378, 1.46072 ],
             [1.195601, 1.457864, 1.617831, 2.079952],
             [0.865123, 0.467887, 1.07858 , 0.693108],...

W0207 12:17:52.705153  9953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:17:52.706403  9953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073574751 / 1073742336 (100%)
Max absolute difference: 7.85925
Max relative difference: 149.57518
 x: array([[[[[[[[1.305878, 3.131934, 4.038926, 4.019178],
             [7.277921, 1.141888, 2.583088, 4.241714],
             [3.465512, 4.071907, 5.931256, 1.83026 ],...
 y: array([[[[[[[[1.516994, 1.911586, 1.646301, 1.704249],
             [1.977183, 2.173321, 2.081489, 1.816995],
             [2.321412, 2.887798, 2.757756, 1.030796],...

W0207 12:20:21.004283 10663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:20:21.005345 10663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147264478 / 2147484672 (100%)
Max absolute difference: 7.986036
Max relative difference: 27398.13
 x: array([[[[[[[[0.87351 , 0.926925, 7.370217, 3.766983],
             [7.262875, 6.79766 , 4.212482, 4.528279],
             [7.39819 , 4.726319, 0.829342, 1.620484],...
 y: array([[[[[[[[0.65758 , 1.296438, 0.816825, 0.472955],
             [0.359227, 1.084321, 1.080497, 0.942913],
             [1.351392, 1.441248, 1.203102, 1.029451],...

W0207 12:22:34.249768 11233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:22:34.250694 11233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1401830020 / 1431656448 (97.9%)
Max absolute difference: 2.9985728
Max relative difference: 1.
 x: array([[[[[[[[2.166917, 2.764312, 1.602725, 1.682495],
             [0.780362, 1.172636, 2.385232, 1.802179],
             [1.891165, 0.810192, 1.161559, 1.778432],...
 y: array([[[[[[[[2.166917, 2.764312, 1.602725, 1.682495],
             [0.780362, 1.172636, 2.385232, 1.802179],
             [1.891165, 0.810192, 1.161559, 1.778432],...

W0207 12:25:32.149713 12159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:25:32.150713 12159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 932068, 4],"float32"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1051372704 / 1073742336 (97.9%)
Max absolute difference: 3.989184
Max relative difference: 1.
 x: array([[[[[[[[2.665298, 1.999836, 2.345844, 1.987422],
             [2.46138 , 3.0191  , 2.698797, 1.41959 ],
             [2.22131 , 2.881582, 2.31254 , 1.897431],...
 y: array([[[[[[[[2.665298, 1.999836, 2.345844, 1.987422],
             [2.46138 , 3.0191  , 2.698797, 1.41959 ],
             [2.22131 , 2.881582, 2.31254 , 1.897431],...

W0207 12:28:03.563597 12766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:28:03.564882 12766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073634639 / 1073744640 (100%)
Max absolute difference: 7.98104292
Max relative difference: 28537.5987723
 x: array([[[[[[[[4.16785 , 7.470507, 2.141989, 1.255052],
             [0.787075, 5.424546, 6.371229, 4.837701],
             [1.372494, 5.654634, 2.145155, 0.089506]],...
 y: array([[[[[[[[1.094871, 0.824404, 1.274144, 0.82977 ],
             [1.63653 , 0.968338, 0.899196, 0.806334],
             [0.965804, 0.903613, 1.137599, 1.495419]],...

W0207 12:29:52.772859 13444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:29:52.773993 13444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 715760089 / 715829760 (100%)
Max absolute difference: 7.93297721
Max relative difference: 648.94748177
 x: array([[[[[[[[1.690161e+00, 6.955946e+00, 4.763889e+00,
              2.669167e+00],
             [7.547328e+00, 6.504707e+00, 4.364010e+00,...
 y: array([[[[[[[[1.190067, 1.569801, 1.49848 , 1.82483 ],
             [1.876893, 0.861516, 1.848351, 1.808777],
             [1.383918, 1.808767, 1.921676, 2.702059]],...

W0207 12:32:31.304924 14159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:32:31.305823 14159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 536787530 / 536872320 (100%)
Max absolute difference: 7.83939121
Max relative difference: 192.38600697
 x: array([[[[[[[[3.763939, 6.639603, 4.436583, 5.341401],
             [4.543763, 4.125371, 4.972752, 7.855374],
             [3.58601 , 4.564047, 3.279186, 1.056678]],...
 y: array([[[[[[[[1.59849 , 2.127712, 1.462819, 2.497784],
             [2.996949, 2.038041, 1.948917, 2.268836],
             [2.31075 , 2.019808, 2.529216, 1.29797 ]],...

W0207 12:34:22.825980 14706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:34:22.826943 14706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073634514 / 1073744640 (100%)
Max absolute difference: 7.97603761
Max relative difference: 17914.46616318
 x: array([[[[[[[[1.789758, 7.594364, 3.764081, 6.053786],
             [1.545004, 3.639971, 6.50797 , 4.069573],
             [2.598731, 3.919192, 1.016036, 2.551969]],...
 y: array([[[[[[[[0.374037, 0.455884, 1.264111, 1.028549],
             [1.464374, 1.098277, 0.59463 , 0.372666],
             [0.973864, 1.457036, 0.304733, 0.181599]],...

W0207 12:36:21.850256 15160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:36:21.851280 15160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 700916522 / 715829760 (97.9%)
Max absolute difference: 2.99925788
Max relative difference: 1.
 x: array([[[[[[[[1.486573, 1.662798, 1.419544, 1.76828 ],
             [0.571373, 1.382884, 1.415305, 1.217343],
             [2.086157, 1.607874, 2.169377, 1.767041]],...
 y: array([[[[[[[[1.486573, 1.662798, 1.419544, 1.76828 ],
             [0.571373, 1.382884, 1.415305, 1.217343],
             [2.086157, 1.607874, 2.169377, 1.767041]],...

W0207 12:38:44.479894 15944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:38:44.481117 15944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"float64"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 525687479 / 536872320 (97.9%)
Max absolute difference: 3.98697861
Max relative difference: 1.
 x: array([[[[[[[[1.106782, 1.397258, 1.568373, 2.037765],
             [1.598777, 1.514561, 1.989235, 1.708694],
             [1.716047, 1.899605, 1.763281, 1.38066 ]],...
 y: array([[[[[[[[1.106782, 1.397258, 1.568373, 2.037765],
             [1.598777, 1.514561, 1.989235, 1.708694],
             [1.716047, 1.899605, 1.763281, 1.38066 ]],...

W0207 12:40:34.612530 16408 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:40:34.613477 16408 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"int64"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 310690, 3, 4],"int64"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 12:42:13.374135 16950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:42:13.375069 16950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 12:43:33.704334 17162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:43:33.705402 17162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147265957 / 2147485824 (100%)
Max absolute difference: 7.9826713
Max relative difference: 12132.93
 x: array([[[[[[[[1.706667, 0.775889, 6.719436, 1.784559],
             [2.966188, 4.207556, 5.13608 , 0.358316],
             [3.318036, 2.298046, 1.085369, 5.537042]],...
 y: array([[[[[[[[0.607812, 1.597037, 0.81182 , 0.671894],
             [0.539534, 0.608163, 0.818897, 1.193894],
             [1.741325, 1.41002 , 1.651129, 0.247388]],...

W0207 12:44:48.146633 17554 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:44:48.147666 17554 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1431517314 / 1431657216 (100%)
Max absolute difference: 7.957497
Max relative difference: 843.58575
 x: array([[[[[[[[6.048886, 6.450222, 7.004216, 2.715099],
             [5.596838, 4.368309, 5.140438, 2.165244],
             [1.413529, 6.620976, 5.541573, 3.412289]],...
 y: array([[[[[[[[1.513142, 1.756353, 1.921162, 1.609004],
             [1.735034, 1.53437 , 1.680286, 1.786638],
             [1.749979, 1.059438, 1.142674, 1.323755]],...

W0207 12:47:43.324836 18352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:47:43.325881 18352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073575729 / 1073742912 (100%)
Max absolute difference: 7.8756485
Max relative difference: 162.16258
 x: array([[[[[[[[6.877751, 7.923908, 4.20475 , 2.397982],
             [1.03525 , 7.489562, 2.197475, 5.665234],
             [1.130572, 1.460447, 4.748645, 0.036734]],...
 y: array([[[[[[[[1.885602, 2.147762, 1.387983, 2.414268],
             [2.592802, 2.181116, 2.664641, 1.869951],
             [2.983842, 1.582113, 1.955133, 3.072649]],...

W0207 12:50:19.278479 19046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:50:19.279670 19046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147265535 / 2147485824 (100%)
Max absolute difference: 7.9875193
Max relative difference: 17152.238
 x: array([[[[[[[[1.036114, 6.997409, 7.279312, 5.095523],
             [7.775368, 6.233095, 6.399998, 4.451143],
             [3.495361, 2.038494, 7.611409, 3.307822]],...
 y: array([[[[[[[[0.690254, 1.144494, 0.860071, 1.073371],
             [1.787068, 1.531576, 0.350464, 0.713454],
             [1.12882 , 0.840313, 1.842083, 0.456346]],...

W0207 12:52:32.220968 19617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:52:32.221832 19617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1401830805 / 1431657216 (97.9%)
Max absolute difference: 2.9987192
Max relative difference: 1.
 x: array([[[[[[[[1.926338, 2.284891, 1.357206, 1.340046],
             [2.660143, 2.326761, 1.779747, 0.78242 ],
             [1.59064 , 1.14364 , 0.88456 , 1.92867 ]],...
 y: array([[[[[[[[1.926338, 2.284891, 1.357206, 1.340046],
             [2.660143, 2.326761, 1.779747, 0.78242 ],
             [1.59064 , 1.14364 , 0.88456 , 1.92867 ]],...

W0207 12:55:33.310302 20460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:55:33.311340 20460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 4, 621379, 3, 4],"float32"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1051373268 / 1073742912 (97.9%)
Max absolute difference: 3.989516
Max relative difference: 1.
 x: array([[[[[[[[2.481671, 2.419074, 1.577259, 2.088901],
             [1.738123, 2.053254, 1.984747, 1.909893],
             [2.021601, 1.723926, 3.291921, 2.429196]],...
 y: array([[[[[[[[2.481671, 2.419074, 1.577259, 2.088901],
             [1.738123, 2.053254, 1.984747, 1.909893],
             [2.021601, 1.723926, 3.291921, 2.429196]],...

W0207 12:58:00.436343 21165 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:58:00.437247 21165 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073632295 / 1073742912 (100%)
Max absolute difference: 7.98294804
Max relative difference: 13214.45336702
 x: array([[[[[[[[0.131873, 4.103303, 3.283526, 0.174105],
             [7.887278, 3.595398, 5.592463, 4.37602 ],
             [1.647722, 4.407149, 4.989666, 4.78975 ]],...
 y: array([[[[[[[[0.639187, 1.444404, 1.220136, 1.375953],
             [0.77451 , 1.156453, 1.098003, 0.654293],
             [0.732   , 1.18422 , 1.453851, 1.524558]],...

W0207 12:59:48.470412 21842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:59:48.471294 21842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 715759286 / 715828608 (100%)
Max absolute difference: 7.9434583
Max relative difference: 595.16782612
 x: array([[[[[[[[4.926167, 7.857799, 3.713649, 1.020045],
             [2.351389, 7.798471, 2.566151, 6.471813],
             [4.738217, 6.137043, 5.832026, 5.581299]],...
 y: array([[[[[[[[1.028573, 1.879701, 1.292691, 1.537765],
             [2.255461, 1.874521, 1.947867, 1.311005],
             [1.548953, 0.320965, 1.029149, 1.440444]],...

W0207 13:02:12.521060 22436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:02:12.522367 22436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 536787543 / 536871456 (100%)
Max absolute difference: 7.83679582
Max relative difference: 191.01006411
 x: array([[[[[[[[5.181371, 0.741636, 3.243053, 7.240396],
             [6.644162, 1.168437, 5.388796, 6.883515],
             [1.673896, 4.629259, 4.269173, 3.055172]],...
 y: array([[[[[[[[1.456767, 1.269631, 2.122563, 1.825043],
             [1.398731, 3.224412, 1.663731, 0.966633],
             [0.9982  , 1.605916, 2.723334, 1.792592]],...

W0207 13:04:10.096009 22975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:04:10.097235 22975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073632899 / 1073742912 (100%)
Max absolute difference: 7.98667868
Max relative difference: 20703.75085909
 x: array([[[[[[[[2.483647, 4.722732, 4.808046, 0.798822],
             [7.033517, 4.453591, 4.431679, 1.987863],
             [3.443385, 6.357164, 4.910335, 5.30335 ]],...
 y: array([[[[[[[[0.373201, 1.063923, 0.910896, 0.829434],
             [1.019946, 1.021073, 1.033492, 1.58002 ],
             [0.713642, 1.483626, 1.337105, 0.894593]],...

W0207 13:05:56.702723 23543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:05:56.703905 23543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 700915381 / 715828608 (97.9%)
Max absolute difference: 2.9980758
Max relative difference: 1.
 x: array([[[[[[[[1.04667 , 1.822729, 1.350159, 1.17485 ],
             [2.348448, 1.586065, 1.287097, 1.313232],
             [1.849033, 1.847659, 2.398962, 1.560752]],...
 y: array([[[[[[[[1.04667 , 1.822729, 1.350159, 1.17485 ],
             [2.348448, 1.586065, 1.287097, 1.313232],
             [1.849033, 1.847659, 2.398962, 1.560752]],...

W0207 13:08:23.890331 24230 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:08:23.891222 24230 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"float64"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 3384 / 3456 (97.9%)
Max absolute difference: 311512.77975292
Max relative difference: 1.
 x: array([[[[[[[[311000.755576, 310649.162046, 310684.21717 ,
              310520.849533],
             [310696.011082, 310795.59546 , 310628.741347,...
 y: array([[[[[[[[311000.755576, 310649.162046, 310684.21717 ,
              310520.849533],
             [310696.011082, 310795.59546 , 310628.741347,...

W0207 13:10:13.673759 24803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:10:13.674657 24803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"int64"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 2, 3, 621379, 2, 3, 4],"int64"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 13:11:11.671504 24970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:11:11.673220 24970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073631731 / 1073742336 (100%)
Max absolute difference: 7.98702914
Max relative difference: 13833.75951383
 x: array([[[[[[[[5.454617, 2.766216, 5.787658, 5.603081],
             [6.929858, 0.848632, 7.804576, 6.231061],
             [0.952725, 3.276824, 6.528074, 6.140792]],...
 y: array([[[[[[[[1.600519, 0.523709, 1.081879, 0.884573],
             [1.251941, 1.48023 , 0.705289, 1.473222],
             [1.698961, 1.00968 , 0.695237, 1.064022]],...

W0207 13:12:15.109125 25261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:12:15.110118 25261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 715758392 / 715828224 (100%)
Max absolute difference: 7.94124266
Max relative difference: 661.24508265
 x: array([[[[[[[[6.597806, 1.014667, 7.980371, 7.369991],
             [5.551621, 3.148954, 4.153289, 1.545984],
             [2.655085, 5.069545, 1.80683 , 6.096344]],...
 y: array([[[[[[[[1.112029, 2.317097, 1.688451, 1.503777],
             [1.009329, 0.888363, 2.065854, 2.236547],
             [1.847036, 1.105365, 1.279389, 1.344438]],...

W0207 13:14:41.223182 25970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:14:41.224045 25970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 536787054 / 536871168 (100%)
Max absolute difference: 7.89181675
Max relative difference: 132.66156884
 x: array([[[[[[[[1.836835e+00, 7.526789e+00, 5.842461e+00,
              3.715618e+00],
             [2.227814e+00, 6.741081e+00, 1.844986e+00,...
 y: array([[[[[[[[1.068552, 2.987317, 2.764621, 2.560312],
             [2.313428, 1.725263, 3.023859, 1.316163],
             [2.621734, 2.597799, 2.747091, 2.36391 ]],...

W0207 13:16:31.609627 26532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:16:31.610534 26532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073632011 / 1073742336 (100%)
Max absolute difference: 7.97930407
Max relative difference: 12945.89357719
 x: array([[[[[[[[6.547939, 4.121646, 7.029693, 7.413223],
             [0.887439, 7.288282, 0.667081, 5.820667],
             [6.451891, 5.069089, 6.648305, 1.007446]],...
 y: array([[[[[[[[1.129365, 1.344504, 0.693586, 1.111458],
             [1.344677, 0.540166, 1.086043, 1.021434],
             [1.12054 , 1.86406 , 0.754391, 0.543094]],...

W0207 13:18:17.466957 26958 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:18:17.467844 26958 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4512 / 4608 (97.9%)
Max absolute difference: 233673.69262359
Max relative difference: 1.
 x: array([[[[[[[[232968.238066, 233347.097599, 232954.774387,
              233340.345765],
             [232923.274977, 233010.910244, 232828.826588,...
 y: array([[[[[[[[232968.238066, 233347.097599, 232954.774387,
              233340.345765],
             [232923.274977, 233010.910244, 232828.826588,...

W0207 13:20:43.553617 27667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:20:43.554495 27667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"float64"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 525686352 / 536871168 (97.9%)
Max absolute difference: 3.98696621
Max relative difference: 1.
 x: array([[[[[[[[2.207673, 3.163465, 1.06334 , 2.063087],
             [2.239837, 1.418343, 2.323052, 1.605505],
             [1.156812, 1.441995, 2.119378, 3.314555]],...
 y: array([[[[[[[[2.207673, 3.163465, 1.06334 , 2.063087],
             [2.239837, 1.418343, 2.323052, 1.605505],
             [1.156812, 1.441995, 2.119378, 3.314555]],...

W0207 13:21:37.011970 27960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:21:37.012856 27960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"int64"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 2, 466034, 4, 2, 3, 4],"int64"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 13:23:12.754091 28483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:23:12.755270 28483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 13:24:38.276016 28670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:24:38.277632 28670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147264276 / 2147484672 (100%)
Max absolute difference: 7.9897933
Max relative difference: 21387.691
 x: array([[[[[[[[4.896896, 4.101648, 7.910583, 2.690991],
             [6.451091, 5.421071, 6.449837, 0.911048],
             [0.505029, 4.519476, 6.332451, 5.286938]],...
 y: array([[[[[[[[0.924335, 1.155864, 1.137152, 1.080837],
             [0.727638, 1.336388, 0.976445, 0.667882],
             [1.791928, 1.577714, 1.168838, 1.263971]],...

W0207 13:25:56.275628 29096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:25:56.276546 29096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1431516971 / 1431656448 (100%)
Max absolute difference: 7.9348445
Max relative difference: 614.39264
 x: array([[[[[[[[1.800963, 0.482161, 5.350247, 7.121163],
             [4.940384, 5.711683, 1.33063 , 0.573986],
             [6.074676, 7.936187, 0.549192, 4.872571]],...
 y: array([[[[[[[[1.016794, 1.359631, 1.706331, 1.791491],
             [0.613968, 0.760722, 1.723268, 2.208731],
             [2.206055, 1.567401, 1.065274, 0.807333]],...

W0207 13:28:52.206943 29921 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:28:52.208541 29921 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073574870 / 1073742336 (100%)
Max absolute difference: 7.858225
Max relative difference: 165.74327
 x: array([[[[[[[[5.983298, 6.515964, 7.845191, 2.213125],
             [3.481102, 7.79712 , 5.836589, 5.601879],
             [6.034991, 3.448231, 1.561298, 0.77778 ]],...
 y: array([[[[[[[[1.66841 , 1.776481, 0.72906 , 2.25286 ],
             [2.309952, 3.077754, 3.740479, 1.813117],
             [3.133167, 2.567461, 1.600627, 2.106119]],...

W0207 13:31:19.188300 30600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:31:19.189805 30600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147264406 / 2147484672 (100%)
Max absolute difference: 7.9863405
Max relative difference: 54268.445
 x: array([[[[[[[[3.568893e+00, 1.590516e+00, 4.778778e+00,
              6.733261e+00],
             [5.688704e-01, 3.017280e+00, 2.988303e+00,...
 y: array([[[[[[[[0.516521, 1.040074, 0.536296, 0.678621],
             [0.228587, 0.719238, 0.785015, 0.838124],
             [1.046957, 1.133745, 1.047923, 0.967216]],...

W0207 13:33:43.204730 31177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:33:43.205832 31177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4512 / 4608 (97.9%)
Max absolute difference: 466911.88
Max relative difference: 1.
 x: array([[[[[[[[466148.12, 465571.5 , 466012.22, 466102.78],
             [466211.72, 466333.28, 466173.62, 466577.12],
             [465783.7 , 466070.62, 465850.28, 466308.5 ]],...
 y: array([[[[[[[[466150.88, 465573.22, 466012.28, 466101.7 ],
             [466210.66, 466332.75, 466175.2 , 466578.75],
             [465783.62, 466070.5 , 465845.94, 466307.28]],...

W0207 13:37:00.426622 32167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:37:00.428277 32167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 2, 932068, 4, 2, 3, 4],"float32"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1051372702 / 1073742336 (97.9%)
Max absolute difference: 3.992932
Max relative difference: 1.
 x: array([[[[[[[[1.075755, 2.933671, 1.284812, 1.683888],
             [3.130834, 1.682283, 2.284918, 2.152344],
             [1.998845, 2.901818, 1.928612, 1.794634]],...
 y: array([[[[[[[[1.075755, 2.933671, 1.284812, 1.683888],
             [3.130834, 1.682283, 2.284918, 2.152344],
             [1.998845, 2.901818, 1.928612, 1.794634]],...

W0207 13:38:22.498040 32585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:38:22.498973 32585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073689966 / 1073744640 (100%)
Max absolute difference: 7.22437932
Max relative difference: 64.51394412
 x: array([[[[[[[[3.244816, 1.970417, 5.902132, 3.273737],
             [0.877205, 0.120472, 4.722692, 6.892116],
             [2.004739, 0.2906  , 0.140205, 2.551   ]],...
 y: array([[[[[[[[1.293054, 0.629211, 0.9806  , 0.163116],
             [0.605818, 1.556155, 0.557142, 0.312703],
             [0.907745, 1.040207, 1.802029, 1.467771]],...

W0207 13:40:11.473241 33146 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:40:11.474596 33146 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 715829650 / 715829760 (100%)
Max absolute difference: 7.40436436
Max relative difference: 21.13428504
 x: array([[[[[[[[2.889014, 7.807956, 1.575974, 6.555379],
             [7.51355 , 3.994416, 4.958284, 4.536932],
             [2.416271, 0.445007, 6.29084 , 4.460283]],...
 y: array([[[[[[[[1.49727 , 2.088194, 0.87316 , 1.206585],
             [2.174613, 1.853347, 2.246014, 1.137613],
             [1.186157, 0.572241, 1.722181, 1.121416]],...

W0207 13:42:39.652462 33856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:42:39.653379 33856 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 536872318 / 536872320 (100%)
Max absolute difference: 6.28289128
Max relative difference: 17.49855102
 x: array([[[[[[[[5.438765, 5.847549, 7.493796, 0.45771 ],
             [7.290893, 2.670397, 3.837055, 2.797968],
             [1.004099, 3.897395, 2.112421, 3.082393]],...
 y: array([[[[[[[[2.151172, 0.316109, 2.107417, 2.128996],
             [2.676231, 3.184598, 2.848491, 2.382786],
             [3.528509, 2.05469 , 1.438261, 2.046342]],...

W0207 13:44:34.865828 34379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:44:34.866866 34379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 6912 / 6912 (100%)
Max absolute difference: 155925.87364412
Max relative difference: 1.
 x: array([[[[[[[[0., 0., 0., 0.],
             [0., 0., 0., 0.],
             [0., 0., 0., 0.]],...
 y: array([[[[[[[[155366.496273, 155203.90282 , 155474.9527  ,
              155260.566358],
             [155583.82941 , 155308.502802, 155303.990292,...

W0207 13:46:18.058641 34947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:46:18.059681 34947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 715829531 / 715829760 (100%)
Max absolute difference: 2.99741411
Max relative difference: 1.
 x: array([[[[[[[[2.258729, 1.088945, 0.6852  , 1.236343],
             [1.802785, 1.579989, 0.747538, 1.297188],
             [1.47693 , 2.417477, 2.069911, 1.705538]],...
 y: array([[[[[[[[2.258729, 1.088945, 0.6852  , 1.236343],
             [1.802785, 1.579989, 0.747538, 1.297188],
             [1.47693 , 2.417477, 2.069911, 1.705538]],...

W0207 13:47:18.726692 35204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:47:18.727550 35204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"float64"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 536872248 / 536872320 (100%)
Max absolute difference: 3.98220718
Max relative difference: 1.
 x: array([[[[[[[[1.736318, 2.582578, 2.743396, 1.220274],
             [3.044461, 1.786276, 1.263945, 1.666527],
             [2.40586 , 2.86631 , 2.539201, 1.710317]],...
 y: array([[[[[[[[1.736318, 2.582578, 2.743396, 1.220274],
             [3.044461, 1.786276, 1.263945, 1.666527],
             [2.40586 , 2.86631 , 2.539201, 1.710317]],...

W0207 13:49:15.591871 35787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:49:15.592754 35787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"int64"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 310690, 3, 4, 2, 3, 4],"int64"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 13:50:57.699520 36227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:50:57.700496 36227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), )
[paddle error] paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), ) 
 (Fatal) If Input.numel() > INT32_MAX, reduce_sum kernel uses EigenTensor sum for reduce_sum function. As a result, its dim should be <= 5. (at ../paddle/phi/kernels/kps/reduce_kernel.cu:301)


W0207 13:52:29.909497 36507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:52:29.910470 36507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 0, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 0, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147376775 / 2147485824 (100%)
Max absolute difference: 6.8243093
Max relative difference: 22.028992
 x: array([[[[[[[[2.997678, 4.818037, 2.891989, 2.393543],
             [7.196881, 3.867775, 6.757202, 6.556717],
             [6.507306, 1.081986, 5.705269, 0.681767]],...
 y: array([[[[[[[[0.576082, 0.427895, 1.612954, 0.962631],
             [0.954828, 1.044298, 1.451633, 1.28412 ],
             [0.555983, 0.769676, 0.396091, 0.708426]],...

W0207 13:53:51.791575 36938 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:53:51.792618 36938 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 1, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 1, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1431656975 / 1431657216 (100%)
Max absolute difference: 7.137714
Max relative difference: 10.563709
 x: array([[[[[[[[6.456947, 7.138989, 5.781373, 2.185671],
             [1.560542, 4.178571, 7.062657, 5.171368],
             [5.632119, 5.927309, 7.800239, 5.317997]],...
 y: array([[[[[[[[1.859276, 1.448375, 1.821433, 0.785718],
             [1.114567, 0.938643, 1.824383, 1.098686],
             [1.430582, 1.064944, 1.059552, 1.755288]],...

W0207 13:56:48.526909 37767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:56:48.527838 37767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 2, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 2, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073742911 / 1073742912 (100%)
Max absolute difference: 6.663229
Max relative difference: 7.672433
 x: array([[[[[[[[0.612588, 4.164774, 4.020026, 5.300087],
             [4.166661, 5.905437, 5.70657 , 3.495527],
             [7.926346, 6.4385  , 3.683438, 1.941675]],...
 y: array([[[[[[[[1.147094, 2.22565 , 3.032691, 2.489148],
             [2.366302, 2.011271, 2.083167, 1.603735],
             [2.123298, 2.016528, 2.10456 , 2.332593]],...

W0207 13:59:16.999727 38470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:59:17.000840 38470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 3, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 3, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 6912 / 6912 (100%)
Max absolute difference: 311583.
Max relative difference: 1.
 x: array([[[[[[[[1.773584, 0.507833, 1.51822 , 0.020424],
             [0.336823, 2.411347, 4.121951, 2.456926],
             [7.548195, 4.712845, 3.754375, 1.150217]],...
 y: array([[[[[[[[310956.38, 310857.3 , 310286.7 , 311211.3 ],
             [310864.28, 311044.8 , 310397.44, 310744.3 ],
             [311119.38, 310910.62, 310950.25, 310597.62]],...

W0207 14:01:25.292191 39040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:01:25.293066 39040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 4, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 4, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1431656869 / 1431657216 (100%)
Max absolute difference: 2.9982905
Max relative difference: 1.
 x: array([[[[[[[[1.723948, 1.576367, 0.8556  , 1.739839],
             [1.196922, 2.093937, 1.081307, 1.531781],
             [1.696655, 2.006947, 0.968939, 1.465625]],...
 y: array([[[[[[[[1.723948, 1.576367, 0.8556  , 1.739839],
             [1.196922, 2.093937, 1.081307, 1.531781],
             [1.696655, 2.006947, 0.968939, 1.465625]],...

W0207 14:02:42.495282 39454 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:02:42.496284 39454 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 5, keepdim=False, dtype=None, )
[accuracy error] paddle.sum(Tensor([2, 3, 4, 621379, 3, 4, 2, 3, 4],"float32"), 5, keepdim=False, dtype=None, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 1073742839 / 1073742912 (100%)
Max absolute difference: 3.9852269
Max relative difference: 1.
 x: array([[[[[[[[2.084896, 1.798764, 2.822691, 2.674159],
             [1.820572, 2.175341, 2.06438 , 2.139094],
             [1.383213, 2.927416, 2.124495, 2.385976]],...
 y: array([[[[[[[[2.084896, 1.798764, 2.822691, 2.674159],
             [1.820572, 2.175341, 2.06438 , 2.139094],
             [1.383213, 2.927416, 2.124495, 2.385976]],...

W0207 14:05:06.821797 40143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:05:06.822993 40143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 89478486],"int64"), axis=list[0,1,2,3,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([2, 3, 4, 89478486],"int64"), axis=list[0,1,2,3,], keepdim=False, name=None, )

W0207 14:06:55.065564 40725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:06:55.067265 40725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 89478486],"int64"), axis=list[0,2,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([2, 3, 4, 89478486],"int64"), axis=list[0,2,], keepdim=False, name=None, )

W0207 14:13:38.975750 42541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:13:38.976644 42541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sum(Tensor([2, 3, 4, 89478486],"int64"), axis=list[-1,], keepdim=False, name=None, )
[Pass] paddle.sum(Tensor([2, 3, 4, 89478486],"int64"), axis=list[-1,], keepdim=False, name=None, )

W0207 14:14:48.878414 42939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:14:48.879293 42939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 65, in main
    print(str(res.stdout.read(), encoding="utf-8"), flush=True)
KeyboardInterrupt
