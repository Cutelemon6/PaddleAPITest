test begin: paddle.reshape(Tensor([8, 2048, 1, 262144],"float32"), shape=list[-1,2048,], )
[Pass] paddle.reshape(Tensor([8, 2048, 1, 262144],"float32"), shape=list[-1,2048,], )

W0211 15:39:05.631574 68502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:39:05.632705 68502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 2048, 262144, 1],"float16"), shape=list[-1,2048,], )
[Pass] paddle.reshape(Tensor([8, 2048, 262144, 1],"float16"), shape=list[-1,2048,], )

W0211 15:42:58.818796 70513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:42:58.819711 70513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 2048, 262144, 1],"float32"), shape=list[-1,2048,], )
[Pass] paddle.reshape(Tensor([8, 2048, 262144, 1],"float32"), shape=list[-1,2048,], )

W0211 15:51:40.386092 76292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:51:40.387210 76292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 2236963, 4, 4, 5, 3],"float32"), list[24,8,10,3,], )
[torch error] paddle.reshape(Tensor([8, 2236963, 4, 4, 5, 3],"float32"), list[24,8,10,3,], ) 
 shape '[24, 8, 10, 3]' is invalid for input of size 4294968960

W0211 15:55:24.557353 78437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:55:24.558480 78437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 256, 1, 2097152],"float32"), shape=list[-1,256,], )
[Pass] paddle.reshape(Tensor([8, 256, 1, 2097152],"float32"), shape=list[-1,256,], )

W0211 15:56:42.174185 80465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:56:42.175201 80465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 256, 2097152, 1],"float32"), shape=list[-1,256,], )
[Pass] paddle.reshape(Tensor([8, 256, 2097152, 1],"float32"), shape=list[-1,256,], )

W0211 16:00:24.073244 84929 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:00:24.074447 84929 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 268435457],"int64"), list[2,4,3,], name="Categorical_sample", )
[torch error] paddle.reshape(Tensor([8, 268435457],"int64"), list[2,4,3,], name="Categorical_sample", ) 
 shape '[2, 4, 3]' is invalid for input of size 2147483656

W0211 16:03:35.486477 88585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:03:35.487632 88585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 268435457],"int64"), list[2,4,3,2,], name="Categorical_sample", )
[torch error] paddle.reshape(Tensor([8, 268435457],"int64"), list[2,4,3,2,], name="Categorical_sample", ) 
 shape '[2, 4, 3, 2]' is invalid for input of size 2147483656

W0211 16:04:22.039935 88944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:04:22.041096 88944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 268435457],"int64"), tuple(-1,1,), )
[Pass] paddle.reshape(Tensor([8, 268435457],"int64"), tuple(-1,1,), )

W0211 16:05:15.661686 89538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:05:15.662513 89538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 2684355, 100],"float64"), list[-1,400,], )
[Pass] paddle.reshape(Tensor([8, 2684355, 100],"float64"), list[-1,400,], )

W0211 16:08:08.744331 91356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:08:08.745339 91356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 3, 1491309, 4, 5, 3],"int64"), list[24,8,10,3,], )
[torch error] paddle.reshape(Tensor([8, 3, 1491309, 4, 5, 3],"int64"), list[24,8,10,3,], ) 
 shape '[24, 8, 10, 3]' is invalid for input of size 2147484960

W0211 16:10:45.856478 92884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:10:45.857791 92884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 3, 2982617, 4, 5, 3],"float32"), list[24,8,10,3,], )
[torch error] paddle.reshape(Tensor([8, 3, 2982617, 4, 5, 3],"float32"), list[24,8,10,3,], ) 
 shape '[24, 8, 10, 3]' is invalid for input of size 4294968480

W0211 16:11:58.182272 93414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:11:58.183393 93414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 3, 4, 1491309, 5, 3],"int64"), list[24,8,10,3,], )
[torch error] paddle.reshape(Tensor([8, 3, 4, 1491309, 5, 3],"int64"), list[24,8,10,3,], ) 
 shape '[24, 8, 10, 3]' is invalid for input of size 2147484960

W0211 16:12:45.624667 93978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:12:45.625828 93978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 3, 4, 2982617, 5, 3],"float32"), list[24,8,10,3,], )
[torch error] paddle.reshape(Tensor([8, 3, 4, 2982617, 5, 3],"float32"), list[24,8,10,3,], ) 
 shape '[24, 8, 10, 3]' is invalid for input of size 4294968480

W0211 16:13:58.742528 94508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:13:58.743687 94508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 3, 4, 4, 1864136, 3],"int64"), list[24,8,10,3,], )
[torch error] paddle.reshape(Tensor([8, 3, 4, 4, 1864136, 3],"int64"), list[24,8,10,3,], ) 
 shape '[24, 8, 10, 3]' is invalid for input of size 2147484672

W0211 16:14:46.360841 95075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:14:46.361934 95075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 3, 4, 4, 3728271, 3],"float32"), list[24,8,10,3,], )
[torch error] paddle.reshape(Tensor([8, 3, 4, 4, 3728271, 3],"float32"), list[24,8,10,3,], ) 
 shape '[24, 8, 10, 3]' is invalid for input of size 4294968192

W0211 16:16:02.384763 95573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:16:02.385742 95573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 3, 4, 4, 5, 1118482],"int64"), list[24,8,10,3,], )
[torch error] paddle.reshape(Tensor([8, 3, 4, 4, 5, 1118482],"int64"), list[24,8,10,3,], ) 
 shape '[24, 8, 10, 3]' is invalid for input of size 2147485440

W0211 16:16:50.105244 96098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:16:50.106333 96098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 3, 4, 4, 5, 2236963],"float32"), list[24,8,10,3,], )
[torch error] paddle.reshape(Tensor([8, 3, 4, 4, 5, 2236963],"float32"), list[24,8,10,3,], ) 
 shape '[24, 8, 10, 3]' is invalid for input of size 4294968960

W0211 16:18:02.392867 96669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:18:02.394100 96669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 4, 134217728],"float32"), list[-1,4000,], )
[torch error] paddle.reshape(Tensor([8, 4, 134217728],"float32"), list[-1,4000,], ) 
 shape '[-1, 4000]' is invalid for input of size 4294967296

W0211 16:19:16.056192 97326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:19:16.057276 97326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 4, 134217728],"float32"), shape=tuple(-1,8,), )
[Pass] paddle.reshape(Tensor([8, 4, 134217728],"float32"), shape=tuple(-1,8,), )

W0211 16:20:39.283771 98215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:20:39.284607 98215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 4, 67108865],"float64"), list[-1,400,], )
[torch error] paddle.reshape(Tensor([8, 4, 67108865],"float64"), list[-1,400,], ) 
 shape '[-1, 400]' is invalid for input of size 2147483680

W0211 16:23:41.225450 100327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:23:41.226661 100327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 4, 67108865],"float64"), shape=list[-1,32,], )
[Pass] paddle.reshape(Tensor([8, 4, 67108865],"float64"), shape=list[-1,32,], )

W0211 16:24:36.700903 100668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:24:36.701819 100668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 4194304, 128],"float32"), shape=list[-1,128,], )
[Pass] paddle.reshape(Tensor([8, 4194304, 128],"float32"), shape=list[-1,128,], )

W0211 16:28:04.038744 102729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:28:04.039623 102729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 512, 1, 1048576],"float32"), shape=list[-1,512,], )
[Pass] paddle.reshape(Tensor([8, 512, 1, 1048576],"float32"), shape=list[-1,512,], )

W0211 16:32:00.165643 104823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:32:00.166640 104823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 512, 1048576, 1],"float32"), shape=list[-1,512,], )
[Pass] paddle.reshape(Tensor([8, 512, 1048576, 1],"float32"), shape=list[-1,512,], )

W0211 16:35:34.441223 107169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:35:34.442086 107169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536870912, 1, 1],"float16"), shape=list[-1,2048,], )
[Pass] paddle.reshape(Tensor([8, 536870912, 1, 1],"float16"), shape=list[-1,2048,], )

W0211 16:39:21.359707 109319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:39:21.360572 109319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536870912, 1, 1],"float32"), shape=list[-1,1024,], )
[Pass] paddle.reshape(Tensor([8, 536870912, 1, 1],"float32"), shape=list[-1,1024,], )

W0211 16:48:15.738236 114542 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:48:15.739388 114542 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536870912, 1, 1],"float32"), shape=list[-1,2048,], )
[Pass] paddle.reshape(Tensor([8, 536870912, 1, 1],"float32"), shape=list[-1,2048,], )

W0211 16:51:55.718598 116679 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:51:55.719475 116679 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536870912, 1, 1],"float32"), shape=list[-1,256,], )
[Pass] paddle.reshape(Tensor([8, 536870912, 1, 1],"float32"), shape=list[-1,256,], )

W0211 16:55:28.568305 118804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:55:28.569146 118804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536870912, 1, 1],"float32"), shape=list[-1,512,], )
[Pass] paddle.reshape(Tensor([8, 536870912, 1, 1],"float32"), shape=list[-1,512,], )

W0211 16:59:18.486832 122959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:59:18.487881 122959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536870912],"float32"), list[8,1024,1,1,], )
[torch error] paddle.reshape(Tensor([8, 536870912],"float32"), list[8,1024,1,1,], ) 
 shape '[8, 1024, 1, 1]' is invalid for input of size 4294967296

W0211 17:03:12.469988 127885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:03:12.470965 127885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536870912],"float32"), list[8,2048,1,1,], )
[torch error] paddle.reshape(Tensor([8, 536870912],"float32"), list[8,2048,1,1,], ) 
 shape '[8, 2048, 1, 1]' is invalid for input of size 4294967296

W0211 17:04:26.186162 129188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:04:26.187301 129188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536870912],"float32"), list[8,256,1,1,], )
[torch error] paddle.reshape(Tensor([8, 536870912],"float32"), list[8,256,1,1,], ) 
 shape '[8, 256, 1, 1]' is invalid for input of size 4294967296

W0211 17:05:39.152747 131049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:05:39.153935 131049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536870912],"float32"), list[8,4,1,], )
[torch error] paddle.reshape(Tensor([8, 536870912],"float32"), list[8,4,1,], ) 
 shape '[8, 4, 1]' is invalid for input of size 4294967296

W0211 17:06:51.751230 132373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:06:51.752336 132373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536870912],"float32"), list[8,512,1,1,], )
[torch error] paddle.reshape(Tensor([8, 536870912],"float32"), list[8,512,1,1,], ) 
 shape '[8, 512, 1, 1]' is invalid for input of size 4294967296

W0211 17:08:03.766141 134526 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:08:03.767211 134526 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 536871, 1000],"float32"), list[-1,4000,], )
[Pass] paddle.reshape(Tensor([8, 536871, 1000],"float32"), list[-1,4000,], )

W0211 17:09:28.981649 135753 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:09:28.983309 135753 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 67108864, 8],"float32"), shape=tuple(-1,8,), )
[Pass] paddle.reshape(Tensor([8, 67108864, 8],"float32"), shape=tuple(-1,8,), )

W0211 17:13:12.788816 140424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:13:12.789719 140424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8, 8388609, 32],"float64"), shape=list[-1,32,], )
[Pass] paddle.reshape(Tensor([8, 8388609, 32],"float64"), shape=list[-1,32,], )

W0211 17:16:39.351091 144576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:16:39.352036 144576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8388608, 512, 1, 1],"float32"), shape=list[-1,512,], )
[Pass] paddle.reshape(Tensor([8388608, 512, 1, 1],"float32"), shape=list[-1,512,], )

W0211 17:19:59.332769 148143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:19:59.333848 148143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8388608, 512],"float32"), list[1,512,1,1,], )
[torch error] paddle.reshape(Tensor([8388608, 512],"float32"), list[1,512,1,1,], ) 
 shape '[1, 512, 1, 1]' is invalid for input of size 4294967296

W0211 17:23:37.413780 153216 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:23:37.414767 153216 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8388608, 512],"float32"), list[8,512,1,1,], )
[torch error] paddle.reshape(Tensor([8388608, 512],"float32"), list[8,512,1,1,], ) 
 shape '[8, 512, 1, 1]' is invalid for input of size 4294967296

W0211 17:24:47.278544 154447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:24:47.279717 154447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([8388608, 8, 1, 32, 2],"float16"), Tensor([4],"int64"), )
[torch error] paddle.reshape(Tensor([8388608, 8, 1, 32, 2],"float16"), Tensor([4],"int64"), ) 
 reshape(): argument 'shape' must be tuple of ints, not Tensor

W0211 17:26:10.963974 155895 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:26:10.965037 155895 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([858993459, 5],"float32"), list[10,], )
[torch error] paddle.reshape(Tensor([858993459, 5],"float32"), list[10,], ) 
 shape '[10]' is invalid for input of size 4294967295

W0211 17:27:22.433879 157320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:27:22.435134 157320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([858993459, 5],"float32"), list[15,4,], )
[torch error] paddle.reshape(Tensor([858993459, 5],"float32"), list[15,4,], ) 
 shape '[15, 4]' is invalid for input of size 4294967295

W0211 17:28:34.098599 159127 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:28:34.099862 159127 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([858993459, 5],"float32"), list[2,25,], )
[torch error] paddle.reshape(Tensor([858993459, 5],"float32"), list[2,25,], ) 
 shape '[2, 25]' is invalid for input of size 4294967295

W0211 17:29:44.615923 160367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:29:44.617282 160367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([858993459, 5],"float32"), list[3,5,], )
[torch error] paddle.reshape(Tensor([858993459, 5],"float32"), list[3,5,], ) 
 shape '[3, 5]' is invalid for input of size 4294967295

W0211 17:30:56.935535 161766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:30:56.936784 161766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([894785, 1, 3, 40, 40],"float32"), shape=list[3,1,3,40,40,], )
[torch error] paddle.reshape(Tensor([894785, 1, 3, 40, 40],"float32"), shape=list[3,1,3,40,40,], ) 
 shape '[3, 1, 3, 40, 40]' is invalid for input of size 4294968000

W0211 17:32:08.102308 163160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:32:08.103677 163160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([894785, 1, 40, 40, 3],"float32"), shape=list[3,1,40,40,3,], )
[torch error] paddle.reshape(Tensor([894785, 1, 40, 40, 3],"float32"), shape=list[3,1,40,40,3,], ) 
 shape '[3, 1, 40, 40, 3]' is invalid for input of size 4294968000

W0211 17:33:20.141988   902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:33:20.143026   902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([894785, 3, 40, 40],"float32"), list[3,3,40,40,], )
[torch error] paddle.reshape(Tensor([894785, 3, 40, 40],"float32"), list[3,3,40,40,], ) 
 shape '[3, 3, 40, 40]' is invalid for input of size 4294968000

W0211 17:34:29.135710  2493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:34:29.136875  2493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([894785, 40, 40, 3],"float32"), list[3,40,40,3,], )
[torch error] paddle.reshape(Tensor([894785, 40, 40, 3],"float32"), list[3,40,40,3,], ) 
 shape '[3, 40, 40, 3]' is invalid for input of size 4294968000

W0211 17:35:40.373842  4037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:35:40.375063  4037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([89808, 488, 2, 7, 7],"float32"), shape=list[2,976,7,7,], )
[torch error] paddle.reshape(Tensor([89808, 488, 2, 7, 7],"float32"), shape=list[2,976,7,7,], ) 
 shape '[2, 976, 7, 7]' is invalid for input of size 4294977792

W0211 17:36:58.826949  5345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:36:58.828037  5345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([89808, 976, 7, 7],"float32"), shape=list[2,2,488,7,7,], )
[torch error] paddle.reshape(Tensor([89808, 976, 7, 7],"float32"), shape=list[2,2,488,7,7,], ) 
 shape '[2, 2, 488, 7, 7]' is invalid for input of size 4294977792

W0211 17:38:20.336024  7207 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:38:20.337126  7207 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([9, 238609295],"int64"), list[18,4,], )
[torch error] paddle.reshape(Tensor([9, 238609295],"int64"), list[18,4,], ) 
 shape '[18, 4]' is invalid for input of size 2147483655

W0211 17:39:13.890843  8801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:39:13.892226  8801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([9, 238609295],"int64"), list[9,10,], name="Categorical_sample", )
[torch error] paddle.reshape(Tensor([9, 238609295],"int64"), list[9,10,], name="Categorical_sample", ) 
 shape '[9, 10]' is invalid for input of size 2147483655

W0211 17:40:02.714346 10052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:40:02.715970 10052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([9, 477218589],"float32"), list[18,4,], )
[torch error] paddle.reshape(Tensor([9, 477218589],"float32"), list[18,4,], ) 
 shape '[18, 4]' is invalid for input of size 4294967301

W0211 17:41:10.427986 11032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:41:10.429122 11032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([913046, 48, 2, 7, 7],"float32"), shape=list[2,96,7,7,], )
[torch error] paddle.reshape(Tensor([913046, 48, 2, 7, 7],"float32"), shape=list[2,96,7,7,], ) 
 shape '[2, 96, 7, 7]' is invalid for input of size 4294968384

W0211 17:42:29.958283 12306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:42:29.960078 12306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([913046, 96, 7, 7],"float32"), shape=list[2,2,48,7,7,], )
[torch error] paddle.reshape(Tensor([913046, 96, 7, 7],"float32"), shape=list[2,2,48,7,7,], ) 
 shape '[2, 2, 48, 7, 7]' is invalid for input of size 4294968384

W0211 17:43:41.397539 14197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:43:41.398922 14197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([94454, 116, 2, 14, 14],"float32"), shape=list[2,232,14,14,], )
[torch error] paddle.reshape(Tensor([94454, 116, 2, 14, 14],"float32"), shape=list[2,232,14,14,], ) 
 shape '[2, 232, 14, 14]' is invalid for input of size 4295012288

W0211 17:44:56.433429 15503 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:44:56.434603 15503 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(Tensor([94454, 232, 14, 14],"float32"), shape=list[2,2,116,14,14,], )
[torch error] paddle.reshape(Tensor([94454, 232, 14, 14],"float32"), shape=list[2,2,116,14,14,], ) 
 shape '[2, 2, 116, 14, 14]' is invalid for input of size 4295012288

W0211 17:46:15.883972 17353 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:46:15.885277 17353 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([10, 429496730],"float32"), shape=list[10,], )
[torch error] paddle.reshape(x=Tensor([10, 429496730],"float32"), shape=list[10,], ) 
 shape '[10]' is invalid for input of size 4294967300

W0211 17:47:36.036815 18946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:47:36.037832 18946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([10, 429496730],"float32"), shape=list[100,], )
[torch error] paddle.reshape(x=Tensor([10, 429496730],"float32"), shape=list[100,], ) 
 shape '[100]' is invalid for input of size 4294967300

W0211 17:48:46.514086 20537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:48:46.515121 20537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([10, 429496730],"float32"), shape=list[80,], )
[torch error] paddle.reshape(x=Tensor([10, 429496730],"float32"), shape=list[80,], ) 
 shape '[80]' is invalid for input of size 4294967300

W0211 17:50:05.543363 22051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:50:05.544446 22051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([1431655765, 3],"float32"), shape=list[6,], )
[torch error] paddle.reshape(x=Tensor([1431655765, 3],"float32"), shape=list[6,], ) 
 shape '[6]' is invalid for input of size 4294967295

W0211 17:51:26.456931 23546 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:51:26.457906 23546 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([15339169, 140, 2, 1],"float32"), shape=list[0,0,2,], )
[torch error] paddle.reshape(x=Tensor([15339169, 140, 2, 1],"float32"), shape=list[0,0,2,], ) 
 shape '[0, 0, 2]' is invalid for input of size 4294967320

W0211 17:52:37.334636 25409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:52:37.335752 25409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([15339169, 140, 2],"float32"), shape=list[0,0,2,1,], )
[torch error] paddle.reshape(x=Tensor([15339169, 140, 2],"float32"), shape=list[0,0,2,1,], ) 
 shape '[0, 0, 2, 1]' is invalid for input of size 4294967320

W0211 17:53:58.954100 26852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:53:58.955492 26852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([15339169, 140, 2],"float32"), shape=list[-1,2,], )
[Pass] paddle.reshape(x=Tensor([15339169, 140, 2],"float32"), shape=list[-1,2,], )

W0211 17:55:24.138692 28717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:55:24.139709 28717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([2, 2147483648, 1],"float32"), shape=list[2,8,], )
[torch error] paddle.reshape(x=Tensor([2, 2147483648, 1],"float32"), shape=list[2,8,], ) 
 shape '[2, 8]' is invalid for input of size 4294967296

W0211 17:59:11.549512 33727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:59:11.550485 33727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([2, 2147483648],"float32"), shape=list[6,], )
[torch error] paddle.reshape(x=Tensor([2, 2147483648],"float32"), shape=list[6,], ) 
 shape '[6]' is invalid for input of size 4294967296

W0211 18:00:29.474375 35058 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:00:29.475473 35058 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([2, 8, 268435456],"float32"), shape=list[2,8,], )
[torch error] paddle.reshape(x=Tensor([2, 8, 268435456],"float32"), shape=list[2,8,], ) 
 shape '[2, 8]' is invalid for input of size 4294967296

W0211 18:01:39.151163 36904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:01:39.169405 36904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([20, 214748365],"float32"), shape=list[200,], )
[torch error] paddle.reshape(x=Tensor([20, 214748365],"float32"), shape=list[200,], ) 
 shape '[200]' is invalid for input of size 4294967300

W0211 18:02:58.234745 38209 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:02:58.235766 38209 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([2097152, 4, 512],"float32"), shape=list[0,0,8,64,], )
[torch error] paddle.reshape(x=Tensor([2097152, 4, 512],"float32"), shape=list[0,0,8,64,], ) 
 shape '[0, 0, 8, 64]' is invalid for input of size 4294967296

W0211 18:04:12.930944 40081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:04:12.932030 40081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([2097152, 4, 8, 64],"float32"), shape=list[0,0,512,], )
[torch error] paddle.reshape(x=Tensor([2097152, 4, 8, 64],"float32"), shape=list[0,0,512,], ) 
 shape '[0, 0, 512]' is invalid for input of size 4294967296

W0211 18:05:28.542958 41421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:05:28.544080 41421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([32, 262144, 512],"float32"), shape=list[0,0,8,64,], )
[torch error] paddle.reshape(x=Tensor([32, 262144, 512],"float32"), shape=list[0,0,8,64,], ) 
 shape '[0, 0, 8, 64]' is invalid for input of size 4294967296

W0211 18:06:40.913970 43279 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:06:40.915199 43279 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([32, 262144, 8, 64],"float32"), shape=list[0,0,512,], )
[torch error] paddle.reshape(x=Tensor([32, 262144, 8, 64],"float32"), shape=list[0,0,512,], ) 
 shape '[0, 0, 512]' is invalid for input of size 4294967296

W0211 18:07:59.269328 44586 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:07:59.270437 44586 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([32, 4, 33554432],"float32"), shape=list[0,0,8,64,], )
[torch error] paddle.reshape(x=Tensor([32, 4, 33554432],"float32"), shape=list[0,0,8,64,], ) 
 shape '[0, 0, 8, 64]' is invalid for input of size 4294967296

W0211 18:09:18.272468 46458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:09:18.273841 46458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([32, 4, 524288, 64],"float32"), shape=list[0,0,512,], )
[torch error] paddle.reshape(x=Tensor([32, 4, 524288, 64],"float32"), shape=list[0,0,512,], ) 
 shape '[0, 0, 512]' is invalid for input of size 4294967296

W0211 18:10:31.716041 48073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:10:31.717324 48073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([32, 4, 8, 4194304],"float32"), shape=list[0,0,512,], )
[torch error] paddle.reshape(x=Tensor([32, 4, 8, 4194304],"float32"), shape=list[0,0,512,], ) 
 shape '[0, 0, 512]' is invalid for input of size 4294967296

W0211 18:11:41.639613 49648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:11:41.640748 49648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([4, 1073741824],"float32"), shape=list[36,], )
[torch error] paddle.reshape(x=Tensor([4, 1073741824],"float32"), shape=list[36,], ) 
 shape '[36]' is invalid for input of size 4294967296

W0211 18:12:53.718703 51201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:12:53.719645 51201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([4294967295, 1],"float32"), shape=list[10,], )
[torch error] paddle.reshape(x=Tensor([4294967295, 1],"float32"), shape=list[10,], ) 
 shape '[10]' is invalid for input of size 4294967295

W0211 18:14:04.317544 53195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:14:04.318742 53195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([4294967295],"float32"), shape=list[10,], )
[torch error] paddle.reshape(x=Tensor([4294967295],"float32"), shape=list[10,], ) 
 shape '[10]' is invalid for input of size 4294967295

W0211 18:15:20.289279 54507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:15:20.290439 54507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([4294967295],"float32"), shape=list[8,], )
[torch error] paddle.reshape(x=Tensor([4294967295],"float32"), shape=list[8,], ) 
 shape '[8]' is invalid for input of size 4294967295

W0211 18:16:36.429936 56075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:16:36.431056 56075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([429496730, 1, 10],"float32"), shape=list[5,10,], )
[torch error] paddle.reshape(x=Tensor([429496730, 1, 10],"float32"), shape=list[5,10,], ) 
 shape '[5, 10]' is invalid for input of size 4294967300

W0211 18:17:57.065629 57654 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:17:57.066797 57654 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([429496730, 1, 10],"int32"), shape=list[5,10,], )
[torch error] paddle.reshape(x=Tensor([429496730, 1, 10],"int32"), shape=list[5,10,], ) 
 shape '[5, 10]' is invalid for input of size 4294967300

W0211 18:19:10.224712 59508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:19:10.225884 59508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([429496730, 1, 10],"uint8"), shape=list[5,10,], )
[torch error] paddle.reshape(x=Tensor([429496730, 1, 10],"uint8"), shape=list[5,10,], ) 
 shape '[5, 10]' is invalid for input of size 4294967300

W0211 18:20:18.836946 60813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:20:18.838092 60813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([429496730, 10],"float32"), shape=list[100,], )
[torch error] paddle.reshape(x=Tensor([429496730, 10],"float32"), shape=list[100,], ) 
 shape '[100]' is invalid for input of size 4294967300

W0211 18:21:31.229902 62386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:21:31.231125 62386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([429496730, 10],"float32"), shape=list[200,], )
[torch error] paddle.reshape(x=Tensor([429496730, 10],"float32"), shape=list[200,], ) 
 shape '[200]' is invalid for input of size 4294967300

W0211 18:22:41.922291 63992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:22:41.923656 63992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([429496730, 10],"float32"), shape=list[80,], )
[torch error] paddle.reshape(x=Tensor([429496730, 10],"float32"), shape=list[80,], ) 
 shape '[80]' is invalid for input of size 4294967300

W0211 18:23:59.761883 65293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:23:59.762936 65293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([477218589, 9],"float32"), shape=list[36,], )
[torch error] paddle.reshape(x=Tensor([477218589, 9],"float32"), shape=list[36,], ) 
 shape '[36]' is invalid for input of size 4294967301

W0211 18:25:17.581439 67164 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:25:17.582504 67164 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([5, 1, 858993459],"float32"), shape=list[5,10,], )
[torch error] paddle.reshape(x=Tensor([5, 1, 858993459],"float32"), shape=list[5,10,], ) 
 shape '[5, 10]' is invalid for input of size 4294967295

W0211 18:26:37.208743 68780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:26:37.210510 68780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([5, 1, 858993459],"int32"), shape=list[5,10,], )
[torch error] paddle.reshape(x=Tensor([5, 1, 858993459],"int32"), shape=list[5,10,], ) 
 shape '[5, 10]' is invalid for input of size 4294967295

W0211 18:27:47.887259 70362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:27:47.888589 70362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([5, 1, 858993459],"uint8"), shape=list[5,10,], )
[torch error] paddle.reshape(x=Tensor([5, 1, 858993459],"uint8"), shape=list[5,10,], ) 
 shape '[5, 10]' is invalid for input of size 4294967295

W0211 18:28:56.925741 71937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:28:56.927186 71937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([5, 85899346, 10],"float32"), shape=list[5,10,], )
[torch error] paddle.reshape(x=Tensor([5, 85899346, 10],"float32"), shape=list[5,10,], ) 
 shape '[5, 10]' is invalid for input of size 4294967300

W0211 18:30:15.413570 73680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:30:15.414517 73680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([5, 85899346, 10],"int32"), shape=list[5,10,], )
[torch error] paddle.reshape(x=Tensor([5, 85899346, 10],"int32"), shape=list[5,10,], ) 
 shape '[5, 10]' is invalid for input of size 4294967300

W0211 18:31:31.931684 75452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:31:31.932888 75452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([5, 85899346, 10],"uint8"), shape=list[5,10,], )
[torch error] paddle.reshape(x=Tensor([5, 85899346, 10],"uint8"), shape=list[5,10,], ) 
 shape '[5, 10]' is invalid for input of size 4294967300

W0211 18:32:38.008463 77037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:32:38.009452 77037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([536870912, 8, 1],"float32"), shape=list[2,8,], )
[torch error] paddle.reshape(x=Tensor([536870912, 8, 1],"float32"), shape=list[2,8,], ) 
 shape '[2, 8]' is invalid for input of size 4294967296

W0211 18:34:21.606178 78325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:34:21.621110 78325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([536870912, 8],"float32"), shape=list[80,], )
[torch error] paddle.reshape(x=Tensor([536870912, 8],"float32"), shape=list[80,], ) 
 shape '[80]' is invalid for input of size 4294967296

W0211 18:35:41.201612 80978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:35:41.203828 80978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([58, 140, 2, 264469],"float32"), shape=list[0,0,2,], )
[torch error] paddle.reshape(x=Tensor([58, 140, 2, 264469],"float32"), shape=list[0,0,2,], ) 
 shape '[0, 0, 2]' is invalid for input of size 4294976560

W0211 18:37:00.859122 82330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:37:00.860433 82330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([58, 140, 528937, 1],"float32"), shape=list[0,0,2,], )
[torch error] paddle.reshape(x=Tensor([58, 140, 528937, 1],"float32"), shape=list[0,0,2,], ) 
 shape '[0, 0, 2]' is invalid for input of size 4294968440

W0211 18:38:11.907804 84199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:38:11.909011 84199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([58, 140, 528937],"float32"), shape=list[0,0,2,1,], )
[torch error] paddle.reshape(x=Tensor([58, 140, 528937],"float32"), shape=list[0,0,2,1,], ) 
 shape '[0, 0, 2, 1]' is invalid for input of size 4294968440

W0211 18:39:31.586674 85505 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:39:31.588006 85505 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([58, 140, 528937],"float32"), shape=list[-1,2,], )
[Pass] paddle.reshape(x=Tensor([58, 140, 528937],"float32"), shape=list[-1,2,], )

W0211 18:40:51.991930 87337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:40:51.992928 87337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([58, 37025581, 2, 1],"float32"), shape=list[0,0,2,], )
[torch error] paddle.reshape(x=Tensor([58, 37025581, 2, 1],"float32"), shape=list[0,0,2,], ) 
 shape '[0, 0, 2]' is invalid for input of size 4294967396

W0211 18:44:29.933861 92038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:44:29.935153 92038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([58, 37025581, 2],"float32"), shape=list[0,0,2,1,], )
[torch error] paddle.reshape(x=Tensor([58, 37025581, 2],"float32"), shape=list[0,0,2,1,], ) 
 shape '[0, 0, 2, 1]' is invalid for input of size 4294967396

W0211 18:45:48.069902 93580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:45:48.071017 93580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([58, 37025581, 2],"float32"), shape=list[-1,2,], )
[Pass] paddle.reshape(x=Tensor([58, 37025581, 2],"float32"), shape=list[-1,2,], )

W0211 18:47:03.593592 95162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:47:03.594807 95162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reshape(x=Tensor([8, 536870912],"float32"), shape=list[80,], )
[torch error] paddle.reshape(x=Tensor([8, 536870912],"float32"), shape=list[80,], ) 
 shape '[80]' is invalid for input of size 4294967296

W0211 18:50:35.175382 99755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:50:35.176573 99755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([1431655765, 3],"bool"), shifts=1, )
[Pass] paddle.roll(Tensor([1431655765, 3],"bool"), shifts=1, )

W0211 18:51:49.785027 101063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:51:49.786108 101063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([1431655765, 3],"bool"), shifts=1, axis=0, )
[Pass] paddle.roll(Tensor([1431655765, 3],"bool"), shifts=1, axis=0, )

W0211 18:54:03.505986 104203 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:54:03.506894 104203 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([1431655765, 3],"float32"), 1, )
[Pass] paddle.roll(Tensor([1431655765, 3],"float32"), 1, )

W0211 18:56:17.220362 106706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:56:17.221309 106706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([2, 2147483648],"float32"), 1, )
[Pass] paddle.roll(Tensor([2, 2147483648],"float32"), 1, )

W0211 18:59:59.399776 110994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:59:59.400723 110994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([3, 1431655765],"bool"), shifts=1, )
[Pass] paddle.roll(Tensor([3, 1431655765],"bool"), shifts=1, )

W0211 19:04:13.702101 116600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:04:13.702975 116600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([3, 1431655765],"bool"), shifts=1, axis=0, )
[Pass] paddle.roll(Tensor([3, 1431655765],"bool"), shifts=1, axis=0, )

W0211 19:06:23.952991 119143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:06:23.953899 119143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([3, 3],"int64"), shifts=Tensor([2147483649],"int64"), axis=list[0,1,], )
[torch error] paddle.roll(Tensor([3, 3],"int64"), shifts=Tensor([2147483649],"int64"), axis=list[0,1,], ) 
 roll(): argument 'shifts' must be tuple of ints, not Tensor

W0211 19:08:08.804141 122352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:08:08.805284 122352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([3, 715827883],"float64"), shifts=1, )
[Pass] paddle.roll(Tensor([3, 715827883],"float64"), shifts=1, )

W0211 19:09:10.319221 123319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:09:10.320207 123319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([3, 715827883],"float64"), shifts=1, axis=0, )
[Pass] paddle.roll(Tensor([3, 715827883],"float64"), shifts=1, axis=0, )

W0211 19:12:01.269793 127099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:12:01.270720 127099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([3, 715827883],"int64"), shifts=Tensor([2],"int64"), axis=list[0,1,], )
[torch error] paddle.roll(Tensor([3, 715827883],"int64"), shifts=Tensor([2],"int64"), axis=list[0,1,], ) 
 roll(): argument 'shifts' must be tuple of ints, not Tensor

W0211 19:14:46.508548 130855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:14:46.509680 130855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([715827883, 3],"float64"), shifts=1, )
[Pass] paddle.roll(Tensor([715827883, 3],"float64"), shifts=1, )

W0211 19:15:48.105043 131848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:15:48.106310 131848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([715827883, 3],"float64"), shifts=1, axis=0, )
[Pass] paddle.roll(Tensor([715827883, 3],"float64"), shifts=1, axis=0, )

W0211 19:19:10.315605 136567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:19:10.316486 136567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.roll(Tensor([715827883, 3],"int64"), shifts=Tensor([2],"int64"), axis=list[0,1,], )
[torch error] paddle.roll(Tensor([715827883, 3],"int64"), shifts=Tensor([2],"int64"), axis=list[0,1,], ) 
 roll(): argument 'shifts' must be tuple of ints, not Tensor

W0211 19:21:52.285302 140060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:21:52.286551 140060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rot90(Tensor([1431655765, 3],"float32"), k=1, axes=list[0,1,], )
[Pass] paddle.rot90(Tensor([1431655765, 3],"float32"), k=1, axes=list[0,1,], )

W0211 19:23:21.291685 141295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:23:21.292536 141295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rot90(Tensor([2, 2147483648],"float32"), k=1, axes=list[0,1,], )
[Pass] paddle.rot90(Tensor([2, 2147483648],"float32"), k=1, axes=list[0,1,], )

W0211 19:27:07.173071 145777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:27:07.173961 145777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 2 in the list.

W0211 19:31:32.632594 152318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:31:32.633797 152318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 2 in the list.

W0211 19:32:20.572829 153288 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:32:20.574054 153288 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 2 in the list.

W0211 19:33:13.636126 154520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:33:13.637214 154520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], )

W0211 19:34:12.755009 155486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:34:12.755978 155486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 1 in the list.

W0211 19:37:00.134671 159021 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:37:00.135932 159021 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 1 in the list.

W0211 19:37:48.763808 160245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:37:48.764900 160245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 1 in the list.

W0211 19:38:41.219426 161231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:38:41.220652 161231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )

W0211 19:39:43.069626 162217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:39:43.070554 162217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),], )

W0211 19:42:37.304315  2516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:42:37.305181  2516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0211 19:45:20.284226  6248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:45:20.285352  6248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 147268 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 19:47:26.771128  7163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:47:26.772181  7163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 2 in the list.

W0211 19:48:18.284161  9991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:48:18.285243  9991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 2 in the list.

W0211 19:49:09.906504 10957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:49:09.907771 10957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], )

W0211 19:50:03.285516 11926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:50:03.286485 11926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 1 in the list.

W0211 19:52:44.188740 15653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:52:44.189846 15653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 1 in the list.

W0211 19:53:34.699397 16592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:53:34.700815 16592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )

W0211 19:54:30.071058 17556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:54:30.072165 17556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),], )

W0211 19:57:30.056267 21329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:57:30.057173 21329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0211 20:00:34.204507 25156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:00:34.205667 25156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 118712 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 20:02:49.453954 26548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:02:49.455057 26548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 2147483649],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 1, 2147483649],"float64"),], )

W0211 20:03:45.130151 29389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:03:45.130982 29389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0211 20:06:50.429824 33427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:06:50.430846 33427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 101646 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 20:08:54.435091 34384 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:08:54.436204 34384 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 2 in the list.

W0211 20:09:46.721746 37198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:09:46.722961 37198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),], )

W0211 20:10:40.616834 38167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:10:40.617894 38167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 1 in the list.

W0211 20:13:27.944833 41667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:13:27.946063 41667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),], )

W0211 20:14:23.717272 42895 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:14:23.718187 42895 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),], )

W0211 20:17:15.341889 46350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:17:15.342808 46350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0211 20:20:22.413655 49806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:20:22.415222 49806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 122840 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 20:22:36.322198 51855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:22:36.323350 51855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 2147483649, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 2147483649, 1],"float64"),], )

W0211 20:23:39.638276 54605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:23:39.639600 54605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0211 20:26:28.014500 58358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:26:28.015980 58358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 74457 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 20:28:57.964915 59580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:28:57.966039 59580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 2147483649],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1, 2147483649],"float64"),], )

W0211 20:29:56.187004 62702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:29:56.187992 62702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0211 20:32:40.932350 66392 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:32:40.933992 66392 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 24261 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 20:34:48.693914 67083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:34:48.694952 67083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1],"float64"),Tensor([1],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1],"float64"),Tensor([1],"float64"),Tensor([2147483649],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 2 in the list.

W0211 20:35:41.481088 69916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:35:41.482343 69916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),Tensor([1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),Tensor([1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2147483649 for tensor number 1 in the list.

W0211 20:36:29.455542 70878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:36:29.456673 70878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1073741825, 2],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1073741825, 2],"float64"),], )

W0211 20:37:33.404855 72108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:37:33.405908 72108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 53228 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 20:41:39.398590 76217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:41:39.399714 76217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], )

W0211 20:42:38.150887 78928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:42:38.151772 78928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2],"float64"),Tensor([1, 2147483649],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([2],"float64"),Tensor([1, 2147483649],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 2147483649 for tensor number 1 in the list.

W0211 20:45:24.655103 82646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:45:24.656222 82646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2],"float64"),Tensor([1073741825, 2],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([2],"float64"),Tensor([1073741825, 2],"float64"),], )

W0211 20:46:22.103845 83890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:46:22.104962 83890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),], )

W0211 20:49:20.576822 87623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:49:20.577791 87623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )

W0211 20:52:19.252722 91096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:52:19.253811 91096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 9329 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 20:56:29.205718 94885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:56:29.206869 94885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649, 1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([2147483649, 1, 1],"float64"),], )

W0211 20:57:24.817087 97686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:57:24.817986 97686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )

W0211 21:00:20.498138 101389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:00:20.499022 101389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 110359 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 21:04:38.607983 105147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:04:38.609114 105147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([2147483649, 1],"float64"),], )

W0211 21:05:38.672420 107692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:05:38.673360 107692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], )

W0211 21:08:36.332407 111416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:08:36.333433 111416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 51759 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 21:12:44.151293 115173 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:12:44.152293 115173 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([2147483649],"float64"),], )

W0211 21:13:47.375909 117973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:13:47.377182 117973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649],"float64"),Tensor([1, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([2147483649],"float64"),Tensor([1, 2],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2147483649 but got size 2 for tensor number 1 in the list.

W0211 21:16:51.820706 122415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:16:51.821826 122415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649],"float64"),Tensor([1],"float64"),Tensor([1],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([2147483649],"float64"),Tensor([1],"float64"),Tensor([1],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0211 21:17:42.507432 123673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:17:42.508754 123673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 77483 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 21:19:55.072193 124368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:19:55.073312 124368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([2147483649],"float64"),Tensor([5],"float64"),Tensor([5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([2147483649],"float64"),Tensor([5],"float64"),Tensor([5],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2147483649 but got size 5 for tensor number 1 in the list.

W0211 21:20:49.280478 127472 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:20:49.281649 127472 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([268435457, 4, 2],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([268435457, 4, 2],"float64"),], )

W0211 21:21:49.008599 128419 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:21:49.009719 128419 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 55278 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 21:25:59.366034 132225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:25:59.367169 132225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )

W0211 21:26:57.024972 135316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:26:57.025938 135316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),], )

W0211 21:29:48.737524 138639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:29:48.738474 138639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),], )

W0211 21:32:48.771835 141635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:32:48.772684 141635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 715827883 for tensor number 2 in the list.

W0211 21:35:49.743276 145202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:35:49.744577 145202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 715827883 for tensor number 1 in the list.

W0211 21:36:46.874294 146035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:36:46.875836 146035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 357913942, 2],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 357913942, 2],"float64"),], )

W0211 21:37:50.639671 147163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:37:50.641299 147163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 130443 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 21:42:02.648147 150713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:42:02.649128 150713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 357913942 but got size 4 for tensor number 1 in the list.

W0211 21:43:00.433277 152899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:43:00.434370 152899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 178956971],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 4, 178956971],"float64"),], )

W0211 21:44:12.875098 153990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:44:12.876060 153990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 8329 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 21:49:06.577481 158339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:49:06.578440 158339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 178956971 but got size 2 for tensor number 1 in the list.

W0211 21:49:59.428550 160548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:49:59.429777 160548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 5 but got size 89478486 for tensor number 2 in the list.

W0211 21:50:48.557287 161639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:50:48.558413 161639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 35791395 for tensor number 2 in the list.

W0211 21:51:37.077005 162452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:51:37.078259 162452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 71582789 for tensor number 2 in the list.

W0211 21:52:28.921936 163291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:52:28.923111 163291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], )

W0211 21:53:23.279321   878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:53:23.280079   878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 5 but got size 89478486 for tensor number 1 in the list.

W0211 21:56:09.897887  4180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:56:09.899020  4180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 35791395 for tensor number 1 in the list.

W0211 21:57:02.496703  4762 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:57:02.497937  4762 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 71582789 for tensor number 1 in the list.

W0211 21:57:56.854030  5857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:57:56.855177  5857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )

W0211 21:58:54.513741  6961 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:58:54.514647  6961 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 89478486],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 4, 2, 89478486],"float64"),], )

W0211 22:02:33.195089 10794 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:02:33.195957 10794 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 89478486 but got size 5 for tensor number 1 in the list.

W0211 22:06:00.721556 14632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:06:00.722592 14632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 132218 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 22:07:58.750702 15748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:07:58.751827 15748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )

W0211 22:08:55.537319 17931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:08:55.538168 17931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 357913942 for tensor number 1 in the list.

W0211 22:12:09.323230 21490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:12:09.324481 21490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 178956971 for tensor number 1 in the list.

W0211 22:12:59.904134 22363 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:12:59.905400 22363 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], )

W0211 22:13:52.604306 23443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:13:52.605654 23443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 357913942 for tensor number 2 in the list.

W0211 22:16:58.971099 26875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:16:58.972298 26875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 178956971 for tensor number 2 in the list.

W0211 22:17:51.291913 27980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:17:51.293164 27980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 35791395, 5],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 4, 35791395, 5],"float64"),], )

W0211 22:18:49.900702 29098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:18:49.901515 29098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 35791395 but got size 2 for tensor number 1 in the list.

W0211 22:21:57.427920 32905 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:21:57.429031 32905 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 29385 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 22:24:13.719166 34169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:24:13.727702 34169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 715827883],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 715827883],"float64"),], )

W0211 22:25:17.933182 37009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:25:17.934216 37009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 715827883 but got size 2 for tensor number 1 in the list.

W0211 22:28:14.796901 41074 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:28:14.798185 41074 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 14458 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 22:30:24.110131 42062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:30:24.111169 42062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 71582789, 2, 5],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([3, 71582789, 2, 5],"float64"),], )

W0211 22:31:27.523998 44842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:31:27.525302 44842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 71582789 but got size 4 for tensor number 1 in the list.

W0211 22:34:19.211455 48613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:34:19.212806 48613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 153837 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 22:36:35.761234 49619 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:36:35.792361 49619 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 5 but got size 2147483649 for tensor number 1 in the list.

W0211 22:37:25.208909 52681 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:37:25.209916 52681 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 5 but got size 2147483649 for tensor number 2 in the list.

W0211 22:38:13.363961 54063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:38:13.365144 54063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([53687092, 4, 2, 5],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([53687092, 4, 2, 5],"float64"),], )

W0211 22:39:15.585026 55052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:39:15.586426 55052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[Pass] paddle.row_stack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )

W0211 22:42:23.704367 58887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:42:23.705432 58887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.row_stack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], )
[torch error] paddle.row_stack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 122752 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 22:47:00.873338 63269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:47:00.874361 63269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([1, 1, 4294967295],"float32"), )
[Pass] paddle.rsqrt(Tensor([1, 1, 4294967295],"float32"), )

W0211 22:48:22.282996 66088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:48:22.283859 66088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([1, 1048576, 4096],"float32"), )
[Pass] paddle.rsqrt(Tensor([1, 1048576, 4096],"float32"), )

W0211 22:52:42.370342 71691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:52:42.371228 71691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([1, 300, 14316558],"float32"), )
[Pass] paddle.rsqrt(Tensor([1, 300, 14316558],"float32"), )

W0211 22:56:23.789372 76383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:56:23.790598 76383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([1, 4294967295, 1],"float32"), )
[Pass] paddle.rsqrt(Tensor([1, 4294967295, 1],"float32"), )

W0211 23:00:07.813985 81299 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:00:07.814857 81299 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([10000, 143166, 3],"float32"), )
[Pass] paddle.rsqrt(Tensor([10000, 143166, 3],"float32"), )

W0211 23:04:22.850997 86547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:04:22.852344 86547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([10000, 2, 107375],"float64"), )
[Pass] paddle.rsqrt(Tensor([10000, 2, 107375],"float64"), )

W0211 23:07:38.065461 91239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:07:38.066519 91239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([10000, 2, 214749],"float32"), )
[Pass] paddle.rsqrt(Tensor([10000, 2, 214749],"float32"), )

W0211 23:11:13.399274 95273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:11:13.400244 95273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([10000, 71583, 3],"float64"), )
[Pass] paddle.rsqrt(Tensor([10000, 71583, 3],"float64"), )

W0211 23:14:28.626411 99684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:14:28.627341 99684 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([1048576, 1, 4096],"float32"), )
[Pass] paddle.rsqrt(Tensor([1048576, 1, 4096],"float32"), )

W0211 23:17:47.530800 103427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:17:47.531683 103427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([1431655765, 3],"float32"), )
[Pass] paddle.rsqrt(Tensor([1431655765, 3],"float32"), )

W0211 23:21:19.156883 107786 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:21:19.157994 107786 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([14316558, 300, 1],"float32"), )
[Pass] paddle.rsqrt(Tensor([14316558, 300, 1],"float32"), )

W0211 23:25:13.658902 112478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:25:13.659793 112478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([16, 134217729],"float64"), )
[Pass] paddle.rsqrt(Tensor([16, 134217729],"float64"), )

W0211 23:28:35.325840 117179 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:28:35.326719 117179 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([16, 268435456],"float32"), )
[Pass] paddle.rsqrt(Tensor([16, 268435456],"float32"), )

W0211 23:31:57.796979 121127 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:31:57.797995 121127 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([2, 1073741825],"float64"), )
[Pass] paddle.rsqrt(Tensor([2, 1073741825],"float64"), )

W0211 23:35:06.970760 125615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:35:06.971642 125615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([2, 2147483648],"float16"), )
[Pass] paddle.rsqrt(Tensor([2, 2147483648],"float16"), )

W0211 23:38:36.639245 129318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:38:36.640311 129318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([2, 2147483648],"float32"), )
[Pass] paddle.rsqrt(Tensor([2, 2147483648],"float32"), )

W0211 23:47:47.457381 140903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:47:47.458251 140903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([2147483649, 1],"float64"), )
[Pass] paddle.rsqrt(Tensor([2147483649, 1],"float64"), )

W0211 23:51:06.065488 145906 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:51:06.066548 145906 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([32, 134217728],"float16"), )
[Pass] paddle.rsqrt(Tensor([32, 134217728],"float16"), )

W0211 23:54:26.974049 149662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:54:26.974928 149662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([32, 134217728],"float32"), )
[Pass] paddle.rsqrt(Tensor([32, 134217728],"float32"), )

W0212 00:03:13.767624 160859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:03:13.768862 160859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([357913942, 2, 3],"float64"), )
[Pass] paddle.rsqrt(Tensor([357913942, 2, 3],"float64"), )

W0212 00:06:37.646095  1784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:06:37.647065  1784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([4294967295, 1],"float16"), )
[Pass] paddle.rsqrt(Tensor([4294967295, 1],"float16"), )

W0212 00:10:30.220275  6145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:10:30.221083  6145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([4294967295, 1],"float32"), )
[Pass] paddle.rsqrt(Tensor([4294967295, 1],"float32"), )

W0212 00:19:08.982064 17362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:19:08.982987 17362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([4294967295],"float32"), )
[Pass] paddle.rsqrt(Tensor([4294967295],"float32"), )

W0212 00:22:53.081374 21740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:22:53.082384 21740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([715827883, 2, 3],"float32"), )
[Pass] paddle.rsqrt(Tensor([715827883, 2, 3],"float32"), )

W0212 00:26:26.836982 26296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:26:26.837863 26296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rsqrt(Tensor([715827883, 3],"float64"), )
[Pass] paddle.rsqrt(Tensor([715827883, 3],"float64"), )

W0212 00:29:35.782617 30662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:29:35.783497 30662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([11930465, 3, 4, 5, 6],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([11930465, 3, 4, 5, 6],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 3, 5, 6], slice size = [11930465, 3, 5, 6]

W0212 00:32:48.330708 34341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:32:48.331684 34341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 17895698, 4, 5, 6],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 17895698, 4, 5, 6],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 3, 5, 6], slice size = [2, 17895698, 5, 6]

W0212 00:33:58.808490 35900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:33:58.809671 35900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 23860930, 5, 6],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, )
[Pass] paddle.select_scatter(Tensor([2, 3, 23860930, 5, 6],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, )

W0212 00:35:17.348465 37459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:35:17.349287 37459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4, 29826162, 6],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4, 29826162, 6],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 3, 5, 6], slice size = [2, 3, 29826162, 6]

W0212 00:39:38.320732 43088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:39:38.321979 43088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 35791395],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4, 5, 35791395],"int32"), Tensor([2, 3, 5, 6],"int32"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 3, 5, 6], slice size = [2, 3, 5, 35791395]

W0212 00:40:56.405143 44352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:40:56.406087 44352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 6],"int32"), Tensor([2, 3, 119304648, 6],"int32"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4, 5, 6],"int32"), Tensor([2, 3, 119304648, 6],"int32"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 3, 119304648, 6], slice size = [2, 3, 5, 6]

W0212 00:42:04.767393 46170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:42:04.768464 46170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 6],"int32"), Tensor([2, 3, 5, 143165577],"int32"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4, 5, 6],"int32"), Tensor([2, 3, 5, 143165577],"int32"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 3, 5, 143165577], slice size = [2, 3, 5, 6]

W0212 00:43:12.666590 47444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:43:12.667783 47444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 6],"int32"), Tensor([2, 71582789, 5, 6],"int32"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4, 5, 6],"int32"), Tensor([2, 71582789, 5, 6],"int32"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 71582789, 5, 6], slice size = [2, 3, 5, 6]

W0212 00:44:21.634871 48717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:44:21.635963 48717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4, 5, 6],"int32"), Tensor([47721859, 3, 5, 6],"int32"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4, 5, 6],"int32"), Tensor([47721859, 3, 5, 6],"int32"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [47721859, 3, 5, 6], slice size = [2, 3, 5, 6]

W0212 00:45:34.266541 50748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:45:34.268059 50748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4, 5],"float64"), Tensor([143165577, 3, 5],"float64"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4, 5],"float64"), Tensor([143165577, 3, 5],"float64"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [143165577, 3, 5], slice size = [2, 3, 5]

W0212 00:46:22.710078 52051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:46:22.711203 52051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 214748365, 5],"float64"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 214748365, 5],"float64"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 214748365, 5], slice size = [2, 3, 5]

W0212 00:47:13.995612 53449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:47:13.997258 53449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 357913942],"float64"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 357913942],"float64"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 3, 357913942], slice size = [2, 3, 5]

W0212 00:48:03.171415 54396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:48:03.172469 54396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 5],"float64"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 5],"float64"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 3, 5], slice size = [2, 3, 89478486]

W0212 00:49:00.053510 55353 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:49:00.056195 55353 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4],"float32"), Tensor([1073741824, 4],"float32"), 1, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4],"float32"), Tensor([1073741824, 4],"float32"), 1, 1, ) 
 expected src to have a size equal to the slice of self. src size = [1073741824, 4], slice size = [2, 4]

W0212 00:50:15.759351 56620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:50:15.760517 56620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 4],"float32"), Tensor([2, 2147483648],"float32"), 1, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 4],"float32"), Tensor([2, 2147483648],"float32"), 1, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 2147483648], slice size = [2, 4]

W0212 00:51:26.450855 58192 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:51:26.451961 58192 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 715827883],"float32"), Tensor([2, 4],"float32"), 1, 1, )
[torch error] paddle.select_scatter(Tensor([2, 3, 715827883],"float32"), Tensor([2, 4],"float32"), 1, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 4], slice size = [2, 715827883]

W0212 00:52:51.769601 59732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:52:51.770923 59732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 5],"float64"), 2, 1, )
[Pass] paddle.select_scatter(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 5],"float64"), 2, 1, )

W0212 00:53:53.916064 61328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:53:53.917044 61328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 536870912, 4],"float32"), Tensor([2, 4],"float32"), 1, 1, )
[Pass] paddle.select_scatter(Tensor([2, 536870912, 4],"float32"), Tensor([2, 4],"float32"), 1, 1, )

W0212 00:57:17.308748 65308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:57:17.309695 65308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 3, 5],"float64"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 3, 5],"float64"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 3, 5], slice size = [2, 53687092, 5]

W0212 01:00:25.738056 69301 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:00:25.739887 69301 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([357913942, 3, 4],"float32"), Tensor([2, 4],"float32"), 1, 1, )
[torch error] paddle.select_scatter(Tensor([357913942, 3, 4],"float32"), Tensor([2, 4],"float32"), 1, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 4], slice size = [357913942, 4]

W0212 01:01:44.121949 70412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:01:44.122931 70412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.select_scatter(Tensor([35791395, 3, 4, 5],"float64"), Tensor([2, 3, 5],"float64"), 2, 1, )
[torch error] paddle.select_scatter(Tensor([35791395, 3, 4, 5],"float64"), Tensor([2, 3, 5],"float64"), 2, 1, ) 
 expected src to have a size equal to the slice of self. src size = [2, 3, 5], slice size = [35791395, 3, 5]

W0212 01:02:35.484476 71507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:02:35.485699 71507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sgn(Tensor([107374183, 20, 2],"float16"), )
[Pass] paddle.sgn(Tensor([107374183, 20, 2],"float16"), )

W0212 01:04:10.871517 72598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:04:10.872455 72598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sgn(Tensor([107374183, 20, 2],"float32"), )
[Pass] paddle.sgn(Tensor([107374183, 20, 2],"float32"), )

W0212 01:13:12.216784 83112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:13:12.218277 83112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sgn(Tensor([12, 178956971, 2],"float16"), )
[Pass] paddle.sgn(Tensor([12, 178956971, 2],"float16"), )

W0212 01:17:13.836771 87163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:17:13.837796 87163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sgn(Tensor([12, 178956971, 2],"float32"), )
[Pass] paddle.sgn(Tensor([12, 178956971, 2],"float32"), )

W0212 01:26:13.503959 90442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:26:13.504840 90442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sgn(Tensor([12, 20, 17895698],"float16"), )
[Pass] paddle.sgn(Tensor([12, 20, 17895698],"float16"), )

W0212 01:30:22.821540 90471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:30:22.822517 90471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sgn(Tensor([12, 20, 17895698],"float32"), )
[Pass] paddle.sgn(Tensor([12, 20, 17895698],"float32"), )

W0212 01:39:14.509753 90554 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:39:14.510726 90554 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sgn(Tensor([12, 20, 8947849],"float64"), )
[Pass] paddle.sgn(Tensor([12, 20, 8947849],"float64"), )

W0212 01:42:48.327570 90609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:42:48.328513 90609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sgn(Tensor([12, 89478486, 2],"float64"), )
[Pass] paddle.sgn(Tensor([12, 89478486, 2],"float64"), )

W0212 01:45:51.305179 90638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:45:51.306015 90638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sgn(Tensor([53687092, 20, 2],"float64"), )
[Pass] paddle.sgn(Tensor([53687092, 20, 2],"float64"), )

W0212 01:49:06.956800 90667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:49:06.957795 90667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([1, 4294967295],"float32"), )
[Pass] paddle.sign(Tensor([1, 4294967295],"float32"), )

W0212 01:52:25.832085 90709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:52:25.833562 90709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([1048576, 32, 128],"float32"), )
[Pass] paddle.sign(Tensor([1048576, 32, 128],"float32"), )

W0212 01:56:31.516911 90751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:56:31.517947 90751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([1073741824, 4],"float32"), )
[Pass] paddle.sign(Tensor([1073741824, 4],"float32"), )

W0212 02:00:36.290290 90793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:00:36.291596 90793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([107374183, 20, 2],"float16"), )
[Pass] paddle.sign(Tensor([107374183, 20, 2],"float16"), )

W0212 02:04:26.918675 90875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:04:26.919530 90875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([107374183, 20, 2],"float32"), )
[Pass] paddle.sign(Tensor([107374183, 20, 2],"float32"), )

W0212 02:13:17.857116 91016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:13:17.857962 91016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([107374183, 20, 2],"int16"), )
[Pass] paddle.sign(Tensor([107374183, 20, 2],"int16"), )

W0212 02:16:56.883560 91045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:16:56.884833 91045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([107374183, 20, 2],"int32"), )
[Pass] paddle.sign(Tensor([107374183, 20, 2],"int32"), )

W0212 02:20:54.883677 91115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:20:54.884508 91115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([107374183, 20, 2],"int8"), )
[Pass] paddle.sign(Tensor([107374183, 20, 2],"int8"), )

W0212 02:25:21.803143 91156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:25:21.803974 91156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([107374183, 20, 2],"uint8"), )
[Pass] paddle.sign(Tensor([107374183, 20, 2],"uint8"), )

W0212 02:28:58.943248 91226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:28:58.944272 91226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([10737419, 400],"float32"), )
[Pass] paddle.sign(Tensor([10737419, 400],"float32"), )

W0212 02:33:01.972208 91269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:33:01.973345 91269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([11, 17, 22967740],"int16"), )
[Pass] paddle.sign(Tensor([11, 17, 22967740],"int16"), )

W0212 02:37:01.159703 91338 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:37:01.161175 91338 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([11, 17, 22967740],"int32"), )
[Pass] paddle.sign(Tensor([11, 17, 22967740],"int32"), )

W0212 02:41:20.997311 91409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:41:20.998178 91409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([11, 390451573],"float32"), )
[Pass] paddle.sign(Tensor([11, 390451573],"float32"), )

W0212 02:45:50.979723 91465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:45:50.980682 91465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([11, 39045158, 10],"int16"), )
[Pass] paddle.sign(Tensor([11, 39045158, 10],"int16"), )

W0212 02:49:24.321683 91520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:49:24.322571 91520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([11, 39045158, 10],"int32"), )
[Pass] paddle.sign(Tensor([11, 39045158, 10],"int32"), )

W0212 02:53:31.117990 91589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:53:31.119668 91589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 178956971, 2],"float16"), )
[Pass] paddle.sign(Tensor([12, 178956971, 2],"float16"), )

W0212 02:58:26.595897 91674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:58:26.596880 91674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 178956971, 2],"float32"), )
[Pass] paddle.sign(Tensor([12, 178956971, 2],"float32"), )

W0212 03:07:31.074501 91799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:07:31.075297 91799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 178956971, 2],"int16"), )
[Pass] paddle.sign(Tensor([12, 178956971, 2],"int16"), )

W0212 03:12:14.129223 91854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:12:14.130475 91854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 178956971, 2],"int32"), )
[Pass] paddle.sign(Tensor([12, 178956971, 2],"int32"), )

W0212 03:16:22.664601 91926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:16:22.665472 91926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 178956971, 2],"int8"), )
[Pass] paddle.sign(Tensor([12, 178956971, 2],"int8"), )

W0212 03:20:38.055410 91983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:20:38.056468 91983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 178956971, 2],"uint8"), )
[Pass] paddle.sign(Tensor([12, 178956971, 2],"uint8"), )

W0212 03:24:33.645692 92025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:24:33.646696 92025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 20, 17895698],"float16"), )
[Pass] paddle.sign(Tensor([12, 20, 17895698],"float16"), )

W0212 03:28:51.553369 92067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:28:51.554282 92067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 20, 17895698],"float32"), )
[Pass] paddle.sign(Tensor([12, 20, 17895698],"float32"), )

W0212 03:37:47.915946 92206 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:37:47.916978 92206 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 20, 17895698],"int16"), )
[Pass] paddle.sign(Tensor([12, 20, 17895698],"int16"), )

W0212 03:41:25.663172 92263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:41:25.664073 92263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 20, 17895698],"int32"), )
[Pass] paddle.sign(Tensor([12, 20, 17895698],"int32"), )

W0212 03:45:48.351138 92346 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:45:48.352077 92346 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 20, 17895698],"int8"), )
[Pass] paddle.sign(Tensor([12, 20, 17895698],"int8"), )

W0212 03:50:22.461699 92430 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:50:22.462597 92430 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 20, 17895698],"uint8"), )
[Pass] paddle.sign(Tensor([12, 20, 17895698],"uint8"), )

W0212 03:54:02.790952 92487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:54:02.791826 92487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 20, 8947849],"float64"), )
[Pass] paddle.sign(Tensor([12, 20, 8947849],"float64"), )

W0212 03:57:47.658962 92556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:57:47.659865 92556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 20, 8947849],"int64"), )
[Pass] paddle.sign(Tensor([12, 20, 8947849],"int64"), )

W0212 04:01:09.437587 92626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:01:09.438493 92626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 89478486, 2],"float64"), )
[Pass] paddle.sign(Tensor([12, 89478486, 2],"float64"), )

W0212 04:04:26.252383 92697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:04:26.253235 92697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([12, 89478486, 2],"int64"), )
[Pass] paddle.sign(Tensor([12, 89478486, 2],"int64"), )

W0212 04:07:22.293393 92752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:07:22.294636 92752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([120, 35791395],"float32"), )
[Pass] paddle.sign(Tensor([120, 35791395],"float32"), )

W0212 04:10:53.942799 92835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:10:53.943953 92835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([1203073, 17, 5, 6, 7],"float16"), )
[Pass] paddle.sign(Tensor([1203073, 17, 5, 6, 7],"float16"), )

W0212 04:14:52.508749 92933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:14:52.509693 92933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([150, 28633116],"float32"), )
[Pass] paddle.sign(Tensor([150, 28633116],"float32"), )

W0212 04:23:46.609360 93144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:23:46.610921 93144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([16, 1, 28, 9586981],"float32"), )
[Pass] paddle.sign(Tensor([16, 1, 28, 9586981],"float32"), )

W0212 04:27:24.559618 93241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:27:24.560509 93241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([16, 1, 9586981, 28],"float32"), )
[Pass] paddle.sign(Tensor([16, 1, 9586981, 28],"float32"), )

W0212 04:30:58.433640 93326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:30:58.434607 93326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([16, 10737419, 5, 5],"float32"), )
[Pass] paddle.sign(Tensor([16, 10737419, 5, 5],"float32"), )

W0212 04:34:45.880689 93423 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:34:45.881578 93423 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([16, 1369569, 14, 14],"float32"), )
[Pass] paddle.sign(Tensor([16, 1369569, 14, 14],"float32"), )

W0212 04:38:21.032131 93508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:38:21.033077 93508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([16, 268435456],"float32"), )
[Pass] paddle.sign(Tensor([16, 268435456],"float32"), )

W0212 04:42:03.173091 93591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:42:03.174031 93591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([16, 342393, 28, 28],"float32"), )
[Pass] paddle.sign(Tensor([16, 342393, 28, 28],"float32"), )

W0212 04:45:49.113322 93689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:45:49.114226 93689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([16, 6, 14, 3195661],"float32"), )
[Pass] paddle.sign(Tensor([16, 6, 14, 3195661],"float32"), )

W0212 04:49:25.756291 93774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:49:25.757412 93774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([16, 6, 3195661, 14],"float32"), )
[Pass] paddle.sign(Tensor([16, 6, 3195661, 14],"float32"), )

W0212 04:53:13.871291 93885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:53:13.872332 93885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([16, 6, 5, 8947849],"float32"), )
[Pass] paddle.sign(Tensor([16, 6, 5, 8947849],"float32"), )

W0212 04:56:54.808652 93957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:56:54.809608 93957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([16, 6, 8947849, 5],"float32"), )
[Pass] paddle.sign(Tensor([16, 6, 8947849, 5],"float32"), )

W0212 05:00:28.456069 94053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:00:28.457800 94053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([2, 107374183, 4, 5],"int8"), )
[Pass] paddle.sign(Tensor([2, 107374183, 4, 5],"int8"), )

W0212 05:04:09.660127 94151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:04:09.661518 94151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([2, 3, 143165577, 5],"int8"), )
[Pass] paddle.sign(Tensor([2, 3, 143165577, 5],"int8"), )

W0212 05:07:59.828629 94249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:07:59.830307 94249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([2, 3, 4, 178956971],"int8"), )
[Pass] paddle.sign(Tensor([2, 3, 4, 178956971],"int8"), )

W0212 05:12:00.089223 94347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:12:00.090163 94347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([2, 3, 4, 89478486],"float64"), )
[Pass] paddle.sign(Tensor([2, 3, 4, 89478486],"float64"), )

W0212 05:16:06.718812 94418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:16:06.719841 94418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([2, 3, 71582789, 5],"float64"), )
[Pass] paddle.sign(Tensor([2, 3, 71582789, 5],"float64"), )

W0212 05:19:02.450790 94474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:19:02.452337 94474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([2, 53687092, 4, 5],"float64"), )
[Pass] paddle.sign(Tensor([2, 53687092, 4, 5],"float64"), )

W0212 05:22:12.271121 94543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:22:12.271978 94543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([2147483649],"float64"), )
[Pass] paddle.sign(Tensor([2147483649],"float64"), )

W0212 05:25:11.228462 94615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:25:11.229954 94615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([2147483649],"int64"), )
[Pass] paddle.sign(Tensor([2147483649],"int64"), )

W0212 05:28:13.701370 94685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:28:13.702626 94685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([252645135, 17],"float32"), )
[Pass] paddle.sign(Tensor([252645135, 17],"float32"), )

W0212 05:32:01.723886 94753 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:32:01.724864 94753 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([25264514, 17, 10],"int16"), )
[Pass] paddle.sign(Tensor([25264514, 17, 10],"int16"), )

W0212 05:35:26.720870 94852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:35:26.721868 94852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([25264514, 17, 10],"int32"), )
[Pass] paddle.sign(Tensor([25264514, 17, 10],"int32"), )

W0212 05:39:59.827637 94936 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:39:59.828744 94936 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([268435456, 16],"float32"), )
[Pass] paddle.sign(Tensor([268435456, 16],"float32"), )

W0212 05:45:59.652093 95034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:45:59.653074 95034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([28633116, 6, 5, 5],"float32"), )
[Pass] paddle.sign(Tensor([28633116, 6, 5, 5],"float32"), )

W0212 05:49:46.104709 95131 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:49:46.105566 95131 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([32, 1, 28, 4793491],"float32"), )
[Pass] paddle.sign(Tensor([32, 1, 28, 4793491],"float32"), )

W0212 05:53:23.890406 95216 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:53:23.891347 95216 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([32, 1, 4793491, 28],"float32"), )
[Pass] paddle.sign(Tensor([32, 1, 4793491, 28],"float32"), )

W0212 05:56:52.484661 95310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:56:52.485793 95310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([32, 1048576, 128],"float32"), )
[Pass] paddle.sign(Tensor([32, 1048576, 128],"float32"), )

W0212 06:00:59.515801 95398 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:00:59.516800 95398 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([32, 134217728],"float32"), )
[Pass] paddle.sign(Tensor([32, 134217728],"float32"), )

W0212 06:05:09.570781 95439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:05:09.571703 95439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([32, 171197, 28, 28],"float32"), )
[Pass] paddle.sign(Tensor([32, 171197, 28, 28],"float32"), )

W0212 06:10:05.456265 95523 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:10:05.457094 95523 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([32, 32, 4194304],"float32"), )
[Pass] paddle.sign(Tensor([32, 32, 4194304],"float32"), )

W0212 06:13:58.005244 95610 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:13:58.006201 95610 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([32, 6, 14, 1597831],"float32"), )
[Pass] paddle.sign(Tensor([32, 6, 14, 1597831],"float32"), )

W0212 06:17:45.510147 95708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:17:45.511011 95708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([32, 6, 1597831, 14],"float32"), )
[Pass] paddle.sign(Tensor([32, 6, 1597831, 14],"float32"), )

W0212 06:21:28.108873 95763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:21:28.109903 95763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([32, 684785, 14, 14],"float32"), )
[Pass] paddle.sign(Tensor([32, 684785, 14, 14],"float32"), )

W0212 06:25:09.757292 95806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:25:09.759184 95806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([35791395, 120],"float32"), )
[Pass] paddle.sign(Tensor([35791395, 120],"float32"), )

W0212 06:29:01.809294 95876 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:29:01.810688 95876 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([35791395, 3, 4, 5],"float64"), )
[Pass] paddle.sign(Tensor([35791395, 3, 4, 5],"float64"), )

W0212 06:32:21.083853 95933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:32:21.084801 95933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([3652184, 6, 14, 14],"float32"), )
[Pass] paddle.sign(Tensor([3652184, 6, 14, 14],"float32"), )

W0212 06:35:53.156466 96016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:35:53.157387 96016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([400, 10737419],"float32"), )
[Pass] paddle.sign(Tensor([400, 10737419],"float32"), )

W0212 06:39:34.804831 96077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:39:34.805902 96077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([4294967295],"uint8"), )
[Pass] paddle.sign(Tensor([4294967295],"uint8"), )

W0212 06:42:56.466955 96155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:42:56.468031 96155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([429496730, 10],"float32"), )
[Pass] paddle.sign(Tensor([429496730, 10],"float32"), )

W0212 06:47:15.836268 96212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:47:15.837288 96212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([477218589, 1, 3, 3],"float32"), )
[Pass] paddle.sign(Tensor([477218589, 1, 3, 3],"float32"), )

W0212 06:51:08.682543 96283 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:51:08.683543 96283 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([51130564, 84],"float32"), )
[Pass] paddle.sign(Tensor([51130564, 84],"float32"), )

W0212 06:55:12.952982 96380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:55:12.954072 96380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([53687092, 20, 2],"float64"), )
[Pass] paddle.sign(Tensor([53687092, 20, 2],"float64"), )

W0212 06:59:07.737102 96464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:59:07.738394 96464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([53687092, 20, 2],"int64"), )
[Pass] paddle.sign(Tensor([53687092, 20, 2],"int64"), )

W0212 07:02:05.106549 96561 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:02:05.107648 96561 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([5478275, 1, 28, 28],"float32"), )
[Pass] paddle.sign(Tensor([5478275, 1, 28, 28],"float32"), )

W0212 07:05:34.129451 96633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:05:34.130255 96633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([6, 1, 238609295, 3],"float32"), )
[Pass] paddle.sign(Tensor([6, 1, 238609295, 3],"float32"), )

W0212 07:09:39.935984 96717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:09:39.936972 96717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([6, 1, 3, 238609295],"float32"), )
[Pass] paddle.sign(Tensor([6, 1, 3, 238609295],"float32"), )

W0212 07:13:07.539067 96786 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:13:07.539882 96786 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([6, 79536432, 3, 3],"float32"), )
[Pass] paddle.sign(Tensor([6, 79536432, 3, 3],"float32"), )

W0212 07:16:53.308974 96884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:16:53.309939 96884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([64, 1, 2396746, 28],"float32"), )
[Pass] paddle.sign(Tensor([64, 1, 2396746, 28],"float32"), )

W0212 07:20:42.808141 97010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:20:42.809873 97010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([64, 1, 28, 2396746],"float32"), )
[Pass] paddle.sign(Tensor([64, 1, 28, 2396746],"float32"), )

W0212 07:24:31.028254 97093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:24:31.029281 97093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([64, 342393, 14, 14],"float32"), )
[Pass] paddle.sign(Tensor([64, 342393, 14, 14],"float32"), )

W0212 07:28:18.123517 97164 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:28:18.124374 97164 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([64, 6, 14, 798916],"float32"), )
[Pass] paddle.sign(Tensor([64, 6, 14, 798916],"float32"), )

W0212 07:33:23.747992 97249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:33:23.748894 97249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([64, 6, 798916, 14],"float32"), )
[Pass] paddle.sign(Tensor([64, 6, 798916, 14],"float32"), )

W0212 07:37:12.233917 97346 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:37:12.234905 97346 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([64, 67108864],"float32"), )
[Pass] paddle.sign(Tensor([64, 67108864],"float32"), )

W0212 07:41:04.115924 97486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:41:04.116901 97486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([64, 85599, 28, 28],"float32"), )
[Pass] paddle.sign(Tensor([64, 85599, 28, 28],"float32"), )

W0212 07:44:49.972028 97598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:44:49.973214 97598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([715827883, 6],"float32"), )
[Pass] paddle.sign(Tensor([715827883, 6],"float32"), )

W0212 07:48:33.740376 97682 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:48:33.741199 97682 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([71582789, 3, 4, 5],"int8"), )
[Pass] paddle.sign(Tensor([71582789, 3, 4, 5],"int8"), )

W0212 07:52:02.880637 97753 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:52:02.882010 97753 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([8, 17, 5, 6, 1052689],"float16"), )
[Pass] paddle.sign(Tensor([8, 17, 5, 6, 1052689],"float16"), )

W0212 07:56:22.475620 97823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:56:22.476557 97823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([8, 17, 5, 902305, 7],"float16"), )
[Pass] paddle.sign(Tensor([8, 17, 5, 902305, 7],"float16"), )

W0212 08:05:40.531373 97962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:05:40.532232 97962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([8, 17, 751921, 6, 7],"float16"), )
[Pass] paddle.sign(Tensor([8, 17, 751921, 6, 7],"float16"), )

W0212 08:14:56.077983 98102 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:14:56.078917 98102 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([8, 2556529, 5, 6, 7],"float16"), )
[Pass] paddle.sign(Tensor([8, 2556529, 5, 6, 7],"float16"), )

W0212 08:24:16.787276 98255 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:24:16.788259 98255 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([84, 51130564],"float32"), )
[Pass] paddle.sign(Tensor([84, 51130564],"float32"), )

W0212 08:32:52.808784 98409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:32:52.809989 98409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sign(Tensor([9, 477218589],"float32"), )
[Pass] paddle.sign(Tensor([9, 477218589],"float32"), )

W0212 08:36:31.341234 98466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:36:31.342196 98466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([107374183, 20, 2],"float32"), )
[paddle error] paddle.signbit(Tensor([107374183, 20, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 69.594666GB memory has been allocated and available memory is only 9.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 08:44:03.098968 98549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:44:03.100287 98549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([107374183, 20, 2],"int16"), )
[Pass] paddle.signbit(Tensor([107374183, 20, 2],"int16"), )

W0212 08:49:12.375416 98663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:49:12.376641 98663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([107374183, 20, 2],"int32"), )
[paddle error] paddle.signbit(Tensor([107374183, 20, 2],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   int* phi::DeviceContext::Alloc<int>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 69.594666GB memory has been allocated and available memory is only 9.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 08:55:36.822131 98802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:55:36.823191 98802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([107374183, 20, 2],"int8"), )
[Pass] paddle.signbit(Tensor([107374183, 20, 2],"int8"), )

W0212 09:00:38.049325 98872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:00:38.050473 98872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([107374183, 20, 2],"uint8"), )
[Pass] paddle.signbit(Tensor([107374183, 20, 2],"uint8"), )

W0212 09:06:48.478668 98943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:06:48.480885 98943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([11, 17, 22967740],"int16"), )
[Pass] paddle.signbit(Tensor([11, 17, 22967740],"int16"), )

W0212 09:12:33.797993 99027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:12:33.798956 99027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([11, 17, 22967740],"int32"), )
[paddle error] paddle.signbit(Tensor([11, 17, 22967740],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   int* phi::DeviceContext::Alloc<int>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 69.594666GB memory has been allocated and available memory is only 9.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 09:19:01.346520 99083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:19:01.347608 99083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([11, 390451573],"float32"), )
[paddle error] paddle.signbit(Tensor([11, 390451573],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 69.594666GB memory has been allocated and available memory is only 9.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 09:24:37.514645 99125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:24:37.516127 99125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([11, 39045158, 10],"int16"), )
[Pass] paddle.signbit(Tensor([11, 39045158, 10],"int16"), )

W0212 09:29:45.614914 99153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:29:45.616107 99153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([11, 39045158, 10],"int32"), )
[paddle error] paddle.signbit(Tensor([11, 39045158, 10],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   int* phi::DeviceContext::Alloc<int>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 69.594666GB memory has been allocated and available memory is only 9.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 09:36:28.164634 99195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:36:28.173482 99195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 178956971, 2],"float32"), )
[paddle error] paddle.signbit(Tensor([12, 178956971, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 69.594666GB memory has been allocated and available memory is only 9.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 09:41:46.415134 99250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:41:46.416311 99250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 178956971, 2],"int16"), )
[Pass] paddle.signbit(Tensor([12, 178956971, 2],"int16"), )

W0212 09:47:00.410516 99954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:47:00.411720 99954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 178956971, 2],"int32"), )
[paddle error] paddle.signbit(Tensor([12, 178956971, 2],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   int* phi::DeviceContext::Alloc<int>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 69.594666GB memory has been allocated and available memory is only 9.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 09:53:09.039593 103617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:53:09.040776 103617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 178956971, 2],"int8"), )
[Pass] paddle.signbit(Tensor([12, 178956971, 2],"int8"), )

W0212 09:58:10.701095 106999 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 09:58:10.702198 106999 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 178956971, 2],"uint8"), )
[Pass] paddle.signbit(Tensor([12, 178956971, 2],"uint8"), )

W0212 10:03:45.660482 110464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:03:45.661420 110464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 20, 17895698],"float32"), )
[paddle error] paddle.signbit(Tensor([12, 20, 17895698],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 69.594666GB memory has been allocated and available memory is only 9.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 10:09:42.544708 113865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:09:42.545940 113865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 20, 17895698],"int16"), )
[Pass] paddle.signbit(Tensor([12, 20, 17895698],"int16"), )

W0212 10:14:49.994098 117235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:14:49.995224 117235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 20, 17895698],"int32"), )
[paddle error] paddle.signbit(Tensor([12, 20, 17895698],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   int* phi::DeviceContext::Alloc<int>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 69.594666GB memory has been allocated and available memory is only 9.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 10:21:16.348522 121048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:21:16.349640 121048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 20, 17895698],"int8"), )
[Pass] paddle.signbit(Tensor([12, 20, 17895698],"int8"), )

W0212 10:26:20.769835 124598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:26:20.771016 124598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 20, 17895698],"uint8"), )
[Pass] paddle.signbit(Tensor([12, 20, 17895698],"uint8"), )

W0212 10:32:09.115219 128321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:32:09.116551 128321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 20, 8947849],"float64"), )
[paddle error] paddle.signbit(Tensor([12, 20, 8947849],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 10:36:11.671761 131797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:36:11.672859 131797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 20, 8947849],"int64"), )
[paddle error] paddle.signbit(Tensor([12, 20, 8947849],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 10:39:05.322696 133983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:39:05.323805 133983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 89478486, 2],"float64"), )
[paddle error] paddle.signbit(Tensor([12, 89478486, 2],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 10:42:05.200706 135864 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:42:05.201996 135864 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([12, 89478486, 2],"int64"), )
[paddle error] paddle.signbit(Tensor([12, 89478486, 2],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 10:45:02.614387 137746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:45:02.615707 137746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([1203073, 17, 5, 6, 7],"float16"), )
[Pass] paddle.signbit(Tensor([1203073, 17, 5, 6, 7],"float16"), )

W0212 10:50:43.255592 139608 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:50:43.256772 139608 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([2, 107374183, 4, 5],"int8"), )
[Pass] paddle.signbit(Tensor([2, 107374183, 4, 5],"int8"), )

W0212 10:56:39.487097 143687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 10:56:39.488230 143687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([2, 3, 143165577, 5],"int8"), )
[Pass] paddle.signbit(Tensor([2, 3, 143165577, 5],"int8"), )

W0212 11:02:43.136651 147395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:02:43.137951 147395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([2, 3, 4, 178956971],"int8"), )
[Pass] paddle.signbit(Tensor([2, 3, 4, 178956971],"int8"), )

W0212 11:08:36.868851 151096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:08:36.870033 151096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([2, 3, 4, 89478486],"float64"), )
[paddle error] paddle.signbit(Tensor([2, 3, 4, 89478486],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 11:12:33.809475 154799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:12:33.810971 154799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([2, 3, 71582789, 5],"float64"), )
[paddle error] paddle.signbit(Tensor([2, 3, 71582789, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 11:15:32.327455 156644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:15:32.328830 156644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([2, 53687092, 4, 5],"float64"), )
[paddle error] paddle.signbit(Tensor([2, 53687092, 4, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 11:18:22.546036 158511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:18:22.547318 158511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([2147483649],"int64"), )
[paddle error] paddle.signbit(Tensor([2147483649],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


/usr/local/lib/python3.9/dist-packages/paddle/tensor/math.py:8033: UserWarning: The shape of broadcast output [-1] is different from the input tensor x with shape: [2147483649], please make sure you are using copysign api correctly.
  warnings.warn(
W0212 11:21:49.337987 160344 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:21:49.339262 160344 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([252645135, 17],"float32"), )
[paddle error] paddle.signbit(Tensor([252645135, 17],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 69.584900GB memory has been allocated and available memory is only 9.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 11:26:39.398033 162226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:26:39.399214 162226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([25264514, 17, 10],"int16"), )
[Pass] paddle.signbit(Tensor([25264514, 17, 10],"int16"), )

W0212 11:31:25.129251  1857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:31:25.130757  1857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([25264514, 17, 10],"int32"), )
[paddle error] paddle.signbit(Tensor([25264514, 17, 10],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   int* phi::DeviceContext::Alloc<int>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 69.594666GB memory has been allocated and available memory is only 9.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 11:37:24.406342  5272 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:37:24.407549  5272 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([35791395, 3, 4, 5],"float64"), )
[paddle error] paddle.signbit(Tensor([35791395, 3, 4, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 11:40:22.298728  8641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:40:22.299906  8641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([4294967295],"uint8"), )
[Pass] paddle.signbit(Tensor([4294967295],"uint8"), )

/usr/local/lib/python3.9/dist-packages/paddle/tensor/math.py:8033: UserWarning: The shape of broadcast output [-1] is different from the input tensor x with shape: [4294967295], please make sure you are using copysign api correctly.
  warnings.warn(
W0212 11:45:06.552564 10489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:45:06.553431 10489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([53687092, 20, 2],"float64"), )
[paddle error] paddle.signbit(Tensor([53687092, 20, 2],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 11:48:35.637691 13651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:48:35.638852 13651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([53687092, 20, 2],"int64"), )
[paddle error] paddle.signbit(Tensor([53687092, 20, 2],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sign(_object*, _object*, _object*)
1   sign_ad_func(paddle::Tensor const&)
2   paddle::experimental::sign(paddle::Tensor const&)
3   void phi::SignKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 67.594666GB memory has been allocated and available memory is only 11.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 11:51:29.383240 15499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:51:29.384375 15499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([71582789, 3, 4, 5],"int8"), )
[Pass] paddle.signbit(Tensor([71582789, 3, 4, 5],"int8"), )

W0212 11:56:19.539744 17352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 11:56:19.540880 17352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([8, 17, 5, 6, 1052689],"float16"), )
[Pass] paddle.signbit(Tensor([8, 17, 5, 6, 1052689],"float16"), )

W0212 12:02:38.414921 21066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:02:38.415935 21066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([8, 17, 5, 902305, 7],"float16"), )
[Pass] paddle.signbit(Tensor([8, 17, 5, 902305, 7],"float16"), )

W0212 12:08:58.254842 24875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:08:58.256116 24875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([8, 17, 751921, 6, 7],"float16"), )
[Pass] paddle.signbit(Tensor([8, 17, 751921, 6, 7],"float16"), )

W0212 12:15:29.882995 29119 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:15:29.884248 29119 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.signbit(Tensor([8, 2556529, 5, 6, 7],"float16"), )
[Pass] paddle.signbit(Tensor([8, 2556529, 5, 6, 7],"float16"), )

W0212 12:22:03.680090 33195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:22:03.681216 33195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([1, 128, 1, 33554432],"float32"), )
[Pass] paddle.sin(Tensor([1, 128, 1, 33554432],"float32"), )

W0212 12:24:36.368973 37250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:24:36.369886 37250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([1, 128, 1048576, 32],"float32"), )
[Pass] paddle.sin(Tensor([1, 128, 1048576, 32],"float32"), )

W0212 12:28:12.988034 39424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:28:12.988884 39424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([1, 134217728, 1, 32],"float32"), )
[Pass] paddle.sin(Tensor([1, 134217728, 1, 32],"float32"), )

W0212 12:32:15.650112 41925 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:32:15.651013 41925 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([10, 20, 21474837],"float32"), )
[Pass] paddle.sin(Tensor([10, 20, 21474837],"float32"), )

W0212 12:35:52.265435 44098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:35:52.266388 44098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([10, 429496730, 1],"float32"), )
[Pass] paddle.sin(Tensor([10, 429496730, 1],"float32"), )

W0212 12:39:32.736147 46529 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:39:32.737187 46529 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([10, 429496730],"float32"), )
[Pass] paddle.sin(Tensor([10, 429496730],"float32"), )

W0212 12:43:11.289258 48691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:43:11.290105 48691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([1048576, 128, 1, 32],"float32"), )
[Pass] paddle.sin(Tensor([1048576, 128, 1, 32],"float32"), )

W0212 12:46:50.924917 51328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:46:50.925750 51328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([134217728, 32],"float16"), )
[Pass] paddle.sin(Tensor([134217728, 32],"float16"), )

W0212 12:50:42.203662 53677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:50:42.204507 53677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([1431655765, 3],"float32"), )
[Pass] paddle.sin(Tensor([1431655765, 3],"float32"), )

W0212 12:59:32.202754 59141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 12:59:32.203655 59141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([2, 2147483648],"float32"), )
[Pass] paddle.sin(Tensor([2, 2147483648],"float32"), )

W0212 13:03:03.364588 61311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:03:03.365383 61311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([2, 3, 715827883],"float32"), )
[Pass] paddle.sin(Tensor([2, 3, 715827883],"float32"), )

W0212 13:07:37.971480 64057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:07:37.972326 64057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([2, 536870912, 4],"float32"), )
[Pass] paddle.sin(Tensor([2, 536870912, 4],"float32"), )

W0212 13:11:24.093552 66246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:11:24.094488 66246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([2147483649],"float64"), )
[Pass] paddle.sin(Tensor([2147483649],"float64"), )

W0212 13:15:04.667623 68718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:15:04.668664 68718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([214748365, 20, 1],"float32"), )
[Pass] paddle.sin(Tensor([214748365, 20, 1],"float32"), )

W0212 13:18:56.028829 70861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:18:56.029699 70861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([357913942, 3, 4],"float32"), )
[Pass] paddle.sin(Tensor([357913942, 3, 4],"float32"), )

W0212 13:22:59.813696 73359 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:22:59.814565 73359 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([4194305, 16, 32],"float64"), )
[Pass] paddle.sin(Tensor([4194305, 16, 32],"float64"), )

W0212 13:26:38.020634 76413 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:26:38.021557 76413 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([4294967295],"float32"), )
[Pass] paddle.sin(Tensor([4294967295],"float32"), )

W0212 13:30:06.718636 78287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:30:06.719460 78287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([429496730, 10],"float32"), )
[Pass] paddle.sin(Tensor([429496730, 10],"float32"), )

W0212 13:33:53.521529 80908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:33:53.522624 80908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([64, 67108864],"float16"), )
[Pass] paddle.sin(Tensor([64, 67108864],"float16"), )

W0212 13:37:50.767814 83097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:37:50.769045 83097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([65, 66076420],"float16"), )
[Pass] paddle.sin(Tensor([65, 66076420],"float16"), )

W0212 13:47:00.100469 88667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:47:00.101425 88667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([8, 16, 16777217],"float64"), )
[Pass] paddle.sin(Tensor([8, 16, 16777217],"float64"), )

W0212 13:55:13.324343 94185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:55:13.325228 94185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.sin(Tensor([8, 16, 33554432],"float16"), )
[Pass] paddle.sin(Tensor([8, 16, 33554432],"float16"), )

W0212 13:58:38.901273 96040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 13:58:38.902213 96040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 65, in main
    print(str(res.stdout.read(), encoding="utf-8"), flush=True)
KeyboardInterrupt
