test begin: paddle.vstack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 17209 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:27:59.655373 24391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:27:59.656422 24391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 30750 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:28:47.517180 25114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:28:47.518190 25114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 47687 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:29:34.518232 25732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:29:34.519341 25732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 68378 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:30:19.345897 26535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:30:19.346987 26535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 85814 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:31:08.058301 27178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:31:08.059445 27178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 93681 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:31:54.893659 27558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:31:54.894634 27558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 110218 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:32:41.161659 28215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:32:41.162684 28215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 127210 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:33:31.537982 28603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:33:31.538971 28603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 144601 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:34:16.127182 29273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:34:16.128258 29273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 161983 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:35:02.412259 29648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:35:02.413252 29648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 7576 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:35:50.924532 30309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:35:50.925665 30309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27071 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:36:37.392165 30968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:36:37.393277 30968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 52937 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:37:24.889932 31327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:37:24.891121 31327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 77199 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:38:11.311349 31981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:38:11.312461 31981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91737 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:38:58.683878 32360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:38:58.685014 32360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 107473 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:39:47.125211 33036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:39:47.126223 33036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 129006 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:40:34.640008 33420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:40:34.641033 33420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 148318 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:41:22.459517 34056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:41:22.460736 34056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 5152 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:42:10.436925 34711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:42:10.437911 34711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 19854 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:42:57.255375 35095 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:42:57.256477 35095 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 36134 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:43:42.481103 35742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:43:42.482116 35742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 56105 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:44:31.294623 36121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:44:31.295593 36121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 78598 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:45:17.204016 36763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:45:17.205128 36763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 102052 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:46:05.021164 37147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:46:05.022171 37147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 117344 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:46:53.362839 37799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:46:53.365413 37799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 139788 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:47:40.705333 38461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:47:40.706408 38461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 158871 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:48:26.386998 38846 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:48:26.388015 38846 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 14702 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:49:14.005977 39468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:49:14.007066 39468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 30460 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:50:01.815307 39850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:50:01.816395 39850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 45193 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:50:50.125393 40519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:50:50.126538 40519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 66097 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:51:38.573607 41173 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:51:38.574687 41173 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 85072 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:52:22.965481 41558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:52:22.966531 41558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 105022 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:53:10.308157 42193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:53:10.309299 42193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 116592 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:53:57.820822 42576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:53:57.821897 42576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 136936 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:54:44.019913 43253 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:54:44.020968 43253 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 157148 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:55:30.404191 43626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:55:30.405200 43626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 13321 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:56:18.270485 44281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:56:18.271466 44281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 35584 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:57:05.234288 44657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:57:05.235265 44657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 48739 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:57:49.363291 45312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:57:49.364259 45312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 68528 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:58:37.319619 45969 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:58:37.320710 45969 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 87464 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:59:25.904949 46356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:59:25.905923 46356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 107928 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:00:14.424578 47024 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:00:14.427052 47024 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 126301 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:01:01.687772 47398 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:01:01.688761 47398 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 143567 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:01:47.401652 48049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:01:47.402627 48049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 162588 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:02:35.581079 48416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:02:35.582142 48416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 18958 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:03:20.407011 49078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:03:20.409669 49078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 37593 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:04:08.381386 49687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:04:08.382365 49687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 50098 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:04:57.061511 50046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:04:57.062487 50046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 70026 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:05:45.349257 50890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:05:45.350222 50890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 95877 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:06:33.654958 51281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:06:33.656033 51281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 118377 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:07:19.205785 51923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:07:19.206809 51923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 136825 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:08:03.568758 52308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:08:03.569752 52308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 146395 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:08:48.016465 53142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:08:48.017591 53142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 2581 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:09:32.503209 53518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:09:32.505205 53518 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 21353 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:10:18.753124 54155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:10:18.754124 54155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 40273 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:11:03.854497 54525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:11:03.855556 54525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 715827883],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 715827883],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 52126 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:11:50.664724 55179 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:11:50.665787 55179 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 715827883],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 715827883],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 72393 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:12:39.851027 55855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:12:39.852174 55855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91942 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:13:24.973873 56227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:13:24.975286 56227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111655 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:14:19.153448 56891 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:14:19.154534 56891 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 135373 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:15:07.234351 57281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:15:07.235451 57281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 145893 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:15:52.026512 57941 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:15:52.037567 57941 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 7496 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:16:35.597000 58591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:16:35.605408 58591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 28069 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:17:24.557592 58961 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:17:24.575816 58961 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 52499 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:18:14.334509 59623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:18:14.335551 59623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 67560 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:19:03.937041 60026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:19:03.938186 60026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 83750 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:19:49.080425 60669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:19:49.081911 60669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 103286 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:20:38.071736 61045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:20:38.072850 61045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 123543 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:21:26.358536 61707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:21:26.359512 61707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 143674 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:22:11.656307 62375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:22:11.657269 62375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.vstack(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 153297 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:22:55.664696 62754 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:22:55.665745 62754 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 9688 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:23:39.891170 63402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:23:39.892175 63402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27325 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:24:28.685853 63771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:24:28.687034 63771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 50215 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:25:13.742885 64442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:25:13.744069 64442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 62257 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:25:57.712788 64801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:25:57.713860 64801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 83470 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:26:48.361423 65466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:26:48.362531 65466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], )
[torch error] paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 106407 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:27:37.598515 65855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:27:37.599609 65855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], name=None, )
[torch error] paddle.vstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 126350 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:28:22.688108 66536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:28:22.689105 66536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([1, 4294967295],"float32"), )
[torch error] paddle.zeros_like(Tensor([1, 4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 146565 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:29:36.265692 67195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:29:36.266671 67195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([10, 429496730],"float32"), )
[torch error] paddle.zeros_like(Tensor([10, 429496730],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 7918 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:30:45.501922 67934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:30:45.502966 67934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([1073741824, 4],"bool"), )
[paddle error] paddle.zeros_like(Tensor([1073741824, 4],"bool"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.565369GB memory has been allocated and available memory is only 3.619507GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 10:32:00.917519 68636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:32:00.918421 68636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([1073741824, 4],"float32"), )
[torch error] paddle.zeros_like(Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 57768 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:33:10.342816 69599 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:33:10.343946 69599 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([1073741825, 2],"int64"), )
[torch error] paddle.zeros_like(Tensor([1073741825, 2],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 88307 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:33:52.524781 70304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:33:52.526003 70304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([107374183, 40],"float16"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([107374183, 40],"float16"), dtype=type(int), ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 110084 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:35:24.532320 70926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:35:24.533319 70926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([107374183, 40],"float32"), )
[torch error] paddle.zeros_like(Tensor([107374183, 40],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 148632 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:36:30.834323 71922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:36:30.835454 71922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([107374183, 40],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([107374183, 40],"float32"), dtype=type(int), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 16632 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:37:39.835160 72588 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:37:39.836180 72588 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([13, 165191050],"int64"), )
[torch error] paddle.zeros_like(Tensor([13, 165191050],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 39658 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:38:24.230197 73297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:38:24.261255 73297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([1431655765, 3],"float32"), )
[torch error] paddle.zeros_like(Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 59115 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:39:49.920892 74268 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:39:49.921887 74268 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([1431655765, 3],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([1431655765, 3],"float32"), dtype=type(int), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 88523 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:40:56.189296 74969 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:40:56.190698 74969 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([143165577, 5, 6],"float32"), )
[torch error] paddle.zeros_like(Tensor([143165577, 5, 6],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111767 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:42:23.134526 75927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:42:23.136683 75927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 1073741824, 2],"float32"), )
[torch error] paddle.zeros_like(Tensor([2, 1073741824, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 151027 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:43:48.869977 76911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:43:48.871022 76911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 1073741825],"int64"), )
[torch error] paddle.zeros_like(Tensor([2, 1073741825],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 16435 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:44:47.009047 77609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:44:47.010442 77609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 107374183, 4, 5],"float32"), )
[torch error] paddle.zeros_like(Tensor([2, 107374183, 4, 5],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 41051 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:45:54.493111 78276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:45:54.494503 78276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 2147483648],"float32"), )
[torch error] paddle.zeros_like(Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 68515 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:47:05.829689 79403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:47:05.830785 79403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 3, 143165577, 5],"float32"), )
[torch error] paddle.zeros_like(Tensor([2, 3, 143165577, 5],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 96808 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:48:12.820303 80112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:48:12.821408 80112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 3, 4, 178956971],"float32"), )
[torch error] paddle.zeros_like(Tensor([2, 3, 4, 178956971],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 121269 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:49:19.468961 80781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:49:19.470096 80781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 3, 4, 89478486],"float64"), )
[torch error] paddle.zeros_like(Tensor([2, 3, 4, 89478486],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 154982 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:50:04.586112 81448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:50:04.587224 81448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 3, 71582789, 5],"float64"), )
[torch error] paddle.zeros_like(Tensor([2, 3, 71582789, 5],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 5552 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:51:02.789959 82083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:51:02.791033 82083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 3, 8, 89478486],"float32"), Dtype(float32), )
[torch error] paddle.zeros_like(Tensor([2, 3, 8, 89478486],"float32"), Dtype(float32), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27340 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:52:11.928995 82743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:52:11.930028 82743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 3, 89478486, 8],"float32"), Dtype(float32), )
[torch error] paddle.zeros_like(Tensor([2, 3, 89478486, 8],"float32"), Dtype(float32), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51426 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:53:25.212980 83425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:53:25.270592 83425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 33554432, 8, 8],"float32"), Dtype(float32), )
[torch error] paddle.zeros_like(Tensor([2, 33554432, 8, 8],"float32"), Dtype(float32), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 84490 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:54:33.415411 84388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:54:33.416532 84388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 4, 268435457],"float64"), )
[torch error] paddle.zeros_like(Tensor([2, 4, 268435457],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 113975 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:55:21.225425 85065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:55:21.226449 85065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 4, 536870912],"float32"), )
[torch error] paddle.zeros_like(Tensor([2, 4, 536870912],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 130019 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:56:36.892051 85718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:56:36.893150 85718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 536870913, 2],"float64"), )
[torch error] paddle.zeros_like(Tensor([2, 536870913, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 3005 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:57:25.040549 86399 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:57:25.041710 86399 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2, 53687092, 4, 5],"float64"), )
[torch error] paddle.zeros_like(Tensor([2, 53687092, 4, 5],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 20300 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:58:11.811656 87040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:58:11.812677 87040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2147483648, 2],"float32"), )
[torch error] paddle.zeros_like(Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 32063 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:59:30.676308 87409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:59:30.677388 87409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2147483649],"float64"), )
[torch error] paddle.zeros_like(Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 69013 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:00:17.210620 88386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:00:17.211745 88386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([2147483649],"int64"), "int64", )
[torch error] paddle.zeros_like(Tensor([2147483649],"int64"), "int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 79187 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:01:17.439481 88769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:01:17.440575 88769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([214748365, 10],"int64"), )
[torch error] paddle.zeros_like(Tensor([214748365, 10],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 102802 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:02:15.501992 89427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:02:15.503121 89427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([21474837, 100],"int64"), )
[torch error] paddle.zeros_like(Tensor([21474837, 100],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 126125 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:03:10.102066 90080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:03:10.103132 90080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([22369622, 3, 8, 8],"float32"), Dtype(float32), )
[torch error] paddle.zeros_like(Tensor([22369622, 3, 8, 8],"float32"), Dtype(float32), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 145819 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:04:20.477854 90733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:04:20.479120 90733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([268435457, 4, 2],"float64"), )
[torch error] paddle.zeros_like(Tensor([268435457, 4, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 13267 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:05:23.849467 91685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:05:23.850572 91685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([268435457, 4, 2],"int64"), )
[torch error] paddle.zeros_like(Tensor([268435457, 4, 2],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 41977 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:06:16.079161 92356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:06:16.080262 92356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([268435457, 8],"int64"), )
[torch error] paddle.zeros_like(Tensor([268435457, 8],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 63239 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:07:12.197726 92732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:07:12.198832 92732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([286331153, 3, 5],"float32"), )
[torch error] paddle.zeros_like(Tensor([286331153, 3, 5],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 86471 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:08:40.936389 93386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:08:40.937510 93386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 1431655765],"float16"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([3, 1431655765],"float16"), dtype=type(int), ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 123767 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:10:07.442490 94321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:10:07.443516 94321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 1431655765],"float32"), )
[torch error] paddle.zeros_like(Tensor([3, 1431655765],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 150531 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:11:26.870208 95196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:11:26.871305 95196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 1431655765],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([3, 1431655765],"float32"), dtype=type(int), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 19375 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:12:35.138473 96101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:12:35.139565 96101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 178956971, 8],"float32"), Dtype(float32), )
[torch error] paddle.zeros_like(Tensor([3, 178956971, 8],"float32"), Dtype(float32), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 178956971, 8) and data type float32

W0213 11:13:27.308029 96690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:13:27.309294 96690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 28, 51130564],"float32"), Dtype(float32), )
[torch error] paddle.zeros_like(Tensor([3, 28, 51130564],"float32"), Dtype(float32), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 28, 51130564) and data type float32

W0213 11:14:20.156436 97241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:14:20.157775 97241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 286331153, 5],"float32"), )
[torch error] paddle.zeros_like(Tensor([3, 286331153, 5],"float32"), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 286331153, 5) and data type float32

W0213 11:15:11.773466 97517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:15:11.774757 97517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 3, 477218589],"float32"), )
[torch error] paddle.zeros_like(Tensor([3, 3, 477218589],"float32"), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 3, 477218589) and data type float32

W0213 11:16:10.120895 98106 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:16:10.121989 98106 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 357913942, 2],"int64"), )
[torch error] paddle.zeros_like(Tensor([3, 357913942, 2],"int64"), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 357913942, 2) and data type int64

W0213 11:16:42.619863 98399 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:16:42.620970 98399 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 4, 178956971],"int64"), )
[torch error] paddle.zeros_like(Tensor([3, 4, 178956971],"int64"), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 4, 178956971) and data type float64

W0213 11:16:49.527539 98688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:16:49.528874 98688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 51130564, 28],"float32"), Dtype(float32), )
[torch error] paddle.zeros_like(Tensor([3, 51130564, 28],"float32"), Dtype(float32), ) 
 Unable to allocate 32.0 GiB for an array with shape (3, 51130564, 28) and data type float64

W0213 11:16:57.039140 98703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:16:57.040067 98703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 715827883],"float64"), )
[torch error] paddle.zeros_like(Tensor([3, 715827883],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 129497 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:17:45.913448 98981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:17:45.914371 98981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 715827883],"float64"), type(numpy.bool_), )
[torch error] paddle.zeros_like(Tensor([3, 715827883],"float64"), type(numpy.bool_), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 715827883) and data type float64

W0213 11:18:15.406777 99341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:18:15.407909 99341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 715827883],"float64"), type(numpy.float32), )
[torch error] paddle.zeros_like(Tensor([3, 715827883],"float64"), type(numpy.float32), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 715827883) and data type float64

W0213 11:18:22.060760 99781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:18:22.061753 99781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 715827883],"float64"), type(numpy.float64), )
[torch error] paddle.zeros_like(Tensor([3, 715827883],"float64"), type(numpy.float64), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 715827883) and data type float64

W0213 11:18:29.042073 100054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:18:29.043195 100054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 715827883],"float64"), type(numpy.int32), )
[torch error] paddle.zeros_like(Tensor([3, 715827883],"float64"), type(numpy.int32), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 715827883) and data type float64

W0213 11:18:35.886193 100069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:18:35.887197 100069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 715827883],"float64"), type(numpy.int64), )
[torch error] paddle.zeros_like(Tensor([3, 715827883],"float64"), type(numpy.int64), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 715827883) and data type float64

W0213 11:19:05.298985 100084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:19:05.300097 100084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 715827883],"int64"), )
[torch error] paddle.zeros_like(Tensor([3, 715827883],"int64"), ) 
 Unable to allocate 16.0 GiB for an array with shape (3, 715827883) and data type int64

W0213 11:19:35.002295 100386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:19:35.003439 100386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3, 8, 178956971],"float32"), Dtype(float32), )
[torch error] paddle.zeros_like(Tensor([3, 8, 178956971],"float32"), Dtype(float32), ) 
 Unable to allocate 32.0 GiB for an array with shape (3, 8, 178956971) and data type float64

W0213 11:19:41.749619 100686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:19:41.750681 100686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([30, 143165577],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([30, 143165577],"float32"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (30, 143165577) and data type float64

W0213 11:19:48.738790 100714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:19:48.739758 100714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([300, 14316558],"float16"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([300, 14316558],"float16"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (300, 14316558) and data type float64

W0213 11:19:55.490814 100742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:19:55.491853 100742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([300, 14316558],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([300, 14316558],"float32"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (300, 14316558) and data type float64

W0213 11:20:02.300140 101017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:20:02.301270 101017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3314018, 8, 9, 18],"float16"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([3314018, 8, 9, 18],"float16"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (3314018, 8, 9, 18) and data type float64

W0213 11:20:09.106914 101045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:20:09.107879 101045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([3314018, 8, 9, 18],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([3314018, 8, 9, 18],"float32"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (3314018, 8, 9, 18) and data type float64

W0213 11:20:15.867421 101073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:20:15.868363 101073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([33554432, 128],"float32"), )
[torch error] paddle.zeros_like(Tensor([33554432, 128],"float32"), ) 
 Unable to allocate 32.0 GiB for an array with shape (33554432, 128) and data type float64

W0213 11:20:22.453676 101088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:20:22.454653 101088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([35791395, 3, 4, 5],"float64"), )
[torch error] paddle.zeros_like(Tensor([35791395, 3, 4, 5],"float64"), ) 
 Unable to allocate 16.0 GiB for an array with shape (35791395, 3, 4, 5) and data type float64

W0213 11:20:30.240916 101362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:20:30.241866 101362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([4, 178956971, 6],"float32"), )
[torch error] paddle.zeros_like(Tensor([4, 178956971, 6],"float32"), ) 
 Unable to allocate 32.0 GiB for an array with shape (4, 178956971, 6) and data type float64

W0213 11:20:37.149468 101377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:20:37.150615 101377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([4, 5, 214748365],"float32"), )
[torch error] paddle.zeros_like(Tensor([4, 5, 214748365],"float32"), ) 
 Unable to allocate 32.0 GiB for an array with shape (4, 5, 214748365) and data type float64

W0213 11:20:44.278525 101393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:20:44.279510 101393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([4294967295, 1],"float16"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([4294967295, 1],"float16"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (4294967295, 1) and data type float64

W0213 11:20:51.088846 101422 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:20:51.089814 101422 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([4294967295],"bool"), )
[torch error] paddle.zeros_like(Tensor([4294967295],"bool"), ) 
 Unable to allocate 32.0 GiB for an array with shape (4294967295,) and data type float64

W0213 11:20:57.751247 101711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:20:57.752382 101711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([4294967295],"float16"), )
[torch error] paddle.zeros_like(Tensor([4294967295],"float16"), ) 
 Unable to allocate 32.0 GiB for an array with shape (4294967295,) and data type float64

W0213 11:21:04.474740 101732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:21:04.475761 101732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([4294967295],"float16"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([4294967295],"float16"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (4294967295,) and data type float64

W0213 11:21:11.533672 101755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:21:11.534610 101755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([4294967295],"float32"), )
[torch error] paddle.zeros_like(Tensor([4294967295],"float32"), ) 
 Unable to allocate 32.0 GiB for an array with shape (4294967295,) and data type float64

W0213 11:21:18.093350 101769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:21:18.094457 101769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([4294967295],"float32"), dtype="int32", )
[torch error] paddle.zeros_like(Tensor([4294967295],"float32"), dtype="int32", ) 
 Unable to allocate 32.0 GiB for an array with shape (4294967295,) and data type float64

W0213 11:21:24.928607 101784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:21:24.929567 101784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([4294967295],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([4294967295],"float32"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (4294967295,) and data type float64

W0213 11:21:32.118376 102058 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:21:32.119385 102058 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([5, 429496730],"int64"), )
[torch error] paddle.zeros_like(Tensor([5, 429496730],"int64"), ) 
 Unable to allocate 16.0 GiB for an array with shape (5, 429496730) and data type int64

W0213 11:22:01.731931 102073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:22:01.733098 102073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([5, 858993459],"float32"), )
[torch error] paddle.zeros_like(Tensor([5, 858993459],"float32"), ) 
 Unable to allocate 32.0 GiB for an array with shape (5, 858993459) and data type float64

W0213 11:22:08.894088 102103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:22:08.895220 102103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([50, 85899346],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([50, 85899346],"float32"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (50, 85899346) and data type float64

W0213 11:22:15.947422 102132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:22:15.948477 102132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([536870912, 4, 2],"float32"), )
[torch error] paddle.zeros_like(Tensor([536870912, 4, 2],"float32"), ) 
 Unable to allocate 32.0 GiB for an array with shape (536870912, 4, 2) and data type float64

W0213 11:22:22.516259 102147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:22:22.517189 102147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([536870913, 4],"float64"), )
[torch error] paddle.zeros_like(Tensor([536870913, 4],"float64"), ) 
 Unable to allocate 16.0 GiB for an array with shape (536870913, 4) and data type float64

W0213 11:22:29.115976 102420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:22:29.116938 102420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([536870913, 4],"float64"), type(numpy.bool_), )
[torch error] paddle.zeros_like(Tensor([536870913, 4],"float64"), type(numpy.bool_), ) 
 Unable to allocate 16.0 GiB for an array with shape (536870913, 4) and data type float64

W0213 11:22:59.079872 102435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:22:59.081153 102435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([536870913, 4],"float64"), type(numpy.float32), )
[torch error] paddle.zeros_like(Tensor([536870913, 4],"float64"), type(numpy.float32), ) 
 Unable to allocate 16.0 GiB for an array with shape (536870913, 4) and data type float64

W0213 11:23:29.107547 102748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:23:29.108693 102748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([536870913, 4],"float64"), type(numpy.float64), )
[torch error] paddle.zeros_like(Tensor([536870913, 4],"float64"), type(numpy.float64), ) 
 Unable to allocate 16.0 GiB for an array with shape (536870913, 4) and data type float64

W0213 11:23:35.947613 103061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:23:35.948678 103061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([536870913, 4],"float64"), type(numpy.int32), )
[torch error] paddle.zeros_like(Tensor([536870913, 4],"float64"), type(numpy.int32), ) 
 Unable to allocate 16.0 GiB for an array with shape (536870913, 4) and data type float64

W0213 11:23:42.527184 103085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:23:42.528126 103085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([536870913, 4],"float64"), type(numpy.int64), )
[torch error] paddle.zeros_like(Tensor([536870913, 4],"float64"), type(numpy.int64), ) 
 Unable to allocate 16.0 GiB for an array with shape (536870913, 4) and data type float64

W0213 11:23:49.327850 103099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:23:49.328948 103099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([536870913, 4],"int64"), )
[torch error] paddle.zeros_like(Tensor([536870913, 4],"int64"), ) 
 Unable to allocate 16.0 GiB for an array with shape (536870913, 4) and data type float64

W0213 11:23:56.560206 103114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:23:56.561479 103114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([5478275, 28, 28],"float32"), Dtype(float32), )
[torch error] paddle.zeros_like(Tensor([5478275, 28, 28],"float32"), Dtype(float32), ) 
 Unable to allocate 32.0 GiB for an array with shape (5478275, 28, 28) and data type float64

W0213 11:24:04.304469 103376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:24:04.305523 103376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([6, 4418691, 9, 18],"float16"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([6, 4418691, 9, 18],"float16"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (6, 4418691, 9, 18) and data type float64

W0213 11:24:12.827414 103391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:24:12.828332 103391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([6, 4418691, 9, 18],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([6, 4418691, 9, 18],"float32"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (6, 4418691, 9, 18) and data type float64

W0213 11:24:19.532909 103405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:24:19.534145 103405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([6, 8, 4971027, 18],"float16"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([6, 8, 4971027, 18],"float16"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (6, 8, 4971027, 18) and data type float64

W0213 11:24:26.142341 103420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:24:26.143376 103420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([6, 8, 4971027, 18],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([6, 8, 4971027, 18],"float32"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (6, 8, 4971027, 18) and data type float64

W0213 11:24:32.786903 103682 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:24:32.787856 103682 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([6, 8, 9, 9942054],"float16"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([6, 8, 9, 9942054],"float16"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (6, 8, 9, 9942054) and data type float64

W0213 11:24:39.391956 103696 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:24:39.392884 103696 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([6, 8, 9, 9942054],"float32"), dtype=type(int), )
[torch error] paddle.zeros_like(Tensor([6, 8, 9, 9942054],"float32"), dtype=type(int), ) 
 Unable to allocate 32.0 GiB for an array with shape (6, 8, 9, 9942054) and data type float64

W0213 11:24:46.865191 103711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:24:46.866278 103711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([67108864, 8, 8],"float32"), Dtype(float32), )
[torch error] paddle.zeros_like(Tensor([67108864, 8, 8],"float32"), Dtype(float32), ) 
 Unable to allocate 32.0 GiB for an array with shape (67108864, 8, 8) and data type float64

W0213 11:24:53.610595 103728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:24:53.611694 103728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([71582789, 3, 4, 5],"float32"), )
[torch error] paddle.zeros_like(Tensor([71582789, 3, 4, 5],"float32"), ) 
 Unable to allocate 32.0 GiB for an array with shape (71582789, 3, 4, 5) and data type float64

W0213 11:25:00.409375 103989 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:25:00.410352 103989 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([8, 268435457],"int64"), )paddle.concat(list[Tensor([2, 1968, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, )
[paddle_to_torch] paddle.zeros_like(Tensor([8, 268435457],"int64"), )paddle.concat(list[Tensor([2, 1968, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, ) 
  axis not in paddle_to_torch_args_map, can not call torch

W0213 11:25:07.296876 104031 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:25:07.297760 104031 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([8, 536870912],"bool"), )
[torch error] paddle.zeros_like(Tensor([8, 536870912],"bool"), ) 
 Unable to allocate 32.0 GiB for an array with shape (8, 536870912) and data type float64

W0213 11:25:13.663618 104087 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:25:13.664546 104087 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.zeros_like(Tensor([858993459, 5],"float32"), )
[torch error] paddle.zeros_like(Tensor([858993459, 5],"float32"), ) 
 Unable to allocate 32.0 GiB for an array with shape (858993459, 5) and data type float64

W0213 11:25:20.083074 104110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:25:20.083961 104110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

