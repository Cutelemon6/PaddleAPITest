test begin: paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([10, 15],"float32"), )
[torch error] paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([10, 15],"float32"), ) 
 The size of tensor a (429496730) must match the size of tensor b (15) at non-singleton dimension 1

W0205 10:02:24.165351 88932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:02:24.166479 88932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([10, 429496730],"float32"), )
[paddle error] paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([10, 429496730],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:04:55.193506 89328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:04:55.194509 89328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([15],"float32"), )
[torch error] paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([15],"float32"), ) 
 The size of tensor a (429496730) must match the size of tensor b (15) at non-singleton dimension 1

W0205 10:06:04.925340 90073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:06:04.926743 90073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([2147483649],"int64"), Tensor([1],"int64"), )
[paddle error] paddle.fmin(Tensor([2147483649],"int64"), Tensor([1],"int64"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:117)


W0205 10:07:01.611425 90366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:07:01.612520 90366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), )
[paddle error] paddle.fmin(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:08:51.085402 90479 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:08:51.086405 90479 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([2147483649],"int64"), Tensor([3],"int64"), )
[torch error] paddle.fmin(Tensor([2147483649],"int64"), Tensor([3],"int64"), ) 
 The size of tensor a (2147483649) must match the size of tensor b (3) at non-singleton dimension 0

W0205 10:09:37.403968 90857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:09:37.405027 90857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([10, 15],"float32"), )
[torch error] paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([10, 15],"float32"), ) 
 The size of tensor a (286331153) must match the size of tensor b (10) at non-singleton dimension 0

W0205 10:10:49.710461 91059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:10:49.711886 91059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([15],"float32"), )
[Pass] paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([15],"float32"), )

W0205 10:12:10.352679 91267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:12:10.353623 91267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([286331153, 15],"float32"), )
[paddle error] paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([286331153, 15],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:17:01.087069 91962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:17:01.087952 91962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([3],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.fmin(Tensor([3],"int64"), Tensor([2147483649],"int64"), ) 
 The size of tensor a (3) must match the size of tensor b (2147483649) at non-singleton dimension 0

W0205 10:17:46.602598 92481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:17:46.603869 92481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([30, 200, 715828],"float32"), )
[torch error] paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([30, 200, 715828],"float32"), ) 
 The size of tensor a (40) must match the size of tensor b (715828) at non-singleton dimension 2

W0205 10:18:57.684118 92694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:18:57.685130 92694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([30, 3579140, 40],"float32"), )
[torch error] paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([30, 3579140, 40],"float32"), ) 
 The size of tensor a (200) must match the size of tensor b (3579140) at non-singleton dimension 1

W0205 10:20:15.625885 92923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:20:15.627254 92923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), )
[torch error] paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), ) 
 The size of tensor a (30) must match the size of tensor b (536871) at non-singleton dimension 0

W0205 10:21:28.682670 93226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:21:28.684028 93226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 40],"float32"), )
[torch error] paddle.fmin(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 40],"float32"), ) 
 The size of tensor a (715828) must match the size of tensor b (40) at non-singleton dimension 2

W0205 10:22:41.434655 93440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:22:41.435671 93440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 715828],"float32"), )
[paddle error] paddle.fmin(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 715828],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:25:18.223838 93729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:25:18.224825 93729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 3579140, 40],"float32"), Tensor([30, 200, 40],"float32"), )
[torch error] paddle.fmin(Tensor([30, 3579140, 40],"float32"), Tensor([30, 200, 40],"float32"), ) 
 The size of tensor a (3579140) must match the size of tensor b (200) at non-singleton dimension 1

W0205 10:26:27.149408 94217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:26:27.150411 94217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 3579140, 40],"float32"), Tensor([30, 3579140, 40],"float32"), )
[paddle error] paddle.fmin(Tensor([30, 3579140, 40],"float32"), Tensor([30, 3579140, 40],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:28:55.704787 94441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:28:55.705739 94441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (4) at non-singleton dimension 0

W0205 10:29:46.492045 94957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:29:46.493218 94957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (4) at non-singleton dimension 0

W0205 10:30:36.796715 95168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:30:36.797865 95168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 10:32:40.214272 95396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:32:40.215381 95396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 10:34:28.443228 95817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:34:28.444523 95817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (268435457) must match the size of tensor b (3) at non-singleton dimension 1

W0205 10:35:19.855152 96142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:35:19.856372 96142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (268435457) must match the size of tensor b (3) at non-singleton dimension 1

W0205 10:36:10.117020 96360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:36:10.118206 96360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (268435457) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 10:38:18.492308 96572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:38:18.493497 96572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float32"), ) 
 The size of tensor a (268435457) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 10:40:06.152160 96975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:40:06.153323 96975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (178956971) must match the size of tensor b (2) at non-singleton dimension 2

W0205 10:40:55.434036 97361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:40:55.435206 97361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (178956971) must match the size of tensor b (2) at non-singleton dimension 2

W0205 10:41:48.263114 97487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:41:48.264109 97487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (178956971) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 10:43:52.762426 97696 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:43:52.763876 97696 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float32"), ) 
 The size of tensor a (178956971) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 10:45:41.069984 98084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:45:41.071182 98084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (4) must match the size of tensor b (357913942) at non-singleton dimension 0

W0205 10:46:48.239509 98485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:46:48.240881 98485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (3) must match the size of tensor b (268435457) at non-singleton dimension 1

W0205 10:47:42.572057 98680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:47:42.573494 98680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (2) must match the size of tensor b (178956971) at non-singleton dimension 2

W0205 10:48:31.970731 98901 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:48:31.971731 98901 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 357913942],"float32"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 10:49:48.195189 99017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:49:48.196468 99017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 536870912, 2],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 10:51:00.281045 99320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:51:00.282146 99320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 10:52:14.810489 99542 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:52:14.811856 99542 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (4) must match the size of tensor b (357913942) at non-singleton dimension 0

W0205 10:53:04.263938 99819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:53:04.265079 99819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (3) must match the size of tensor b (268435457) at non-singleton dimension 1

W0205 10:53:55.089057 100026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:53:55.090179 100026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (2) must match the size of tensor b (178956971) at non-singleton dimension 2

W0205 10:54:44.358143 100154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:54:44.359124 100154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 10:56:13.879626 100349 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:56:13.880856 100349 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 10:57:43.618192 100640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:57:43.619434 100640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 10:59:09.961261 100959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:59:09.962445 100959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 11:00:41.346865 101282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:00:41.348040 101282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float32"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 11:01:52.629601 101580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:01:52.630618 101580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 11:03:22.120915 101811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:03:22.122237 101811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 11:04:37.668730 102236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:04:37.669976 102236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 11:06:12.464900 102647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:06:12.466176 102647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 11:07:24.582971 103062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:07:24.584190 103062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (178956971) at non-singleton dimension 2

W0205 11:09:30.038039 103401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:09:30.039237 103401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0205 11:11:00.879148 104024 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:11:00.880326 104024 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0205 11:12:35.378756 104388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:12:35.379935 104388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 357913942],"float32"), )
[paddle error] paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 357913942],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.594666GB memory has been allocated and available memory is only 13.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:15:16.866163 104806 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:15:16.867444 104806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:15:16.868263 104806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (178956971) at non-singleton dimension 2

W0205 11:17:13.517815 105377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:17:13.518966 105377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0205 11:18:24.852620 105828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:18:24.854074 105828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0205 11:19:41.716327 106070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:19:41.717471 106070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 357913942],"float16"), )
[paddle error] paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 357913942],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.594666GB memory has been allocated and available memory is only 13.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:22:14.684662 106443 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:22:14.686038 106443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:22:14.686919 106443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (268435457) at non-singleton dimension 1

W0205 11:24:25.845559 107013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:24:25.846822 107013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0205 11:25:51.642793 107493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:25:51.644014 107493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0205 11:27:16.879379 107821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:27:16.880513 107821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 536870912, 2],"float32"), )
[paddle error] paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 536870912, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:29:49.862630 108147 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:29:49.863878 108147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:29:49.864845 108147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (268435457) at non-singleton dimension 1

W0205 11:31:56.479344 108680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:31:56.480511 108680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0205 11:33:08.385210 109055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:33:08.386663 109055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0205 11:34:27.498075 109357 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:34:27.499198 109357 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 536870912, 2],"float16"), )
[paddle error] paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 536870912, 2],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:37:07.797335 109609 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:37:07.798628 109609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:37:07.799643 109609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([536871, 200, 40],"float32"), Tensor([30, 200, 40],"float32"), )
[torch error] paddle.fmin(Tensor([536871, 200, 40],"float32"), Tensor([30, 200, 40],"float32"), ) 
 The size of tensor a (536871) must match the size of tensor b (30) at non-singleton dimension 0

W0205 11:38:39.744009 110177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:38:39.745674 110177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([536871, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), )
[paddle error] paddle.fmin(Tensor([536871, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:41:24.074851 110481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:41:24.075956 110481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (357913942) at non-singleton dimension 0

W0205 11:43:24.906522 111014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:43:24.907624 111014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0205 11:44:53.299618 111418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:44:53.301030 111418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0205 11:46:17.187413 111709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:46:17.188413 111709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), )
[paddle error] paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.594666GB memory has been allocated and available memory is only 13.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:49:00.419901 112016 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:49:00.421052 112016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:49:00.421952 112016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (357913942) at non-singleton dimension 0

W0205 11:51:04.021212 112667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:51:04.022512 112667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0205 11:52:26.308178 113100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:52:26.309736 113100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0205 11:53:40.119053 113324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:53:40.120306 113324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), )
[paddle error] paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.594666GB memory has been allocated and available memory is only 13.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:56:16.947459 113642 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:56:16.949023 113642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:56:16.949954 113642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.frac(Tensor([10, 20, 21474837],"float32"), )
[paddle error] paddle.frac(Tensor([10, 20, 21474837],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:57:39.523970 114159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:57:39.524945 114159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([10, 429496730, 1],"float32"), )
[paddle error] paddle.frac(Tensor([10, 429496730, 1],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:59:04.842625 114532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:59:04.843608 114532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([1431655765, 3],"float32"), )
[paddle error] paddle.frac(Tensor([1431655765, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:00:30.872087 114972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:00:30.872936 114972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([1431655765, 3],"int32"), )
[torch error] paddle.frac(Tensor([1431655765, 3],"int32"), ) 
 "frac_cuda" not implemented for 'Int'

W0205 12:01:59.088270 115333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:01:59.091055 115333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.frac(Tensor([2, 1073741825],"float64"), )
[paddle error] paddle.frac(Tensor([2, 1073741825],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:02:54.994423 115565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:02:54.995340 115565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([2, 1073741825],"int64"), )
[torch error] paddle.frac(Tensor([2, 1073741825],"int64"), ) 
 "frac_cuda" not implemented for 'Long'

W0205 12:03:52.188220 115867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:03:52.189406 115867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.frac(Tensor([2, 2147483648],"float32"), )
[paddle error] paddle.frac(Tensor([2, 2147483648],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:05:08.330421 116011 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:05:08.331319 116011 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([2, 2147483648],"int32"), )
[torch error] paddle.frac(Tensor([2, 2147483648],"int32"), ) 
 "frac_cuda" not implemented for 'Int'

W0205 12:06:28.767778 116316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:06:28.768849 116316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.frac(Tensor([214748365, 20, 1],"float32"), )
[paddle error] paddle.frac(Tensor([214748365, 20, 1],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:07:47.022841 116539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:07:47.023852 116539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([715827883, 3],"float64"), )
[paddle error] paddle.frac(Tensor([715827883, 3],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:08:55.316978 116844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:08:55.318405 116844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([715827883, 3],"int64"), )
[torch error] paddle.frac(Tensor([715827883, 3],"int64"), ) 
 "frac_cuda" not implemented for 'Long'

W0205 12:09:53.285336 117162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:09:53.286549 117162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[], fill_value=Tensor([2147483649],"int64"), dtype="int64", )
[torch error] paddle.full(shape=list[], fill_value=Tensor([2147483649],"int64"), dtype="int64", ) 
 full() received an invalid combination of arguments - got (size=list, dtype=str, fill_value=Tensor, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:10:42.311218 117302 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:10:42.312404 117302 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[1,2,], dtype=type(numpy.float32), fill_value=Tensor([4294967295],"float32"), )
[torch error] paddle.full(shape=list[1,2,], dtype=type(numpy.float32), fill_value=Tensor([4294967295],"float32"), ) 
 full() received an invalid combination of arguments - got (size=list, fill_value=Tensor, dtype=type, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:12:00.628000 117509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:12:00.629137 117509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([1],"int64"),Tensor([2147483649],"int64"),], dtype="float32", fill_value=1.1, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([1],"int64"),Tensor([2147483649],"int64"),], dtype="float32", fill_value=1.1, ) 
 full() received an invalid combination of arguments - got (size=list, fill_value=float, dtype=str, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:12:48.818575 117746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:12:48.819897 117746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([2147483649],"int64"),Tensor([1],"int64"),], dtype="float32", fill_value=1.1, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([2147483649],"int64"),Tensor([1],"int64"),], dtype="float32", fill_value=1.1, ) 
 full() received an invalid combination of arguments - got (size=list, fill_value=float, dtype=str, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:13:42.009397 117939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:13:42.010499 117939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=0.0, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=0.0, ) 
 full(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got Tensor"

W0205 12:14:56.977483 118149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:14:56.978766 118149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=10000000000, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=10000000000, ) 
 full(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got Tensor"

W0205 12:16:12.649624 118386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:16:12.651204 118386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=3, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=3, ) 
 full(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got Tensor"

W0205 12:17:24.968112 118690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:17:24.969276 118690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=3.8, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=3.8, ) 
 full(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got Tensor"

W0205 12:18:43.192466 118915 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:18:43.193677 118915 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=0.0, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=0.0, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:19:56.667356 119219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:19:56.668926 119219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=10000000000, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=10000000000, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:21:15.867952 119442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:21:15.869071 119442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=3, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=3, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:22:27.967139 119748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:22:27.968420 119748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=3.8, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=3.8, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:23:40.636722 119972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:23:40.638064 119972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int64"),Tensor([1],"int64"),], dtype="float32", fill_value=1.1, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int64"),Tensor([1],"int64"),], dtype="float32", fill_value=1.1, ) 
 full() received an invalid combination of arguments - got (size=list, fill_value=float, dtype=str, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:25:03.782053 120277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:25:03.783108 120277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], dtype="float32", fill_value=1.1, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], dtype="float32", fill_value=1.1, ) 
 full() received an invalid combination of arguments - got (size=list, fill_value=float, dtype=str, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:27:38.170979 120649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:27:38.175508 120649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=0.0, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=0.0, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:30:09.933748 121185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:30:09.934813 121185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=10000000000, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=10000000000, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:32:38.430732 121687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:32:38.431929 121687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=3, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=3, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:34:48.174964 122169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:34:48.176666 122169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=3.8, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=3.8, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:37:08.003952 122575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:37:08.005003 122575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([2],"int32"), fill_value=Tensor([4294967295],"float32"), )
[torch error] paddle.full(shape=Tensor([2],"int32"), fill_value=Tensor([4294967295],"float32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:38:24.766884 123049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:38:24.768309 123049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([2],"int32"), fill_value=Tensor([4294967295],"int32"), )
[torch error] paddle.full(shape=Tensor([2],"int32"), fill_value=Tensor([4294967295],"int32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:39:43.926926 123290 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:39:43.928146 123290 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), dtype="float32", fill_value=1.1, )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), dtype="float32", fill_value=1.1, ) 
 full() received an invalid combination of arguments - got (size=Tensor, fill_value=float, dtype=str, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:41:05.304008 123569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:41:05.304994 123569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), fill_value=3.8, )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), fill_value=3.8, ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:42:20.005136 123859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:42:20.006134 123859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([1],"float32"), )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([1],"float32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:43:38.111702 124082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:43:38.112672 124082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([1],"int32"), )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([1],"int32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:44:57.246291 124372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:44:57.248374 124372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([4294967295],"float32"), )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([4294967295],"float32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:47:11.432245 124597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:47:11.433305 124597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([4294967295],"int32"), )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([4294967295],"int32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:49:31.937192 125080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:49:31.938398 125080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1, 1048576, 4096],"float32"), 1, )
[accuracy error] paddle.full_like(Tensor([1, 1048576, 4096],"float32"), 1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],...

W0205 12:50:53.302937 125485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:50:53.304128 125485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1, 3, 715827883],"float64"), fill_value=1, )
[accuracy error] paddle.full_like(Tensor([1, 3, 715827883],"float64"), fill_value=1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]])
 y: array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.]]])

W0205 12:56:42.646741 126719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:56:42.647991 126719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1, 300, 14316558],"float32"), 1, )
[Pass] paddle.full_like(Tensor([1, 300, 14316558],"float32"), 1, )

W0205 13:01:36.988735 127629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:01:36.989650 127629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1, 4294967295],"float32"), dtype=type(numpy.float32), fill_value=1.1, )
[torch error] paddle.full_like(Tensor([1, 4294967295],"float32"), dtype=type(numpy.float32), fill_value=1.1, ) 
 full_like(): argument 'dtype' must be torch.dtype, not type

W0205 13:05:09.893764 128373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:05:09.894944 128373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1, 536870913, 4],"float64"), fill_value=1, )
[accuracy error] paddle.full_like(Tensor([1, 536870913, 4],"float64"), fill_value=1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],...
 y: array([[[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],...

W0205 13:06:05.285360 128677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:06:05.286260 128677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([10, 214748365],"float64"), 0, )
[Pass] paddle.full_like(Tensor([10, 214748365],"float64"), 0, )

W0205 13:10:31.147292 129496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:10:31.148159 129496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([10, 429496730],"float32"), 0, )
[Pass] paddle.full_like(Tensor([10, 429496730],"float32"), 0, )

W0205 13:14:16.235983 130182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:14:16.237262 130182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1024, 4194304],"float32"), 0.3917133774091194, )
[accuracy error] paddle.full_like(Tensor([1024, 4194304],"float32"), 0.3917133774091194, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 0.39171338
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[0.391713, 0.391713, 0.391713, ..., 0.391713, 0.391713, 0.391713],
       [0.391713, 0.391713, 0.391713, ..., 0.391713, 0.391713, 0.391713],
       [0.391713, 0.391713, 0.391713, ..., 0.391713, 0.391713, 0.391713],...

W0205 13:18:18.103765 131027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:18:18.104651 131027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1073741824, 4],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([1073741824, 4],"float32"), 0.0, )

W0205 13:23:19.550228 132068 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:23:19.551374 132068 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1073741824, 4],"float32"), 3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([1073741824, 4],"float32"), 3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.],...
 y: array([[3.402823e+38, 3.402823e+38, 3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38, 3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38, 3.402823e+38, 3.402823e+38],...

W0205 13:27:05.121788 132819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:27:05.123024 132819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1073741824, 4],"float32"), -3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([1073741824, 4],"float32"), -3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.],...
 y: array([[-3.402823e+38, -3.402823e+38, -3.402823e+38, -3.402823e+38],
       [-3.402823e+38, -3.402823e+38, -3.402823e+38, -3.402823e+38],
       [-3.402823e+38, -3.402823e+38, -3.402823e+38, -3.402823e+38],...

W0205 13:32:44.421094 133883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:32:44.422217 133883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1073741824, 4],"float32"), math.inf, )
[accuracy error] paddle.full_like(Tensor([1073741824, 4],"float32"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.],...
 y: array([[inf, inf, inf, inf],
       [inf, inf, inf, inf],
       [inf, inf, inf, inf],...

W0205 13:38:35.724076 135108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:38:35.724948 135108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1073741824, 4],"float32"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([1073741824, 4],"float32"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.],...
 y: array([[-inf, -inf, -inf, -inf],
       [-inf, -inf, -inf, -inf],
       [-inf, -inf, -inf, -inf],...

W0205 13:40:38.763283 135554 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:40:38.764351 135554 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([107374183, 40],"float32"), 1.0, )
[Pass] paddle.full_like(Tensor([107374183, 40],"float32"), 1.0, )

W0205 13:43:03.336674 136055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:43:03.337559 136055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([107374183, 40],"float32"), -1.0, )
[Pass] paddle.full_like(Tensor([107374183, 40],"float32"), -1.0, )

W0205 13:47:01.637315 136918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:47:01.638656 136918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([114, 18837576],"float64"), 0.0, )
[Pass] paddle.full_like(Tensor([114, 18837576],"float64"), 0.0, )

W0205 13:50:21.286278 137657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:50:21.287201 137657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([114, 18837576],"float64"), 1.7976931348623157e+308, )
[accuracy error] paddle.full_like(Tensor([114, 18837576],"float64"), 1.7976931348623157e+308, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483664 / 2147483664 (100%)
Max absolute difference: 1.79769313e+308
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1.797693e+308, 1.797693e+308, 1.797693e+308, ..., 1.797693e+308,
        1.797693e+308, 1.797693e+308],
       [1.797693e+308, 1.797693e+308, 1.797693e+308, ..., 1.797693e+308,...

W0205 13:53:22.944222 138298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:53:22.945161 138298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([114, 18837576],"float64"), -2.220446049250313e-16, )
[Pass] paddle.full_like(Tensor([114, 18837576],"float64"), -2.220446049250313e-16, )

W0205 13:57:23.625662 139103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:57:23.626681 139103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([114, 18837576],"float64"), math.inf, )
[accuracy error] paddle.full_like(Tensor([114, 18837576],"float64"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[inf, inf, inf, ..., inf, inf, inf],
       [inf, inf, inf, ..., inf, inf, inf],
       [inf, inf, inf, ..., inf, inf, inf],...

W0205 14:00:41.521309 139821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:00:41.522344 139821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([114, 18837576],"float64"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([114, 18837576],"float64"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[-inf, -inf, -inf, ..., -inf, -inf, -inf],
       [-inf, -inf, -inf, ..., -inf, -inf, -inf],
       [-inf, -inf, -inf, ..., -inf, -inf, -inf],...

W0205 14:02:19.574605 140135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:02:19.575538 140135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([128, 33554432],"float16"), 127, )
[accuracy error] paddle.full_like(Tensor([128, 33554432],"float16"), 127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[127., 127., 127., ..., 127., 127., 127.],
       [127., 127., 127., ..., 127., 127., 127.],
       [127., 127., 127., ..., 127., 127., 127.],...

W0205 14:04:38.136649 140553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:04:38.137547 140553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([128, 33554432],"float16"), -127, )
[accuracy error] paddle.full_like(Tensor([128, 33554432],"float16"), -127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[-127., -127., -127., ..., -127., -127., -127.],
       [-127., -127., -127., ..., -127., -127., -127.],
       [-127., -127., -127., ..., -127., -127., -127.],...

W0205 14:18:19.306234 143323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:18:19.307149 143323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([131072, 8, 64, 64],"float16"), 127, )
[accuracy error] paddle.full_like(Tensor([131072, 8, 64, 64],"float16"), 127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[127., 127., 127., ..., 127., 127., 127.],
         [127., 127., 127., ..., 127., 127., 127.],
         [127., 127., 127., ..., 127., 127., 127.],...

W0205 14:31:46.162573 145962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:31:46.163698 145962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([131072, 8, 64, 64],"float16"), -127, )
[accuracy error] paddle.full_like(Tensor([131072, 8, 64, 64],"float16"), -127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[-127., -127., -127., ..., -127., -127., -127.],
         [-127., -127., -127., ..., -127., -127., -127.],
         [-127., -127., -127., ..., -127., -127., -127.],...

W0205 14:45:23.247363 151105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:45:23.248626 151105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([1431655765, 3],"float32"), 0.0, )

W0205 14:58:48.319082 153732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:58:48.319933 153732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 0.5, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), 0.5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 0.5
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[0.5, 0.5, 0.5],
       [0.5, 0.5, 0.5],
       [0.5, 0.5, 0.5],...

W0205 15:02:29.704545 154514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:02:29.705425 154514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 1.0, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[1., 1., 1.],
       [1., 1., 1.],
       [1., 1., 1.],...

W0205 15:07:34.274921 155487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:07:34.275818 155487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), -10.0, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), -10.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 10.
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[-10., -10., -10.],
       [-10., -10., -10.],
       [-10., -10., -10.],...

W0205 15:13:23.985904 156680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:13:23.986799 156680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 100.0, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), 100.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 100.
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[100., 100., 100.],
       [100., 100., 100.],
       [100., 100., 100.],...

W0205 15:19:09.322175 157751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:19:09.323021 157751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 2.0, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), 2.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 2.
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[2., 2., 2.],
       [2., 2., 2.],
       [2., 2., 2.],...

W0205 15:25:01.538748 158966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:25:01.539686 158966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), 3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[3.402823e+38, 3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38, 3.402823e+38],...

W0205 15:29:52.958178 159951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:29:52.959273 159951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), -3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), -3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[-3.402823e+38, -3.402823e+38, -3.402823e+38],
       [-3.402823e+38, -3.402823e+38, -3.402823e+38],
       [-3.402823e+38, -3.402823e+38, -3.402823e+38],...

W0205 15:34:44.036902 160926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:34:44.037786 160926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), fill_value=math.inf, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), fill_value=math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[inf, inf, inf],
       [inf, inf, inf],
       [inf, inf, inf],...

W0205 15:39:34.208461 161917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:39:34.209389 161917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), fill_value=nan, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), fill_value=nan, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y nan location mismatch:
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan],...

W0205 15:41:36.736406 162334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:41:36.737250 162334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), math.inf, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[inf, inf, inf],
       [inf, inf, inf],
       [inf, inf, inf],...

W0205 15:43:29.068573 162849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:43:29.069607 162849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[-inf, -inf, -inf],
       [-inf, -inf, -inf],
       [-inf, -inf, -inf],...

W0205 15:45:42.118121 163723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:45:42.119537 163723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 5, 5804010],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([148, 5, 5804010],"float32"), 0.0, )

W0205 15:48:06.951970   972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:48:06.952914   972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 5, 5804010],"float32"), -1.1920928955078125e-07, )
[Pass] paddle.full_like(Tensor([148, 5, 5804010],"float32"), -1.1920928955078125e-07, )

W0205 15:51:57.562817  2063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:51:57.563980  2063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 5, 5804010],"float32"), 3.4028234663852886e+38, )
[Pass] paddle.full_like(Tensor([148, 5, 5804010],"float32"), 3.4028234663852886e+38, )

W0205 15:55:35.421103  3018 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:55:35.422358  3018 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 5, 5804010],"float32"), math.inf, )
[Pass] paddle.full_like(Tensor([148, 5, 5804010],"float32"), math.inf, )

W0205 15:59:23.838184  4140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:59:23.839053  4140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 5, 5804010],"float32"), -math.inf, )
[Pass] paddle.full_like(Tensor([148, 5, 5804010],"float32"), -math.inf, )

W0205 16:01:52.105823  4853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:01:52.107071  4853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 9673350, 3],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([148, 9673350, 3],"float32"), 0.0, )

W0205 16:04:26.838492  5541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:04:26.839462  5541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 9673350, 3],"float32"), -1.1920928955078125e-07, )
[Pass] paddle.full_like(Tensor([148, 9673350, 3],"float32"), -1.1920928955078125e-07, )

W0205 16:07:57.766391  6622 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:07:57.767305  6622 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 9673350, 3],"float32"), 3.4028234663852886e+38, )
[Pass] paddle.full_like(Tensor([148, 9673350, 3],"float32"), 3.4028234663852886e+38, )

W0205 16:11:51.304536  7647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:11:51.305852  7647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 9673350, 3],"float32"), math.inf, )
[Pass] paddle.full_like(Tensor([148, 9673350, 3],"float32"), math.inf, )

W0205 16:15:30.908772  8911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:15:30.909633  8911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 9673350, 3],"float32"), -math.inf, )
[Pass] paddle.full_like(Tensor([148, 9673350, 3],"float32"), -math.inf, )

W0205 16:18:17.044785  9651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:18:17.045994  9651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([16, 134217729],"float64"), 1.0, )
[accuracy error] paddle.full_like(Tensor([16, 134217729],"float64"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483664 / 2147483664 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0205 16:20:05.111203 10316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:20:05.112205 10316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([16, 134217729],"float64"), 1e-20, )
[Pass] paddle.full_like(Tensor([16, 134217729],"float64"), 1e-20, )

W0205 16:23:54.243057 11291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:23:54.243945 11291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([16, 268435456],"float32"), 1.0, )
[accuracy error] paddle.full_like(Tensor([16, 268435456],"float32"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0205 16:27:15.887393 12108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:27:15.888312 12108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([16, 268435456],"float32"), 1e-20, )
[Pass] paddle.full_like(Tensor([16, 268435456],"float32"), 1e-20, )

W0205 16:31:52.069772 13368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:31:52.070665 13368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([178956971, 12],"float64"), 0, )
[Pass] paddle.full_like(Tensor([178956971, 12],"float64"), 0, )

W0205 16:35:00.969976 14331 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:35:00.970966 14331 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([178956971, 3, 4],"float64"), fill_value=1, )
[accuracy error] paddle.full_like(Tensor([178956971, 3, 4],"float64"), fill_value=1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]],...
 y: array([[[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]],...

W0205 16:38:11.821329 15276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:38:11.822186 15276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"float16"), 0.0, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"float16"), 0.0, None, None, )

W0205 16:42:48.397490 16401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:42:48.398450 16401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"float32"), 0.0, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"float32"), 0.0, None, None, )

W0205 16:51:57.438918 18926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:51:57.440254 18926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"float32"), 0.0, VarType(bfloat16), None, )
[torch error] paddle.full_like(Tensor([18512791, 232],"float32"), 0.0, VarType(bfloat16), None, ) 
 full_like(): argument 'dtype' must be torch.dtype, not paddle.base.libpaddle.VarType

W0205 16:55:53.557799 20042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:55:53.559057 20042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, Dtype(int16), None, )
[torch error] paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, Dtype(int16), None, ) 
 full_like(): argument 'dtype' must be torch.dtype, not paddle.base.libpaddle.DataType

W0205 16:57:14.363988 20460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:57:14.365316 20460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, None, None, )

W0205 16:58:36.671198 20874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:58:36.672107 20874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, VarType(float32), None, )
[torch error] paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, VarType(float32), None, ) 
 full_like(): argument 'dtype' must be torch.dtype, not paddle.base.libpaddle.VarType

W0205 17:03:14.537645 22116 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:03:14.539013 22116 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 1.0, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"int32"), 1.0, None, None, )

W0205 17:04:39.477973 22521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:04:39.478798 22521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 1e-10, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"int32"), 1e-10, None, None, )

W0205 17:09:42.736984 23877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:09:42.737793 23877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

