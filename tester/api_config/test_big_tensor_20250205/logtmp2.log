test begin: paddle.concat(list[Tensor([2, 2400, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2400, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:04:41.490787 89776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:04:41.491719 89776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2400, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2400, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 10:05:50.592636 90057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:05:50.593668 90057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 126145, 7],"float32"),Tensor([2, 32, 126145, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2432, 126145, 7],"float32"),Tensor([2, 32, 126145, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000066GB memory on GPU 0, 66.998962GB memory has been allocated and available memory is only 12.185913GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:07:22.244257 90273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:07:22.245216 90273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 126145, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2432, 126145, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 126145 but got size 7 for tensor number 1 in the list.

W0205 10:08:37.933750 90572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:08:37.934710 90572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 126145],"float32"),Tensor([2, 32, 7, 126145],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2432, 7, 126145],"float32"),Tensor([2, 32, 7, 126145],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000066GB memory on GPU 0, 66.998962GB memory has been allocated and available memory is only 12.185913GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:10:11.220494 90843 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:10:11.221350 90843 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 126145],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2432, 7, 126145],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 126145 but got size 7 for tensor number 1 in the list.

W0205 10:11:22.454114 91171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:11:22.455374 91171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:12:46.026369 91377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:12:46.027575 91377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:14:02.286037 91661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:14:02.287343 91661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:15:37.887555 91942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:15:37.888525 91942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 10:16:51.161572 92245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:16:51.162578 92245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:18:21.902828 92467 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:18:21.904009 92467 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 244, 14, 628655],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 244, 14, 628655],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 628655 for tensor number 1 in the list.

W0205 10:19:37.579888 92810 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:19:37.580889 92810 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 244, 628655, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 244, 628655, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 628655 for tensor number 1 in the list.

W0205 10:20:59.724485 93114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:20:59.725574 93114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([89808, 244, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([89808, 244, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 89808 for tensor number 1 in the list.

W0205 10:22:16.157547 93410 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:22:16.158630 93410 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 628655],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 14, 628655],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 628655 but got size 14 for tensor number 1 in the list.

W0205 10:23:31.263243 93618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:23:31.264236 93618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 628655],"float32"),Tensor([2, 244, 14, 628655],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 14, 628655],"float32"),Tensor([2, 244, 14, 628655],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 147094 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:25:46.081866 93927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:25:46.082998 93927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 628655, 14],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 628655, 14],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 628655 but got size 14 for tensor number 1 in the list.

W0205 10:27:00.668653 94329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:27:00.669631 94329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 628655, 14],"float32"),Tensor([2, 244, 628655, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 628655, 14],"float32"),Tensor([2, 244, 628655, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 130498 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:29:14.333348 94632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:29:14.334450 94632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 124507, 7],"float32"),Tensor([2, 32, 124507, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2464, 124507, 7],"float32"),Tensor([2, 32, 124507, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000098GB memory on GPU 0, 66.995056GB memory has been allocated and available memory is only 12.189819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:30:42.532877 95070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:30:42.533866 95070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 124507, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2464, 124507, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 124507 but got size 7 for tensor number 1 in the list.

W0205 10:31:53.048576 95427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:31:53.050395 95427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 124507],"float32"),Tensor([2, 32, 7, 124507],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2464, 7, 124507],"float32"),Tensor([2, 32, 7, 124507],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000098GB memory on GPU 0, 66.995056GB memory has been allocated and available memory is only 12.189819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:33:25.677453 95625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:33:25.679683 95625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 124507],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2464, 7, 124507],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 124507 but got size 7 for tensor number 1 in the list.

W0205 10:34:35.224934 95939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:34:35.226089 95939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:35:56.833356 96249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:35:56.834596 96249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:37:14.769445 96462 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:37:14.770562 96462 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:38:45.761250 96777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:38:45.762176 96777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 10:39:54.998947 97071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:39:55.000339 97071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 122911, 7],"float32"),Tensor([2, 32, 122911, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2496, 122911, 7],"float32"),Tensor([2, 32, 122911, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000129GB memory on GPU 0, 66.991150GB memory has been allocated and available memory is only 12.193726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:41:27.294358 97267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:41:27.296954 97267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 122911, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2496, 122911, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 122911 but got size 7 for tensor number 1 in the list.

W0205 10:42:37.550289 97585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:42:37.551601 97585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 122911],"float32"),Tensor([2, 32, 7, 122911],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2496, 7, 122911],"float32"),Tensor([2, 32, 7, 122911],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000129GB memory on GPU 0, 66.991150GB memory has been allocated and available memory is only 12.193726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:44:18.065280 97876 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:44:18.066120 97876 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 122911],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2496, 7, 122911],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 122911 but got size 7 for tensor number 1 in the list.

W0205 10:45:26.600279 98194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:45:26.601428 98194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:46:50.618084 98390 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:46:50.619202 98390 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:48:10.644975 98695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:48:10.645961 98695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:49:40.009840 99001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:49:40.010722 99001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 10:50:55.090253 99292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:50:55.091416 99292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 121355, 7],"float32"),Tensor([2, 32, 121355, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2528, 121355, 7],"float32"),Tensor([2, 32, 121355, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000108GB memory on GPU 0, 66.983337GB memory has been allocated and available memory is only 12.201538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:52:28.327842 99529 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:52:28.328924 99529 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 121355, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2528, 121355, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 121355 but got size 7 for tensor number 1 in the list.

W0205 10:53:35.770176 99834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:53:35.771561 99834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 121355],"float32"),Tensor([2, 32, 7, 121355],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2528, 7, 121355],"float32"),Tensor([2, 32, 7, 121355],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000108GB memory on GPU 0, 66.983337GB memory has been allocated and available memory is only 12.201538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:55:08.743852 100138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:55:08.744729 100138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 121355],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2528, 7, 121355],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 121355 but got size 7 for tensor number 1 in the list.

W0205 10:56:17.879434 100445 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:56:17.880623 100445 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:57:32.270190 100667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:57:32.271163 100667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:58:51.816639 100944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:58:51.817731 100944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:00:22.897120 101161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:00:22.898370 101161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 11:01:32.152940 101482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:01:32.153941 101482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([116509, 256, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([116509, 256, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 116509 for tensor number 1 in the list.

W0205 11:02:51.176360 101795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:02:51.177570 101795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 14913081, 12, 12],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 14913081, 12, 12],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:04:20.919499 102078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:04:20.920500 102078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 256, 12, 699051],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 256, 12, 699051],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 12 but got size 699051 for tensor number 1 in the list.

W0205 11:05:36.248991 102532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:05:36.250573 102532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 256, 699051, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 256, 699051, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 12 but got size 699051 for tensor number 1 in the list.

W0205 11:06:51.227622 102925 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:06:51.228660 102925 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 699051],"float32"),Tensor([2, 256, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 12, 699051],"float32"),Tensor([2, 256, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 699051 but got size 12 for tensor number 1 in the list.

W0205 11:08:16.046947 103245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:08:16.047868 103245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 699051],"float32"),Tensor([2, 256, 12, 699051],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 12, 699051],"float32"),Tensor([2, 256, 12, 699051],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 20012 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:10:46.865589 103708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:10:46.873392 103708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:12:21.864650 104372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:12:21.865511 104372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:13:51.258903 104695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:13:51.259773 104695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 256, 13, 645278],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 256, 13, 645278],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 645278 for tensor number 1 in the list.

W0205 11:15:04.458618 105054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:15:04.459926 105054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 256, 645278, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 256, 645278, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 645278 for tensor number 1 in the list.

W0205 11:16:20.896960 105358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:16:20.897960 105358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([198547, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([198547, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 198547 for tensor number 2 in the list.

W0205 11:17:40.975574 105589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:17:40.976966 105589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:19:11.009383 105943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:19:11.010530 105943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 1290556, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 1290556, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 1290556 for tensor number 2 in the list.

W0205 11:20:28.955976 106248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:20:28.957119 106248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 1290556],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 1290556],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 1290556 for tensor number 2 in the list.

W0205 11:21:44.884337 106569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:21:44.885440 106569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([198547, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([198547, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 198547 for tensor number 3 in the list.

W0205 11:23:00.489992 106888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:23:00.490975 106888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:24:36.269047 107251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:24:36.269979 107251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 1290556, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 1290556, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 1290556 for tensor number 3 in the list.

W0205 11:25:46.599086 107603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:25:46.600185 107603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 1290556],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 1290556],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 1290556 for tensor number 3 in the list.

W0205 11:27:08.468979 107815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:27:08.470089 107815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 516223],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 516223],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 516223 for tensor number 1 in the list.

W0205 11:28:22.771024 108133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:28:22.771983 108133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 516223, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 516223, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 516223 for tensor number 1 in the list.

W0205 11:29:45.474067 108343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:29:45.475137 108343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([79419, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([79419, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 79419 for tensor number 1 in the list.

W0205 11:31:00.516464 108664 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:31:00.517448 108664 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([99274, 256, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([99274, 256, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 99274 for tensor number 1 in the list.

W0205 11:32:14.418469 108942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:32:14.419499 108942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 645278 but got size 13 for tensor number 1 in the list.

W0205 11:33:30.820067 109176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:33:30.821180 109176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 256, 13, 645278],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 256, 13, 645278],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 74497 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:36:01.850200 109481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:36:01.851205 109481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 645278 but got size 13 for tensor number 1 in the list.

W0205 11:37:19.638908 109968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:37:19.660076 109968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 320, 13, 645278],"float32"),Tensor([2, 128, 13, 645278],"float32"),Tensor([2, 128, 13, 645278],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 320, 13, 645278],"float32"),Tensor([2, 128, 13, 645278],"float32"),Tensor([2, 128, 13, 645278],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 115555 has 45.00 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, and 5.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:41:07.854933 110191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:41:07.856053 110191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 1398102, 6],"float32"),Tensor([2, 320, 1398102, 6],"float32"),Tensor([2, 128, 1398102, 6],"float32"),Tensor([2, 128, 1398102, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 1398102, 6],"float32"),Tensor([2, 320, 1398102, 6],"float32"),Tensor([2, 128, 1398102, 6],"float32"),Tensor([2, 128, 1398102, 6],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 11847 has 45.00 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:44:52.674039 110987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:44:52.676963 110987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 1398102, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 1398102, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1398102 but got size 6 for tensor number 1 in the list.

W0205 11:46:17.608805 111723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:46:17.610232 111723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:47:47.643743 112029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:47:47.644726 112029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 11:48:58.348306 112362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:48:58.349334 112362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 11:50:21.208323 112572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:50:21.209545 112572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 11:51:40.283525 112877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:51:40.284775 112877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 599187],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 14, 599187],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 599187 but got size 14 for tensor number 1 in the list.

W0205 11:53:06.645308 113211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:53:06.646523 113211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 599187],"float32"),Tensor([2, 32, 14, 599187],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 14, 599187],"float32"),Tensor([2, 32, 14, 599187],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:54:46.969012 113532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:54:46.971644 113532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 256, 26, 322639],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 256, 26, 322639],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 26 but got size 322639 for tensor number 1 in the list.

W0205 11:56:04.964104 113853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:56:04.965267 113853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 256, 322639, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 256, 322639, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 26 but got size 322639 for tensor number 1 in the list.

W0205 11:57:21.163703 114143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:57:21.164896 114143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 3176751, 26, 26],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 3176751, 26, 26],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:58:52.692756 114393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:58:52.694242 114393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([24819, 256, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([24819, 256, 26, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 24819 for tensor number 1 in the list.

W0205 12:00:01.083015 114833 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:00:01.084160 114833 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 322639],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 26, 322639],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 322639 but got size 26 for tensor number 1 in the list.

W0205 12:01:18.076074 115235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:01:18.077450 115235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 322639],"float32"),Tensor([2, 256, 26, 322639],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 26, 322639],"float32"),Tensor([2, 256, 26, 322639],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 65190 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:03:41.436349 115467 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:03:41.437441 115467 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 12:05:02.865137 115997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:05:02.866418 115997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:06:41.294332 116301 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:06:41.295603 116301 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 12:07:52.820551 116633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:07:52.821782 116633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 12:09:09.660706 116867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:09:09.661883 116867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 299594],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 28, 299594],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 299594 but got size 28 for tensor number 1 in the list.

W0205 12:10:40.083469 117177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:10:40.100169 117177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 299594],"float32"),Tensor([2, 32, 28, 299594],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 28, 299594],"float32"),Tensor([2, 32, 28, 299594],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000046GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:12:29.524408 117520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:12:29.525381 117520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 299594, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 299594, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 299594 but got size 28 for tensor number 1 in the list.

W0205 12:13:40.663499 117844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:13:40.664564 117844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 299594, 28],"float32"),Tensor([2, 32, 299594, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 299594, 28],"float32"),Tensor([2, 32, 299594, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000046GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:15:19.234144 118154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:15:19.235231 118154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 322639, 26],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 322639, 26],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 322639 but got size 26 for tensor number 1 in the list.

W0205 12:16:38.091931 118483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:16:38.093130 118483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 322639, 26],"float32"),Tensor([2, 256, 322639, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 322639, 26],"float32"),Tensor([2, 256, 322639, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 163384 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:19:03.331729 118802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:19:03.332891 118802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 599187, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 599187, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 599187 but got size 14 for tensor number 1 in the list.

W0205 12:20:30.033885 119315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:20:30.035028 119315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 599187, 14],"float32"),Tensor([2, 32, 599187, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 599187, 14],"float32"),Tensor([2, 32, 599187, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:22:18.536039 119649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:22:18.536998 119649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 1398102],"float32"),Tensor([2, 320, 6, 1398102],"float32"),Tensor([2, 128, 6, 1398102],"float32"),Tensor([2, 128, 6, 1398102],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 1398102],"float32"),Tensor([2, 320, 6, 1398102],"float32"),Tensor([2, 128, 6, 1398102],"float32"),Tensor([2, 128, 6, 1398102],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 105249 has 45.00 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:25:41.917444 119944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:25:41.918576 119944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 1398102],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 1398102],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1398102 but got size 6 for tensor number 1 in the list.

W0205 12:27:09.171833 120783 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:27:09.172816 120783 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 1118482, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 1118482, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 1118482 for tensor number 1 in the list.

W0205 12:28:28.896307 121074 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:28:28.897505 121074 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 1118482],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 1118482],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 1118482 for tensor number 1 in the list.

W0205 12:29:52.874212 121366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:29:52.875514 121366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 2 in the list.

W0205 12:31:10.366369 121563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:31:10.367507 121563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 2 in the list.

W0205 12:32:34.384079 121869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:32:34.385288 121869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 3 in the list.

W0205 12:33:57.886493 122159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:33:57.887745 122159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 3 in the list.

W0205 12:35:20.605185 122382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:35:20.606667 122382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:36:58.067998 122674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:36:58.069187 122674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 932068 for tensor number 3 in the list.

W0205 12:38:12.582800 122954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:38:12.583974 122954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:39:49.021397 123259 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:39:49.022281 123259 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 932068 for tensor number 2 in the list.

W0205 12:41:06.744767 123582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:41:06.745829 123582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:42:38.796976 123872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:42:38.798154 123872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([372828, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([372828, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 372828 for tensor number 1 in the list.

W0205 12:43:55.652938 124177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:43:55.654175 124177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 645278 but got size 13 for tensor number 1 in the list.

W0205 12:45:15.202309 124387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:45:15.203285 124387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 256, 645278, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 256, 645278, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 91800 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:47:47.668007 124693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:47:47.669021 124693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 645278 but got size 13 for tensor number 1 in the list.

W0205 12:49:13.414384 125193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:49:13.415179 125193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 320, 645278, 13],"float32"),Tensor([2, 128, 645278, 13],"float32"),Tensor([2, 128, 645278, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 320, 645278, 13],"float32"),Tensor([2, 128, 645278, 13],"float32"),Tensor([2, 128, 645278, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 138052 has 45.00 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, and 5.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:52:50.273762 125471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:52:50.274773 125471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 699051, 12],"float32"),Tensor([2, 256, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 699051, 12],"float32"),Tensor([2, 256, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 699051 but got size 12 for tensor number 1 in the list.

W0205 12:54:07.434866 126138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:54:07.435999 126138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 699051, 12],"float32"),Tensor([2, 256, 699051, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 699051, 12],"float32"),Tensor([2, 256, 699051, 12],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 43758 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:56:37.906842 126427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:56:37.907971 126427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 119838, 7],"float32"),Tensor([2, 32, 119838, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2560, 119838, 7],"float32"),Tensor([2, 32, 119838, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 66.979431GB memory has been allocated and available memory is only 12.205444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:58:44.616232 126926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:58:44.617048 126926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 119838, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2560, 119838, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 119838 but got size 7 for tensor number 1 in the list.

W0205 13:00:10.976326 127324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:00:10.978061 127324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 119838],"float32"),Tensor([2, 32, 7, 119838],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2560, 7, 119838],"float32"),Tensor([2, 32, 7, 119838],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 66.979431GB memory has been allocated and available memory is only 12.205444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:01:41.634253 127616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:01:41.635203 127616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 119838],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2560, 7, 119838],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 119838 but got size 7 for tensor number 1 in the list.

W0205 13:02:48.712298 127942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:02:48.714275 127942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:04:09.470252 128151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:04:09.471416 128151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:05:24.456655 128468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:05:24.457671 128468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:07:02.420539 128692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:07:02.421918 128692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 13:08:20.051234 128997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:08:20.052309 128997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 118358, 7],"float32"),Tensor([2, 32, 118358, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2592, 118358, 7],"float32"),Tensor([2, 32, 118358, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 66.975525GB memory has been allocated and available memory is only 12.209351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:10:00.423848 129288 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:10:00.424736 129288 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 118358, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2592, 118358, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 118358 but got size 7 for tensor number 1 in the list.

W0205 13:11:27.082067 129593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:11:27.083120 129593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 118358],"float32"),Tensor([2, 32, 7, 118358],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2592, 7, 118358],"float32"),Tensor([2, 32, 7, 118358],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 66.975525GB memory has been allocated and available memory is only 12.209351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:12:59.503046 129873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:12:59.505394 129873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 118358],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2592, 7, 118358],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 118358 but got size 7 for tensor number 1 in the list.

W0205 13:14:13.725395 130201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:14:13.726475 130201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:15:34.920887 130501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:15:34.922068 130501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:16:54.768612 130804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:16:54.769822 130804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:18:30.929071 131056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:18:30.930029 131056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 13:19:47.246198 131348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:19:47.247423 131348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 262144, 128, 64],"float16"),Tensor([2, 262144, 1, 64],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 262144, 128, 64],"float16"),Tensor([2, 262144, 1, 64],"float16"),], axis=2, )

W0205 13:21:28.338740 131652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:21:28.340335 131652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 262144, 128, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 262144, 128, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 262144 but got size 8 for tensor number 1 in the list.

W0205 13:30:41.006139 133499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:30:41.007284 133499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 116915, 7],"float32"),Tensor([2, 32, 116915, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2624, 116915, 7],"float32"),Tensor([2, 32, 116915, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000082GB memory on GPU 0, 66.967712GB memory has been allocated and available memory is only 12.217163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:32:22.201395 133776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:32:22.202528 133776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 116915, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2624, 116915, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 116915 but got size 7 for tensor number 1 in the list.

W0205 13:33:39.107049 134094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:33:39.108148 134094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 116915],"float32"),Tensor([2, 32, 7, 116915],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2624, 7, 116915],"float32"),Tensor([2, 32, 7, 116915],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000082GB memory on GPU 0, 66.967712GB memory has been allocated and available memory is only 12.217163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:35:20.013082 134386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:35:20.015460 134386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 116915],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2624, 7, 116915],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 116915 but got size 7 for tensor number 1 in the list.

W0205 13:36:32.375223 134719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:36:32.377877 134719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:37:47.039417 135010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:37:47.040829 135010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:39:03.381398 135232 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:39:03.382781 135232 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:40:37.999650 135538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:40:38.000541 135538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 13:41:55.122406 135844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:41:55.123941 135844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 115506, 7],"float32"),Tensor([2, 32, 115506, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2656, 115506, 7],"float32"),Tensor([2, 32, 115506, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 66.963806GB memory has been allocated and available memory is only 12.221069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:43:36.633478 136083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:43:36.634281 136083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 115506, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2656, 115506, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 115506 but got size 7 for tensor number 1 in the list.

W0205 13:44:46.202508 136487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:44:46.203552 136487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 115506],"float32"),Tensor([2, 32, 7, 115506],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2656, 7, 115506],"float32"),Tensor([2, 32, 7, 115506],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 66.963806GB memory has been allocated and available memory is only 12.221069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:46:20.310261 136696 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:46:20.311334 136696 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 115506],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2656, 7, 115506],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 115506 but got size 7 for tensor number 1 in the list.

W0205 13:47:36.383666 137016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:47:36.384618 137016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:48:56.238644 137333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:48:56.240135 137333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:50:18.180235 137558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:50:18.181645 137558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:51:57.013082 137865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:51:57.014111 137865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 13:53:13.449033 138174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:53:13.450163 138174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:54:52.489068 138493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:54:52.490018 138493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 87633 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:57:00.703630 138799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:57:00.704658 138799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 26920 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:00:20.887295 139286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:00:20.888460 139286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 268435456 but got size 8 for tensor number 1 in the list.

W0205 14:01:41.302246 139947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:01:41.303421 139947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 112, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 112, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:03:16.532773 140261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:03:16.533661 140261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 12, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 12, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:04:48.439167 140579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:04:48.440126 140579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 16, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 16, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:06:16.738976 140872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:06:16.739886 140872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 24, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 24, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:07:43.404860 141164 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:07:43.405774 141164 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 41384 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:10:15.664191 141494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:10:15.665395 141494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:11:48.456804 141956 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:11:48.457661 141956 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:13:21.474058 142309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:13:21.475052 142309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 58, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 58, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:14:47.047461 142617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:14:47.048261 142617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 88, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 88, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:16:16.764703 142908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:16:16.765718 142908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 133153, 56],"float32"),Tensor([2, 48, 133153, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 133153, 56],"float32"),Tensor([2, 48, 133153, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:18:00.741652 143200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:18:00.742493 143200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 133153, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 133153, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 133153 but got size 56 for tensor number 1 in the list.

W0205 14:19:10.336166 143535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:19:10.337338 143535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:20:38.110592 143838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:20:38.111496 143838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 14:21:47.408006 144130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:21:47.408980 144130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 14:23:15.237429 144325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:23:15.238652 144325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 14:24:39.794456 144615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:24:39.795647 144615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 532611],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 14, 532611],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 532611 but got size 14 for tensor number 1 in the list.

W0205 14:25:56.622778 144893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:25:56.623970 144893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 532611],"float32"),Tensor([2, 32, 14, 532611],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 14, 532611],"float32"),Tensor([2, 32, 14, 532611],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:27:33.096263 145089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:27:33.097240 145089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 32, 266306, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 32, 266306, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:29:11.803934 145381 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:29:11.804824 145381 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 28 for tensor number 1 in the list.

W0205 14:30:21.563694 145752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:30:21.565086 145752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 48, 266306, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 48, 266306, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:32:11.150291 145976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:32:11.152541 145976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 28 for tensor number 1 in the list.

W0205 14:33:20.286223 146345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:33:20.292788 146345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 32, 28, 266306],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 32, 28, 266306],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 70.137634GB memory has been allocated and available memory is only 9.047241GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:35:02.712790 146670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:35:02.713840 146670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 28 for tensor number 1 in the list.

W0205 14:36:22.100405 147656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:36:22.101244 147656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 48, 28, 266306],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 48, 28, 266306],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:38:22.747893 148055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:38:22.748843 148055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 28 for tensor number 1 in the list.

W0205 14:39:40.047263 149319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:39:40.048463 149319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0205 14:40:54.321316 150321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:40:54.322463 150321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 14:42:11.519626 150531 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:42:11.520825 150531 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:43:40.679198 150813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:43:40.680058 150813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 14:44:50.176496 151090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:44:50.177556 151090 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 14:46:04.843008 151313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:46:04.844147 151313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 14:47:27.713495 151590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:47:27.714670 151590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 14:48:42.385267 151787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:48:42.386546 151787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 532611, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 532611, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 532611 but got size 14 for tensor number 1 in the list.

W0205 14:49:58.868003 152077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:49:58.869516 152077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 532611, 14],"float32"),Tensor([2, 32, 532611, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 532611, 14],"float32"),Tensor([2, 32, 532611, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:51:38.970201 152286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:51:38.973749 152286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 133153],"float32"),Tensor([2, 48, 56, 133153],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 56, 133153],"float32"),Tensor([2, 48, 56, 133153],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:53:14.500275 152644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:53:14.501236 152644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 133153],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 56, 133153],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 133153 but got size 56 for tensor number 1 in the list.

W0205 14:54:23.502254 152937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:54:23.503259 152937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 48, 56, 798916],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 48, 56, 798916],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 798916 for tensor number 1 in the list.

W0205 14:55:36.270388 153134 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:55:36.271512 153134 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 48, 798916, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 48, 798916, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 798916 for tensor number 1 in the list.

W0205 14:56:50.946142 153411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:56:50.947371 153411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000016GB memory on GPU 0, 66.612244GB memory has been allocated and available memory is only 12.572632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:58:23.146385 153634 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:58:23.147257 153634 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([28533, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([28533, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 28533 for tensor number 1 in the list.

W0205 14:59:34.345784 153923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:59:34.346999 153923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:01:06.159561 154221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:01:06.160634 154221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:02:31.890985 154500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:02:31.891883 154500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:03:58.873173 154735 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:03:58.874043 154735 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 72796 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:06:22.938257 155025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:06:22.939260 155025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 17515 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:09:52.681571 155513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:09:52.682693 155513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 715827883 for tensor number 1 in the list.

W0205 15:11:26.109726 156212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:11:26.110972 156212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([2, 536870912, 4],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([2, 536870912, 4],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:13:06.483448 156489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:13:06.484452 156489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([357913942, 3, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([357913942, 3, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 357913942 for tensor number 1 in the list.

W0205 15:14:19.086810 156890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:14:19.087946 156890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 715827883 but got size 4 for tensor number 1 in the list.

W0205 15:15:33.738482 157086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:15:33.739835 157086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 61111 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:17:55.005237 157375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:17:55.006289 157375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:19:02.997399 157771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:19:02.998550 157771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),], )
[torch error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 3 but got size 1073741825 for tensor number 1 in the list.

W0205 15:19:53.481817 157975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:19:53.482995 157975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:21:07.262290 158181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:21:07.263187 158181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], )
[torch error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 3 but got size 1073741825 for tensor number 2 in the list.

W0205 15:21:56.093554 158453 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:21:56.094652 158453 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:23:02.101172 158565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:23:02.102088 158565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], )
[paddle error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:24:05.067617 158761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:24:05.068490 158761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 715827883 for tensor number 2 in the list.

W0205 15:24:52.109553 159075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:24:52.110719 159075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 715827883 for tensor number 1 in the list.

W0205 15:25:49.277808 159177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:25:49.278965 159177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),], )
[paddle error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:26:56.191728 159370 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:26:56.192608 159370 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 715827883 for tensor number 1 in the list.

W0205 15:27:51.613700 159579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:27:51.614957 159579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 128, 26, 26],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 128, 26, 26],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:29:30.512063 159774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:29:30.514183 159774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 192, 26, 26],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 192, 26, 26],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:30:58.928316 160065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:30:58.929194 160065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:32:25.603988 160405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:32:25.604820 160405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 3176751, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 3176751, 26, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 106705 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:34:34.037369 160716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:34:34.038426 160716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:36:12.332023 161219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:36:12.333025 161219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 15:37:27.487785 161497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:37:27.489061 161497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 15:38:42.578354 161711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:38:42.579368 161711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 15:40:04.088513 162037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:40:04.089792 162037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 4793491],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 14, 4793491],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4793491 but got size 14 for tensor number 1 in the list.

W0205 15:41:29.592964 162320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:41:29.594211 162320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 4793491],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 14, 4793491],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 3151 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:43:52.584667 162673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:43:52.585779 162673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([1048576, 32, 1, 128],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([1048576, 32, 1, 128],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2 but got size 1048576 for tensor number 1 in the list.

W0205 15:45:27.882597 163587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:45:27.883630 163587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 16777216, 1, 128],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 16777216, 1, 128],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 32 but got size 16777216 for tensor number 1 in the list.

W0205 15:47:05.375339   566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:47:05.376559   566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 32, 1, 67108864],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 32, 1, 67108864],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 128 but got size 67108864 for tensor number 1 in the list.

W0205 15:48:36.063030  1036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:48:36.064127  1036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 32, 524288, 128],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 32, 524288, 128],"float16"),], axis=2, )

W0205 15:50:10.961365  1472 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:50:10.962404  1472 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 2097152],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 32, 32, 2097152],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2097152 but got size 128 for tensor number 1 in the list.

W0205 15:59:13.758738  4025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:59:13.759835  4025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 2097152],"float16"),Tensor([2, 32, 1, 2097152],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 32, 32, 2097152],"float16"),Tensor([2, 32, 1, 2097152],"float16"),], axis=2, )

W0205 16:00:52.241819  4551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:00:52.242729  4551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 4793491, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 4793491, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4793491 but got size 14 for tensor number 1 in the list.

W0205 16:09:56.437563  7076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:09:56.438652  7076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 4793491, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 4793491, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 140975 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:12:11.556560  7482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:12:11.566474  7482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 524288, 128],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 32, 524288, 128],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, )

W0205 16:13:47.415897  8283 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:13:47.416803  8283 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 524288, 128],"float16"),Tensor([2, 32, 524288, 128],"float16"),], axis=2, )
[paddle error] paddle.concat(list[Tensor([2, 32, 524288, 128],"float16"),Tensor([2, 32, 524288, 128],"float16"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:24:34.890496 10900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:24:34.892176 10900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 192, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 192, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 38.40 GiB. GPU 0 has a total capacity of 79.18 GiB of which 19.60 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 133062 has 26.59 GiB memory in use. Of the allocated memory 25.60 GiB is allocated by PyTorch, and 3.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:29:13.527935 11731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:29:13.528904 11731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 5 for tensor number 1 in the list.

W0205 16:30:41.375108 13049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:30:41.376219 13049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),Tensor([2, 192, 1342178, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),Tensor([2, 192, 1342178, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 38.40 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 97692 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:34:19.635877 13480 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:34:19.638535 13480 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 5 for tensor number 1 in the list.

W0205 16:35:45.868746 14459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:35:45.869948 14459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:37:20.768962 14858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:37:20.769819 14858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 16:38:30.659572 15286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:38:30.660462 15286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 16:39:45.216661 15591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:39:45.217630 15591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 16:41:00.432209 15970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:41:00.433152 15970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 479350],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 14, 479350],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 479350 but got size 14 for tensor number 1 in the list.

W0205 16:42:26.255810 16276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:42:26.257035 16276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 479350],"float32"),Tensor([2, 32, 14, 479350],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 14, 479350],"float32"),Tensor([2, 32, 14, 479350],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:44:04.266422 16689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:44:04.267364 16689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 239675, 28],"float32"),Tensor([2, 32, 239675, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 239675, 28],"float32"),Tensor([2, 32, 239675, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:45:44.478600 17117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:45:44.479487 17117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 239675, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 239675, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 239675 but got size 28 for tensor number 1 in the list.

W0205 16:46:55.007213 17635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:46:55.008523 17635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 239675],"float32"),Tensor([2, 32, 28, 239675],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 28, 239675],"float32"),Tensor([2, 32, 28, 239675],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:48:38.154328 17949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:48:38.155304 17949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 239675],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 28, 239675],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 239675 but got size 28 for tensor number 1 in the list.

W0205 16:49:57.332775 18382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:49:57.333793 18382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 16:51:12.428470 18773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:51:12.429654 18773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:52:51.321943 19178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:52:51.322925 19178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 16:54:08.597290 19603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:54:08.598508 19603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 16:55:30.585232 19989 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:55:30.586462 19989 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 479350, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 479350, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 479350 but got size 14 for tensor number 1 in the list.

W0205 16:56:56.618700 20320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:56:56.626207 20320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 479350, 14],"float32"),Tensor([2, 32, 479350, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 479350, 14],"float32"),Tensor([2, 32, 479350, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:58:33.700219 20752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:58:33.701359 20752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 192, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 192, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 38.40 GiB. GPU 0 has a total capacity of 79.18 GiB of which 19.60 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 57206 has 26.59 GiB memory in use. Of the allocated memory 25.60 GiB is allocated by PyTorch, and 3.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:02:52.815521 21185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:02:52.816720 21185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 5 for tensor number 1 in the list.

W0205 17:04:19.752085 22394 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:04:19.753278 22394 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),Tensor([2, 192, 5, 1342178],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),Tensor([2, 192, 5, 1342178],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 38.40 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 1562 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:08:03.625514 22819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:08:03.626823 22819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 5 for tensor number 1 in the list.

W0205 17:09:31.600044 23769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:09:31.601243 23769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 2236963, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 2236963, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 2236963 for tensor number 1 in the list.

W0205 17:10:45.307484 24185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:10:45.308424 24185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 2236963],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 2236963],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 2236963 for tensor number 1 in the list.

W0205 17:11:59.618238 24556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:11:59.619238 24556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 559241],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 559241],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 559241 for tensor number 2 in the list.

W0205 17:13:21.223773 24870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:13:21.225001 24870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 559241, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 559241, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 559241 for tensor number 2 in the list.

W0205 17:14:37.438472 25264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:14:37.440122 25264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:16:13.435359 25582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:16:13.436162 25582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

