test begin: paddle.broadcast_to(Tensor([1073741824, 1, 4],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([1073741824, 1, 4],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (1073741824) at non-singleton dimension 0.  Target sizes: [2, 2, 4].  Tensor sizes: [1073741824, 1, 4]

W0205 15:42:35.730765 162659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:42:35.731854 162659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741824, 1, 4],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([1073741824, 1, 4],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43081 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:43:48.137796 162946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:43:48.138908 162946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741824, 1, 4],"int32"), tuple(5,1,4,), )
[torch error] paddle.broadcast_to(Tensor([1073741824, 1, 4],"int32"), tuple(5,1,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100750 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:44:57.332720 163557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:44:57.333683 163557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741824, 4],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([1073741824, 4],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (1073741824) at non-singleton dimension 1.  Target sizes: [2, 2, 4].  Tensor sizes: [1073741824, 4]

W0205 15:46:02.458865   413 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:46:02.460245   413 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741825, 2],"int64"), list[4,2,], )
[torch error] paddle.broadcast_to(Tensor([1073741825, 2],"int64"), list[4,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37610 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:46:47.354876   725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:46:47.355899   725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741825, 2],"int64"), tuple(2,2,), )
[torch error] paddle.broadcast_to(Tensor([1073741825, 2],"int64"), tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 73851 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:47:30.572840   984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:47:30.573972   984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741825, 2],"int64"), tuple(3,2,), )
[torch error] paddle.broadcast_to(Tensor([1073741825, 2],"int64"), tuple(3,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101613 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:48:14.255420  1163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:48:14.256474  1163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([111, 222, 87148],"float64"), list[111,222,333,], )
[torch error] paddle.broadcast_to(Tensor([111, 222, 87148],"float64"), list[111,222,333,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145142 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:49:03.035374  1418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:49:03.036425  1418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([111, 58099, 333],"float64"), list[111,222,333,], )
[torch error] paddle.broadcast_to(Tensor([111, 58099, 333],"float64"), list[111,222,333,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10933 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:49:49.546252  1606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:49:49.547410  1606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([128, 16777217],"int64"), tuple(128,1,), )
[torch error] paddle.broadcast_to(Tensor([128, 16777217],"int64"), tuple(128,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 47252 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:50:34.335464  1858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:50:34.336460  1858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([128, 33554432],"float32"), tuple(128,8,), )
[torch error] paddle.broadcast_to(Tensor([128, 33554432],"float32"), tuple(128,8,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72444 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:51:41.902724  2031 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:51:41.903795  2031 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"bool"), list[3,3,], )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"bool"), list[3,3,], ) 
 The expanded size of the tensor (3) must match the existing size (1431655765) at non-singleton dimension 0.  Target sizes: [3, 3].  Tensor sizes: [1431655765, 3]

W0205 15:52:51.790359  2335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:52:51.791666  2335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(1,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 18573 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:54:01.815896  2708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:54:01.817008  2708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(2,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68824 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:55:16.368919  2992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:55:16.369997  2992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(3,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(3,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130937 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:56:27.185879  3390 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:56:27.186997  3390 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(4,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(4,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19466 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:57:36.296391  3714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:57:36.297374  3714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(8,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(8,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64075 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:58:45.507431  4000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:58:45.508430  4000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"int32"), tuple(1,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"int32"), tuple(1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125812 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:59:54.903080  4404 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:59:54.904170  4404 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1619, 1327104],"int64"), tuple(64,1327104,), )
[torch error] paddle.broadcast_to(Tensor([1619, 1327104],"int64"), tuple(64,1327104,), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15923 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:00:38.410400  4703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:00:38.411485  4703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([171798692, 5, 5],"float16"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([171798692, 5, 5],"float16"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40662 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:02:01.573381  4881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:02:01.574486  4881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([171798692, 5, 5],"float32"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([171798692, 5, 5],"float32"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 105001 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:03:10.761241  5274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:03:10.762488  5274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([171798692, 5, 5],"int32"), tuple(1,5,5,), )
[torch error] paddle.broadcast_to(Tensor([171798692, 5, 5],"int32"), tuple(1,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162207 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:04:19.577498  5564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:04:19.578646  5564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([178956971, 12],"float64"), tuple(5,12,), )
[torch error] paddle.broadcast_to(Tensor([178956971, 12],"float64"), tuple(5,12,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45410 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:05:06.606065  5939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:05:06.607041  5939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([178956971, 3, 4],"float64"), tuple(2,3,4,), )
[torch error] paddle.broadcast_to(Tensor([178956971, 3, 4],"float64"), tuple(2,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72995 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:05:52.870405  6104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:05:52.871510  6104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([178956971, 3, 4],"float64"), tuple(5,3,4,), )
[torch error] paddle.broadcast_to(Tensor([178956971, 3, 4],"float64"), tuple(5,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118890 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:06:38.116674  6349 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:06:38.117794  6349 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 1, 2147483648],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 1, 2147483648],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (4) must match the existing size (2147483648) at non-singleton dimension 2.  Target sizes: [2, 2, 4].  Tensor sizes: [2, 1, 2147483648]

W0205 16:07:44.646742  6514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:07:44.647867  6514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 1, 2147483648],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 1, 2147483648],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37570 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:08:54.534931  6899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:08:54.535915  6899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 1073741825],"float64"), tuple(2,3,), )
[torch error] paddle.broadcast_to(Tensor([2, 1073741825],"float64"), tuple(2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92822 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:09:41.915558  7191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:09:41.916544  7191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 1073741825],"int64"), tuple(2,2,), )
[torch error] paddle.broadcast_to(Tensor([2, 1073741825],"int64"), tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 126882 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:10:24.283015  7361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:10:24.284091  7361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2, 1073741824],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2, 1073741824],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (4) must match the existing size (1073741824) at non-singleton dimension 2.  Target sizes: [2, 2, 4].  Tensor sizes: [2, 2, 1073741824]

W0205 16:11:31.663275  7658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:11:31.664331  7658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2, 1073741824],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2, 1073741824],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43333 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:12:40.801303  8015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:12:40.802345  8015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2, 1073741824],"float32"), list[3,2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2, 1073741824],"float32"), list[3,2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100638 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:13:56.351629  8348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:13:56.352705  8348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648, 1],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648, 1],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 1.  Target sizes: [2, 2, 4].  Tensor sizes: [2, 2147483648, 1]

W0205 16:15:03.927713  8761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:15:03.928929  8761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648, 1],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648, 1],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 36984 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:16:22.120932  9128 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:16:22.121904  9128 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648, 1],"float32"), list[3,2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648, 1],"float32"), list[3,2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103726 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:17:38.715241  9500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:17:38.716295  9500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[1,2,2,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[1,2,2,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 2.  Target sizes: [1, 2, 2].  Tensor sizes: [2, 2147483648]

W0205 16:18:43.299172  9803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:18:43.300326  9803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[2,2,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[2,2,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 1.  Target sizes: [2, 2].  Tensor sizes: [2, 2147483648]

W0205 16:19:47.696623 10170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:19:47.697798 10170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (4) must match the existing size (2147483648) at non-singleton dimension 2.  Target sizes: [2, 2, 4].  Tensor sizes: [2, 2147483648]

W0205 16:20:51.026293 10455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:20:51.027555 10455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"float32"), tuple(2,2,), )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"float32"), tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139420 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:22:04.289706 10728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:22:04.290663 10728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"float32"), tuple(2,3,), )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"float32"), tuple(2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27338 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:23:17.336679 11039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:23:17.337646 11039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"int32"), tuple(2,1,), )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"int32"), tuple(2,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 86879 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:24:30.789546 11417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:24:30.790537 11417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 268435457, 4],"float64"), tuple(2,3,4,), )
[torch error] paddle.broadcast_to(Tensor([2, 268435457, 4],"float64"), tuple(2,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132023 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:25:14.988101 11711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:25:14.989132 11711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 3, 357913942],"float64"), tuple(2,3,4,), )
[torch error] paddle.broadcast_to(Tensor([2, 3, 357913942],"float64"), tuple(2,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10715 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:26:00.111035 11963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:26:00.112278 11963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 536870912, 4],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 536870912, 4],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (536870912) at non-singleton dimension 1.  Target sizes: [2, 2, 4].  Tensor sizes: [2, 536870912, 4]

W0205 16:27:18.326876 12135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:27:18.328258 12135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 536870912, 4],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 536870912, 4],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109686 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:28:31.996317 12521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:28:31.997277 12521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 536870912, 4],"float32"), list[3,2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 536870912, 4],"float32"), list[3,2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 157628 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:29:38.306813 12805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:29:38.307926 12805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([21053762, 17, 1, 6],"float64"), list[5,17,0,6,], )
[torch error] paddle.broadcast_to(Tensor([21053762, 17, 1, 6],"float64"), list[5,17,0,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42352 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:30:22.583910 13089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:30:22.585000 13089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([21053762, 17, 6],"float64"), list[0,5,17,6,], )
[torch error] paddle.broadcast_to(Tensor([21053762, 17, 6],"float64"), list[0,5,17,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 79956 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:31:07.249131 13340 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:31:07.250528 13340 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([21053762, 17, 6],"float64"), list[5,17,6,], )
[torch error] paddle.broadcast_to(Tensor([21053762, 17, 6],"float64"), list[5,17,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108483 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:31:58.058101 13527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:31:58.059219 13527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2, 1],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2, 1],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 0.  Target sizes: [2, 2, 4].  Tensor sizes: [2147483648, 2, 1]

W0205 16:33:01.575467 13780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:33:01.576766 13780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2, 1],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2, 1],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 32463 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:34:08.993425 14044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:34:08.994390 14044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2, 1],"float32"), list[3,2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2, 1],"float32"), list[3,2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84583 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:35:22.836134 14342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:35:22.837178 14342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"bool"), list[1,2,2,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"bool"), list[1,2,2,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 1.  Target sizes: [1, 2, 2].  Tensor sizes: [2147483648, 2]

W0205 16:36:27.027078 14723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:36:27.028239 14723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"bool"), list[2,2,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"bool"), list[2,2,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 0.  Target sizes: [2, 2].  Tensor sizes: [2147483648, 2]

W0205 16:37:31.552395 15011 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:37:31.553869 15011 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"float32"), list[4,2,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"float32"), list[4,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68044 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:38:44.916024 15323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:38:44.917150 15323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(2,2,), )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 131408 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:39:55.790879 15700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:39:55.791954 15700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(4,2,), )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(4,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20271 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:41:09.138432 15992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:41:09.139395 15992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(5,2,), )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(5,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75413 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:42:15.945092 16295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:42:15.957020 16295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(1,3,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132511 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:43:02.582135 16657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:43:02.583194 16657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(128,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(128,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 160019 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:43:45.706403 16829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:43:45.707929 16829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(28,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(28,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 30154 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:44:29.616600 17085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:44:29.617743 17085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(30,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(30,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57540 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:45:25.696849 17250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:45:25.698057 17250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(38,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(38,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101797 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:46:08.625672 17516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:46:08.627171 17516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(4,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(4,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138105 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:46:51.684782 17688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:46:51.685894 17688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(5,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(5,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 8626 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:47:47.736660 17923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:47:47.737788 17923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(8,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(8,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49626 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:48:33.397239 18194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:48:33.398268 18194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), list[1,1,2048,2048,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), list[1,1,2048,2048,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 81701 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:49:22.980175 18369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:49:22.981297 18369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), list[10,10,5,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), list[10,10,5,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125910 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:50:10.029578 18628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:50:10.030892 18628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), list[100,100,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), list[100,100,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4218 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:51:00.329927 18801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:51:00.330878 18801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), list[4,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), list[4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35794 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:51:48.824342 19059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:51:48.825362 19059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), shape=tuple(1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), shape=tuple(1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70239 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:52:38.778383 19319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:52:38.779336 19319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), shape=tuple(5000,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), shape=tuple(5000,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 106889 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:53:28.600531 19497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:53:28.601543 19497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), tuple(168,), )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), tuple(168,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144565 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:54:17.973692 19757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:54:17.974785 19757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[1,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24015 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:55:01.498900 20016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:55:01.500005 20016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[2,100,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[2,100,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52461 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:55:47.436514 20181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:55:47.437500 20181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,10,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,10,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 91552 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:56:34.153254 20434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:56:34.154227 20434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,4,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 124553 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:57:18.343701 20625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:57:18.344822 20625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,4,2,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,4,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4240 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:58:01.600718 20893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:58:01.601833 20893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[5,4,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[5,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 36174 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:58:45.116390 21046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:58:45.117544 21046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([214748365, 1, 10],"float64"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([214748365, 1, 10],"float64"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72691 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:59:30.884291 21299 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:59:30.885337 21299 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([214748365, 1, 10],"int64"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([214748365, 1, 10],"int64"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102421 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:00:14.257418 21457 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:00:14.258863 21457 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([214748365, 20],"int32"), list[10,20,], )
[torch error] paddle.broadcast_to(Tensor([214748365, 20],"int32"), list[10,20,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145657 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:01:23.081774 21706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:01:23.082778 21706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([21474837, 100],"float64"), list[100,100,], )
[torch error] paddle.broadcast_to(Tensor([21474837, 100],"float64"), list[100,100,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28872 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:02:10.717674 21983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:02:10.718724 21983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([222, 9673350],"float64"), list[111,222,333,], )
[torch error] paddle.broadcast_to(Tensor([222, 9673350],"float64"), list[111,222,333,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70602 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:02:59.724614 22155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:02:59.791499 22155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([28, 153391690],"float32"), tuple(28,5,), )
[torch error] paddle.broadcast_to(Tensor([28, 153391690],"float32"), tuple(28,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101689 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:04:08.494244 22407 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:04:08.495208 22407 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([28, 76695845],"int64"), tuple(28,1,), )
[torch error] paddle.broadcast_to(Tensor([28, 76695845],"int64"), tuple(28,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154916 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:04:55.826488 22706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:04:55.827454 22706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([29050, 222, 333],"float64"), list[111,222,333,], )
[torch error] paddle.broadcast_to(Tensor([29050, 222, 333],"float64"), list[111,222,333,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27560 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:05:48.000715 22960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:05:48.001820 22960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 1431655765],"bool"), list[3,40,], )
[torch error] paddle.broadcast_to(Tensor([3, 1431655765],"bool"), list[3,40,], ) 
 The expanded size of the tensor (40) must match the existing size (1431655765) at non-singleton dimension 1.  Target sizes: [3, 40].  Tensor sizes: [3, 1431655765]

W0205 17:06:52.770503 23209 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:06:52.771631 23209 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 1431655765],"float32"), tuple(3,3,), )
[torch error] paddle.broadcast_to(Tensor([3, 1431655765],"float32"), tuple(3,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120726 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:08:16.449808 23473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:08:16.450887 23473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 1431655765],"float32"), tuple(3,5,), )
[torch error] paddle.broadcast_to(Tensor([3, 1431655765],"float32"), tuple(3,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26872 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:09:30.671978 23872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:09:30.672960 23872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 2, 715827883],"float32"), tuple(3,2,5,), )
[torch error] paddle.broadcast_to(Tensor([3, 2, 715827883],"float32"), tuple(3,2,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 73412 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:10:43.646135 24165 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:10:43.647094 24165 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 286331153, 5],"float32"), tuple(3,2,5,), )
[torch error] paddle.broadcast_to(Tensor([3, 286331153, 5],"float32"), tuple(3,2,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135915 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:11:51.940502 24537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:11:51.941637 24537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 715827883],"float64"), tuple(3,5,), )
[torch error] paddle.broadcast_to(Tensor([3, 715827883],"float64"), tuple(3,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23419 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:12:42.488143 24837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:12:42.489226 24837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 715827883],"int64"), tuple(3,2,), )
[torch error] paddle.broadcast_to(Tensor([3, 715827883],"int64"), tuple(3,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64130 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:13:26.045979 25096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:13:26.047140 25096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([30, 143165577],"bool"), list[30,3,], )
[torch error] paddle.broadcast_to(Tensor([30, 143165577],"bool"), list[30,3,], ) 
 The expanded size of the tensor (3) must match the existing size (143165577) at non-singleton dimension 1.  Target sizes: [30, 3].  Tensor sizes: [30, 143165577]

W0205 17:14:31.157291 25274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:14:31.158432 25274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([30, 143165577],"float32"), tuple(30,5,), )
[torch error] paddle.broadcast_to(Tensor([30, 143165577],"float32"), tuple(30,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144267 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:15:38.030268 25556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:15:38.031456 25556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([30, 71582789],"int64"), tuple(30,1,), )
[torch error] paddle.broadcast_to(Tensor([30, 71582789],"int64"), tuple(30,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 34529 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:16:21.514631 25824 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:16:21.515726 25824 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

