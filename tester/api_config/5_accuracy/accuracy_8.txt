paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 1, 8],"float32"), Tensor([8, 8],"float32"), Tensor([8, 8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), 0.0, 0.0, activation="gelu", pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, Tensor([4],"float32"), Tensor([4],"float32"), dropout1_rate=0, dropout2_rate=0, activation="relu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=False, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, dropout1_rate=0, dropout2_rate=0, activation="gelu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=True, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, dropout1_rate=0, dropout2_rate=0, activation="relu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=True, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 98, 508],"float32"), Tensor([508, 130],"float32"), Tensor([130, 508],"float32"), Tensor([130],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), 0.0, 0.0, activation="gelu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 98, 508],"float32"), Tensor([508, 130],"float32"), Tensor([130, 508],"float32"), Tensor([130],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), 0.0, 0.0, activation="relu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 98, 508],"float64"), Tensor([508, 130],"float64"), Tensor([130, 508],"float64"), Tensor([130],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), 0.0, 0.0, activation="gelu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), activation="gelu", dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), dropout1_rate=0, dropout2_rate=0, pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), ln1_scale=Tensor([2],"float32"), ln1_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), ln2_scale=Tensor([2],"float32"), ln2_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(Tensor([8, 128, 1024],"float32"), Tensor([8, 128, 1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 0.0, 1e-05, )
paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(x=Tensor([1, 2, 4],"float32"), residual=Tensor([1, 2, 4],"float32"), bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, dropout_rate=0.0, ln_epsilon=1e-05, training=True, mode="upscale_in_train", name=None, )
paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(x=Tensor([1, 2, 4],"float32"), residual=Tensor([1, 2, 4],"float32"), bias=Tensor([4],"float32"), ln_scale=Tensor([4],"float32"), ln_bias=Tensor([4],"float32"), dropout_rate=0.0, ln_epsilon=1e-05, training=True, mode="upscale_in_train", name=None, )
paddle.Tensor.greater_equal(Tensor([19],"int64"), Tensor([],"int64"), )
paddle.Tensor.greater_equal(Tensor([21],"int64"), Tensor([],"int64"), )
paddle.Tensor.slice(Tensor([4, 4],"float32"), list[1,], list[0,], list[1,], )
paddle.zeros(name="x", shape=list[100,10,], dtype="uint16", )
paddle.Tensor.reshape(Tensor([0, 0, 5, 5],"float32"), list[0,1,], )
paddle.Tensor.reshape(Tensor([0, 0, 5, 5],"float32"), list[1,0,], )
paddle.Tensor.reshape(Tensor([0, 0],"float32"), list[0,0,5,5,0,0,5,5,], )
paddle.Tensor.reshape(Tensor([0, 0],"float32"), list[5,0,5,0,5,0,5,0,], )
paddle.Tensor.reshape(Tensor([0, 0],"float32"), list[5,5,0,5,5,5,0,5,], )
paddle.Tensor.reshape(Tensor([0, 0],"float32"), list[5,5,5,0,5,5,5,0,], )
paddle.Tensor.reshape(Tensor([0, 0],"float64"), list[0,5,5,5,0,5,5,5,], )
paddle.Tensor.reshape(Tensor([0, 10, 8],"float64"), list[0,], )
paddle.Tensor.reshape(Tensor([0, 2, 3],"float32"), list[0,6,], )
paddle.Tensor.reshape(Tensor([0, 4, 5, 5],"float64"), list[0,4,], )
paddle.Tensor.reshape(Tensor([0, 5, 5, 5],"float32"), list[1,0,], )
paddle.Tensor.reshape(Tensor([0, 5, 5, 5],"float64"), list[0,1,], )
paddle.Tensor.reshape(Tensor([0, 5, 5, 5],"float64"), list[1,0,], )
paddle.Tensor.reshape(Tensor([0, 7, 11],"float32"), list[0,], )
paddle.Tensor.reshape(Tensor([0, 7, 7],"float32"), list[0,], )
paddle.Tensor.reshape(Tensor([0, 9, 9],"float32"), list[0,], )
paddle.Tensor.reshape(Tensor([125, 0],"float32"), list[1,5,5,5,0,5,5,5,], )
paddle.Tensor.reshape(Tensor([5, 0, 4, 3],"float32"), list[5,0,], )
paddle.Tensor.reshape(Tensor([5, 0, 5, 0],"float32"), list[0,1,], )
paddle.Tensor.reshape(Tensor([5, 0, 5, 0],"float32"), list[1,0,], )
paddle.Tensor.reshape(Tensor([5, 5, 0, 5],"float32"), list[0,1,], )
paddle.Tensor.reshape(Tensor([5, 5, 0, 5],"float32"), list[1,0,], )
paddle.Tensor.reshape(Tensor([5, 5, 5, 0],"float32"), list[0,1,], )
paddle.Tensor.reshape(Tensor([5, 5, 5, 0],"float32"), list[1,0,], )
paddle.geometric.send_ue_recv(Tensor([10, 20],"float64"), Tensor([15, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "mean", None, None, )
paddle.geometric.send_ue_recv(Tensor([10, 20],"float64"), Tensor([150, 1],"float64"), Tensor([150],"int64"), Tensor([150],"int64"), "mul", "sum", None, None, )
paddle.geometric.send_ue_recv(Tensor([10, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
paddle.geometric.send_ue_recv(Tensor([3, 3],"float32"), Tensor([4, 1],"float32"), Tensor([4],"int32"), Tensor([4],"int32"), "sub", "max", )
paddle.nn.functional.instance_norm(Tensor([2, 100, 3, 5],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, )
paddle.nn.functional.instance_norm(Tensor([2, 100, 3, 5],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, )
paddle.nn.functional.label_smooth(label=Tensor([264, 14, 33712],"float32"), epsilon=0.1, )
paddle.Tensor.flip(Tensor([16, 3, 224, 224],"float32"), 0, )
paddle.Tensor.flip(Tensor([16],"int64"), 0, )
paddle.Tensor.flip(Tensor([2, 2],"float32"), 1, )
paddle.Tensor.flip(Tensor([2, 3],"float32"), 0, )
paddle.Tensor.flip(Tensor([4, 2, 64, 64],"float32"), 1, )
paddle.Tensor.flip(Tensor([4, 2],"float32"), 1, )
paddle.Tensor.outer(x=Tensor([1, 4],"float32"), y=Tensor([1, 4],"float32"), )
paddle.Tensor.outer(x=Tensor([1, 4],"float64"), y=Tensor([1, 4],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 1],"float64"), y=Tensor([4, 1],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2, 3],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 2, 5, 2],"float64"), y=Tensor([2, 3, 4, 4],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3, 4],"float64"), )
paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 5],"float64"), q=list[0.25,0.5,0.75,], axis=3, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 5],"float64"), q=tuple(0.11,0.5,0.73,0.9,), axis=4, keepdim=False, )
paddle.Tensor.take_along_axis(Tensor([128, 1000],"float32"), indices=Tensor([128, 1],"int32"), axis=-1, )
paddle.Tensor.take_along_axis(Tensor([80, 1000],"float32"), indices=Tensor([80, 1],"int32"), axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=Tensor([],"float32"), axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=Tensor([],"float32"), axis=0, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=None, dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([3, 3, 4],"float32"), x=None, dx=Tensor([],"int64"), axis=1, )
paddle.cumulative_trapezoid(y=Tensor([3, 3, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, )
paddle.dsplit(Tensor([4, 2, 6],"bool"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"float16"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"float32"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"float64"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"int32"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"int64"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"uint8"), 3, )
paddle.dsplit(Tensor([4, 3, 6],"int64"), 2, )
paddle.dsplit(Tensor([4, 3, 6],"int64"), 3, )
paddle.hsplit(Tensor([4, 6, 3],"int64"), 2, )
paddle.hsplit(Tensor([4, 6, 3],"int64"), 3, )
paddle.hsplit(Tensor([4, 6],"int64"), 2, )
paddle.hsplit(Tensor([4, 6],"int64"), 3, )
paddle.hsplit(Tensor([6],"bool"), 3, )
paddle.hsplit(Tensor([6],"float16"), 3, )
paddle.hsplit(Tensor([6],"float32"), 3, )
paddle.hsplit(Tensor([6],"float64"), 3, )
paddle.hsplit(Tensor([6],"int32"), 3, )
paddle.hsplit(Tensor([6],"int64"), 2, )
paddle.hsplit(Tensor([6],"int64"), 3, )
paddle.hsplit(Tensor([6],"uint8"), 3, )
paddle.logsumexp(Tensor([1000],"float32"), )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float32"), )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float32"), None, False, )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float32"), None, True, )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float64"), None, False, )
paddle.logsumexp(Tensor([3, 5],"float32"), axis=None, )
paddle.logsumexp(Tensor([3, 5],"float32"), keepdim=True, )
paddle.logsumexp(Tensor([30, 200, 40],"float32"), )
paddle.logsumexp(Tensor([30, 200, 40],"float32"), keepdim=False, )
paddle.logsumexp(Tensor([],"float32"), axis=None, )
paddle.nn.functional.unfold(Tensor([3, 3, 20, 20],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, )
paddle.vsplit(Tensor([6, 4, 3],"int64"), 2, )
paddle.vsplit(Tensor([6, 4, 3],"int64"), 3, )
paddle.vsplit(Tensor([6, 4],"bool"), 3, )
paddle.vsplit(Tensor([6, 4],"float16"), 3, )
paddle.vsplit(Tensor([6, 4],"float32"), 3, )
paddle.vsplit(Tensor([6, 4],"float64"), 3, )
paddle.vsplit(Tensor([6, 4],"int32"), 3, )
paddle.vsplit(Tensor([6, 4],"int64"), 2, )
paddle.vsplit(Tensor([6, 4],"int64"), 3, )
paddle.vsplit(Tensor([6, 4],"uint8"), 3, )
paddle.add(Tensor([20, 128, 76, 136],"float32"), Tensor([20, 128, 76, 136],"float16"), )
paddle.add(Tensor([20, 256, 38, 68],"float32"), Tensor([20, 256, 38, 68],"float16"), )
paddle.add(Tensor([20, 64, 152, 272],"float32"), Tensor([20, 64, 152, 272],"float16"), )
paddle.add(Tensor([32, 40, 31, 31],"float32"), Tensor([32, 40, 31, 31],"float16"), )
paddle.add(Tensor([32, 96, 16, 16],"float32"), Tensor([32, 96, 16, 16],"float16"), )
paddle.add(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), )
paddle.add(x=Tensor([160, 128, 16, 12],"float32"), y=Tensor([160, 128, 16, 12],"float16"), )
paddle.add(x=Tensor([160, 32, 64, 48],"float32"), y=Tensor([160, 32, 64, 48],"float16"), )
paddle.add(x=Tensor([160, 64, 32, 24],"float32"), y=Tensor([160, 64, 32, 24],"float16"), )
paddle.add(x=Tensor([24, 128, 32, 32],"float32"), y=Tensor([24, 128, 32, 32],"float16"), )
paddle.add(x=Tensor([24, 32, 128, 128],"float32"), y=Tensor([24, 32, 128, 128],"float16"), )
paddle.add(x=Tensor([24, 32, 256, 256],"float32"), y=Tensor([24, 32, 256, 256],"float16"), )
paddle.add(x=Tensor([24, 64, 64, 64],"float32"), y=Tensor([24, 64, 64, 64],"float16"), )
paddle.add_n(inputs=Tensor([10],"int32"), )
paddle.add_n(list[Tensor([100, 200],"int32"),Tensor([100, 200],"int32"),], )
paddle.cummax(Tensor([100, 100],"float32"), axis=-2, dtype="int32", )
paddle.cummin(Tensor([100, 100],"float32"), axis=-2, dtype="int32", )
paddle.cumsum(Tensor([1, 1],"int32"), )
paddle.cumsum(Tensor([12, 7],"int32"), axis=1, )
paddle.cumsum(Tensor([120, 60],"int32"), axis=0, )
paddle.cumsum(Tensor([13, 10],"int32"), axis=1, )
paddle.cumsum(Tensor([13, 14],"int32"), axis=1, )
paddle.cumsum(Tensor([13, 3],"int32"), axis=1, )
paddle.cumsum(Tensor([13, 7],"int32"), axis=1, )
paddle.cumsum(Tensor([16, 60],"int32"), axis=0, )
paddle.cumsum(Tensor([2, 1],"int32"), )
paddle.cumsum(Tensor([24, 60],"int32"), axis=0, )
paddle.cumsum(Tensor([2],"int32"), )
paddle.cumsum(Tensor([40, 60],"int32"), axis=0, )
paddle.cumsum(Tensor([4],"int32"), )
paddle.cumsum(Tensor([5],"int32"), )
paddle.cumsum(Tensor([8, 60],"int32"), axis=0, )
paddle.cumsum(Tensor([80, 60],"int32"), axis=0, )
paddle.increment(x=Tensor([1],"int64"), value=1.0, )
paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 10],"int32"), bias=Tensor([10],"float32"), dequant_scales=Tensor([10],"float32"), act_method="gelu", compute_dtype="fp32", )
paddle.median(Tensor([3, 4, 2],"float32"), None, True, )
paddle.median(Tensor([3, 4, 2],"float64"), None, True, )
paddle.median(Tensor([3, 4, 2],"int32"), 0, False, )
paddle.median(Tensor([3, 4, 2],"int32"), 0, True, )
paddle.median(Tensor([3, 4, 2],"int32"), None, True, )
paddle.median(Tensor([3, 4, 2],"int64"), 0, False, )
paddle.median(Tensor([3, 4, 2],"int64"), 0, True, )
paddle.median(Tensor([3, 4, 2],"int64"), None, True, )
paddle.median(Tensor([3, 4],"float16"), -1, False, )
paddle.median(Tensor([3, 4],"float16"), -1, True, )
paddle.median(Tensor([3, 4],"float16"), 0, False, )
paddle.median(Tensor([3, 4],"float16"), 0, True, )
paddle.median(Tensor([3, 4],"float16"), 1, False, )
paddle.median(Tensor([3, 4],"float16"), 1, True, )
paddle.median(Tensor([3, 4],"float16"), None, False, )
paddle.median(Tensor([3, 4],"float16"), None, True, )
paddle.median(Tensor([3, 4],"float16"), None, True, mode="min", )
paddle.median(Tensor([3, 4],"float32"), None, True, )
paddle.median(Tensor([3, 4],"float64"), None, True, )
paddle.median(Tensor([3, 5],"float32"), keepdim=True, )
paddle.median(Tensor([5, 4],"float32"), None, True, mode="min", )
paddle.median(Tensor([5, 4],"float64"), None, True, mode="min", )
paddle.nanmedian(Tensor([120],"float32"), keepdim=True, )
paddle.nanmedian(Tensor([120],"float32"), keepdim=True, mode="min", )
paddle.nanmedian(Tensor([120],"float64"), keepdim=True, )
paddle.nanmedian(Tensor([120],"float64"), keepdim=True, mode="min", )
paddle.nanmedian(Tensor([2, 3, 4, 5],"float32"), keepdim=True, )
paddle.nanmedian(Tensor([2, 3, 4, 5],"float32"), keepdim=True, mode="min", )
paddle.nanmedian(Tensor([2, 3, 4, 5],"float64"), keepdim=True, )
paddle.nanmedian(Tensor([2, 3, 4, 5],"float64"), keepdim=True, mode="min", )
paddle.nanmedian(Tensor([3, 5],"float32"), keepdim=True, )
paddle.nanmedian(Tensor([4, 5],"float64"), keepdim=True, )
paddle.nanmedian(Tensor([4, 5],"float64"), keepdim=True, mode="min", )
paddle.nn.functional.adaptive_max_pool1d(Tensor([1, 1, 4],"float64"), 4, True, None, )
paddle.nn.functional.adaptive_max_pool1d(x=Tensor([1, 1, 4],"float64"), output_size=4, return_mask=True, )
paddle.nn.functional.adaptive_max_pool2d(Tensor([1, 1, 5, 5],"float32"), output_size=3, return_mask=True, name=None, )
paddle.nn.functional.adaptive_max_pool2d(Tensor([1, 1, 5, 5],"float64"), output_size=3, return_mask=True, name=None, )
paddle.nn.functional.adaptive_max_pool2d(x=Tensor([1, 1, 5, 5],"float32"), output_size=3, return_mask=True, )
paddle.nn.functional.adaptive_max_pool2d(x=Tensor([1, 1, 5, 5],"float64"), output_size=3, return_mask=True, )
paddle.nn.functional.adaptive_max_pool3d(Tensor([1, 1, 5, 5, 5],"float32"), output_size=3, return_mask=True, name=None, )
paddle.nn.functional.adaptive_max_pool3d(Tensor([1, 1, 5, 5, 5],"float64"), output_size=3, return_mask=True, name=None, )
paddle.nn.functional.adaptive_max_pool3d(x=Tensor([1, 1, 5, 5, 5],"float32"), output_size=3, return_mask=True, )
paddle.nn.functional.adaptive_max_pool3d(x=Tensor([1, 1, 5, 5, 5],"float64"), output_size=3, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([1, 1, 2],"float64"), 2, 2, 0, True, False, None, )
paddle.nn.functional.max_pool1d(Tensor([1, 3, 16],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([1, 3, 16],"float64"), 2, 2, 0, True, False, None, )
paddle.nn.functional.max_pool1d(Tensor([1, 3, 16],"float64"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([1, 3, 6],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([2, 3, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool1d(x=Tensor([1, 1, 2],"float64"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 1, 4, 4],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 1, 4, 4],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 1, 4, 5],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 2, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 3, 6, 6],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 11, 11],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 33, 33],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 40, 40],"float64"), kernel_size=2, stride=None, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 40, 40],"float64"), kernel_size=4, stride=2, padding=2, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 40, 40],"float64"), kernel_size=4, stride=None, padding=2, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 40, 40],"float64"), kernel_size=tuple(2,4,), stride=None, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([64, 16, 86, 39],"float32"), 2, 2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([64, 32, 21, 9],"float32"), 2, 2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([64, 32, 43, 19],"float32"), 2, 2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([64, 8, 172, 79],"float32"), 2, 2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([8, 192, 15, 15],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 256, 20, 20],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 64, 576, 704],"float32"), kernel_size=3, stride=2, padding=1, )
paddle.nn.functional.max_pool3d(Tensor([1, 2, 6, 33, 33],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 4, 4, 6],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 4, 4, 6],"float64"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 4, 4, 6],"float64"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.scale(x=Tensor([3, 3, 3],"int32"), scale=1.0, bias=0.0, bias_after_scale=True, act=None, )
paddle.scale(x=Tensor([3, 3, 3],"int64"), scale=1.0, bias=0.0, bias_after_scale=True, act=None, )
paddle.shape(Tensor([],"float32"), )
paddle.shape(Tensor([],"int64"), )
