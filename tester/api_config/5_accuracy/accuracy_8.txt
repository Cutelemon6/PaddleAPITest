paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 1, 8],"float32"), Tensor([8, 8],"float32"), Tensor([8, 8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), 0.0, 0.0, activation="gelu", pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, Tensor([4],"float32"), Tensor([4],"float32"), dropout1_rate=0, dropout2_rate=0, activation="relu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=False, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, dropout1_rate=0, dropout2_rate=0, activation="gelu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=True, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, dropout1_rate=0, dropout2_rate=0, activation="relu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=True, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 98, 508],"float32"), Tensor([508, 130],"float32"), Tensor([130, 508],"float32"), Tensor([130],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), 0.0, 0.0, activation="gelu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 98, 508],"float32"), Tensor([508, 130],"float32"), Tensor([130, 508],"float32"), Tensor([130],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), 0.0, 0.0, activation="relu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 98, 508],"float64"), Tensor([508, 130],"float64"), Tensor([130, 508],"float64"), Tensor([130],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), 0.0, 0.0, activation="gelu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), activation="gelu", dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), dropout1_rate=0, dropout2_rate=0, pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), ln1_scale=Tensor([2],"float32"), ln1_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), ln2_scale=Tensor([2],"float32"), ln2_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(Tensor([8, 128, 1024],"float32"), Tensor([8, 128, 1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 0.0, 1e-05, )
paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(x=Tensor([1, 2, 4],"float32"), residual=Tensor([1, 2, 4],"float32"), bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, dropout_rate=0.0, ln_epsilon=1e-05, training=True, mode="upscale_in_train", name=None, )
paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(x=Tensor([1, 2, 4],"float32"), residual=Tensor([1, 2, 4],"float32"), bias=Tensor([4],"float32"), ln_scale=Tensor([4],"float32"), ln_bias=Tensor([4],"float32"), dropout_rate=0.0, ln_epsilon=1e-05, training=True, mode="upscale_in_train", name=None, )
paddle.Tensor.greater_equal(Tensor([19],"int64"), Tensor([],"int64"), )
paddle.Tensor.greater_equal(Tensor([21],"int64"), Tensor([],"int64"), )
paddle.Tensor.flip(Tensor([16, 3, 224, 224],"float32"), 0, )
paddle.Tensor.flip(Tensor([16],"int64"), 0, )
paddle.Tensor.flip(Tensor([2, 2],"float32"), 1, )
paddle.Tensor.flip(Tensor([2, 3],"float32"), 0, )
paddle.Tensor.flip(Tensor([4, 2, 64, 64],"float32"), 1, )
paddle.Tensor.flip(Tensor([4, 2],"float32"), 1, )
paddle.Tensor.outer(x=Tensor([1, 4],"float32"), y=Tensor([1, 4],"float32"), )
paddle.Tensor.outer(x=Tensor([1, 4],"float64"), y=Tensor([1, 4],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 1],"float64"), y=Tensor([4, 1],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2, 3],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 2, 5, 2],"float64"), y=Tensor([2, 3, 4, 4],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3, 4],"float64"), )
paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 5],"float64"), q=list[0.25,0.5,0.75,], axis=3, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 5],"float64"), q=tuple(0.11,0.5,0.73,0.9,), axis=4, keepdim=False, )
paddle.Tensor.take_along_axis(Tensor([128, 1000],"float32"), indices=Tensor([128, 1],"int32"), axis=-1, )
paddle.Tensor.take_along_axis(Tensor([80, 1000],"float32"), indices=Tensor([80, 1],"int32"), axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=Tensor([],"float32"), axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=Tensor([],"float32"), axis=0, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=None, dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([3, 3, 4],"float32"), x=None, dx=Tensor([],"int64"), axis=1, )
paddle.cumulative_trapezoid(y=Tensor([3, 3, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, )
paddle.dsplit(Tensor([4, 2, 6],"bool"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"float16"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"float32"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"float64"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"int32"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"int64"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"uint8"), 3, )
paddle.dsplit(Tensor([4, 3, 6],"int64"), 2, )
paddle.dsplit(Tensor([4, 3, 6],"int64"), 3, )
paddle.hsplit(Tensor([4, 6, 3],"int64"), 2, )
paddle.hsplit(Tensor([4, 6, 3],"int64"), 3, )
paddle.hsplit(Tensor([4, 6],"int64"), 2, )
paddle.hsplit(Tensor([4, 6],"int64"), 3, )
paddle.hsplit(Tensor([6],"bool"), 3, )
paddle.hsplit(Tensor([6],"float16"), 3, )
paddle.hsplit(Tensor([6],"float32"), 3, )
paddle.hsplit(Tensor([6],"float64"), 3, )
paddle.hsplit(Tensor([6],"int32"), 3, )
paddle.hsplit(Tensor([6],"int64"), 2, )
paddle.hsplit(Tensor([6],"int64"), 3, )
paddle.hsplit(Tensor([6],"uint8"), 3, )
paddle.logsumexp(Tensor([1000],"float32"), )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float32"), )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float32"), None, False, )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float32"), None, True, )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float64"), None, False, )
paddle.logsumexp(Tensor([3, 5],"float32"), axis=None, )
paddle.logsumexp(Tensor([3, 5],"float32"), keepdim=True, )
paddle.logsumexp(Tensor([30, 200, 40],"float32"), )
paddle.logsumexp(Tensor([30, 200, 40],"float32"), keepdim=False, )
paddle.logsumexp(Tensor([],"float32"), axis=None, )
paddle.nn.functional.unfold(Tensor([3, 3, 20, 20],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, )
paddle.vsplit(Tensor([6, 4, 3],"int64"), 2, )
paddle.vsplit(Tensor([6, 4, 3],"int64"), 3, )
paddle.vsplit(Tensor([6, 4],"bool"), 3, )
paddle.vsplit(Tensor([6, 4],"float16"), 3, )
paddle.vsplit(Tensor([6, 4],"float32"), 3, )
paddle.vsplit(Tensor([6, 4],"float64"), 3, )
paddle.vsplit(Tensor([6, 4],"int32"), 3, )
paddle.vsplit(Tensor([6, 4],"int64"), 2, )
paddle.vsplit(Tensor([6, 4],"int64"), 3, )
paddle.vsplit(Tensor([6, 4],"uint8"), 3, )
