paddle.nanquantile(Tensor([2, 3],"float32"), list[0.3,0.7,], 1, )
paddle.nanquantile(Tensor([4, 7, 6],"float64"), q=0.1, axis=list[1,2,], keepdim=True, )
paddle.nanquantile(Tensor([4, 7, 6],"float64"), q=0.75, axis=list[0,2,], )
paddle.nanquantile(Tensor([8],"float32"), list[0.55,0.7,], 0, )
paddle.nn.functional.fold(Tensor([3, 12, 12],"float64"), output_sizes=list[4,5,], kernel_sizes=list[2,2,], strides=list[1,1,], paddings=list[0,0,0,0,], dilations=list[1,1,], name=None, )
paddle.nn.functional.layer_norm(Tensor([1, 2, 2],"float32"), 2, epsilon=1e-05, weight=None, bias=None, )
paddle.nn.functional.layer_norm(Tensor([1, 2, 2],"float32"), 2, epsilon=1e-05, weight=Tensor([2],"float32"), bias=Tensor([2],"float32"), )
paddle.nn.functional.layer_norm(Tensor([10, 20],"float16"), list[20,], Tensor([20],"float32"), Tensor([20],"float32"), )
paddle.nn.functional.layer_norm(Tensor([14, 209, 384],"float32"), 384, weight=Tensor([384],"float32"), bias=Tensor([384],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([2, 3, 10, 10],"float32"), list[3,10,10,], Tensor([300],"float32"), Tensor([300],"float32"), )
paddle.nn.functional.layer_norm(Tensor([2, 6, 6, 3],"float32"), list[6,6,3,], weight=None, bias=Tensor([108],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([2, 6, 6, 3],"float32"), list[6,6,3,], weight=Tensor([108],"float32"), bias=None, epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([2, 6, 6, 3],"float32"), list[6,6,3,], weight=Tensor([108],"float32"), bias=Tensor([108],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([2, 6, 6, 3],"float64"), list[6,6,3,], weight=None, bias=Tensor([108],"float64"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([2, 6, 6, 3],"float64"), list[6,6,3,], weight=Tensor([108],"float64"), bias=None, epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([2, 6, 6, 3],"float64"), list[6,6,3,], weight=Tensor([108],"float64"), bias=Tensor([108],"float64"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([20, 10, 60, 30],"float32"), list[10,60,30,], weight=Tensor([18000],"float32"), bias=Tensor([18000],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([20, 10, 60, 70],"float32"), list[60,70,], weight=Tensor([4200],"float32"), bias=Tensor([4200],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([4, 10, 4, 4],"float32"), 4, )
paddle.nn.functional.layer_norm(Tensor([64, 64, 128],"float32"), list[64,128,], Tensor([8192],"float32"), Tensor([8192],"float32"), )
paddle.nn.functional.layer_norm(Tensor([7, 165, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([7, 186, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([7, 206, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([7, 209, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([7, 220, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([7, 286, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([7, 435, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
paddle.tril_indices(4, None, 2, )
paddle.triu_indices(4, None, 2, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 1, 8],"float32"), Tensor([8, 8],"float32"), Tensor([8, 8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), 0.0, 0.0, activation="gelu", pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, Tensor([4],"float32"), Tensor([4],"float32"), dropout1_rate=0, dropout2_rate=0, activation="relu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=False, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, dropout1_rate=0, dropout2_rate=0, activation="gelu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=True, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, dropout1_rate=0, dropout2_rate=0, activation="relu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=True, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 98, 508],"float32"), Tensor([508, 130],"float32"), Tensor([130, 508],"float32"), Tensor([130],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), 0.0, 0.0, activation="gelu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 98, 508],"float32"), Tensor([508, 130],"float32"), Tensor([130, 508],"float32"), Tensor([130],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), 0.0, 0.0, activation="relu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 98, 508],"float64"), Tensor([508, 130],"float64"), Tensor([130, 508],"float64"), Tensor([130],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), 0.0, 0.0, activation="gelu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), activation="gelu", dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), dropout1_rate=0, dropout2_rate=0, pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), ln1_scale=Tensor([2],"float32"), ln1_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), ln2_scale=Tensor([2],"float32"), ln2_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(Tensor([8, 128, 1024],"float32"), Tensor([8, 128, 1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 0.0, 1e-05, )
paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(x=Tensor([1, 2, 4],"float32"), residual=Tensor([1, 2, 4],"float32"), bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, dropout_rate=0.0, ln_epsilon=1e-05, training=True, mode="upscale_in_train", name=None, )
paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(x=Tensor([1, 2, 4],"float32"), residual=Tensor([1, 2, 4],"float32"), bias=Tensor([4],"float32"), ln_scale=Tensor([4],"float32"), ln_bias=Tensor([4],"float32"), dropout_rate=0.0, ln_epsilon=1e-05, training=True, mode="upscale_in_train", name=None, )
paddle.Tensor.greater_equal(Tensor([19],"int64"), Tensor([],"int64"), )
paddle.Tensor.greater_equal(Tensor([21],"int64"), Tensor([],"int64"), )
paddle.Tensor.slice(Tensor([4, 4],"float32"), list[1,], list[0,], list[1,], )
paddle.zeros(name="x", shape=list[100,10,], dtype="uint16", )
paddle.Tensor.reshape(Tensor([0, 0, 5, 5],"float32"), list[0,1,], )
paddle.Tensor.reshape(Tensor([0, 0, 5, 5],"float32"), list[1,0,], )
paddle.Tensor.reshape(Tensor([0, 0],"float32"), list[0,0,5,5,0,0,5,5,], )
paddle.Tensor.reshape(Tensor([0, 0],"float32"), list[5,0,5,0,5,0,5,0,], )
paddle.Tensor.reshape(Tensor([0, 0],"float32"), list[5,5,0,5,5,5,0,5,], )
paddle.Tensor.reshape(Tensor([0, 0],"float32"), list[5,5,5,0,5,5,5,0,], )
paddle.Tensor.reshape(Tensor([0, 0],"float64"), list[0,5,5,5,0,5,5,5,], )
paddle.Tensor.reshape(Tensor([0, 10, 8],"float64"), list[0,], )
paddle.Tensor.reshape(Tensor([0, 2, 3],"float32"), list[0,6,], )
paddle.Tensor.reshape(Tensor([0, 4, 5, 5],"float64"), list[0,4,], )
paddle.Tensor.reshape(Tensor([0, 5, 5, 5],"float32"), list[1,0,], )
paddle.Tensor.reshape(Tensor([0, 5, 5, 5],"float64"), list[0,1,], )
paddle.Tensor.reshape(Tensor([0, 5, 5, 5],"float64"), list[1,0,], )
paddle.Tensor.reshape(Tensor([0, 7, 11],"float32"), list[0,], )
paddle.Tensor.reshape(Tensor([0, 7, 7],"float32"), list[0,], )
paddle.Tensor.reshape(Tensor([0, 9, 9],"float32"), list[0,], )
paddle.Tensor.reshape(Tensor([125, 0],"float32"), list[1,5,5,5,0,5,5,5,], )
paddle.Tensor.reshape(Tensor([5, 0, 4, 3],"float32"), list[5,0,], )
paddle.Tensor.reshape(Tensor([5, 0, 5, 0],"float32"), list[0,1,], )
paddle.Tensor.reshape(Tensor([5, 0, 5, 0],"float32"), list[1,0,], )
paddle.Tensor.reshape(Tensor([5, 5, 0, 5],"float32"), list[0,1,], )
paddle.Tensor.reshape(Tensor([5, 5, 0, 5],"float32"), list[1,0,], )
paddle.Tensor.reshape(Tensor([5, 5, 5, 0],"float32"), list[0,1,], )
paddle.Tensor.reshape(Tensor([5, 5, 5, 0],"float32"), list[1,0,], )
paddle.geometric.send_ue_recv(Tensor([10, 20],"float64"), Tensor([15, 20],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "mean", None, None, )
paddle.geometric.send_ue_recv(Tensor([10, 20],"float64"), Tensor([150, 1],"float64"), Tensor([150],"int64"), Tensor([150],"int64"), "mul", "sum", None, None, )
paddle.geometric.send_ue_recv(Tensor([10, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "sum", None, None, )
paddle.geometric.send_ue_recv(Tensor([3, 3],"float32"), Tensor([4, 1],"float32"), Tensor([4],"int32"), Tensor([4],"int32"), "sub", "max", )
paddle.nn.functional.instance_norm(Tensor([2, 100, 3, 5],"float32"), None, None, Tensor([100],"float32"), Tensor([100],"float32"), True, 0.9, 1e-05, )
paddle.nn.functional.instance_norm(Tensor([2, 100, 3, 5],"float64"), None, None, Tensor([100],"float64"), Tensor([100],"float64"), True, 0.9, 1e-05, )
paddle.nn.functional.label_smooth(label=Tensor([264, 14, 33712],"float32"), epsilon=0.1, )
paddle.Tensor.flip(Tensor([16, 3, 224, 224],"float32"), 0, )
paddle.Tensor.flip(Tensor([16],"int64"), 0, )
paddle.Tensor.flip(Tensor([2, 2],"float32"), 1, )
paddle.Tensor.flip(Tensor([2, 3],"float32"), 0, )
paddle.Tensor.flip(Tensor([4, 2, 64, 64],"float32"), 1, )
paddle.Tensor.flip(Tensor([4, 2],"float32"), 1, )
paddle.Tensor.outer(x=Tensor([1, 4],"float32"), y=Tensor([1, 4],"float32"), )
paddle.Tensor.outer(x=Tensor([1, 4],"float64"), y=Tensor([1, 4],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 1],"float64"), y=Tensor([4, 1],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 2, 3],"float64"), y=Tensor([4, 2, 3],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 2, 5, 2],"float64"), y=Tensor([2, 3, 4, 4],"float64"), )
paddle.Tensor.outer(x=Tensor([4, 2],"float64"), y=Tensor([2, 3, 4],"float64"), )
paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 5],"float64"), q=list[0.25,0.5,0.75,], axis=3, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 5],"float64"), q=tuple(0.11,0.5,0.73,0.9,), axis=4, keepdim=False, )
paddle.Tensor.take_along_axis(Tensor([128, 1000],"float32"), indices=Tensor([128, 1],"int32"), axis=-1, )
paddle.Tensor.take_along_axis(Tensor([80, 1000],"float32"), indices=Tensor([80, 1],"int32"), axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=Tensor([],"float32"), axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=Tensor([],"float32"), axis=0, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=None, dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, )
paddle.cumulative_trapezoid(y=Tensor([3, 3, 4],"float32"), x=None, dx=Tensor([],"int64"), axis=1, )
paddle.cumulative_trapezoid(y=Tensor([3, 3, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, )
paddle.dsplit(Tensor([4, 2, 6],"bool"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"float16"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"float32"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"float64"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"int32"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"int64"), 3, )
paddle.dsplit(Tensor([4, 2, 6],"uint8"), 3, )
paddle.dsplit(Tensor([4, 3, 6],"int64"), 2, )
paddle.dsplit(Tensor([4, 3, 6],"int64"), 3, )
paddle.hsplit(Tensor([4, 6, 3],"int64"), 2, )
paddle.hsplit(Tensor([4, 6, 3],"int64"), 3, )
paddle.hsplit(Tensor([4, 6],"int64"), 2, )
paddle.hsplit(Tensor([4, 6],"int64"), 3, )
paddle.hsplit(Tensor([6],"bool"), 3, )
paddle.hsplit(Tensor([6],"float16"), 3, )
paddle.hsplit(Tensor([6],"float32"), 3, )
paddle.hsplit(Tensor([6],"float64"), 3, )
paddle.hsplit(Tensor([6],"int32"), 3, )
paddle.hsplit(Tensor([6],"int64"), 2, )
paddle.hsplit(Tensor([6],"int64"), 3, )
paddle.hsplit(Tensor([6],"uint8"), 3, )
paddle.logsumexp(Tensor([1000],"float32"), )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float32"), )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float32"), None, False, )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float32"), None, True, )
paddle.logsumexp(Tensor([2, 3, 4, 5],"float64"), None, False, )
paddle.logsumexp(Tensor([3, 5],"float32"), axis=None, )
paddle.logsumexp(Tensor([3, 5],"float32"), keepdim=True, )
paddle.logsumexp(Tensor([30, 200, 40],"float32"), )
paddle.logsumexp(Tensor([30, 200, 40],"float32"), keepdim=False, )
paddle.logsumexp(Tensor([],"float32"), axis=None, )
paddle.nn.functional.unfold(Tensor([3, 3, 20, 20],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, )
paddle.vsplit(Tensor([6, 4, 3],"int64"), 2, )
paddle.vsplit(Tensor([6, 4, 3],"int64"), 3, )
paddle.vsplit(Tensor([6, 4],"bool"), 3, )
paddle.vsplit(Tensor([6, 4],"float16"), 3, )
paddle.vsplit(Tensor([6, 4],"float32"), 3, )
paddle.vsplit(Tensor([6, 4],"float64"), 3, )
paddle.vsplit(Tensor([6, 4],"int32"), 3, )
paddle.vsplit(Tensor([6, 4],"int64"), 2, )
paddle.vsplit(Tensor([6, 4],"int64"), 3, )
paddle.vsplit(Tensor([6, 4],"uint8"), 3, )
