paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 1, 128, 1, 32],"float32"), None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=True, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([1, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([1, 1, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([100, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([100, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([101, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([101, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([104, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([104, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([123, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([123, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([131, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([131, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([136, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([136, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([145, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([145, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([154, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([154, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([167, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([167, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([172, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([172, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([181, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([181, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([2, 1, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([2, 1, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, begin_norm_axis=1, quant_scale=0.17649085819721222, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.11210860311985016, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.12998223304748535, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.1337163746356964, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.13811707496643066, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.15001465380191803, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.18028168380260468, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.18152809143066406, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.1875457912683487, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.10790305584669113, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.11413285881280899, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.12078320235013962, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.13032963871955872, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.1428571492433548, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.16197405755519867, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.18854722380638123, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([2, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([203, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([203, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([221, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([221, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([31, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([31, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([32, 256],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([32, 256],"float16"), quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-06, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-06, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([32, 256],"float32"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, begin_norm_axis=1, quant_scale=0.17649085819721222, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.11210860311985016, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.12998223304748535, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.1337163746356964, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.13811707496643066, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.15001465380191803, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.18028168380260468, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.18152809143066406, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.1875457912683487, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.10790305584669113, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.11413285881280899, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.12078320235013962, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.13032963871955872, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.1428571492433548, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.16197405755519867, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.18854722380638123, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([58, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([58, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([60, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([60, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([64, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([64, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([67, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([67, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([71, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([71, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([74, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([74, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([77, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([77, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([78, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([78, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([81, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([81, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([87, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([87, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([88, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([88, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([89, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([89, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([92, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([92, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([97, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([97, 64],"float16"), )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"float16"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, None, None, None, 1, 0, False, "default", -1, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"float16"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, None, None, None, 1, 0, False, "default", 10, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"int32"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, Tensor([3, 32, 128],"float32"), None, None, 1, 0, False, "fp16", -1, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([1, 1, 192],"float16"), cache_kv=Tensor([2, 1, 1, 50, 64],"float16"), src_mask=Tensor([1, 1, 1, 50],"float16"), sequence_lengths=Tensor([1, 1],"int32"), rotary_tensor=Tensor([2, 1, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 1024],"float16"), cache_kv=Tensor([2, 2, 2, 32768, 128],"float16"), src_mask=Tensor([2, 1, 1, 32768],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 128],"float32"), rotary_emb_dims=1, use_neox_rotary_style=False, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 192],"float16"), cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=None, rotary_emb_dims=0, use_neox_rotary_style=False, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 192],"float16"), cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.02483507990837097, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.025167126208543777, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.030970240011811256, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03103782795369625, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03455723449587822, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03654532507061958, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.037230949848890305, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03799910843372345, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 2304],"float16"), cache_kv=Tensor([2, 2, 8, 4096, 96],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 96],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 8, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1],"int32"), Tensor([1],"int32"), Tensor([1, 1, 64, 64],"float32"), 0.25, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([3, 16, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([3, 1, 64, 64],"float16"), 0.17677669529663687, )
paddle.meshgrid(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([100],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([2],"complex128"),Tensor([1],"complex128"),Tensor([3],"complex128"),Tensor([0],"complex128"),], )
paddle.meshgrid(list[Tensor([2],"float16"),Tensor([2],"float16"),Tensor([1],"float16"),Tensor([0],"float16"),], )
paddle.meshgrid(list[Tensor([2],"float64"),Tensor([4],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([2],"int64"),Tensor([2],"int64"),Tensor([1],"int64"),Tensor([0],"int64"),], )
paddle.meshgrid(list[Tensor([3],"complex128"),Tensor([5],"complex128"),Tensor([5],"complex128"),Tensor([0],"complex128"),], )
paddle.meshgrid(list[Tensor([3],"float64"),Tensor([5],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([3],"int32"),Tensor([5],"int32"),Tensor([3],"int32"),Tensor([0],"int32"),], )
paddle.meshgrid(list[Tensor([4],"float16"),Tensor([3],"float16"),Tensor([5],"float16"),Tensor([0],"float16"),], )
paddle.meshgrid(list[Tensor([4],"float32"),Tensor([2],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([4],"int32"),Tensor([4],"int32"),Tensor([5],"int32"),Tensor([0],"int32"),], )
paddle.meshgrid(list[Tensor([5],"complex64"),Tensor([2],"complex64"),Tensor([5],"complex64"),Tensor([0],"complex64"),], )
paddle.meshgrid(list[Tensor([5],"complex64"),Tensor([4],"complex64"),Tensor([3],"complex64"),Tensor([0],"complex64"),], )
paddle.meshgrid(list[Tensor([5],"int64"),Tensor([4],"int64"),Tensor([4],"int64"),Tensor([0],"int64"),], )
paddle.nn.functional.feature_alpha_dropout(x=Tensor([40, 40],"bfloat16"), p=0.0, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float16"), weight=Tensor([10, 1],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float16"), weight=Tensor([10, 10],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float32"), weight=Tensor([10, 10],"float16"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 5],"float32"), weight=Tensor([5, 5],"float16"), bias=Tensor([5],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([1, 96],"float32"), weight=Tensor([96, 4],"float16"), bias=Tensor([4],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([10, 10],"float16"), weight=Tensor([10, 10],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1000],"float32"), weight=Tensor([1000, 1000],"float16"), bias=Tensor([1000],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1024],"float32"), weight=Tensor([1024, 1024],"float16"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1024],"float32"), weight=Tensor([1024, 1024],"float16"), bias=Tensor([1024],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2],"float32"), weight=Tensor([2, 2],"float16"), bias=Tensor([2],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2],"float32"), weight=Tensor([2, 4],"float16"), bias=Tensor([4],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2048],"float16"), weight=Tensor([2048, 102],"float32"), bias=Tensor([102],"float32"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 8, 8, 8],"float32"), weight=Tensor([8, 8],"float16"), bias=Tensor([8],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([32, 1000],"float32"), weight=Tensor([1000, 1000],"float16"), bias=Tensor([1000],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([5, 5],"float32"), weight=Tensor([5, 5],"float16"), bias=Tensor([5],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([8, 2048],"float16"), weight=Tensor([2048, 102],"float32"), bias=Tensor([102],"float32"), name=None, )
paddle.nn.functional.linear(x=Tensor([8, 4096],"float16"), weight=Tensor([4096, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
paddle.nn.functional.linear(x=tuple(Tensor([1, 10],"float32"),), weight=Tensor([10, 10],"float16"), bias=None, name=None, )
paddle.nn.functional.poisson_nll_loss(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), log_input=True, full=False, epsilon=1e-08, reduction="mean", )
paddle.nn.functional.poisson_nll_loss(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), log_input=True, full=False, epsilon=1e-08, reduction="mean", name=None, )
paddle.normal(0.0, 1.0, list[Tensor([],"int32"),Tensor([],"int32"),Tensor([],"int32"),], )
paddle.roll(Tensor([0, 3],"float32"), shifts=1, )
paddle.roll(Tensor([0, 3],"float32"), shifts=1, axis=0, )
paddle.roll(Tensor([3, 3],"bool"), shifts=1, )
paddle.roll(Tensor([3, 3],"bool"), shifts=1, axis=0, )
paddle.roll(Tensor([4, 0, 3],"float32"), shifts=1, )
paddle.roll(Tensor([4, 0, 3],"float32"), shifts=1, axis=0, )
paddle.signal.istft(Tensor([257, 471],"complex128"), 512, None, None, Tensor([512],"float64"), True, False, True, None, False, )
paddle.slice(Tensor([0, 2],"int64"), axes=list[1,], starts=list[0,], ends=list[1,], )
paddle.slice(Tensor([0, 2],"int64"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([0],"float32"), axes=list[0,], starts=list[0,], ends=list[0,], )
paddle.slice(Tensor([4, 3, 6],"int64"), axes=list[2,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 3, 6],"int64"), axes=list[2,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([4, 6, 3],"int64"), axes=list[1,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 6, 3],"int64"), axes=list[1,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([4, 6],"int64"), axes=list[1,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 6],"int64"), axes=list[1,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6, 4, 3],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6, 4, 3],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6, 4],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6, 4],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[16,], ends=list[16,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[6,], ends=list[6,], )
paddle.Tensor.matmul(Tensor([0, 1],"float32"), Tensor([1, 0],"float32"), )
paddle.Tensor.matmul(Tensor([0, 1],"float64"), Tensor([1, 0],"float64"), )
paddle.Tensor.matmul(Tensor([125, 1],"float32"), Tensor([1, 0],"float32"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 128],"bfloat16"), Tensor([128],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([1, 1024, 1, 16],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 1, 128],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 4096],"bfloat16"), Tensor([4096],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 768],"bfloat16"), Tensor([768],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 1, 16],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 8, 96],"bfloat16"), Tensor([1, 1024, 1, 96],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 114, 64],"bfloat16"), Tensor([64],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 302, 768],"bfloat16"), Tensor([768],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 302, 8, 96],"bfloat16"), Tensor([2, 302, 1, 96],"bfloat16"), )