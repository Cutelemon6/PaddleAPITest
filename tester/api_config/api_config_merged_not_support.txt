paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 1, 128, 1, 32],"float32"), None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=True, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"float16"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, None, None, None, 1, 0, False, "default", -1, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"float16"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, None, None, None, 1, 0, False, "default", 10, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"int32"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, Tensor([3, 32, 128],"float32"), None, None, 1, 0, False, "fp16", -1, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([1, 1, 192],"float16"), cache_kv=Tensor([2, 1, 1, 50, 64],"float16"), src_mask=Tensor([1, 1, 1, 50],"float16"), sequence_lengths=Tensor([1, 1],"int32"), rotary_tensor=Tensor([2, 1, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 1024],"float16"), cache_kv=Tensor([2, 2, 2, 32768, 128],"float16"), src_mask=Tensor([2, 1, 1, 32768],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 128],"float32"), rotary_emb_dims=1, use_neox_rotary_style=False, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 192],"float16"), cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=None, rotary_emb_dims=0, use_neox_rotary_style=False, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 192],"float16"), cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.02483507990837097, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.025167126208543777, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.030970240011811256, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03103782795369625, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03455723449587822, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03654532507061958, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.037230949848890305, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03799910843372345, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 2304],"float16"), cache_kv=Tensor([2, 2, 8, 4096, 96],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 96],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.nn.functional.feature_alpha_dropout(x=Tensor([40, 40],"bfloat16"), p=0.0, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float16"), weight=Tensor([10, 1],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float16"), weight=Tensor([10, 10],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float32"), weight=Tensor([10, 10],"float16"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 5],"float32"), weight=Tensor([5, 5],"float16"), bias=Tensor([5],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([1, 96],"float32"), weight=Tensor([96, 4],"float16"), bias=Tensor([4],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([10, 10],"float16"), weight=Tensor([10, 10],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1000],"float32"), weight=Tensor([1000, 1000],"float16"), bias=Tensor([1000],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1024],"float32"), weight=Tensor([1024, 1024],"float16"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1024],"float32"), weight=Tensor([1024, 1024],"float16"), bias=Tensor([1024],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2],"float32"), weight=Tensor([2, 2],"float16"), bias=Tensor([2],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2],"float32"), weight=Tensor([2, 4],"float16"), bias=Tensor([4],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2048],"float16"), weight=Tensor([2048, 102],"float32"), bias=Tensor([102],"float32"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 8, 8, 8],"float32"), weight=Tensor([8, 8],"float16"), bias=Tensor([8],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([32, 1000],"float32"), weight=Tensor([1000, 1000],"float16"), bias=Tensor([1000],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([5, 5],"float32"), weight=Tensor([5, 5],"float16"), bias=Tensor([5],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([8, 2048],"float16"), weight=Tensor([2048, 102],"float32"), bias=Tensor([102],"float32"), name=None, )
paddle.nn.functional.linear(x=Tensor([8, 4096],"float16"), weight=Tensor([4096, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
paddle.nn.functional.linear(x=tuple(Tensor([1, 10],"float32"),), weight=Tensor([10, 10],"float16"), bias=None, name=None, )
paddle.normal(0.0, 1.0, list[Tensor([],"int32"),Tensor([],"int32"),Tensor([],"int32"),], )
paddle.signal.istft(Tensor([257, 471],"complex128"), 512, None, None, Tensor([512],"float64"), True, False, True, None, False, )
paddle.slice(Tensor([0, 2],"int64"), axes=list[1,], starts=list[0,], ends=list[1,], )
paddle.slice(Tensor([0, 2],"int64"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([0],"float32"), axes=list[0,], starts=list[0,], ends=list[0,], )
paddle.slice(Tensor([4, 3, 6],"int64"), axes=list[2,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 3, 6],"int64"), axes=list[2,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([4, 6, 3],"int64"), axes=list[1,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 6, 3],"int64"), axes=list[1,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([4, 6],"int64"), axes=list[1,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 6],"int64"), axes=list[1,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6, 4, 3],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6, 4, 3],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6, 4],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6, 4],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[16,], ends=list[16,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[6,], ends=list[6,], )
paddle.Tensor.matmul(Tensor([0, 1],"float32"), Tensor([1, 0],"float32"), )
paddle.Tensor.matmul(Tensor([0, 1],"float64"), Tensor([1, 0],"float64"), )
paddle.Tensor.matmul(Tensor([125, 1],"float32"), Tensor([1, 0],"float32"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 128],"bfloat16"), Tensor([128],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([1, 1024, 1, 16],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 1, 128],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 4096],"bfloat16"), Tensor([4096],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 768],"bfloat16"), Tensor([768],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 1, 16],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 8, 96],"bfloat16"), Tensor([1, 1024, 1, 96],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 114, 64],"bfloat16"), Tensor([64],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 302, 768],"bfloat16"), Tensor([768],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 302, 8, 96],"bfloat16"), Tensor([2, 302, 1, 96],"bfloat16"), )
paddle.vision.ops.nms(Tensor([64, 4],"float32"), 0.5, Tensor([64],"float32"), Tensor([64],"int64"), list[0,1,2,3,], 20, )
paddle.vision.ops.psroi_pool(Tensor([2, 128, 32, 32],"float32"), Tensor([4, 4],"float32"), Tensor([2],"int32"), 8, 1.1, )
paddle.vision.ops.psroi_pool(Tensor([2, 128, 32, 32],"float64"), Tensor([4, 4],"float64"), Tensor([2],"int32"), 8, 1.1, )
paddle.vision.ops.psroi_pool(Tensor([2, 490, 28, 28],"float32"), Tensor([3, 4],"float32"), Tensor([2],"int32"), 7, )
paddle.vision.ops.psroi_pool(Tensor([2, 490, 28, 28],"float32"), Tensor([3, 4],"float32"), Tensor([2],"int32"), tuple(7,7,), )
paddle.vision.ops.psroi_pool(Tensor([2, 490, 28, 28],"float64"), Tensor([3, 4],"float64"), Tensor([2],"int32"), tuple(7,7,), )
paddle.vision.ops.psroi_pool(Tensor([3, 12, 6, 4],"float64"), Tensor([6, 4],"float64"), Tensor([3],"int32"), tuple(2,2,), 0.25, )