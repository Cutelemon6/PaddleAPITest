paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 1, 128, 1, 32],"float32"), None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=True, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), None, Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), None, Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), None, Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), None, Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), None, Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), None, Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"float16"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, None, None, None, 1, 0, False, "default", -1, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"float16"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, None, None, None, 1, 0, False, "default", 10, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"int32"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, Tensor([3, 32, 128],"float32"), None, None, 1, 0, False, "fp16", -1, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([1, 1, 192],"float16"), cache_kv=Tensor([2, 1, 1, 50, 64],"float16"), src_mask=Tensor([1, 1, 1, 50],"float16"), sequence_lengths=Tensor([1, 1],"int32"), rotary_tensor=Tensor([2, 1, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 1024],"float16"), cache_kv=Tensor([2, 2, 2, 32768, 128],"float16"), src_mask=Tensor([2, 1, 1, 32768],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 128],"float32"), rotary_emb_dims=1, use_neox_rotary_style=False, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 192],"float16"), cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=None, rotary_emb_dims=0, use_neox_rotary_style=False, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 192],"float16"), cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.02483507990837097, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.025167126208543777, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.030970240011811256, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03103782795369625, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03455723449587822, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03654532507061958, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.037230949848890305, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03799910843372345, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 2304],"float16"), cache_kv=Tensor([2, 2, 8, 4096, 96],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 96],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 8, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1],"int32"), Tensor([1],"int32"), Tensor([1, 1, 64, 64],"float32"), 0.25, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([3, 16, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([3, 1, 64, 64],"float16"), 0.17677669529663687, )
paddle.meshgrid(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([100],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([2],"complex128"),Tensor([1],"complex128"),Tensor([3],"complex128"),Tensor([0],"complex128"),], )
paddle.meshgrid(list[Tensor([2],"float16"),Tensor([2],"float16"),Tensor([1],"float16"),Tensor([0],"float16"),], )
paddle.meshgrid(list[Tensor([2],"float64"),Tensor([4],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([2],"int64"),Tensor([2],"int64"),Tensor([1],"int64"),Tensor([0],"int64"),], )
paddle.meshgrid(list[Tensor([3],"complex128"),Tensor([5],"complex128"),Tensor([5],"complex128"),Tensor([0],"complex128"),], )
paddle.meshgrid(list[Tensor([3],"float64"),Tensor([5],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([3],"int32"),Tensor([5],"int32"),Tensor([3],"int32"),Tensor([0],"int32"),], )
paddle.meshgrid(list[Tensor([4],"float16"),Tensor([3],"float16"),Tensor([5],"float16"),Tensor([0],"float16"),], )
paddle.meshgrid(list[Tensor([4],"float32"),Tensor([2],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([4],"int32"),Tensor([4],"int32"),Tensor([5],"int32"),Tensor([0],"int32"),], )
paddle.meshgrid(list[Tensor([5],"complex64"),Tensor([2],"complex64"),Tensor([5],"complex64"),Tensor([0],"complex64"),], )
paddle.meshgrid(list[Tensor([5],"complex64"),Tensor([4],"complex64"),Tensor([3],"complex64"),Tensor([0],"complex64"),], )
paddle.meshgrid(list[Tensor([5],"int64"),Tensor([4],"int64"),Tensor([4],"int64"),Tensor([0],"int64"),], )
paddle.nn.functional.embedding(Tensor([1, 1, 1],"int64"), weight=Tensor([20, 32],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 10],"int64"), weight=Tensor([10, 32],"float64"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 10],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 100],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 101],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 102],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 103],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 104],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 105],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 106],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 107],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 108],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 109],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 11],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 110],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 111],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 112],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 113],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 114],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 115],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 116],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 117],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 118],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 119],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 120],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.feature_alpha_dropout(x=Tensor([40, 40],"bfloat16"), p=0.0, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float16"), weight=Tensor([10, 1],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float16"), weight=Tensor([10, 10],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float32"), weight=Tensor([10, 10],"float16"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 5],"float32"), weight=Tensor([5, 5],"float16"), bias=Tensor([5],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([1, 96],"float32"), weight=Tensor([96, 4],"float16"), bias=Tensor([4],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([10, 10],"float16"), weight=Tensor([10, 10],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1000],"float32"), weight=Tensor([1000, 1000],"float16"), bias=Tensor([1000],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1024],"float32"), weight=Tensor([1024, 1024],"float16"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1024],"float32"), weight=Tensor([1024, 1024],"float16"), bias=Tensor([1024],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2],"float32"), weight=Tensor([2, 2],"float16"), bias=Tensor([2],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2],"float32"), weight=Tensor([2, 4],"float16"), bias=Tensor([4],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2048],"float16"), weight=Tensor([2048, 102],"float32"), bias=Tensor([102],"float32"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 8, 8, 8],"float32"), weight=Tensor([8, 8],"float16"), bias=Tensor([8],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([32, 1000],"float32"), weight=Tensor([1000, 1000],"float16"), bias=Tensor([1000],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([5, 5],"float32"), weight=Tensor([5, 5],"float16"), bias=Tensor([5],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([8, 2048],"float16"), weight=Tensor([2048, 102],"float32"), bias=Tensor([102],"float32"), name=None, )
paddle.nn.functional.linear(x=Tensor([8, 4096],"float16"), weight=Tensor([4096, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
paddle.nn.functional.linear(x=tuple(Tensor([1, 10],"float32"),), weight=Tensor([10, 10],"float16"), bias=None, name=None, )
paddle.nn.functional.nll_loss(Tensor([10, 10],"float64"), Tensor([10],"int64"), weight=None, ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([10, 10],"float64"), Tensor([10],"int64"), weight=None, ignore_index=-100, reduction="sum", name=None, )
paddle.nn.functional.nll_loss(Tensor([10, 10],"float64"), Tensor([10],"int64"), weight=Tensor([10],"float64"), ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([10, 10],"float64"), Tensor([10],"int64"), weight=Tensor([10],"float64"), ignore_index=-100, reduction="none", name=None, )
paddle.nn.functional.nll_loss(Tensor([10, 10],"float64"), Tensor([10],"int64"), weight=Tensor([10],"float64"), ignore_index=-100, reduction="sum", name=None, )
paddle.nn.functional.nll_loss(Tensor([4, 4],"float32"), Tensor([4],"int64"), )
paddle.nn.functional.nll_loss(Tensor([5, 2],"float64"), label=Tensor([5, 5],"int64"), weight=None, ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 2],"float64"), Tensor([5, 5],"int64"), weight=None, ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 2, 4],"float32"), Tensor([5, 2, 4],"int64"), )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=None, ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([3],"float64"), ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([3],"float64"), ignore_index=-100, reduction="none", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([3],"float64"), ignore_index=-100, reduction="sum", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5],"float64"), Tensor([5, 5, 5],"int64"), weight=None, ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5],"float64"), Tensor([5, 5, 5],"int64"), weight=None, ignore_index=-100, reduction="sum", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5],"float64"), Tensor([5, 5, 5],"int64"), weight=Tensor([3],"float64"), ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5],"float64"), Tensor([5, 5, 5],"int64"), weight=Tensor([3],"float64"), ignore_index=-100, reduction="sum", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3],"float32"), Tensor([5],"int64"), )
paddle.nn.functional.poisson_nll_loss(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), log_input=True, full=False, epsilon=1e-08, reduction="mean", )
paddle.nn.functional.poisson_nll_loss(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), log_input=True, full=False, epsilon=1e-08, reduction="mean", name=None, )
paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, fastemit_lambda=0.0, reduction="none", name=None, )
paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, reduction="mean", fastemit_lambda=0.0, )
paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, reduction="sum", fastemit_lambda=0.0, )
paddle.nn.functional.sequence_mask(Tensor([0],"int64"), )
paddle.nn.functional.sequence_mask(Tensor([3],"float32"), dtype=type(numpy.float64), )
paddle.nn.functional.sequence_mask(Tensor([3],"int64"), )
paddle.nn.functional.sequence_mask(Tensor([3],"int64"), dtype=type(numpy.float64), )
paddle.nn.functional.sequence_mask(Tensor([4],"int64"), None, "float64", None, )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([1, 10],"float32"), Tensor([1, 1],"int64"), )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([100, 10],"float32"), Tensor([100, 1],"int64"), )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 64],"float32"), Tensor([2, 1, 32, 64],"int64"), axis=1, )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 64],"float32"), Tensor([2, 16, 1, 64],"int64"), axis=2, )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 64],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=-1, )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 64],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=3, )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16],"float32"), Tensor([2, 1],"int64"), )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16],"float32"), Tensor([2, 1],"int64"), return_softmax=True, )
paddle.normal(0.0, 1.0, list[Tensor([],"int32"),Tensor([],"int32"),Tensor([],"int32"),], )
paddle.repeat_interleave(Tensor([],"float32"), Tensor([],"int64"), None, )
paddle.repeat_interleave(Tensor([],"float32"), Tensor([1],"int32"), None, )
paddle.repeat_interleave(Tensor([10, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(Tensor([12, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(Tensor([16, 16],"float32"), repeats=2, axis=Tensor([],"int32"), name=None, )
paddle.repeat_interleave(Tensor([2, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(Tensor([2, 3],"bfloat16"), Tensor([6],"int32"), None, )
paddle.repeat_interleave(Tensor([2, 3],"int32"), Tensor([6],"int32"), None, )
paddle.repeat_interleave(Tensor([24, 16],"float32"), repeats=2, axis=Tensor([],"int32"), name=None, )
paddle.repeat_interleave(Tensor([3, 4],"float32"), Tensor([3],"int32"), axis=0, )
paddle.repeat_interleave(Tensor([3, 4],"float32"), Tensor([4],"int32"), 1, )
paddle.repeat_interleave(Tensor([3, 4],"float32"), Tensor([4],"int32"), -1, )
paddle.repeat_interleave(Tensor([4, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(Tensor([6, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(Tensor([8, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(x=Tensor([4, 2, 4, 4, 5],"int32"), repeats=Tensor([2],"int32"), axis=1, )
paddle.roll(Tensor([0, 3],"float32"), shifts=1, )
paddle.roll(Tensor([0, 3],"float32"), shifts=1, axis=0, )
paddle.roll(Tensor([3, 3],"bool"), shifts=1, )
paddle.roll(Tensor([3, 3],"bool"), shifts=1, axis=0, )
paddle.roll(Tensor([4, 0, 3],"float32"), shifts=1, )
paddle.roll(Tensor([4, 0, 3],"float32"), shifts=1, axis=0, )
paddle.signal.istft(Tensor([257, 471],"complex128"), 512, None, None, Tensor([512],"float64"), True, False, True, None, False, )
paddle.slice(Tensor([0, 2],"int64"), axes=list[1,], starts=list[0,], ends=list[1,], )
paddle.slice(Tensor([0, 2],"int64"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([0],"float32"), axes=list[0,], starts=list[0,], ends=list[0,], )
paddle.slice(Tensor([4, 3, 6],"int64"), axes=list[2,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 3, 6],"int64"), axes=list[2,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([4, 6, 3],"int64"), axes=list[1,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 6, 3],"int64"), axes=list[1,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([4, 6],"int64"), axes=list[1,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 6],"int64"), axes=list[1,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6, 4, 3],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6, 4, 3],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6, 4],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6, 4],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[16,], ends=list[16,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[6,], ends=list[6,], )
paddle.take_along_axis(Tensor([1, 36828, 4],"float32"), Tensor([1, 900, 4],"int64"), 1, )
paddle.take_along_axis(Tensor([1, 38367, 4],"float32"), Tensor([1, 900, 4],"int64"), 1, )
paddle.take_along_axis(Tensor([1, 6380, 4],"float32"), Tensor([1, 300, 4],"int64"), axis=1, )
paddle.take_along_axis(Tensor([1, 8550, 4],"float32"), Tensor([1, 300, 4],"int64"), axis=1, )
paddle.take_along_axis(Tensor([1],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([1024],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([1184],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([128, 8],"float32"), Tensor([128, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([16384],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([168],"float64"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([2, 2],"float32"), Tensor([4, 2],"float32"), 0, )
paddle.take_along_axis(Tensor([2, 2],"float32"), Tensor([4, 2],"int64"), 0, )
paddle.take_along_axis(Tensor([2, 3, 4],"float64"), Tensor([1, 3, 4],"int32"), axis=0, )
paddle.take_along_axis(Tensor([2, 3],"float32"), Tensor([2, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([2, 3],"float64"), Tensor([1, 3],"int32"), axis=0, )
paddle.take_along_axis(Tensor([20],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([2160],"float64"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([28, 5],"float32"), Tensor([28, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([3, 2, 5],"float32"), Tensor([1, 1, 3],"int64"), axis=-1, )
paddle.take_along_axis(Tensor([3, 3, 3],"float32"), Tensor([1, 3, 3],"int32"), axis=0, )
paddle.take_along_axis(Tensor([3, 3, 3],"float64"), Tensor([1, 3, 3],"int32"), axis=0, )
paddle.take_along_axis(Tensor([3, 3],"float32"), Tensor([1, 3],"float32"), 0, )
paddle.take_along_axis(Tensor([3, 3],"float32"), Tensor([1, 3],"int64"), 0, )
paddle.take_along_axis(Tensor([3, 3],"float32"), Tensor([1, 3],"int64"), 0, False, )
paddle.take_along_axis(Tensor([3, 5],"float32"), Tensor([1, 3],"int64"), axis=-1, )
paddle.take_along_axis(Tensor([3, 5],"float32"), Tensor([3, 2],"int64"), axis=-1, )
paddle.take_along_axis(Tensor([3, 5],"float64"), Tensor([1, 3],"int64"), axis=-1, )
paddle.take_along_axis(Tensor([3, 6, 3, 4, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"int32"), axis=3, )
paddle.take_along_axis(Tensor([3, 6, 3, 4, 2, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"int32"), axis=4, )
paddle.take_along_axis(Tensor([3, 6, 3, 4, 2, 5],"float64"), Tensor([3, 6, 3, 4, 2, 1],"int32"), axis=5, )
paddle.take_along_axis(Tensor([3],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([30, 5],"float32"), Tensor([30, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([32],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([35968],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([37],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([38, 5],"float32"), Tensor([38, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([4, 2],"float32"), Tensor([4, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([4, 2],"float64"), Tensor([1, 1],"int64"), 1, )
paddle.take_along_axis(Tensor([4, 3, 2],"float32"), Tensor([1, 3, 2],"int64"), axis=1, )
paddle.take_along_axis(Tensor([4, 3],"float32"), Tensor([4, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([4, 4, 4, 2],"float64"), Tensor([1, 1, 1, 1],"int64"), 0, )
paddle.take_along_axis(Tensor([4, 4, 4],"float64"), Tensor([1, 1, 1],"int64"), 0, )
paddle.take_along_axis(Tensor([4, 4],"float64"), Tensor([1, 1],"int64"), 0, )
paddle.take_along_axis(Tensor([4, 42],"float64"), Tensor([4, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([4, 7, 6],"float64"), Tensor([4, 1, 6],"int32"), axis=1, )
paddle.take_along_axis(Tensor([4, 7, 6],"float64"), Tensor([4, 7, 1],"int32"), axis=2, )
paddle.take_along_axis(Tensor([4, 7],"float32"), Tensor([4, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([4, 7],"float64"), Tensor([4, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([4],"float32"), Tensor([1],"int64"), 0, )
paddle.take_along_axis(Tensor([4],"float64"), Tensor([1],"int64"), 0, )
paddle.take_along_axis(Tensor([5, 12],"float64"), Tensor([5, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([5, 2],"float32"), Tensor([5, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([5, 3, 4],"float64"), Tensor([5, 1, 4],"int32"), axis=1, )
paddle.take_along_axis(Tensor([512],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([6],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([7, 24],"float64"), Tensor([7, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([8, 3],"float32"), Tensor([8, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([8],"float32"), Tensor([1],"int32"), axis=0, )
paddle.Tensor.matmul(Tensor([0, 1],"float32"), Tensor([1, 0],"float32"), )
paddle.Tensor.matmul(Tensor([0, 1],"float64"), Tensor([1, 0],"float64"), )
paddle.Tensor.matmul(Tensor([125, 1],"float32"), Tensor([1, 0],"float32"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 128],"bfloat16"), Tensor([128],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([1, 1024, 1, 16],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 1, 128],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 4096],"bfloat16"), Tensor([4096],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 768],"bfloat16"), Tensor([768],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 1, 16],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 8, 96],"bfloat16"), Tensor([1, 1024, 1, 96],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 114, 64],"bfloat16"), Tensor([64],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 302, 768],"bfloat16"), Tensor([768],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 302, 8, 96],"bfloat16"), Tensor([2, 302, 1, 96],"bfloat16"), )
paddle.tensordot(Tensor([0, 0, 5, 5],"float32"), Tensor([0, 0, 5, 5],"float32"), list[list[],list[],], )
paddle.tensordot(Tensor([0, 5, 5, 5],"float64"), Tensor([0, 5, 5, 5],"float64"), list[list[],list[],], )
paddle.tensordot(Tensor([1, 5, 5, 5],"float32"), Tensor([0, 5, 5, 5],"float32"), list[list[],list[],], )
paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), list[Tensor([2],"int64"),Tensor([2],"int64"),], )
paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), Tensor([1],"int64"), )
paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), Tensor([2, 2],"int64"), )
paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), tuple(Tensor([2],"int64"),Tensor([2],"int64"),), )
paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 5],"float64"), list[Tensor([2],"int64"),Tensor([2],"int64"),], )
paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 5],"float64"), Tensor([1],"int64"), )
paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 5],"float64"), Tensor([2, 2],"int64"), )
paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 5],"float64"), tuple(Tensor([2],"int64"),Tensor([2],"int64"),), )
paddle.tensordot(Tensor([5, 0, 5, 0],"float32"), Tensor([5, 0, 5, 0],"float32"), list[list[],list[],], )
paddle.tensordot(Tensor([5, 5, 0, 5],"float32"), Tensor([5, 5, 0, 5],"float32"), list[list[],list[],], )
paddle.tensordot(Tensor([5, 5, 5, 0],"float32"), Tensor([5, 5, 5, 0],"float32"), list[list[],list[],], )
paddle.tile(Tensor([1, 4],"float32"), list[Tensor([],"int64"),1,], )
paddle.tile(Tensor([1, 8],"float32"), list[Tensor([],"int64"),1,], )
paddle.tile(x=Tensor([3],"int64"), repeat_times=Tensor([2],"int32"), )
paddle.view(Tensor([10, 10, 10, 20],"float32"), "uint8", )
paddle.view(Tensor([10, 10, 10, 20],"float32"), Dtype(uint8), )
paddle.vision.ops.decode_jpeg(Tensor([142887],"uint8"), )
paddle.vision.ops.decode_jpeg(Tensor([142887],"uint8"), mode="gray", )
paddle.vision.ops.decode_jpeg(Tensor([142887],"uint8"), mode="rgb", )
paddle.vision.ops.distribute_fpn_proposals(fpn_rois=Tensor([10, 4],"float32"), min_level=2, max_level=5, refer_level=4, refer_scale=224, rois_num=Tensor([2],"int32"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([1, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([10, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([1024, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([2],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([106, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([11, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([110, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([113, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([116, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([117, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([119, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([12, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([122, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([123, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([124, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([125, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([126, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([127, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([128, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([129, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([13, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([130, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([131, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([132, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([133, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([134, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([135, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([136, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([137, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([138, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([139, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([14, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([141, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([142, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([143, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([144, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([145, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([147, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([148, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([149, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([15, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([150, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([151, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([152, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([153, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([154, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([155, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([157, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([158, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([159, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([16, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([160, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([161, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([162, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([163, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([164, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([165, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([166, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([167, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([168, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([169, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([17, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([171, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([172, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([173, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([174, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([175, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([176, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([177, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([178, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([179, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([18, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([180, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([181, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([182, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([183, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([184, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([186, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([187, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([188, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([189, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([19, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([190, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([191, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([192, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([193, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([194, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([195, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([196, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([197, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([198, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([199, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([2, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([20, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([200, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([201, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([202, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([203, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([204, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([2048, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([205, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([206, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([207, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([208, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([209, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([21, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([210, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([212, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([213, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([214, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([215, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([216, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([217, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([218, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([219, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([220, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([221, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([222, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([223, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([224, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([225, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([226, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([227, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([228, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([229, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([230, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([231, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([232, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([233, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([234, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([235, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([236, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([237, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([238, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([239, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([24, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([240, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([241, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([242, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([243, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([244, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([245, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([246, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([247, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([248, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([249, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([25, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([250, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([251, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([252, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([253, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([254, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([255, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([256, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([257, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([258, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([259, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([26, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([260, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([261, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([262, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([263, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([264, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([265, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([266, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([267, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([268, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([269, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([270, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([271, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([272, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([273, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([274, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([275, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([276, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([277, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([278, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([279, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([280, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([281, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([282, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([283, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([284, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([285, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([286, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([287, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([288, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([289, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([290, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([291, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([292, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([293, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([294, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([295, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([296, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([297, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([298, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([299, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([3, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([300, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([301, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([302, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([303, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([304, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([305, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([306, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([307, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([308, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([309, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([310, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([311, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([312, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([313, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([314, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([315, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([316, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([317, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([318, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([319, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([320, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([321, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([322, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([323, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([324, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([325, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([326, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([327, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([328, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([329, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([330, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([331, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([332, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([333, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([334, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([335, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([336, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([337, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([338, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([339, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([340, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([341, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([342, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([343, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([344, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([345, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([346, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([347, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([348, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([349, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([350, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([351, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([352, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([353, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([354, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([355, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([356, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([357, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([358, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([359, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([360, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([362, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([364, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([365, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([366, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([367, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([368, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([369, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([371, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([372, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([374, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([375, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([376, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([377, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([378, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([379, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([380, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([381, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([382, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([383, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([384, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([385, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([386, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([387, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([388, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([389, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([392, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([393, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([394, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([395, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([396, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([397, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([398, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([399, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([400, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([401, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([402, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([403, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([405, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([406, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([407, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([408, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([409, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([411, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([413, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([414, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([415, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([416, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([417, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([418, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([419, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([420, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([421, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([422, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([423, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([424, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([425, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([426, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([427, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([428, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([429, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([431, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([432, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([433, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([434, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([435, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([436, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([437, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([439, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([440, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([441, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([444, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([445, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([448, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([449, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([450, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([451, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([452, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([454, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([455, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([457, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([461, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([463, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([464, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([467, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([469, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([470, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([472, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([473, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([474, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([476, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([478, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([483, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([484, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([486, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([494, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([495, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([499, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([502, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([504, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([505, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([510, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([511, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([512, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([512, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([512, 4],"float32"), 2, 6, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([8, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([80, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([9, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([97, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.nms(Tensor([64, 4],"float32"), 0.5, Tensor([64],"float32"), Tensor([64],"int64"), list[0,1,2,3,], 20, )
paddle.vision.ops.psroi_pool(Tensor([2, 128, 32, 32],"float32"), Tensor([4, 4],"float32"), Tensor([2],"int32"), 8, 1.1, )
paddle.vision.ops.psroi_pool(Tensor([2, 128, 32, 32],"float64"), Tensor([4, 4],"float64"), Tensor([2],"int32"), 8, 1.1, )
paddle.vision.ops.psroi_pool(Tensor([2, 490, 28, 28],"float32"), Tensor([3, 4],"float32"), Tensor([2],"int32"), 7, )
paddle.vision.ops.psroi_pool(Tensor([2, 490, 28, 28],"float32"), Tensor([3, 4],"float32"), Tensor([2],"int32"), tuple(7,7,), )
paddle.vision.ops.psroi_pool(Tensor([2, 490, 28, 28],"float64"), Tensor([3, 4],"float64"), Tensor([2],"int32"), tuple(7,7,), )
paddle.vision.ops.psroi_pool(Tensor([3, 12, 6, 4],"float64"), Tensor([6, 4],"float64"), Tensor([3],"int32"), tuple(2,2,), 0.25, )