paddle.autograd.hessian(Tensor([5, 1],"float32"), list[Tensor([5, 2],"float32"),Tensor([5, 2],"float32"),], batch_axis=0, )
paddle.autograd.jacobian(Tensor([],"float64"), list[Tensor([4],"float64"),Tensor([4],"float64"),], batch_axis=None, )
paddle.cartesian_prod(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.cartesian_prod(list[Tensor([2],"complex128"),Tensor([1],"complex128"),Tensor([3],"complex128"),Tensor([0],"complex128"),], )
paddle.cartesian_prod(list[Tensor([2],"float16"),Tensor([2],"float16"),Tensor([1],"float16"),Tensor([0],"float16"),], )
paddle.cartesian_prod(list[Tensor([2],"float64"),Tensor([4],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.cartesian_prod(list[Tensor([2],"int64"),Tensor([2],"int64"),Tensor([1],"int64"),Tensor([0],"int64"),], )
paddle.cartesian_prod(list[Tensor([3],"complex128"),Tensor([5],"complex128"),Tensor([5],"complex128"),Tensor([0],"complex128"),], )
paddle.cartesian_prod(list[Tensor([3],"float64"),Tensor([5],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.cartesian_prod(list[Tensor([3],"int32"),Tensor([5],"int32"),Tensor([3],"int32"),Tensor([0],"int32"),], )
paddle.cartesian_prod(list[Tensor([4],"float16"),Tensor([3],"float16"),Tensor([5],"float16"),Tensor([0],"float16"),], )
paddle.cartesian_prod(list[Tensor([4],"float32"),Tensor([2],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.cartesian_prod(list[Tensor([4],"int32"),Tensor([4],"int32"),Tensor([5],"int32"),Tensor([0],"int32"),], )
paddle.cartesian_prod(list[Tensor([5],"complex64"),Tensor([2],"complex64"),Tensor([5],"complex64"),Tensor([0],"complex64"),], )
paddle.cartesian_prod(list[Tensor([5],"complex64"),Tensor([4],"complex64"),Tensor([3],"complex64"),Tensor([0],"complex64"),], )
paddle.cartesian_prod(list[Tensor([5],"int64"),Tensor([4],"int64"),Tensor([4],"int64"),Tensor([0],"int64"),], )
paddle.einsum("...ab,...ba,...ab,...ab", Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 64, 64, False, out_scale=1.0, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, None, None, Tensor([2, 1, 128, 1, 32],"float32"), None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), Tensor([2, 8],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=True, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 1536],"float16"), Tensor([4, 8, 64, 64],"uint8"), Tensor([4, 8, 64, 64],"uint8"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), None, None, None, None, None, None, None, None, None, 64, 64, False, use_dynamic_cachekv_quant=False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([128, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([128],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, None, 64, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 1536],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([4, 8, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.block_multihead_attention(Tensor([2, 768],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([4, 2, 64, 64],"float16"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([2, 2],"int32"), None, None, None, None, None, None, None, None, None, None, Tensor([1],"int32"), Tensor([1],"int32"), None, None, Tensor([2, 8, 1, 65],"float16"), 1, 64, False, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([1, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([1, 1, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([100, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([100, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([101, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([101, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([104, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([104, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([123, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([123, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([131, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([131, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([136, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([136, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([145, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([145, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([154, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([154, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([167, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([167, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([172, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([172, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([181, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([181, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([2, 1, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([2, 1, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, begin_norm_axis=1, quant_scale=0.17649085819721222, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.11210860311985016, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.12998223304748535, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.1337163746356964, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.13811707496643066, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.15001465380191803, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.18028168380260468, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.18152809143066406, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.1875457912683487, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.10790305584669113, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.11413285881280899, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.12078320235013962, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.13032963871955872, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.1428571492433548, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.16197405755519867, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.18854722380638123, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([2, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([203, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([203, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([221, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([221, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([31, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([31, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([32, 256],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([32, 256],"float16"), quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-06, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-06, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([32, 256],"float32"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, begin_norm_axis=1, quant_scale=0.17649085819721222, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.11210860311985016, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.12998223304748535, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.1337163746356964, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.13811707496643066, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.15001465380191803, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.18028168380260468, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.18152809143066406, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.1875457912683487, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.10790305584669113, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.11413285881280899, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.12078320235013962, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.13032963871955872, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.1428571492433548, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.16197405755519867, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.18854722380638123, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([58, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([58, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([60, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([60, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([64, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([64, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([67, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([67, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([71, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([71, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([74, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([74, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([77, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([77, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([78, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([78, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([81, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([81, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([87, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([87, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([88, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([88, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([89, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([89, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([92, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([92, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([97, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([97, 64],"float16"), )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), None, Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), None, Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), None, Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), None, Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), None, Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), None, Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"float16"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, None, None, None, 1, 0, False, "default", -1, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"float16"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, None, None, None, 1, 0, False, "default", 10, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(Tensor([2, 12288],"int32"), Tensor([2, 2, 32, 33, 128],"float16"), Tensor([3, 32, 128],"float16"), Tensor([2, 1, 1, 33],"float16"), None, None, None, None, Tensor([3, 32, 128],"float32"), None, None, 1, 0, False, "fp16", -1, 1, 126, -126, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([1, 1, 192],"float16"), cache_kv=Tensor([2, 1, 1, 50, 64],"float16"), src_mask=Tensor([1, 1, 1, 50],"float16"), sequence_lengths=Tensor([1, 1],"int32"), rotary_tensor=Tensor([2, 1, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 1024],"float16"), cache_kv=Tensor([2, 2, 2, 32768, 128],"float16"), src_mask=Tensor([2, 1, 1, 32768],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 128],"float32"), rotary_emb_dims=1, use_neox_rotary_style=False, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 192],"float16"), cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=None, rotary_emb_dims=0, use_neox_rotary_style=False, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 192],"float16"), cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.02483507990837097, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.025167126208543777, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.030970240011811256, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03103782795369625, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03455723449587822, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03654532507061958, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.037230949848890305, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03799910843372345, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 2304],"float16"), cache_kv=Tensor([2, 2, 8, 4096, 96],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 96],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 8, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1, 2, 64, 16],"float32"), Tensor([1],"int32"), Tensor([1],"int32"), Tensor([1, 1, 64, 64],"float32"), 0.25, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1, 232, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1, 36, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1, 37, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1, 38, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1, 45, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1, 47, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1, 50, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1, 52, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1, 57, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1, 59, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 2, 38, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 2, 39, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 2, 40, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 2, 41, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 2, 47, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 2, 51, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 2, 53, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 2, 54, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 4, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 2, 57, 128],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 32768, 32768],"float16"), scale=0.08838834764831845, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 107, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 107, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 8, 235, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 109, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 109, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 8, 237, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 110, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 110, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 8, 238, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 111, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 111, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 8, 239, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 112, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 8, 202, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 8, 74, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 8, 207, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 8, 79, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 8, 208, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 8, 80, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 8, 210, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 8, 82, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 8, 219, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 8, 91, 96],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([3, 16, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3, 2, 64, 32],"float16"), Tensor([3],"int32"), Tensor([3],"int32"), Tensor([3, 1, 64, 64],"float16"), 0.17677669529663687, )
paddle.incubate.softmax_mask_fuse_upper_triangle(x=Tensor([7, 11, 32, 32],"float32"), )
paddle.linalg.matrix_power(Tensor([0, 0],"float32"), 2, )
paddle.linalg.matrix_power(Tensor([2, 3, 0, 0],"float32"), 2, )
paddle.linalg.norm(Tensor([2, 3, 4, 5],"bfloat16"), 2.0, 1, False, )
paddle.linalg.pca_lowrank(Tensor([1, 100, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([1, 100, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([1, 100, 40],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([1, 100, 40],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([1, 100, 40],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([1, 17, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([1, 17, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([1, 4, 100],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([1, 4, 100],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([1, 4, 17],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([1, 4, 17],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([1, 40, 100],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([1, 40, 100],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([1, 40, 100],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([100, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([100, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([100, 40],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([100, 40],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([100, 40],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([17, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([17, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 100, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 100, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 100, 40],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 100, 40],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 100, 40],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 17, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 17, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 4, 100],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 4, 100],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 4, 17],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 4, 17],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 40, 100],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 40, 100],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 40, 100],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([3, 100, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([3, 100, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([3, 100, 40],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([3, 100, 40],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([3, 100, 40],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([3, 17, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([3, 17, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([3, 4, 100],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([3, 4, 100],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([3, 4, 17],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([3, 4, 17],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([3, 40, 100],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([3, 40, 100],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([3, 40, 100],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([4, 100],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([4, 100],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([4, 17],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([4, 17],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([40, 100],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([40, 100],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([40, 100],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([5, 5],"float64"), None, center=False, )
paddle.linalg.solve(Tensor([10, 0, 0],"float32"), Tensor([10, 0, 0],"float32"), left=False, )
paddle.linalg.svdvals(Tensor([1, 12, 10],"float32"), )
paddle.matmul(Tensor([1, 2, 2048, 2048],"bfloat16"), Tensor([1, 2, 2048, 128],"bfloat16"), )
paddle.matmul(Tensor([2, 11008],"int8"), Tensor([64, 11008],"int8"), False, True, )
paddle.matmul(Tensor([2, 64],"int8"), Tensor([192, 64],"int8"), False, True, )
paddle.matmul(Tensor([2, 64],"int8"), Tensor([22016, 64],"int8"), False, True, )
paddle.matmul(Tensor([2, 64],"int8"), Tensor([64, 64],"int8"), False, True, )
paddle.matmul(Tensor([464, 11008],"int8"), Tensor([64, 11008],"int8"), False, True, )
paddle.matmul(Tensor([464, 64],"int8"), Tensor([192, 64],"int8"), False, True, )
paddle.matmul(Tensor([464, 64],"int8"), Tensor([22016, 64],"int8"), False, True, )
paddle.matmul(Tensor([464, 64],"int8"), Tensor([64, 64],"int8"), False, True, )
paddle.matmul(x=Tensor([1, 2, 2048, 128],"bfloat16"), y=Tensor([1, 2, 2048, 128],"bfloat16"), transpose_x=False, transpose_y=True, )
paddle.matmul(x=Tensor([3, 2, 2, 5],"float64"), y=Tensor([5],"float64"), transpose_x=False, transpose_y=True, )
paddle.meshgrid(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([100],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([2],"complex128"),Tensor([1],"complex128"),Tensor([3],"complex128"),Tensor([0],"complex128"),], )
paddle.meshgrid(list[Tensor([2],"float16"),Tensor([2],"float16"),Tensor([1],"float16"),Tensor([0],"float16"),], )
paddle.meshgrid(list[Tensor([2],"float64"),Tensor([4],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([2],"int64"),Tensor([2],"int64"),Tensor([1],"int64"),Tensor([0],"int64"),], )
paddle.meshgrid(list[Tensor([3],"complex128"),Tensor([5],"complex128"),Tensor([5],"complex128"),Tensor([0],"complex128"),], )
paddle.meshgrid(list[Tensor([3],"float64"),Tensor([5],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([3],"int32"),Tensor([5],"int32"),Tensor([3],"int32"),Tensor([0],"int32"),], )
paddle.meshgrid(list[Tensor([4],"float16"),Tensor([3],"float16"),Tensor([5],"float16"),Tensor([0],"float16"),], )
paddle.meshgrid(list[Tensor([4],"float32"),Tensor([2],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([4],"int32"),Tensor([4],"int32"),Tensor([5],"int32"),Tensor([0],"int32"),], )
paddle.meshgrid(list[Tensor([5],"complex64"),Tensor([2],"complex64"),Tensor([5],"complex64"),Tensor([0],"complex64"),], )
paddle.meshgrid(list[Tensor([5],"complex64"),Tensor([4],"complex64"),Tensor([3],"complex64"),Tensor([0],"complex64"),], )
paddle.meshgrid(list[Tensor([5],"int64"),Tensor([4],"int64"),Tensor([4],"int64"),Tensor([0],"int64"),], )
paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([128, 16],"float32"), Tensor([128],"int64"), Tensor([16, 8],"float32"), list[list[Tensor([16, 8],"float32"),Tensor([8, 5],"float32"),],list[Tensor([16, 4],"float32"),Tensor([4, 5],"float32"),],list[Tensor([16, 2],"float32"),Tensor([2, 5],"float32"),],], list[5,10,15,20,], None, )
paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([4, 8],"float32"), Tensor([4],"int64"), Tensor([8, 3],"float32"), list[list[Tensor([8, 4],"float32"),Tensor([4, 2],"float32"),],], list[2,4,], None, )
paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([8, 8],"float32"), Tensor([8],"int64"), Tensor([8, 3],"float32"), list[list[Tensor([8, 4],"float32"),Tensor([4, 2],"float32"),],], list[2,4,], None, )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), Tensor([1],"float32"), output_size=Tensor([2],"int64"), )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), output_size=Tensor([2],"int32"), stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.ctc_loss(Tensor([25, 256, 37],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([25, 256, 96],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([25, 512, 37],"float32"), Tensor([512, 25],"int32"), Tensor([512],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([3, 3, 15],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int64"), Tensor([3],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([4, 4, 34],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="mean", )
paddle.nn.functional.ctc_loss(Tensor([4, 4, 34],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="sum", )
paddle.nn.functional.ctc_loss(Tensor([40, 192, 6625],"float32"), Tensor([192, 25],"int32"), Tensor([192],"int64"), Tensor([192],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([40, 4, 6625],"float32"), Tensor([4, 25],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([40, 64, 6625],"float32"), Tensor([64, 25],"int32"), Tensor([64],"int64"), Tensor([64],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([40, 8, 6625],"float32"), Tensor([8, 25],"int32"), Tensor([8],"int64"), Tensor([8],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([40, 96, 6625],"float32"), Tensor([96, 25],"int32"), Tensor([96],"int64"), Tensor([96],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([5, 2, 3],"float64"), labels=Tensor([2, 3],"int32"), input_lengths=Tensor([2],"int64"), label_lengths=Tensor([2],"int64"), blank=0, reduction="mean", )
paddle.nn.functional.ctc_loss(Tensor([5, 2, 3],"float64"), labels=Tensor([2, 3],"int32"), input_lengths=Tensor([2],"int64"), label_lengths=Tensor([2],"int64"), blank=0, reduction="none", )
paddle.nn.functional.ctc_loss(Tensor([5, 2, 3],"float64"), Tensor([2, 3],"int32"), Tensor([2],"int64"), Tensor([2],"int64"), 0, "mean", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([5, 2, 3],"float64"), Tensor([2, 3],"int32"), Tensor([2],"int64"), Tensor([2],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([80, 64, 6625],"float32"), Tensor([64, 25],"int32"), Tensor([64],"int64"), Tensor([64],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.dice_loss(Tensor([5, 2],"float64"), label=Tensor([5, 1],"int64"), epsilon=1e-05, )
paddle.nn.functional.embedding(Tensor([1, 1, 1],"int64"), weight=Tensor([20, 32],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 10],"int64"), weight=Tensor([10, 32],"float64"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 10],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 100],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 101],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 102],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 103],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 104],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 105],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 106],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 107],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 108],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 109],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 11],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 110],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 111],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 112],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 113],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 114],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 115],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 116],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 117],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 118],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 119],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.embedding(Tensor([1, 120],"int64"), weight=Tensor([8000, 256],"float32"), padding_idx=None, max_norm=None, norm_type=2.0, sparse=False, scale_grad_by_freq=False, name=None, )
paddle.nn.functional.feature_alpha_dropout(x=Tensor([40, 40],"bfloat16"), p=0.0, )
paddle.nn.functional.gather_tree(Tensor([11, 4, 4],"int64"), Tensor([11, 4, 4],"int64"), )
paddle.nn.functional.gather_tree(Tensor([11, 4, 8],"int64"), Tensor([11, 4, 8],"int64"), )
paddle.nn.functional.gather_tree(Tensor([21, 8, 4],"int64"), Tensor([21, 8, 4],"int64"), )
paddle.nn.functional.gather_tree(Tensor([3, 2, 2],"int64"), Tensor([3, 2, 2],"int64"), )
paddle.nn.functional.gather_tree(Tensor([6, 4, 4],"int64"), Tensor([6, 4, 4],"int64"), )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2, 3],"float32"), Tensor([10, 2, 3],"float32"), Tensor([10, 2, 1],"float32"), False, 1e-06, "none", None, )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2, 3],"float32"), Tensor([10, 2, 3],"float32"), Tensor([10, 2, 1],"float32"), full=False, reduction="none", )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2, 3],"float32"), Tensor([10, 2, 3],"float32"), Tensor([10, 2],"float32"), False, 1e-06, "none", None, )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2, 3],"float32"), Tensor([10, 2, 3],"float32"), Tensor([10, 2],"float32"), full=False, reduction="none", )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), False, 1e-06, "none", None, )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), full=False, reduction="none", )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), full=True, reduction="mean", )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), full=True, reduction="sum", )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), True, 1e-06, "mean", None, )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), Tensor([10, 2],"float32"), True, 1e-06, "sum", None, )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2],"float64"), Tensor([10, 2],"float64"), Tensor([10, 2],"float64"), False, 1e-06, "none", None, )
paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2],"float64"), Tensor([10, 2],"float64"), Tensor([10, 2],"float64"), full=False, reduction="none", )
paddle.nn.functional.linear(x=Tensor([1, 10],"float16"), weight=Tensor([10, 1],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float16"), weight=Tensor([10, 10],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 10],"float32"), weight=Tensor([10, 10],"float16"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([1, 5],"float32"), weight=Tensor([5, 5],"float16"), bias=Tensor([5],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([1, 96],"float32"), weight=Tensor([96, 4],"float16"), bias=Tensor([4],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([10, 10],"float16"), weight=Tensor([10, 10],"float32"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1000],"float32"), weight=Tensor([1000, 1000],"float16"), bias=Tensor([1000],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1024],"float32"), weight=Tensor([1024, 1024],"float16"), bias=None, name=None, )
paddle.nn.functional.linear(x=Tensor([100, 1024],"float32"), weight=Tensor([1024, 1024],"float16"), bias=Tensor([1024],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2],"float32"), weight=Tensor([2, 2],"float16"), bias=Tensor([2],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2],"float32"), weight=Tensor([2, 4],"float16"), bias=Tensor([4],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 2048],"float16"), weight=Tensor([2048, 102],"float32"), bias=Tensor([102],"float32"), name=None, )
paddle.nn.functional.linear(x=Tensor([2, 8, 8, 8],"float32"), weight=Tensor([8, 8],"float16"), bias=Tensor([8],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([32, 1000],"float32"), weight=Tensor([1000, 1000],"float16"), bias=Tensor([1000],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([5, 5],"float32"), weight=Tensor([5, 5],"float16"), bias=Tensor([5],"float16"), name=None, )
paddle.nn.functional.linear(x=Tensor([8, 2048],"float16"), weight=Tensor([2048, 102],"float32"), bias=Tensor([102],"float32"), name=None, )
paddle.nn.functional.linear(x=Tensor([8, 4096],"float16"), weight=Tensor([4096, 4096],"float32"), bias=Tensor([4096],"float32"), name=None, )
paddle.nn.functional.linear(x=tuple(Tensor([1, 10],"float32"),), weight=Tensor([10, 10],"float16"), bias=None, name=None, )
paddle.nn.functional.nll_loss(Tensor([10, 10],"float64"), Tensor([10],"int64"), weight=None, ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([10, 10],"float64"), Tensor([10],"int64"), weight=None, ignore_index=-100, reduction="sum", name=None, )
paddle.nn.functional.nll_loss(Tensor([10, 10],"float64"), Tensor([10],"int64"), weight=Tensor([10],"float64"), ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([10, 10],"float64"), Tensor([10],"int64"), weight=Tensor([10],"float64"), ignore_index=-100, reduction="none", name=None, )
paddle.nn.functional.nll_loss(Tensor([10, 10],"float64"), Tensor([10],"int64"), weight=Tensor([10],"float64"), ignore_index=-100, reduction="sum", name=None, )
paddle.nn.functional.nll_loss(Tensor([4, 4],"float32"), Tensor([4],"int64"), )
paddle.nn.functional.nll_loss(Tensor([5, 2],"float64"), label=Tensor([5, 5],"int64"), weight=None, ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 2],"float64"), Tensor([5, 5],"int64"), weight=None, ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 2, 4],"float32"), Tensor([5, 2, 4],"int64"), )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=None, ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([3],"float64"), ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([3],"float64"), ignore_index=-100, reduction="none", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5, 5],"float64"), Tensor([5, 5, 5, 5],"int64"), weight=Tensor([3],"float64"), ignore_index=-100, reduction="sum", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5],"float64"), Tensor([5, 5, 5],"int64"), weight=None, ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5],"float64"), Tensor([5, 5, 5],"int64"), weight=None, ignore_index=-100, reduction="sum", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5],"float64"), Tensor([5, 5, 5],"int64"), weight=Tensor([3],"float64"), ignore_index=-100, reduction="mean", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3, 5, 5],"float64"), Tensor([5, 5, 5],"int64"), weight=Tensor([3],"float64"), ignore_index=-100, reduction="sum", name=None, )
paddle.nn.functional.nll_loss(Tensor([5, 3],"float32"), Tensor([5],"int64"), )
paddle.nn.functional.pad(Tensor([1, 1, 1, 1],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 1, 1],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 10, 10],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 100, 100],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 100, 100],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 101, 101],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 101, 101],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 102, 102],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 102, 102],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 103, 103],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 103, 103],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 104, 104],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 104, 104],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 105, 105],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 106, 106],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 106, 106],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 107, 107],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 108, 108],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 108, 108],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 109, 109],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 109, 109],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 11, 11],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 110, 110],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 110, 110],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 111, 111],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 111, 111],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 112, 112],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 112, 112],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 113, 113],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 113, 113],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 114, 114],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 114, 114],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 115, 115],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 115, 115],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 116, 116],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 116, 116],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 117, 117],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 117, 117],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 118, 118],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 118, 118],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 119, 119],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 119, 119],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 12, 12],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 120, 120],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 120, 120],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 121, 121],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 121, 121],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 122, 122],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 123, 123],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 123, 123],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 124, 124],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 124, 124],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 125, 125],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 125, 125],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 126, 126],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 126, 126],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 127, 127],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 127, 127],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 128, 128],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 128, 128],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 128, 224],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 129, 129],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 129, 129],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 13, 13],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 130, 130],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 130, 130],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 131, 131],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 132, 132],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 133, 133],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 133, 133],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 134, 134],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 134, 134],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 135, 135],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 135, 135],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 136, 136],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 137, 137],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 138, 138],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 138, 138],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 139, 139],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 139, 139],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 14, 14],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 140, 140],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 140, 140],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 141, 141],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 141, 141],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 142, 142],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 142, 142],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 143, 143],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 144, 144],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 144, 144],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 145, 145],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 146, 146],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 147, 147],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 147, 147],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 148, 148],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 149, 149],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 149, 149],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 15, 15],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 150, 150],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 150, 150],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 151, 151],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 151, 151],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 152, 152],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 153, 153],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 154, 154],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 154, 154],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 155, 155],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 155, 155],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 156, 156],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 157, 157],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 158, 158],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 158, 158],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 159, 159],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 16, 16],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 160, 160],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 160, 416],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 161, 161],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 162, 162],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 162, 162],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 163, 163],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 163, 163],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 164, 164],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 164, 164],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 165, 165],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 165, 165],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 166, 166],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 167, 167],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 168, 168],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 169, 169],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 169, 169],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 17, 17],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 17, 17],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 170, 170],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 170, 170],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 171, 171],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 171, 171],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 172, 172],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 172, 172],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 173, 173],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 173, 173],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 174, 174],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 175, 175],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 175, 175],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 176, 176],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 176, 176],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 177, 177],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 178, 178],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 179, 179],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 18, 18],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 180, 180],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 181, 181],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 181, 181],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 182, 182],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 183, 183],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 183, 183],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 184, 184],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 185, 185],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 186, 186],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 187, 187],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 187, 187],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 188, 188],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 189, 189],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 189, 189],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 19, 19],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 19, 19],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 190, 190],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 190, 190],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 191, 191],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 191, 191],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 192, 192],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 192, 192],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 192, 512],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 193, 193],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 193, 193],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 194, 194],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 194, 194],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 195, 195],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 196, 196],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 197, 197],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 197, 197],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 198, 198],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 198, 198],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 199, 199],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 1],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2, 2],"int32"), pad=list[2,2,2,2,2,2,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2, 2],"int64"), pad=list[2,2,2,2,2,2,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2],"int32"), pad=list[2,2,2,2,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 2],"int64"), pad=list[2,2,2,2,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 20, 20],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 20, 20],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 200, 200],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 200, 200],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 201, 201],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 202, 202],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 203, 203],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 203, 203],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 204, 204],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 205, 205],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 206, 206],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 207, 207],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 207, 207],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 208, 208],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 209, 209],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 209, 209],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 21, 21],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 21, 21],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 210, 210],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 210, 210],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 211, 211],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 211, 211],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 212, 212],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 212, 212],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 213, 213],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 214, 214],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 215, 215],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 216, 216],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 217, 217],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 218, 218],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 219, 219],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 22, 22],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 220, 220],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 220, 220],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 221, 221],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 222, 222],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 222, 222],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 223, 223],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 224, 224],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 225, 225],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 226, 226],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 226, 226],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 227, 227],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 227, 227],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 228, 228],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 229, 229],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 23, 23],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 23, 23],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 230, 230],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 231, 231],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 232, 232],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 233, 233],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 234, 234],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 235, 235],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 236, 236],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 237, 237],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 238, 238],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 239, 239],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 24, 24],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 24, 24],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 240, 240],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 240, 240],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 241, 241],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 241, 241],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 242, 242],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 243, 243],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 243, 243],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 244, 244],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 245, 245],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 246, 246],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 247, 247],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 248, 248],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 249, 249],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 249, 249],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 25, 25],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 250, 250],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 251, 251],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 252, 252],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 253, 253],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 253, 253],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 254, 254],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 255, 255],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 256, 256],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 257, 257],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 258, 258],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 259, 259],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 26, 26],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 26, 26],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 260, 260],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 261, 261],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 262, 262],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 263, 263],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 264, 264],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 264, 264],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 265, 265],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 266, 266],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 267, 267],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 268, 268],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 268, 268],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 269, 269],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 27, 27],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 270, 270],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 270, 270],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 271, 271],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 272, 272],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 273, 273],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 274, 274],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 274, 274],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 275, 275],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 276, 276],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 276, 276],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 277, 277],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 277, 277],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 278, 278],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 279, 279],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 28, 28],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 28, 28],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 280, 280],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 281, 281],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 282, 282],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 283, 283],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 284, 284],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 285, 285],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 286, 286],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 287, 287],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 288, 288],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 289, 289],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 29, 29],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 29, 29],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 290, 290],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 291, 291],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 292, 292],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 293, 293],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 293, 293],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 298, 298],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 3, 2],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 3, 3],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 30, 30],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 30, 30],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 302, 302],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 307, 307],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 31, 31],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 31, 31],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 32],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 32],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 512],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 544],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 576],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 32, 672],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 33, 33],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 33, 33],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 336, 336],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 339, 339],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 34, 34],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 34, 34],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 35, 35],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 35, 35],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 355, 355],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 36, 36],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 36, 36],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 369, 369],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 37, 37],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 38, 38],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 39, 39],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 39, 39],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 4, 4],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 40, 40],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 41, 41],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 42, 42],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 42, 42],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 43, 43],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 43, 43],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 44, 44],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 44, 44],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 45, 45],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 457, 457],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 46, 46],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 46, 46],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 47, 47],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 47, 47],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 477, 477],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 48, 48],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 48, 48],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 49, 49],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 49, 49],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 498, 498],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 5, 5],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 50, 50],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 50, 50],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 51, 51],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 52, 52],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 52, 52],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 53, 53],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 53, 53],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 54, 54],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 54, 54],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 55, 55],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 55, 55],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 56, 56],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 56, 56],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 57, 57],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 57, 57],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 58, 58],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 59, 59],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 59, 59],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 6, 6],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 60, 60],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 61, 61],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 61, 61],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 62, 62],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 62, 62],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 63, 63],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 63, 63],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 64, 64],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 64, 64],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 65, 65],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 66, 66],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 66, 66],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 67, 67],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 67, 67],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 68, 68],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 68, 68],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 69, 69],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 69, 69],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 7, 7],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 70, 70],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 70, 70],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 71, 71],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 71, 71],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 72, 72],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 72, 72],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 73, 73],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 73, 73],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 74, 74],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 74, 74],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 75, 75],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 75, 75],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 76, 76],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 76, 76],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 77, 77],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 77, 77],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 78, 78],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 78, 78],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 79, 79],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 79, 79],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 8, 8],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 80, 80],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 80, 80],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 81, 81],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 81, 81],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 82, 82],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 82, 82],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 83, 83],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 83, 83],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 84, 84],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 84, 84],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 85, 85],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 85, 85],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 86, 86],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 86, 86],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 87, 87],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 87, 87],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 88, 88],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 88, 88],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 89, 89],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 9, 9],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 90, 90],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 90, 90],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 91, 91],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 91, 91],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 92, 92],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 92, 92],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 93, 93],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 93, 93],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 94, 94],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 94, 94],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 95, 95],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 95, 95],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 256],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 288],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 384],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 416],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 448],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 576],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 608],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 640],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 96],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 96, 96],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 97, 97],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 97, 97],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 98, 98],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 98, 98],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 99, 99],"int32"), Tensor([4],"int32"), value=False, )
paddle.nn.functional.pad(Tensor([1, 1, 99, 99],"int32"), tuple(0,0,0,0,), value=False, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 104],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 112],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 144],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 152],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 40],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 72],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 24, 96],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 32, 56],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 40, 104],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 48, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 8, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 8, 136],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 8, 144],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 128, 8, 168],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int32"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int32"), pad=list[1,2,], mode="reflect", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int32"), pad=list[1,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int32"), pad=list[2,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int64"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int64"), pad=list[1,2,], mode="reflect", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int64"), pad=list[1,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3],"int64"), pad=list[2,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 20],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 32],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 36],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 48],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 52],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 56],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 72],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 76],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 12, 80],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 16, 28],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 20, 52],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 24, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 4, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 4, 68],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 4, 72],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 256, 4, 84],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([1, 6, 6, 3],"float32"), Tensor([4],"int32"), data_format="NHWC", )
paddle.nn.functional.pad(Tensor([1, 64, 16, 256],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 16, 272],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 16, 288],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 16, 336],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 128],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 144],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 192],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 208],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 224],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 288],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 304],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 320],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 48, 80],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 64, 112],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 80, 208],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1, 64, 96, 256],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 192],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 224],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 256],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 288],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 320],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 384],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 32, 96],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 192],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 224],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 256],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 288],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 320],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 352],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 384],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 416],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 512],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([10, 1, 64, 544],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([14, 1, 10, 7],"int64"), pad=list[0,3,0,0,], mode="constant", value=0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([14, 1, 7, 7],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([14, 1, 7, 7],"int64"), pad=list[0,0,0,3,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([14, 1, 8, 7],"int64"), pad=list[0,1,0,0,], mode="constant", value=0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 3, 3],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 32, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 32, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 32, 640],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 4, 4],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 224],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 320],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 512],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 64],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 64, 640],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 96, 224],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 96, 320],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 1, 96, 480],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 16, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 16, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 16, 40],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 16, 56],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 16, 80],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 24, 120],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 24, 56],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 24, 80],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 8, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 128, 8, 32],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex128"), pad=Tensor([4],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex128"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex128"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NHWC", )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex64"), pad=Tensor([4],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex64"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"complex64"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NHWC", )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"float32"), pad=Tensor([4],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"float32"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 3, 4, 5],"float32"), pad=Tensor([4],"int32"), mode="constant", value=100, data_format="NHWC", )
paddle.nn.functional.pad(Tensor([2, 64, 16, 32],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 16, 320],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 16, 64],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 112],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 160],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 256],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 32],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 320],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 32, 80],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 48, 112],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 48, 160],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([2, 64, 48, 240],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([3, 1, 32, 160],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([3, 1, 64, 32],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([3, 1, 64, 416],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([3, 1, 64, 672],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"complex128"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"complex128"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NDHWC", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"complex64"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"complex64"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NDHWC", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"float32"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 7],"float32"), pad=Tensor([6],"int64"), mode="reflect", value=0.0, data_format="NDHWC", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex128"), pad=Tensor([2],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex128"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NCL", )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex128"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NLC", )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex64"), pad=Tensor([2],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex64"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NCL", )
paddle.nn.functional.pad(Tensor([3, 4, 5],"complex64"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NLC", )
paddle.nn.functional.pad(Tensor([3, 4, 5],"float32"), pad=Tensor([2],"int32"), mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([3, 4, 5],"float32"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NCL", )
paddle.nn.functional.pad(Tensor([3, 4, 5],"float32"), pad=Tensor([2],"int32"), mode="constant", value=100, data_format="NLC", )
paddle.nn.functional.pad(Tensor([3, 64, 16, 80],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([3, 64, 32, 16],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([3, 64, 32, 208],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([3, 64, 32, 336],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 1, 3, 3],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 32, 288],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 1, 32, 32],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 1, 32, 480],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 1, 32, 608],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 1, 32, 96],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 4, 4],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 1, 64, 96],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([4, 3, 224, 224],"int64"), pad=list[2,2,4,1,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 6],"int32"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 6],"int64"), pad=list[1,2,3,4,5,6,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 6],"int64"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 6],"int64"), pad=Tensor([6],"int32"), mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 6],"int64"), pad=tuple(1,2,3,4,5,6,), mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 6],"int32"), pad=list[2,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 6],"int64"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 6],"int64"), pad=list[2,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 6],"int64"), pad=Tensor([2],"int32"), mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 6],"int64"), pad=tuple(1,2,), mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 64, 16, 144],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 64, 16, 240],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 64, 16, 304],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 64, 16, 48],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 64, 32, 48],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([5, 1, 64, 128],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([5, 1, 64, 256],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([5, 1, 64, 576],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([6, 1, 3, 3],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 32, 192],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([6, 1, 32, 352],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([6, 1, 32, 448],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([6, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 4, 3],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 4, 4],"int64"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 5, 4],"int64"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([6, 1, 64, 384],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([7, 1, 64, 192],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([7, 1, 64, 608],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([8, 1, 32, 256],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([8, 1, 64, 448],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([8, 1, 64, 480],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([9, 1, 32, 416],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([9, 1, 64, 352],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.poisson_nll_loss(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), log_input=True, full=False, epsilon=1e-08, reduction="mean", )
paddle.nn.functional.poisson_nll_loss(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), log_input=True, full=False, epsilon=1e-08, reduction="mean", name=None, )
paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, fastemit_lambda=0.0, reduction="none", name=None, )
paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, reduction="mean", fastemit_lambda=0.0, )
paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, reduction="sum", fastemit_lambda=0.0, )
paddle.nn.functional.sequence_mask(Tensor([0],"int64"), )
paddle.nn.functional.sequence_mask(Tensor([3],"float32"), dtype=type(numpy.float64), )
paddle.nn.functional.sequence_mask(Tensor([3],"int64"), )
paddle.nn.functional.sequence_mask(Tensor([3],"int64"), dtype=type(numpy.float64), )
paddle.nn.functional.sequence_mask(Tensor([4],"int64"), None, "float64", None, )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([1, 10],"float32"), Tensor([1, 1],"int64"), )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([100, 10],"float32"), Tensor([100, 1],"int64"), )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 64],"float32"), Tensor([2, 1, 32, 64],"int64"), axis=1, )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 64],"float32"), Tensor([2, 16, 1, 64],"int64"), axis=2, )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 64],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=-1, )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 64],"float32"), Tensor([2, 16, 32, 1],"int64"), axis=3, )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16],"float32"), Tensor([2, 1],"int64"), )
paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16],"float32"), Tensor([2, 1],"int64"), return_softmax=True, )
paddle.normal(0.0, 1.0, list[Tensor([],"int32"),Tensor([],"int32"),Tensor([],"int32"),], )
paddle.repeat_interleave(Tensor([],"float32"), Tensor([],"int64"), None, )
paddle.repeat_interleave(Tensor([],"float32"), Tensor([1],"int32"), None, )
paddle.repeat_interleave(Tensor([10, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(Tensor([12, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(Tensor([16, 16],"float32"), repeats=2, axis=Tensor([],"int32"), name=None, )
paddle.repeat_interleave(Tensor([2, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(Tensor([2, 3],"bfloat16"), Tensor([6],"int32"), None, )
paddle.repeat_interleave(Tensor([2, 3],"int32"), Tensor([6],"int32"), None, )
paddle.repeat_interleave(Tensor([24, 16],"float32"), repeats=2, axis=Tensor([],"int32"), name=None, )
paddle.repeat_interleave(Tensor([3, 4],"float32"), Tensor([3],"int32"), axis=0, )
paddle.repeat_interleave(Tensor([3, 4],"float32"), Tensor([4],"int32"), 1, )
paddle.repeat_interleave(Tensor([3, 4],"float32"), Tensor([4],"int32"), -1, )
paddle.repeat_interleave(Tensor([4, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(Tensor([6, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(Tensor([8, 1],"int64"), Tensor([],"int64"), axis=1, )
paddle.repeat_interleave(x=Tensor([4, 2, 4, 4, 5],"int32"), repeats=Tensor([2],"int32"), axis=1, )
paddle.roll(Tensor([0, 3],"float32"), shifts=1, )
paddle.roll(Tensor([0, 3],"float32"), shifts=1, axis=0, )
paddle.roll(Tensor([3, 3],"bool"), shifts=1, )
paddle.roll(Tensor([3, 3],"bool"), shifts=1, axis=0, )
paddle.roll(Tensor([4, 0, 3],"float32"), shifts=1, )
paddle.roll(Tensor([4, 0, 3],"float32"), shifts=1, axis=0, )
paddle.shard_index(input=Tensor([2, 1],"int64"), index_num=20, nshards=2, shard_id=1, )
paddle.shard_index(input=Tensor([2, 1],"int64"), index_num=6, nshards=40, shard_id=4, )
paddle.shard_index(input=Tensor([4, 1],"int64"), index_num=13, nshards=3, shard_id=0, )
paddle.shard_index(input=Tensor([4, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, )
paddle.shard_index(input=Tensor([4, 2, 1],"int64"), index_num=20, nshards=4, shard_id=1, ignore_value=16, )
paddle.signal.istft(Tensor([257, 471],"complex128"), 512, None, None, Tensor([512],"float64"), True, False, True, None, False, )
paddle.slice(Tensor([0, 2],"int64"), axes=list[1,], starts=list[0,], ends=list[1,], )
paddle.slice(Tensor([0, 2],"int64"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([0],"float32"), axes=list[0,], starts=list[0,], ends=list[0,], )
paddle.slice(Tensor([4, 3, 6],"int64"), axes=list[2,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 3, 6],"int64"), axes=list[2,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([4, 6, 3],"int64"), axes=list[1,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 6, 3],"int64"), axes=list[1,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([4, 6],"int64"), axes=list[1,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([4, 6],"int64"), axes=list[1,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6, 4, 3],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6, 4, 3],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6, 4],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6, 4],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([6],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([6],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[16,], ends=list[16,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[2,], ends=list[2,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[5,], ends=list[5,], )
paddle.slice(Tensor([7],"int64"), axes=list[0,], starts=list[6,], ends=list[6,], )
paddle.take_along_axis(Tensor([1, 36828, 4],"float32"), Tensor([1, 900, 4],"int64"), 1, )
paddle.take_along_axis(Tensor([1, 38367, 4],"float32"), Tensor([1, 900, 4],"int64"), 1, )
paddle.take_along_axis(Tensor([1, 6380, 4],"float32"), Tensor([1, 300, 4],"int64"), axis=1, )
paddle.take_along_axis(Tensor([1, 8550, 4],"float32"), Tensor([1, 300, 4],"int64"), axis=1, )
paddle.take_along_axis(Tensor([1],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([1024],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([1184],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([128, 8],"float32"), Tensor([128, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([16384],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([168],"float64"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([2, 2],"float32"), Tensor([4, 2],"float32"), 0, )
paddle.take_along_axis(Tensor([2, 2],"float32"), Tensor([4, 2],"int64"), 0, )
paddle.take_along_axis(Tensor([2, 3, 4],"float64"), Tensor([1, 3, 4],"int32"), axis=0, )
paddle.take_along_axis(Tensor([2, 3],"float32"), Tensor([2, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([2, 3],"float64"), Tensor([1, 3],"int32"), axis=0, )
paddle.take_along_axis(Tensor([20],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([2160],"float64"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([28, 5],"float32"), Tensor([28, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([3, 2, 5],"float32"), Tensor([1, 1, 3],"int64"), axis=-1, )
paddle.take_along_axis(Tensor([3, 3, 3],"float32"), Tensor([1, 3, 3],"int32"), axis=0, )
paddle.take_along_axis(Tensor([3, 3, 3],"float64"), Tensor([1, 3, 3],"int32"), axis=0, )
paddle.take_along_axis(Tensor([3, 3],"float32"), Tensor([1, 3],"float32"), 0, )
paddle.take_along_axis(Tensor([3, 3],"float32"), Tensor([1, 3],"int64"), 0, )
paddle.take_along_axis(Tensor([3, 3],"float32"), Tensor([1, 3],"int64"), 0, False, )
paddle.take_along_axis(Tensor([3, 5],"float32"), Tensor([1, 3],"int64"), axis=-1, )
paddle.take_along_axis(Tensor([3, 5],"float32"), Tensor([3, 2],"int64"), axis=-1, )
paddle.take_along_axis(Tensor([3, 5],"float64"), Tensor([1, 3],"int64"), axis=-1, )
paddle.take_along_axis(Tensor([3, 6, 3, 4, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"int32"), axis=3, )
paddle.take_along_axis(Tensor([3, 6, 3, 4, 2, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"int32"), axis=4, )
paddle.take_along_axis(Tensor([3, 6, 3, 4, 2, 5],"float64"), Tensor([3, 6, 3, 4, 2, 1],"int32"), axis=5, )
paddle.take_along_axis(Tensor([3],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([30, 5],"float32"), Tensor([30, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([32],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([35968],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([37],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([38, 5],"float32"), Tensor([38, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([4, 2],"float32"), Tensor([4, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([4, 2],"float64"), Tensor([1, 1],"int64"), 1, )
paddle.take_along_axis(Tensor([4, 3, 2],"float32"), Tensor([1, 3, 2],"int64"), axis=1, )
paddle.take_along_axis(Tensor([4, 3],"float32"), Tensor([4, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([4, 4, 4, 2],"float64"), Tensor([1, 1, 1, 1],"int64"), 0, )
paddle.take_along_axis(Tensor([4, 4, 4],"float64"), Tensor([1, 1, 1],"int64"), 0, )
paddle.take_along_axis(Tensor([4, 4],"float64"), Tensor([1, 1],"int64"), 0, )
paddle.take_along_axis(Tensor([4, 42],"float64"), Tensor([4, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([4, 7, 6],"float64"), Tensor([4, 1, 6],"int32"), axis=1, )
paddle.take_along_axis(Tensor([4, 7, 6],"float64"), Tensor([4, 7, 1],"int32"), axis=2, )
paddle.take_along_axis(Tensor([4, 7],"float32"), Tensor([4, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([4, 7],"float64"), Tensor([4, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([4],"float32"), Tensor([1],"int64"), 0, )
paddle.take_along_axis(Tensor([4],"float64"), Tensor([1],"int64"), 0, )
paddle.take_along_axis(Tensor([5, 12],"float64"), Tensor([5, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([5, 2],"float32"), Tensor([5, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([5, 3, 4],"float64"), Tensor([5, 1, 4],"int32"), axis=1, )
paddle.take_along_axis(Tensor([512],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([6],"float32"), Tensor([1],"int32"), axis=0, )
paddle.take_along_axis(Tensor([7, 24],"float64"), Tensor([7, 1],"int32"), axis=1, )
paddle.take_along_axis(Tensor([8, 3],"float32"), Tensor([8, 1],"int64"), axis=1, )
paddle.take_along_axis(Tensor([8],"float32"), Tensor([1],"int32"), axis=0, )
paddle.Tensor.__mul__(Tensor([1, 1024, 128],"bfloat16"), Tensor([128],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([1, 1024, 1, 16],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 1, 128],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 4096],"bfloat16"), Tensor([4096],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 768],"bfloat16"), Tensor([768],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 1, 16],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 8, 96],"bfloat16"), Tensor([1, 1024, 1, 96],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 114, 64],"bfloat16"), Tensor([64],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 302, 768],"bfloat16"), Tensor([768],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 302, 8, 96],"bfloat16"), Tensor([2, 302, 1, 96],"bfloat16"), )
paddle.Tensor.matmul(Tensor([0, 1],"float32"), Tensor([1, 0],"float32"), )
paddle.Tensor.matmul(Tensor([0, 1],"float64"), Tensor([1, 0],"float64"), )
paddle.Tensor.matmul(Tensor([125, 1],"float32"), Tensor([1, 0],"float32"), )
paddle.tensordot(Tensor([0, 0, 5, 5],"float32"), Tensor([0, 0, 5, 5],"float32"), list[list[],list[],], )
paddle.tensordot(Tensor([0, 5, 5, 5],"float64"), Tensor([0, 5, 5, 5],"float64"), list[list[],list[],], )
paddle.tensordot(Tensor([1, 5, 5, 5],"float32"), Tensor([0, 5, 5, 5],"float32"), list[list[],list[],], )
paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), list[Tensor([2],"int64"),Tensor([2],"int64"),], )
paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), Tensor([1],"int64"), )
paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), Tensor([2, 2],"int64"), )
paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), tuple(Tensor([2],"int64"),Tensor([2],"int64"),), )
paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 5],"float64"), list[Tensor([2],"int64"),Tensor([2],"int64"),], )
paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 5],"float64"), Tensor([1],"int64"), )
paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 5],"float64"), Tensor([2, 2],"int64"), )
paddle.tensordot(Tensor([3, 4, 4],"float64"), Tensor([4, 4, 5],"float64"), tuple(Tensor([2],"int64"),Tensor([2],"int64"),), )
paddle.tensordot(Tensor([5, 0, 5, 0],"float32"), Tensor([5, 0, 5, 0],"float32"), list[list[],list[],], )
paddle.tensordot(Tensor([5, 5, 0, 5],"float32"), Tensor([5, 5, 0, 5],"float32"), list[list[],list[],], )
paddle.tensordot(Tensor([5, 5, 5, 0],"float32"), Tensor([5, 5, 5, 0],"float32"), list[list[],list[],], )
paddle.tile(Tensor([1, 4],"float32"), list[Tensor([],"int64"),1,], )
paddle.tile(Tensor([1, 8],"float32"), list[Tensor([],"int64"),1,], )
paddle.tile(x=Tensor([3],"int64"), repeat_times=Tensor([2],"int32"), )
paddle.view(Tensor([10, 10, 10, 20],"float32"), "uint8", )
paddle.view(Tensor([10, 10, 10, 20],"float32"), Dtype(uint8), )
paddle.vision.ops.decode_jpeg(Tensor([142887],"uint8"), )
paddle.vision.ops.decode_jpeg(Tensor([142887],"uint8"), mode="gray", )
paddle.vision.ops.decode_jpeg(Tensor([142887],"uint8"), mode="rgb", )
paddle.vision.ops.deform_conv2d(x=Tensor([12, 512, 10, 10],"float16"), offset=Tensor([12, 18, 10, 10],"float16"), weight=Tensor([512, 512, 3, 3],"float16"), bias=None, stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([12, 9, 10, 10],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([12, 512, 20, 20],"float16"), offset=Tensor([12, 18, 10, 10],"float16"), weight=Tensor([512, 512, 3, 3],"float16"), bias=None, stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([12, 9, 10, 10],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([20, 128, 76, 136],"float16"), offset=Tensor([20, 18, 76, 136],"float16"), weight=Tensor([64, 128, 3, 3],"float16"), bias=Tensor([64],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([20, 9, 76, 136],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([20, 256, 38, 68],"float16"), offset=Tensor([20, 18, 38, 68],"float16"), weight=Tensor([128, 256, 3, 3],"float16"), bias=Tensor([128],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([20, 9, 38, 68],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([20, 512, 19, 34],"float16"), offset=Tensor([20, 18, 19, 34],"float16"), weight=Tensor([256, 512, 3, 3],"float16"), bias=Tensor([256],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([20, 9, 19, 34],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 128, 100, 100],"float16"), offset=Tensor([6, 36, 100, 100],"float16"), weight=Tensor([128, 128, 3, 3],"float16"), bias=None, stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 100, 100],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 128, 200, 200],"float16"), offset=Tensor([6, 36, 100, 100],"float16"), weight=Tensor([128, 128, 3, 3],"float16"), bias=None, stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 100, 100],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 256, 100, 100],"float16"), offset=Tensor([6, 36, 50, 50],"float16"), weight=Tensor([256, 256, 3, 3],"float16"), bias=None, stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 50, 50],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 256, 50, 50],"float16"), offset=Tensor([6, 36, 50, 50],"float16"), weight=Tensor([256, 256, 3, 3],"float16"), bias=None, stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 50, 50],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 512, 25, 25],"float16"), offset=Tensor([6, 36, 25, 25],"float16"), weight=Tensor([512, 512, 3, 3],"float16"), bias=None, stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 25, 25],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 512, 50, 50],"float16"), offset=Tensor([6, 36, 25, 25],"float16"), weight=Tensor([512, 512, 3, 3],"float16"), bias=None, stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 25, 25],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([64, 64, 16, 16],"float16"), offset=Tensor([64, 144, 16, 16],"float16"), weight=Tensor([64, 64, 3, 3],"float16"), bias=Tensor([64],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=8, groups=1, mask=Tensor([64, 72, 16, 16],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([64, 64, 32, 32],"float16"), offset=Tensor([64, 144, 32, 32],"float16"), weight=Tensor([64, 64, 3, 3],"float16"), bias=Tensor([64],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=8, groups=1, mask=Tensor([64, 72, 32, 32],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([64, 64, 64, 64],"float16"), offset=Tensor([64, 144, 64, 64],"float16"), weight=Tensor([64, 64, 3, 3],"float16"), bias=Tensor([64],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=8, groups=1, mask=Tensor([64, 72, 64, 64],"float16"), )
paddle.vision.ops.distribute_fpn_proposals(fpn_rois=Tensor([10, 4],"float32"), min_level=2, max_level=5, refer_level=4, refer_scale=224, rois_num=Tensor([2],"int32"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([1, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([10, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([1024, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([2],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([106, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([11, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([110, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([113, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([116, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([117, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([119, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([12, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([122, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([123, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([124, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([125, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([126, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([127, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([128, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([129, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([13, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([130, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([131, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([132, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([133, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([134, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([135, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([136, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([137, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([138, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([139, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([14, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([141, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([142, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([143, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([144, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([145, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([147, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([148, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([149, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([15, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([150, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([151, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([152, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([153, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([154, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([155, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([157, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([158, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([159, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([16, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([160, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([161, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([162, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([163, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([164, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([165, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([166, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([167, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([168, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([169, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([17, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([171, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([172, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([173, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([174, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([175, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([176, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([177, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([178, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([179, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([18, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([180, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([181, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([182, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([183, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([184, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([186, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([187, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([188, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([189, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([19, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([190, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([191, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([192, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([193, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([194, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([195, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([196, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([197, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([198, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([199, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([2, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([20, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([200, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([201, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([202, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([203, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([204, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([2048, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([205, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([206, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([207, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([208, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([209, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([21, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([210, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([212, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([213, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([214, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([215, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([216, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([217, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([218, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([219, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([220, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([221, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([222, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([223, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([224, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([225, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([226, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([227, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([228, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([229, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([230, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([231, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([232, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([233, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([234, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([235, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([236, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([237, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([238, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([239, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([24, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([240, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([241, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([242, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([243, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([244, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([245, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([246, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([247, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([248, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([249, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([25, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([250, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([251, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([252, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([253, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([254, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([255, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([256, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([257, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([258, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([259, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([26, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([260, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([261, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([262, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([263, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([264, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([265, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([266, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([267, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([268, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([269, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([270, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([271, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([272, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([273, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([274, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([275, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([276, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([277, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([278, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([279, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([280, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([281, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([282, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([283, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([284, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([285, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([286, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([287, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([288, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([289, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([290, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([291, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([292, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([293, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([294, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([295, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([296, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([297, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([298, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([299, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([3, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([300, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([301, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([302, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([303, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([304, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([305, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([306, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([307, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([308, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([309, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([310, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([311, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([312, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([313, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([314, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([315, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([316, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([317, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([318, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([319, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([320, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([321, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([322, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([323, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([324, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([325, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([326, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([327, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([328, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([329, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([330, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([331, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([332, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([333, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([334, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([335, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([336, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([337, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([338, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([339, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([340, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([341, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([342, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([343, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([344, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([345, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([346, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([347, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([348, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([349, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([350, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([351, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([352, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([353, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([354, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([355, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([356, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([357, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([358, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([359, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([360, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([362, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([364, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([365, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([366, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([367, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([368, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([369, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([371, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([372, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([374, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([375, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([376, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([377, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([378, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([379, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([380, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([381, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([382, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([383, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([384, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([385, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([386, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([387, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([388, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([389, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([392, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([393, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([394, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([395, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([396, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([397, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([398, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([399, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([400, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([401, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([402, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([403, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([405, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([406, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([407, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([408, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([409, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([411, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([413, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([414, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([415, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([416, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([417, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([418, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([419, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([420, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([421, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([422, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([423, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([424, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([425, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([426, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([427, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([428, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([429, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([431, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([432, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([433, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([434, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([435, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([436, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([437, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([439, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([440, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([441, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([444, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([445, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([448, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([449, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([450, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([451, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([452, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([454, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([455, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([457, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([461, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([463, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([464, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([467, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([469, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([470, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([472, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([473, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([474, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([476, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([478, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([483, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([484, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([486, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([494, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([495, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([499, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([502, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([504, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([505, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([510, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([511, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([512, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([512, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([512, 4],"float32"), 2, 6, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([8, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([80, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([9, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([1],"int64"), )
paddle.vision.ops.distribute_fpn_proposals(Tensor([97, 4],"float32"), 2, 5, 4, 224, rois_num=Tensor([4],"int64"), )
paddle.vision.ops.generate_proposals(Tensor([1, 3, 96, 168],"float16"), Tensor([1, 12, 96, 168],"float16"), Tensor([1, 2],"float32"), Tensor([48384, 4],"float32"), Tensor([48384, 4],"float32"), pre_nms_top_n=2000, post_nms_top_n=2000, nms_thresh=0.7, min_size=0.0, eta=1.0, return_rois_num=True, )
paddle.vision.ops.nms(Tensor([64, 4],"float32"), 0.5, Tensor([64],"float32"), Tensor([64],"int64"), list[0,1,2,3,], 20, )
paddle.vision.ops.psroi_pool(Tensor([2, 128, 32, 32],"float32"), Tensor([4, 4],"float32"), Tensor([2],"int32"), 8, 1.1, )
paddle.vision.ops.psroi_pool(Tensor([2, 128, 32, 32],"float64"), Tensor([4, 4],"float64"), Tensor([2],"int32"), 8, 1.1, )
paddle.vision.ops.psroi_pool(Tensor([2, 490, 28, 28],"float32"), Tensor([3, 4],"float32"), Tensor([2],"int32"), 7, )
paddle.vision.ops.psroi_pool(Tensor([2, 490, 28, 28],"float32"), Tensor([3, 4],"float32"), Tensor([2],"int32"), tuple(7,7,), )
paddle.vision.ops.psroi_pool(Tensor([2, 490, 28, 28],"float64"), Tensor([3, 4],"float64"), Tensor([2],"int32"), tuple(7,7,), )
paddle.vision.ops.psroi_pool(Tensor([3, 12, 6, 4],"float64"), Tensor([6, 4],"float64"), Tensor([3],"int32"), tuple(2,2,), 0.25, )