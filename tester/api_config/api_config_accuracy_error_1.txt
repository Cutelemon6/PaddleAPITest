paddle.nn.functional.batch_norm(Tensor([2, 1, 2, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2, 4, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 4, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.gelu(Tensor([128, 96, 96, 768],"float32"), False, None, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 256],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([10, 1, 37, 293],"float32"), Tensor([64, 1, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([10, 1, 69, 357],"float32"), Tensor([64, 1, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([10, 1, 69, 517],"float32"), Tensor([64, 1, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([10, 1, 69, 549],"float32"), Tensor([64, 1, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([3, 1, 69, 421],"float32"), Tensor([64, 1, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([5, 1, 69, 581],"float32"), Tensor([64, 1, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([7, 1, 69, 613],"float32"), Tensor([64, 1, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([8, 1, 69, 453],"float32"), Tensor([64, 1, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([8, 1, 69, 485],"float32"), Tensor([64, 1, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([8, 128, 256, 256],"float32"), Tensor([128, 128, 3, 3],"float32"), bias=None, stride=1, padding=1, )
paddle.nn.functional.conv2d(Tensor([8, 3, 256, 256],"float32"), Tensor([128, 3, 1, 1],"float32"), bias=None, stride=1, padding=0, )
paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16, 16],"float16"), Tensor([2048, 128, 4, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
paddle.nn.functional.max_pool1d(Tensor([2, 3, 8],"float64"), 2, 1, list[1,1,], False, False, None, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 3, 8],"float64"), kernel_size=2, stride=1, padding=list[1,1,], )
paddle.nn.functional.max_pool2d(Tensor([1, 24, 368, 368],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 24, 384, 384],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 32, 368, 368],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 48, 288, 288],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 48, 320, 320],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 48, 352, 352],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([14, 32, 192, 192],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 32, 320, 320],"float16"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 32, 320, 320],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 12, 12],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 13, 13],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 14, 14],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 15, 15],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 16, 16],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 17, 17],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 18, 18],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 19, 19],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 20, 20],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 20, 20],"float16"), kernel_size=9, stride=1, padding=4, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 21, 21],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 22, 22],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 23, 23],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([16, 384, 24, 24],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 32, 240, 240],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 32, 272, 272],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 32, 320, 320],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 48, 320, 320],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([32, 32, 224, 224],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([32, 48, 112, 112],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([4, 48, 320, 320],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([64, 16, 112, 112],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([64, 16, 224, 224],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([64, 24, 112, 112],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([64, 32, 112, 112],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 192, 13, 13],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 192, 16, 16],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 192, 17, 17],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 192, 19, 19],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 192, 20, 20],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 192, 21, 21],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 192, 22, 22],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 192, 23, 23],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 192, 24, 24],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 32, 272, 272],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 48, 224, 224],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([8, 512, 20, 20],"float16"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], )
paddle.scale(Tensor([2, 1, 1, 2, 3],"float32"), scale=Tensor([],"float32"), )
paddle.scale(Tensor([2, 1, 1, 2, 3],"float64"), scale=Tensor([],"float32"), )
paddle.scale(Tensor([2, 1, 2, 3],"float32"), scale=Tensor([],"float32"), )
paddle.scale(Tensor([2, 1, 2, 3],"float64"), scale=Tensor([],"float32"), )
paddle.scale(Tensor([2, 3, 4, 5, 6],"float32"), scale=Tensor([1],"float32"), )
paddle.cumprod(x=Tensor([3, 4],"int32"), dim=0, )
paddle.Tensor.set_(Tensor([3, 8],"float16"), Tensor([6, 3],"float16"), list[3,8,], list[2,2,], 0, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 512, 2, 2],"float32"), output_size=tuple(7,7,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([2, 3, 7, 7],"float32"), list[2,5,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([2, 3, 7, 7],"float32"), output_size=5, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([2, 3, 7, 7],"float32"), output_size=list[2,5,], data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(x=Tensor([2, 3, 7, 7],"float32"), output_size=5, )
paddle.nn.functional.adaptive_avg_pool2d(x=Tensor([2, 3, 7, 7],"float32"), output_size=list[2,5,], )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 7],"float32"), list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 7],"float32"), output_size=5, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 7],"float32"), output_size=5, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
paddle.incubate.softmax_mask_fuse(Tensor([1, 1, 8, 32],"float32"), Tensor([1, 1, 8, 32],"float32"), )
paddle.incubate.softmax_mask_fuse(x=Tensor([2, 8, 8, 1020],"float16"), mask=Tensor([2, 1, 8, 1020],"float16"), )
paddle.incubate.softmax_mask_fuse(x=Tensor([2, 8, 8, 32],"float16"), mask=Tensor([2, 1, 8, 32],"float16"), )
paddle.incubate.softmax_mask_fuse(x=Tensor([6, 8, 8, 32],"float16"), mask=Tensor([6, 1, 8, 32],"float16"), )
paddle.incubate.softmax_mask_fuse(x=Tensor([7, 3, 16, 32],"float16"), mask=Tensor([7, 1, 16, 32],"float16"), )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009313154732808471, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009654839523136616, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009928022045642138, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010831302497535944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010981468949466944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0014022786635905504, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.001479289960116148, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0016999575309455395, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009313154732808471, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009654839523136616, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009928022045642138, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010831302497535944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010981468949466944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0014022786635905504, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.001479289960116148, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0016999575309455395, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 10],"int32"), bias=Tensor([10],"float16"), dequant_scales=Tensor([10],"float32"), act_method="gelu", compute_dtype="fp16", )
paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 512],"int32"), bias=Tensor([512],"float16"), dequant_scales=Tensor([512],"float32"), shift=Tensor([256],"float16"), smooth=Tensor([256],"float16"), act_method="geglu", compute_dtype="fp16", quant_scale=0.5, quant_round_type=1, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 512],"int32"), bias=Tensor([512],"float16"), dequant_scales=Tensor([512],"float32"), shift=Tensor([512],"float16"), smooth=Tensor([512],"float16"), act_method="gelu", compute_dtype="fp16", quant_scale=0.5, quant_round_type=1, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 512],"int32"), bias=Tensor([512],"float32"), dequant_scales=Tensor([512],"float32"), shift=Tensor([512],"float32"), smooth=Tensor([512],"float32"), act_method="gelu", compute_dtype="fp32", quant_scale=0.5, quant_round_type=1, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([4, 12],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=True, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([32, 128, 768],"float16"), qkv_weight=Tensor([3, 12, 64, 768],"float16"), linear_weight=Tensor([768, 768],"float16"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float16"), linear_bias=Tensor([768],"float16"), cache_kv=None, attn_mask=Tensor([32, 1, 1, 128],"float16"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([32, 128, 768],"float32"), qkv_weight=Tensor([3, 12, 64, 768],"float32"), linear_weight=Tensor([768, 768],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float32"), linear_bias=Tensor([768],"float32"), cache_kv=None, attn_mask=Tensor([32, 1, 1, 128],"float32"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([64, 128, 768],"float16"), qkv_weight=Tensor([3, 12, 64, 768],"float16"), linear_weight=Tensor([768, 768],"float16"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float16"), linear_bias=Tensor([768],"float16"), cache_kv=None, attn_mask=Tensor([64, 1, 1, 128],"float16"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([64, 128, 768],"float32"), qkv_weight=Tensor([3, 12, 64, 768],"float32"), linear_weight=Tensor([768, 768],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float32"), linear_bias=Tensor([768],"float32"), cache_kv=None, attn_mask=Tensor([64, 1, 1, 128],"float32"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 16, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([256],"float32"), pre_ln_bias=Tensor([256],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([96, 128, 768],"float16"), qkv_weight=Tensor([3, 12, 64, 768],"float16"), linear_weight=Tensor([768, 768],"float16"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float16"), linear_bias=Tensor([768],"float16"), cache_kv=None, attn_mask=Tensor([96, 1, 1, 128],"float16"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([96, 128, 768],"float32"), qkv_weight=Tensor([3, 12, 64, 768],"float32"), linear_weight=Tensor([768, 768],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([768],"float32"), ln_bias=Tensor([768],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 12, 64],"float32"), linear_bias=Tensor([768],"float32"), cache_kv=None, attn_mask=Tensor([96, 1, 1, 128],"float32"), dropout_rate=0.1, attn_dropout_rate=0.1, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=12, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), None, Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), None, Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), None, Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), None, Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), None, Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), None, Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), None, Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([2, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 1, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 2, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([2, 8],"int64"), use_neox_rotary_style=True, time_major=True, )
